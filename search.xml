<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/ji-yu-llama.cpp-de-mo-xing-zhuan-huan-wei-gguf-ge-shi-ollama-bu-shu-open-webui-bu-shu/"/>
      <url>/ji-yu-llama.cpp-de-mo-xing-zhuan-huan-wei-gguf-ge-shi-ollama-bu-shu-open-webui-bu-shu/</url>
      
        <content type="html"><![CDATA[<h1 id="一、将-huggingface-转换为-GGUF-模型"><a href="#一、将-huggingface-转换为-GGUF-模型" class="headerlink" title="一、将 huggingface 转换为 GGUF 模型"></a>一、将 huggingface 转换为 GGUF 模型</h1><h2 id="1-1-创建虚拟环境"><a href="#1-1-创建虚拟环境" class="headerlink" title="1.1 创建虚拟环境"></a>1.1 创建虚拟环境</h2><p>我们新建一个名叫llama.cpp的python虚拟环境</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建虚拟环境</span>conda create <span class="token parameter variable">-n</span> llama.cpp <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.10</span><span class="token comment"># 切换环境</span>conda activate llama.cpp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="1-2-下载-llama-cpp仓库"><a href="#1-2-下载-llama-cpp仓库" class="headerlink" title="1.2 下载 llama. cpp仓库"></a>1.2 下载 llama. cpp仓库</h2><p>在llama.cpp虚拟环境下</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 克隆仓库到本地</span><span class="token function">git</span> clone https://github.com/ggerganov/llama.cpp.git<span class="token comment"># 安装依赖</span>pip <span class="token function">install</span> <span class="token parameter variable">-r</span> llama.cpp/requirements.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="1-3-转换模型"><a href="#1-3-转换模型" class="headerlink" title="1.3 转换模型"></a>1.3 转换模型</h2><p>执行下列命令，其中<code>/home/moyuai/moyuai/llm/Qwen/Qwen1-5-4B-Chat-train</code>为自己本地的模型路径，<code>Qwen1-5-4B-Chat-train-gguf.gguf</code>是我们转换后设置的模型名字。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 不进行模型量化，保留模型效果</span>python llama.cpp/convert_hf_to_gguf.py /home/moyuai/moyuai/llm/Qwen/Qwen1-5-4B-Chat-train <span class="token parameter variable">--outtype</span> auto <span class="token parameter variable">--verbose</span> <span class="token parameter variable">--outfile</span> Qwen1-5-4B-Chat-train.gguf<span class="token comment"># 需要量化（加速模型但有损失效果），执行下面脚本</span>python llama.cpp/convert_hf_to_gguf.py /home/moyuai/moyuai/llm/Qwen/Qwen1-5-4B-Chat-train <span class="token parameter variable">--outtype</span> q8_0 <span class="token parameter variable">--verbose</span> <span class="token parameter variable">--outfile</span> /home/moyuai/moyuai/llm/GGUF/Qwen1-5-4B-Chat-train-q8.gguf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>脚本参数说明：<br>这里<code>--outtype</code>是输出类型，代表含义：</p><ul><li>q2_k：特定张量（Tensor）采用较高的精度设置，而其他的则保持基础级别。 </li><li>q3_k_l、q3_k_m、q3_k_s：这些变体在不同张量上使用不同级别的精度，从而达到性能和效率的平衡。 </li><li>q4_0：这是最初的量化方案，使用 4 位精度。 </li><li>q4_1 和 q4_k_m、q4_k_s：这些提供了不同程度的准确性和推理速度，适合需要平衡资源使用的场景。 </li><li>q5_0、q5_1、q5_k_m、q5_k_s：这些版本在保证更高准确度的同时，会使用更多的资源并且推理速度较 慢。</li><li>q6_k 和 q8_0：这些提供了最高的精度，但是因为高资源消耗和慢速度，可能不适合所有用户。</li><li>fp16 和 f32: 不量化，保留原始精度。<br>这里<code>--outfile</code>是输出文件名字和路径。</li></ul><h1 id="二、ollama本地部署调用模型"><a href="#二、ollama本地部署调用模型" class="headerlink" title="二、ollama本地部署调用模型"></a>二、ollama本地部署调用模型</h1><h2 id="2-1-安装ollama"><a href="#2-1-安装ollama" class="headerlink" title="2.1 安装ollama"></a>2.1 安装ollama</h2><p>执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-2-启动ollama服务"><a href="#2-2-启动ollama服务" class="headerlink" title="2.2 启动ollama服务"></a>2.2 启动ollama服务</h2><p>执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama serve<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-3-创建ModelFile"><a href="#2-3-创建ModelFile" class="headerlink" title="2.3 创建ModelFile"></a>2.3 创建ModelFile</h2><p>复制模型路径，创建名为“ModelFile”的meta文件，内容如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#GGUF文件路径 </span>FROM /home/moyuai/moyuai/llm/ollama-models/Qwen1-5-4B-Chat-train.gguf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="2-4-创建自定义模型"><a href="#2-4-创建自定义模型" class="headerlink" title="2.4 创建自定义模型"></a>2.4 创建自定义模型</h2><p> 使用ollama create命令创建自定义模型，<code>Qwen1-5-4B-Chat-train</code>是我们命名的ollama模型名字，<code>--file</code>后面跟的是我们创建的ModeIFile文件路径。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama create Qwen1-5-4B-Chat-train <span class="token parameter variable">--file</span> /home/moyuai/moyuai/ModeIFile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="2-5-运行模型"><a href="#2-5-运行模型" class="headerlink" title="2.5 运行模型"></a>2.5 运行模型</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama run Qwen1-5-4B-Chat-train<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其实这里运行后，我有测试过模型效果，发现非常差，所以就没放效果图。</p><h1 id="三、使用-Open-WebUI-部署模型"><a href="#三、使用-Open-WebUI-部署模型" class="headerlink" title="三、使用 Open WebUI 部署模型"></a>三、使用 Open WebUI 部署模型</h1><p>Open WebUI 是一个可扩展的、自托管的 AI 界面，可以适应您的工作流程，同时完全离线操作。<br>Open WebUI仓库： <a href="https://github.com/open-webui/open-webui">https://github.com/open-webui/open-webui</a><br>Open WebUI文档： <a href="https://docs.openwebui.com/">https://docs.openwebui.com/</a></p><h2 id="3-1-创建虚拟环境"><a href="#3-1-创建虚拟环境" class="headerlink" title="3.1 创建虚拟环境"></a>3.1 创建虚拟环境</h2><p>我们在选择虚拟环境时，必须选用python3.11 版本，因为openwebui有要求。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda create <span class="token parameter variable">-n</span> open-webui <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.11</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-2-安装所需依赖"><a href="#3-2-安装所需依赖" class="headerlink" title="3.2 安装所需依赖"></a>3.2 安装所需依赖</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda activate open-webui pip <span class="token function">install</span> <span class="token parameter variable">-U</span> open-webui torch transformers<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="3-3-运行ollama"><a href="#3-3-运行ollama" class="headerlink" title="3.3 运行ollama"></a>3.3 运行ollama</h2><p>ollama运行后会在本地端口暴露一个 openai API 服务，我们后面使用 open-webui 来连接就可以了。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama serve<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-4-启动open-webui"><a href="#3-4-启动open-webui" class="headerlink" title="3.4 启动open-webui"></a>3.4 启动open-webui</h2><p>运行 open-webui 由于 ollama 的运行导致原终端阻塞，因此要另外开一个新终端 。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda activate open-webui <span class="token builtin class-name">export</span> <span class="token assign-left variable">HF_ENDPOINT</span><span class="token operator">=</span>https://hf-mirror.com  <span class="token comment"># Hugging Face 镜像网站</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">ENABLE_OLLAMA_API</span><span class="token operator">=</span>True             <span class="token comment"># 访问ollama端口</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">OPENAI_API_BASE_URL</span><span class="token operator">=</span>http://127.0.0.1:11434/v1 <span class="token comment"># 导出ollama服务端口</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">DEFAULT_MODELS</span><span class="token operator">=</span><span class="token string">"/home/moyuai/moyuai/llm/Qwen/Qwen1___5-4B-Chat"</span>  <span class="token comment"># 加载默认模型</span>open-webui serve  <span class="token comment"># 启动服务</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启动open-webui后，就可以在浏览器弹出的界面中使用我们训练的大模型了。</p><h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="1-执行-python-llama-cpp-convert-hf-to-gguf-py-脚本时报错"><a href="#1-执行-python-llama-cpp-convert-hf-to-gguf-py-脚本时报错" class="headerlink" title="1.执行 python llama.cpp/convert_hf_to_gguf.py 脚本时报错"></a>1.执行 <code>python llama.cpp/convert_hf_to_gguf.py</code> 脚本时报错</h2><p>报错信息如下：</p><pre class="line-numbers language-none"><code class="language-none"># 完整命令python llama.cpp/convert_hf_to_gguf.py /home/moyuai/moyuai/llm/Qwen/Qwen1-5-4B-Chat-train  --outtype f16 --verbose --outfile Qwen1-5-4B-Chat-train-gguf.gguf# 报错信息usage: convert_hf_to_gguf.py [-h] [--vocab-only] [--outfile OUTFILE]                             [--outtype {f32,f16,bf16,q8_0,tq1_0,tq2_0,auto}]                             [--bigendian] [--use-temp-file] [--no-lazy]                             [--model-name MODEL_NAME] [--verbose]                             [--split-max-tensors SPLIT_MAX_TENSORS]                             [--split-max-size SPLIT_MAX_SIZE] [--dry-run]                             [--no-tensor-first-split] [--metadata METADATA]                             [--print-supported-models] [--remote] [--mmproj]                             [model]convert_hf_to_gguf.py: error: unrecognized arguments:  --outtype f16<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>解决方法：是由于命令中–outtype命令前多了一个空格导致的</p><hr><h2 id="2-ollama-serve启动报错"><a href="#2-ollama-serve启动报错" class="headerlink" title="2. ollama serve启动报错"></a>2. ollama serve启动报错</h2><pre class="line-numbers language-none"><code class="language-none"># 执行命令ollama serve# 报错信息Error: listen tcp 127.0.0.1:11434: bind: address already in use<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个错误表明 Ollama 尝试在&nbsp;<code>127.0.0.1:11434</code>&nbsp;上启动服务时，发现该端口已经被占用。网上查找有两个解决方法，我是用的原因二解决的：</p><h3 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h3><h4 id="1-检查端口占用"><a href="#1-检查端口占用" class="headerlink" title="1.&nbsp;检查端口占用"></a>1.&nbsp;<strong>检查端口占用</strong></h4><p>首先，确认&nbsp;<code>11434</code>&nbsp;端口是否被其他进程占用。</p><h5 id="Windows下检查端口占用"><a href="#Windows下检查端口占用" class="headerlink" title="Windows下检查端口占用"></a><strong>Windows下检查端口占用</strong></h5><p>打开命令提示符（CMD）或 PowerShell，运行以下命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">netstat</span> <span class="token parameter variable">-ano</span> <span class="token operator">|</span> findstr :11434<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>如果端口被占用，会显示类似以下内容：  <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">TCP    <span class="token number">127.0</span>.0.1:11434    <span class="token number">0.0</span>.0.0:0    LISTENING   <span class="token number">12345</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>  其中&nbsp;<code>12345</code>&nbsp;是占用该端口的进程 ID（PID）。</li></ul><h5 id="Linux-macOS-下检查端口占用"><a href="#Linux-macOS-下检查端口占用" class="headerlink" title="Linux/macOS 下检查端口占用"></a><strong>Linux/macOS 下检查端口占用</strong></h5><p>运行以下命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">lsof</span> <span class="token parameter variable">-i</span> :11434<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>如果端口被占用，会显示类似以下内容：  <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">   COMMAND PID  <span class="token environment constant">USER</span>    FD   TYPE  DEVICE   SIZE/OFF NODE NAMEollama  <span class="token number">172</span>  ollama  3u   IPv4  <span class="token number">4919680</span>  0t0      TCP  localhost:11434 <span class="token punctuation">(</span>LISTEN<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><hr><h4 id="2-终止占用端口的进程"><a href="#2-终止占用端口的进程" class="headerlink" title="2.&nbsp;终止占用端口的进程"></a>2.&nbsp;<strong>终止占用端口的进程</strong></h4><p>如果发现端口被占用，可以终止占用该端口的进程。</p><h5 id="Windows-下终止进程"><a href="#Windows-下终止进程" class="headerlink" title="Windows 下终止进程"></a><strong>Windows 下终止进程</strong></h5><ol><li>找到占用端口的进程 ID（PID）。</li><li>运行以下命令终止进程： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">taskkill /PID <span class="token number">12345</span> /F<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> 其中&nbsp;<code>12345</code>&nbsp;是进程 ID。</li></ol><h5 id="Linux-macOS-下终止进程"><a href="#Linux-macOS-下终止进程" class="headerlink" title="Linux/macOS 下终止进程"></a><strong>Linux/macOS 下终止进程</strong></h5><ol><li>找到占用端口的进程 ID（PID）。</li><li>运行以下命令终止进程： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">kill</span> <span class="token parameter variable">-9</span> <span class="token number">172</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> 其中&nbsp;<code>12345</code>&nbsp;是进程 ID。</li></ol><hr><h3 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h3><p>是因为没有配置环境变量</p><h4 id="1-配置环境变量"><a href="#1-配置环境变量" class="headerlink" title="1.  配置环境变量"></a>1.  配置环境变量</h4><ol><li>打开默认建立的ollama.service文件</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">vim</span> /etc/systemd/system/ollama.service<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>看到默认的一些设置</li></ol><pre class="line-numbers language-cobol" data-language="cobol"><code class="language-cobol">[<span class="token keyword">Unit</span>]Description<span class="token operator">=</span>Ollama Service<span class="token keyword">After</span><span class="token operator">=</span>network-online<span class="token punctuation">.</span>target [Service]ExecStart<span class="token operator">=</span><span class="token operator">/</span>usr<span class="token operator">/</span><span class="token keyword">local</span><span class="token operator">/</span>bin<span class="token operator">/</span>ollama serveUser<span class="token operator">=</span>ollama<span class="token keyword">Group</span><span class="token operator">=</span>ollamaRestart<span class="token operator">=</span>alwaysRestartSec<span class="token operator">=</span><span class="token number">3</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"PATH=/data/1-software/1-setup/1-miniconda/bin:/data/1-software/1-setup/1-miniconda/condabin:/data/1-software/1-setup/1-miniconda/bin:/usr/bin:/usr/local/bin:/usr/local/cuda/bin:/usr/bin/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin"</span>  [Install]WantedBy<span class="token operator">=</span><span class="token keyword">default</span><span class="token punctuation">.</span>target<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3.在&nbsp;[Service]下面增加环境配置参数</p><pre class="line-numbers language-cobol" data-language="cobol"><code class="language-cobol">[<span class="token keyword">Unit</span>]Description<span class="token operator">=</span>Ollama Service<span class="token keyword">After</span><span class="token operator">=</span>network-online<span class="token punctuation">.</span>target [Service]ExecStart<span class="token operator">=</span><span class="token operator">/</span>usr<span class="token operator">/</span><span class="token keyword">local</span><span class="token operator">/</span>bin<span class="token operator">/</span>ollama serveUser<span class="token operator">=</span>ollama<span class="token keyword">Group</span><span class="token operator">=</span>ollamaRestart<span class="token operator">=</span>alwaysRestartSec<span class="token operator">=</span><span class="token number">3</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"PATH=/data/1-software/1-setup/1-miniconda/bin:/data/1-software/1-setup/1-miniconda/condabin:/data/1-software/1-setup/1-miniconda/bin:/usr/bin:/usr/local/bin:/usr/local/cuda/bin:/usr/bin/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin"</span>  <span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_MODELS=/home/moyuai/moyuai/llm/ollama-models"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_HOST=0.0.0.0:11435"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_KEEP_ALIVE=24h"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_NUM_PARALLEL=100"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_MAX_LOADED_MODELS=4"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_SCHED_SPREAD=1"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_FLASH_ATTENTION=1"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_DEBUG=1"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_ACCELERATE=1"</span> [Install]WantedBy<span class="token operator">=</span><span class="token keyword">default</span><span class="token punctuation">.</span>target<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>按esc，输入“:wq”，退出文件编辑</li></ol><h4 id="2-重新加载systemd配置并重启服务"><a href="#2-重新加载systemd配置并重启服务" class="headerlink" title="2. 重新加载systemd配置并重启服务"></a>2. 重新加载systemd配置并重启服务</h4><ol><li>重新加载systemd</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl daemon-reload<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>启动服务</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl start ollama<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>查看状态</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl status ollama<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>若想停止服务</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl stop ollama<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>设置开机自启动</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> ollama<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="6"><li>若想停止开机自启动</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl disable ollama<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后重新执行<code>ollama serve</code>命令就成功解决。</p><hr>]]></content>
      
      
      
        <tags>
            
            <tag> ollama </tag>
            
            <tag> Python </tag>
            
            <tag> PyTorch </tag>
            
            <tag> huggingface </tag>
            
            <tag> Linux </tag>
            
            <tag> open-webui </tag>
            
            <tag> llama_cpp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于LLaMA-Factory的LlaMa3.2-1b模型微调弱智吧数据集全流程</title>
      <link href="/ji-yu-llama-factory-de-llama3.2-1b-mo-xing-wei-diao-ruo-zhi-ba-shu-ju-ji-quan-liu-cheng/"/>
      <url>/ji-yu-llama-factory-de-llama3.2-1b-mo-xing-wei-diao-ruo-zhi-ba-shu-ju-ji-quan-liu-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="一、项目背景"><a href="#一、项目背景" class="headerlink" title="一、项目背景"></a>一、项目背景</h2><p>在大模型应用学习中，学习到LLaMA-Factory模型微调框架，于是打算自己来根据LLaMA-Factory框架完整的微调一遍大模型来当作练习，选择基地模型和数据集分别是 Unichat-llama3.2-Chinese-1B 和 弱智吧数据集，选择的原因一个是个人练习用，所以选择一个模型参数量较小的，另一个就是原版模型对中文的支持比较弱，使用选择了一个中文版本，数据集则选择非常有特色的，训练后能够很好的出效果的数据集。</p><p>整个流程包括：模型下载、数据集整理、LoRA模式训练、模型评估、模型量化</p><h2 id="二、环境准备"><a href="#二、环境准备" class="headerlink" title="二、环境准备"></a>二、环境准备</h2><p>选择的是AutoDL算力云平台 ，GPU和软件环境选择如下</p><p><strong>GPU</strong>： RTX 3090(24GB)  + 软件环境：PyTorch 2.3.0+Python 3.12(ubuntu22.04)+CUDA 12.1</p><p>本地使用软件vs code进行远程服务器连接</p><h2 id="三、前期准备"><a href="#三、前期准备" class="headerlink" title="三、前期准备"></a>三、前期准备</h2><p>首先准备下载模型和数据集，这里下载有两种方式，一种是到我们租的服务器直接下载，一种是我们本地下载，这里我们选本地下载，因为下载的数据集还需要进行数据处理，本地处理比较方便，数据准备完成后上传到服务器即可。</p><h3 id="3-1-模型下载"><a href="#3-1-模型下载" class="headerlink" title="3.1 模型下载"></a>3.1 模型下载</h3><p>通过魔塔社区SDK来下载</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 安装ModelScope</span>pip <span class="token function">install</span> modelscope<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 下载模型Unichat-llama3.2-Chinese-1B模型</span><span class="token keyword">from</span> modelscope <span class="token keyword">import</span> snapshot_downloadmodel_dir <span class="token operator">=</span> snapshot_download<span class="token punctuation">(</span>    <span class="token string">'UnicomAI/Unichat-llama3.2-Chinese-1B'</span><span class="token punctuation">,</span>  <span class="token comment"># 模型名称</span>    cache_dir<span class="token operator">=</span><span class="token string">r"E:\xuexiziliao\AiProject\LLaMA-Factory-learn\llm"</span>  <span class="token comment"># 模型存放路径</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下载完成后，模型目录文件如下图：</p><p><img src="https://pic1.imgdb.cn/item/680b4b7458cb8da5c8cb7203.png" alt="Unichat-llama3.2-Chinese-1B模型目录"></p><h3 id="3-2-数据集下载"><a href="#3-2-数据集下载" class="headerlink" title="3.2 数据集下载"></a>3.2 数据集下载</h3><p>到魔塔社区中的数据集中搜索<strong>ruozhiba</strong>，然后我们找到<strong>w10442005/ruozhiba_qa</strong>数据集，下载代码如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 下载数据集前需要安装下面依赖</span>pip <span class="token function">install</span> numpypip <span class="token function">install</span> datasetspip <span class="token function">install</span> addict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 数据集下载</span><span class="token keyword">from</span> modelscope<span class="token punctuation">.</span>msdatasets <span class="token keyword">import</span> MsDatasetds <span class="token operator">=</span>  MsDataset<span class="token punctuation">.</span>load<span class="token punctuation">(</span>    <span class="token string">'w10442005/ruozhiba_qa'</span><span class="token punctuation">,</span>  <span class="token comment"># 数据集名称</span>    subset_name<span class="token operator">=</span><span class="token string">'default'</span><span class="token punctuation">,</span>   <span class="token comment"># 数据集子集名称</span>    split<span class="token operator">=</span><span class="token string">'train'</span> <span class="token punctuation">,</span>  <span class="token comment"># 数据集划分  </span>    data_dir<span class="token operator">=</span><span class="token string">r"E:\xuexiziliao\AiProject\LLaMA-Factory-learn\data"</span><span class="token punctuation">,</span>  <span class="token comment"># 数据集存放路径</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果下载不成功则换为git clone 来下载，或者直接到魔塔社区<code>ruozhiba_qa</code>数据集文件中直接下载<code>ruozhiba_qaswift.json</code>文件。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://www.modelscope.cn/datasets/w10442005/ruozhiba_qa.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下载完成后我们得到的数据集目录如下图：</p><p><img src="https://pic1.imgdb.cn/item/680b4c7e58cb8da5c8cb728d.png" alt="ruozhiba_qa数据集目录"></p><p>我们要用到的就是其中<code>ruozhiba_qaswift.json</code>数据集文件，里面内容如下：</p><p><img src="https://pic1.imgdb.cn/item/680b4c7e58cb8da5c8cb728e.png" alt="ruozhiba_qaswift.json文件内容"></p><h3 id="3-3-数据整理转换"><a href="#3-3-数据整理转换" class="headerlink" title="3.3 数据整理转换"></a>3.3 数据整理转换</h3><p>数据集文件我们拿到还不能够直接使用，因为<strong>LLaMA-Factory</strong>对数据集的格式要求是固定的，需要将里面的内容格式改为<code>identity.json</code>文件所示格式。如下图：</p><p><img src="https://pic1.imgdb.cn/item/680b989858cb8da5c8cd12fe.png" alt="identity.json文件格式"></p><p>我们只需要将<code>ruozhiba_qaswift.json</code> 中的<code>query</code>和<code>response</code>替换为<code>identity.json</code>中的<code>instruction</code>和<code>output</code>,并添加一个<code>input</code>值即可。</p><p>这里我们编写一个python程序来帮我们进行数据格式整理：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> json<span class="token comment"># 读取ruozhiba_qaswift.json文件</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">r"\data\ruozhiba_qaswift.json"</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    data <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token comment"># 转换格式</span>converted_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> item <span class="token keyword">in</span> data<span class="token punctuation">:</span>    converted_item <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"instruction"</span><span class="token punctuation">:</span> item<span class="token punctuation">[</span><span class="token string">"query"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">""</span><span class="token punctuation">,</span>        <span class="token comment"># 新增input字段并设为空字符串</span>        <span class="token string">"output"</span><span class="token punctuation">:</span> item<span class="token punctuation">[</span><span class="token string">"response"</span><span class="token punctuation">]</span>    <span class="token punctuation">}</span>    converted_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>converted_item<span class="token punctuation">)</span><span class="token comment"># 保存为新的JSON文件</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'converted_file.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>converted_data<span class="token punctuation">,</span> f<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> sort_keys<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"转换完成！转换后的数据已保存为 converted_file.json"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将转换后的json文件重命名为<code>ruozhiba_qaswift.json</code></p><p>到此我们的模型和数据集就已经准备好了，接下来就是连接服务器准备开始训练</p><h2 id="四、连接-AutoDL-服务器"><a href="#四、连接-AutoDL-服务器" class="headerlink" title="四、连接 AutoDL 服务器"></a>四、连接 AutoDL 服务器</h2><p>到<a href="https://www.autodl.com/market/list">AutoDL</a>算力市场租一台机器,选择环境如下：</p><p><img src="https://pic1.imgdb.cn/item/680b6ef358cb8da5c8cc75fe.png" alt="服务器软件环境选择"></p><p>选择好后开机，这时我们会得到远程服务器的ssh登入指令和密码，我们通过vs code来连接远程服务器</p><p><img src="https://pic1.imgdb.cn/item/680b6ef358cb8da5c8cc75fd.png" alt="服务器ssh登入指令和密码"></p><p><img src="https://pic1.imgdb.cn/item/680b6ef358cb8da5c8cc75ff.png" alt="通过vs code来连接服务器"></p><p>服务器连接完成后，我们进入到服务器<code>root</code>目录下,<code>root</code>目录内容如下：</p><p><img src="https://pic1.imgdb.cn/item/680b702358cb8da5c8cc77f5.png" alt="服务器root目录内容"></p><h2 id="五、安装LLaMA-Factory"><a href="#五、安装LLaMA-Factory" class="headerlink" title="五、安装LLaMA-Factory"></a>五、安装LLaMA-Factory</h2><p>下面我们安装<code>LLaMA-Factory</code>,我们安装在root目录下的<code>autodl-tmp</code>，这是服务器数据盘</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 进入autodl-tmp目录</span><span class="token builtin class-name">cd</span> autodl-tmp/<span class="token comment"># AutoDL 学术加速</span><span class="token builtin class-name">source</span> /etc/network_turbo<span class="token comment"># 下载LLaMA-Factory仓库</span><span class="token function">git</span> clone https://github.com/hiyouga/LLaMA-Factory.git<span class="token comment"># 安装auto-gptq量化包，要先于vllm安装，且auto-gptq量化包需要 PyTorch2.2.1+cuda121 版本</span>pip <span class="token function">install</span> auto-gptq<span class="token comment"># 进入LLaMA-Factory文件夹</span><span class="token builtin class-name">cd</span> LLaMA-Factory<span class="token comment"># 安装vllm</span>pip <span class="token function">install</span> <span class="token parameter variable">-e</span> .<span class="token punctuation">[</span><span class="token string">"vllm"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下载完成后<code>LLaMA-Factory</code>目录内容如下：</p><p><img src="https://pic1.imgdb.cn/item/680b7b0658cb8da5c8ccbcc9.png" alt="LLaMA-Factory目录内容"></p><p>全部安装完成后，我们将准备好的模型和数据集上传到服务器，将<code>ruozhiba_qaswift.json</code>文件放到<code>LLaMA-Factory</code>目录的<code>data</code>目录下，如图位置：</p><p><img src="https://pic1.imgdb.cn/item/680b7b0658cb8da5c8ccbcca.png" alt="ruozhiba_qaswift.json文件位置"></p><p>然后打开<code>LLaMA-Factory</code>目录的<code>data</code>目录下的<code>dataset_info.json</code>文件，在这里我们配置我们的数据集信息，在文件开始部分添加如下内容：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token property">"ruozhiba_qaswift"</span><span class="token operator">:</span> <span class="token punctuation">{</span>  <span class="token property">"file_name"</span><span class="token operator">:</span> <span class="token string">"ruozhiba_qaswift.json"</span><span class="token punctuation">,</span>  <span class="token property">"columns"</span><span class="token operator">:</span> <span class="token punctuation">{</span>    <span class="token property">"prompt"</span><span class="token operator">:</span> <span class="token string">"instruction"</span><span class="token punctuation">,</span>    <span class="token property">"query"</span><span class="token operator">:</span> <span class="token string">"input"</span><span class="token punctuation">,</span>    <span class="token property">"response"</span><span class="token operator">:</span> <span class="token string">"output"</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>修改后的<code>dataset_info.json</code>内容如下：</p><p><img src="https://pic1.imgdb.cn/item/680b7b0658cb8da5c8ccbccb.png" alt="修改后的dataset_info.json内容"></p><h2 id="六、准备LoAR训练"><a href="#六、准备LoAR训练" class="headerlink" title="六、准备LoAR训练"></a>六、准备LoAR训练</h2><p>全部条件准备完成后我们启动Web UI 准备开始模型训练。</p><p>进入<code>LLaMA-Factory</code>目录，我们执行命令启动Web UI：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> LLaMA-Factory<span class="token comment"># 运行LLaMA-Factory的webui</span>llamafactory-cli webui<span class="token comment"># 也可以使用以下命令，这样可以在后台运行webui，而不用担心终端关闭后webui会停止运行,这条命令会将输出重定向到webui.log文件中</span><span class="token function">nohup</span> llamafactory-cli webui <span class="token operator">&gt;</span> webui.log <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span><span class="token comment"># 如果要停止运行，你需要使用以下命令查找到 nohup 运行脚本到 PID，然后使用 kill 命令来删除：</span><span class="token function">ps</span> <span class="token parameter variable">-aux</span> <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">"runoob.sh"</span> <span class="token function">kill</span> <span class="token parameter variable">-9</span>  进程号PID<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行完后会自动跳转到浏览器打开webui界面，我们接下来配置训练参数</p><h3 id="6-1-模型参数配置"><a href="#6-1-模型参数配置" class="headerlink" title="6.1 模型参数配置"></a>6.1 模型参数配置</h3><p>将界面修改为中文，这次我们需要设置参数为训练的模型名字，模型路径，其他保持默认</p><p>其他参数：</p><ul><li>微调方法选择 lora</li><li>检查点路径：训练模型权重保存路径，一般默认</li><li>最下面一排参数先默认</li></ul><p>模型路径为我们服务器上模型存放的路径，如下图：</p><p><img src="https://pic1.imgdb.cn/item/680b816258cb8da5c8ccd5ff.png" alt="模型配置部分"></p><h3 id="6-2-Train参数配置"><a href="#6-2-Train参数配置" class="headerlink" title="6.2 Train参数配置"></a>6.2 Train参数配置</h3><p>Train参数本次设置如下：</p><p><img src="https://pic1.imgdb.cn/item/680b844158cb8da5c8cce0c8.png" alt="Train参数配置部分"></p><p>本次训练所配置参数就上面这些，其他这次保持默认。</p><p>我们点击开始，等待训练，我们这次训练轮次设置的为1000。</p><div class="alert alert-success"><b>模型继续训练：有两种方法，一种是将模型和最新保存的权重文件合并后设置训练参数然后继续训练，另一种是不合并直接设置训练参数然后继续训练。</b></div><h3 id="6-3-模型效果测试"><a href="#6-3-模型效果测试" class="headerlink" title="6.3 模型效果测试"></a>6.3 模型效果测试</h3><p>训练完成后，遇到了一个问题，就是训练过程中loss值一直降到非常低，这里我们不管，只要loss值一直在降低没有过拟合就行。</p><p>当然模型训练的loss并不是评估模型效果的唯一指标，我们需要根据具体情况来判断一个模型的训练好坏。</p><p>训练过程中的两个阶段的loss值趋势如下：</p><center class="half">    <img src="https://pic1.imgdb.cn/item/680c41f358cb8da5c8ce1557.webp" width="500">    <img src="https://pic1.imgdb.cn/item/680c41f358cb8da5c8ce1556.webp" width="500"></center>可以看到在1000轮之后，loss值就一直降低到0.5以下，到后面几乎接近0，这里我们取1000轮左右保存的训练权重和最后轮的训练训练权重来做对比，看谁的效果更好。<p>后面由于安装<code>auto-gptq</code>包时环境出了问题，后面上网查找原因时，是因为安装<code>auto-gptq</code>包必须要有指定PyTorch和CUDA版本，要求的版本为</p><ul><li>PyTorch  2.1.2</li><li>CUDA  11.8<br>的后续换了一个服务器，软件环境选择如下：</li></ul><p><img src="https://pic1.imgdb.cn/item/680c41f458cb8da5c8ce1559.png" alt="更换服务器后的环境选择"></p><p>这里我们重新安装一下<code>LLaMA-Factory</code>，这里和之前安装步骤有点不同，安装<code>LLaMA-Factory</code>所需依赖前，需要先安装量化包<code>auto-gptq</code> 。这是后续模型量化步骤的所必须的，而且安装<code>vllm</code>包之前要先安装<code>auto-gptq</code>包，这也是我们为什么要换环境的原因。</p><p>执行以下命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 进入autodl-tmp目录</span><span class="token builtin class-name">cd</span> autodl-tmp/<span class="token comment"># AutoDL 学术加速</span><span class="token builtin class-name">source</span> /etc/network_turbo<span class="token comment"># 下载LLaMA-Factory仓库</span><span class="token function">git</span> clone https://github.com/hiyouga/LLaMA-Factory.git<span class="token comment"># 安装auto-gptq量化包</span>pip <span class="token function">install</span> auto-gptq<span class="token comment"># 安装vllm</span>pip <span class="token function">install</span> <span class="token parameter variable">-e</span> .<span class="token punctuation">[</span><span class="token string">"vllm"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>环境安装成功后，我们准备测试模型训练效果</p><p>将我们另一个服务器训练好的权重复制到新的服务器上来，并重新下载一遍模型，权重准备好后，准备开启web ui</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> LLaMA-Factory<span class="token comment"># 运行LLaMA-Factory的webui</span>llamafactory-cli webui<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这次我们要用到<code>LLaMA-FactoryChat</code>的Chat推理功能，参数说明如下图：</p><p><img src="https://pic1.imgdb.cn/item/680c4c8f58cb8da5c8ce186d.png" alt="Chat推理参数设置"></p><p>下面我们用原始模型，以及加载不同训练轮次的权重模型后，对同一问题模型给的回答来进行一个对比。</p><p>加载模型准备开始测试</p><p>因为训练时顺便加了关于自我认知的数据集，所以来进行自我认知测试，模型回答如下：</p><figure class="half">    <img src="https://pic1.imgdb.cn/item/680c528c58cb8da5c8ce1d10.png">    <img src="https://pic1.imgdb.cn/item/680c528c58cb8da5c8ce1d11.png">    <img src="https://pic1.imgdb.cn/item/680c529858cb8da5c8ce1d18.png"></figure><p>对模型用弱智吧的问题进行提问，模型回答如下：</p><figure class="half">    <img src="https://pic1.imgdb.cn/item/680c528c58cb8da5c8ce1d12.png">    <img src="https://pic1.imgdb.cn/item/680c528c58cb8da5c8ce1d0f.png">    <img src="https://pic1.imgdb.cn/item/680c529858cb8da5c8ce1d19.png">    <img src="https://pic1.imgdb.cn/item/680c529858cb8da5c8ce1d1a.png"></figure>这里模型训练效果都感觉一般，我推测是因为选择的基座模型的原因，后续可以换一个基座模型在测试一遍，这次先将流程走完。<h3 id="6-4-模型合并导出"><a href="#6-4-模型合并导出" class="headerlink" title="6.4 模型合并导出"></a>6.4 模型合并导出</h3><p>我们先将模型合并，然后在进行模型量化导出，模型导出设置如下，我们用1000轮的权重来进行模型合并</p><p><img src="https://pic1.imgdb.cn/item/680c908358cb8da5c8cec05f.png" alt="模型导出设置"></p><h3 id="6-5-模型量化导出"><a href="#6-5-模型量化导出" class="headerlink" title="6.5 模型量化导出"></a>6.5 模型量化导出</h3><p>将我们上面导出的模型文件加载进来，量化导出设置如下：</p><p><img src="https://pic1.imgdb.cn/item/680c908358cb8da5c8cec05e.png" alt="量化模型导出设置"></p><p>这里导出我们看控制台有没有报错信息，可能会要提示我们安装一些环境，提示缺什么我们就安装什么。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> optimum<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装完成后记得重启webui，然后我们重新配置一下等待模型量化导出完成。</p><p>这里我一共导出了q2,q4,q8精度的量化模型，然后来分别对它们的效果进行对比，q4和q8精度下，模型效果和没量化前区别不大，到测试q2时，模型已经完全不行了，全都回答乱码。</p><figure class="half">    <img src="https://pic1.imgdb.cn/item/680c9bed58cb8da5c8cedd4a.png">    <img src="https://pic1.imgdb.cn/item/680c9bed58cb8da5c8cedd4b.png">    <img src="https://pic1.imgdb.cn/item/680c9bed58cb8da5c8cedd4c.png"></figure><p>所以目前量化一般量化到4位和8位。</p><h3 id="6-5-模型评估"><a href="#6-5-模型评估" class="headerlink" title="6.5 模型评估"></a>6.5 模型评估</h3><p>我们首先准备好测试数据集，这次我们先从<code>ruozhiba_qaswift.json</code>文件中取一部分数据从来作为我们的测试数据集,在<code>LLaMA-Factory/data</code>目录下面新建<code>ruozhiba_qaswift_test.json</code>文件，复制一部分<code>ruozhiba_qaswift.json</code>中的数据到<code>ruozhiba_qaswift_test.json</code>文件中，然后在<code>dataset_info.json</code>文件中配置<code>ruozhiba_qaswift_test.json</code>文件，准备好后我们开始模型评估。</p><p>我们导入基座模型，设置好我们要评估的权重，然后进入<code>Evaluate &amp; Predict</code>界面，参数设置如下图：</p><p><img src="https://pic1.imgdb.cn/item/68102dc658cb8da5c8d2b9f1.png" alt="模型评估设置"></p><p>我们点击开始评估，这时会要求我们安装几个评估要用的包，我们依次根据提示安装即可</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> jiebapip <span class="token function">install</span> nltkpip <span class="token function">install</span> rouge_chinese<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>包安装完成后，模型评估开始，评估结果如下：</p><p>训练1000轮权重的模型评估得分：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>    <span class="token property">"predict_bleu-4"</span><span class="token operator">:</span> <span class="token number">25.71370314171123</span><span class="token punctuation">,</span>    <span class="token property">"predict_model_preparation_time"</span><span class="token operator">:</span> <span class="token number">0.0023</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-1"</span><span class="token operator">:</span> <span class="token number">48.205860895721926</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-2"</span><span class="token operator">:</span> <span class="token number">27.524134157754013</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-l"</span><span class="token operator">:</span> <span class="token number">41.42147493315508</span><span class="token punctuation">,</span>    <span class="token property">"predict_runtime"</span><span class="token operator">:</span> <span class="token number">347.7339</span><span class="token punctuation">,</span>    <span class="token property">"predict_samples_per_second"</span><span class="token operator">:</span> <span class="token number">4.302</span><span class="token punctuation">,</span>    <span class="token property">"predict_steps_per_second"</span><span class="token operator">:</span> <span class="token number">0.359</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>训练3100轮的模型评估得分：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>    <span class="token property">"predict_bleu-4"</span><span class="token operator">:</span> <span class="token number">92.7214736631016</span><span class="token punctuation">,</span>    <span class="token property">"predict_model_preparation_time"</span><span class="token operator">:</span> <span class="token number">0.0024</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-1"</span><span class="token operator">:</span> <span class="token number">95.9076695855615</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-2"</span><span class="token operator">:</span> <span class="token number">94.5167354946524</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-l"</span><span class="token operator">:</span> <span class="token number">95.47345046791445</span><span class="token punctuation">,</span>    <span class="token property">"predict_runtime"</span><span class="token operator">:</span> <span class="token number">318.3357</span><span class="token punctuation">,</span>    <span class="token property">"predict_samples_per_second"</span><span class="token operator">:</span> <span class="token number">4.699</span><span class="token punctuation">,</span>    <span class="token property">"predict_steps_per_second"</span><span class="token operator">:</span> <span class="token number">0.393</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这是一段 JSON 格式数据，用于表示模型预测性能的相关指标。以下是各字段的解释：</p><ul><li>predict_bleu4: BLEU-4 得分。</li><li>predict_model_preparation_time: 模型准备时间</li><li>predict_rouge1: ROUGE-1 得分</li><li>predict_rouge2: ROUGE-2 得分</li><li>predict_rougel: ROUGE-L 得分</li><li>predict_runtime: 总运行时间</li><li>predict_samples_per_second: 每秒处理样本数</li><li>predict_steps_per_second: 每秒处理步骤数</li></ul><p>这些指标用于评估模型性能，帮助优化。（详细资料可参考：<a href="https://blog.csdn.net/weixin_45573296/article/details/141333719">BLEU、ROUGE详解-语言模型的常用评价指标-举例附代码实现</a></p><p>可以看出这次训练1000轮的效果其实并不好，评分都较低，和我们主观测试的结果差不多，而训练3100轮的效果就不错，得分较高。</p><h3 id="6-6-关于QLoRA"><a href="#6-6-关于QLoRA" class="headerlink" title="6.6 关于QLoRA"></a>6.6 关于QLoRA</h3><p>QLoRA是一种优于LoRA训练的一个手段，QLoRA可以帮助我们在一定程度上降低训练时显存需要，而不像量化导出那样损失较大参数，并且可以加快训练速度，所以训练可以使用QLoRA来进行，</p><p>开启QLoRA训练的一些设置：<br><img src="https://pic1.imgdb.cn/item/681033bd58cb8da5c8d2d9b4.png" alt="QLoRA设置"></p><p><img src="https://pic1.imgdb.cn/item/681033bd58cb8da5c8d2d9b3.png" alt="QLoRA设置"></p><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="在AutoDL服务器中安装pip-install-auto-gptq-包出现报错"><a href="#在AutoDL服务器中安装pip-install-auto-gptq-包出现报错" class="headerlink" title="在AutoDL服务器中安装pip install auto-gptq 包出现报错"></a>在AutoDL服务器中安装pip install auto-gptq 包出现报错</h3><pre class="line-numbers language-root@autodl-container-3fac46b1d9-74c33bae:~/autodl-tmp/LLaMA-Factory#" data-language="root@autodl-container-3fac46b1d9-74c33bae:~/autodl-tmp/LLaMA-Factory#"><div class="caption"><span>pip install auto-gptq</span></div><code class="language-root@autodl-container-3fac46b1d9-74c33bae:~/autodl-tmp/LLaMA-Factory#">Looking in indexes: http://mirrors.aliyun.com/pypi/simpleCollecting auto-gptq  Using cached http://mirrors.aliyun.com/pypi/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz (126 kB)  Preparing metadata (setup.py) ... doneDiscarding http://mirrors.aliyun.com/pypi/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz#sha256=5c61ad380e9b4c603757c254765e9083a90a820cd0aff1b5d2c6f7fd96c85e80 (from http://mirrors.aliyun.com/pypi/simple/auto-gptq/) (requires-python:&gt;=3.8.0): Requested auto-gptq from http://mirrors.aliyun.com/pypi/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz#sha256=5c61ad380e9b4c603757c254765e9083a90a820cd0aff1b5d2c6f7fd96c85e80 has inconsistent version: expected '0.7.1', but metadata has '0.7.1+cu124'  Using cached http://mirrors.aliyun.com/pypi/packages/34/71/c3e73cf17681f6ff4754ef8f4cb8b67af3def230fc8711eac1250bbd78d5/auto_gptq-0.7.0.tar.gz (124 kB)  Preparing metadata (setup.py) ... doneDiscarding http://mirrors.aliyun.com/pypi/packages/34/71/c3e73cf17681f6ff4754ef8f4cb8b67af3def230fc8711eac1250bbd78d5/auto_gptq-0.7.0.tar.gz#sha256=50a5396fae2db5a19446b3198ef0e86ee520846b881db47bdbf4eb9260eac723 (from http://mirrors.aliyun.com/pypi/simple/auto-gptq/) (requires-python:&gt;=3.8.0): Requested auto-gptq from http://mirrors.aliyun.com/pypi/packages/34/71/c3e73cf17681f6ff4754ef8f4cb8b67af3def230fc8711eac1250bbd78d5/auto_gptq-0.7.0.tar.gz#sha256=50a5396fae2db5a19446b3198ef0e86ee520846b881db47bdbf4eb9260eac723 has inconsistent version: expected '0.7.0', but metadata has '0.7.0+cu124'  Using cached http://mirrors.aliyun.com/pypi/packages/49/af/02b66e55dfd9aeb0ece923843043724ed7432ec0c649ea0f3b9fa1dd90c6/auto_gptq-0.6.0.tar.gz (120 kB)  Preparing metadata (setup.py) ... error  error: subprocess-exited-with-error    × python setup.py egg_info did not run successfully.  │ exit code: 1  ╰─&gt; [20 lines of output]      python: can't open file '/tmp/pip-install-g1v4mpt6/auto-gptq_c460ab0157b140969c62922c52a5ab77/./autogptq_extension/qigen/generate.py': [Errno 2] No such file or directory      Traceback (most recent call last):        File "/tmp/pip-install-g1v4mpt6/auto-gptq_c460ab0157b140969c62922c52a5ab77/setup.py", line 109, in &lt;module&gt;          subprocess.check_output(["python", "./autogptq_extension/qigen/generate.py", "--module", "--search", "--p", str(p)])        File "/root/miniconda3/lib/python3.12/subprocess.py", line 466, in check_output          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^        File "/root/miniconda3/lib/python3.12/subprocess.py", line 571, in run          raise CalledProcessError(retcode, process.args,      subprocess.CalledProcessError: Command '['python', './autogptq_extension/qigen/generate.py', '--module', '--search', '--p', '112']' returned non-zero exit status 2.            During handling of the above exception, another exception occurred:            Traceback (most recent call last):        File "&lt;string&gt;", line 2, in &lt;module&gt;        File "&lt;pip-setuptools-caller&gt;", line 34, in &lt;module&gt;        File "/tmp/pip-install-g1v4mpt6/auto-gptq_c460ab0157b140969c62922c52a5ab77/setup.py", line 111, in &lt;module&gt;          raise Exception(f"Generating QiGen kernels failed with the error shown above.")      Exception: Generating QiGen kernels failed with the error shown above.      Generating qigen kernels...      [end of output]    note: This error originates from a subprocess, and is likely not a problem with pip.error: metadata-generation-failed× Encountered error while generating package metadata.╰─&gt; See above for output.note: This is an issue with the package mentioned above, not pip.hint: See above for details.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> PyTorch </tag>
            
            <tag> vllm </tag>
            
            <tag> LLaMA-Factory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ollama调用本地模型</title>
      <link href="/ollama-diao-yong-ben-di-mo-xing/"/>
      <url>/ollama-diao-yong-ben-di-mo-xing/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux安装Ollama"><a href="#Linux安装Ollama" class="headerlink" title="Linux安装Ollama"></a>Linux安装Ollama</h1><h2 id="安装命令："><a href="#安装命令：" class="headerlink" title="安装命令："></a>安装命令：</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果下载速度很慢，可以开启学术加速</p><h3 id="开启学术加速"><a href="#开启学术加速" class="headerlink" title="开启学术加速:"></a>开启学术加速:</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">source</span> /etc/network_turbo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="取消学术加速"><a href="#取消学术加速" class="headerlink" title="取消学术加速:"></a>取消学术加速:</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">unset</span> http_proxy <span class="token operator">&amp;&amp;</span> <span class="token builtin class-name">unset</span> https_proxy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="Ollama安装模型："><a href="#Ollama安装模型：" class="headerlink" title="Ollama安装模型："></a>Ollama安装模型：</h2><h3 id="下载模型"><a href="#下载模型" class="headerlink" title="下载模型"></a>下载模型</h3><p>以 llama3.2:1b 模型为例，运行下面命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama run llama3.2:1b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>等待命令结束。</p><h3 id="使用模型"><a href="#使用模型" class="headerlink" title="使用模型"></a>使用模型</h3><p>ollama使用模型有两种方式，一种通过终端命令使用，一种通过python代码使用，两种方式都需要首先开启ollama服务</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama serve<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="1-通过终端使用"><a href="#1-通过终端使用" class="headerlink" title="1.通过终端使用"></a>1.通过终端使用</h4><p>终端运行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama run llama3.2:1b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>终端会进入对话模式，这时输入你要问的问题即可使用模型。</p><h4 id="2-通过python代码使用模型"><a href="#2-通过python代码使用模型" class="headerlink" title="2.通过python代码使用模型"></a>2.通过python代码使用模型</h4><p>安装 openai 包</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> opeani<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>python代码简单调用</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI<span class="token comment"># 通过openai接口调用模型，导入模型地址，和api_key</span>client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>base_url<span class="token operator">=</span><span class="token string">"http://localhost:11434/v1/"</span><span class="token punctuation">,</span>api_key<span class="token operator">=</span><span class="token string">"ollama"</span><span class="token punctuation">)</span><span class="token comment"># 提示词模板，并输入用户问题，指定使用模型名字</span>responce<span class="token operator">=</span>client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>    messages<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span><span class="token string">"user"</span><span class="token punctuation">,</span><span class="token string">"content"</span><span class="token punctuation">:</span><span class="token string">"你好!你是谁？你是由谁创造的？"</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span>model<span class="token operator">=</span><span class="token string">"llama3.2:1B"</span><span class="token punctuation">)</span><span class="token comment"># 打印结果</span><span class="token keyword">print</span><span class="token punctuation">(</span>responce<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>base_url：启动<code>ollama serve</code>后会给出地址和端口，一般为<a href="http://localhost:11434/">http://localhost:11434</a></p><p>api_key：为ollama，因为使用的ollama框架</p><p>简单多轮对话框架调用：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#多轮对话</span><span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI<span class="token comment">#定义多轮对话方法</span><span class="token keyword">def</span> <span class="token function">run_chat_session</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment">#初始化客户端</span>    client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>base_url<span class="token operator">=</span><span class="token string">"http://localhost:11434/v1/"</span><span class="token punctuation">,</span>api_key<span class="token operator">=</span><span class="token string">"ollama"</span><span class="token punctuation">)</span>    <span class="token comment">#初始化对话历史</span>    chat_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment">#启动多轮对话</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        <span class="token comment">#获取用户输入</span>        user_input <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"用户："</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> user_input<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">==</span><span class="token string">"exit"</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"退出对话"</span><span class="token punctuation">)</span>            <span class="token keyword">break</span>        <span class="token comment">#更新对话历史（添加用户输入）</span>        chat_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span><span class="token string">"user"</span><span class="token punctuation">,</span><span class="token string">"content"</span><span class="token punctuation">:</span>user_input<span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment">#调用模型回答</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            chat_complition <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>messages<span class="token operator">=</span>chat_history<span class="token punctuation">,</span>model<span class="token operator">=</span><span class="token string">"llama3.2:1b"</span><span class="token punctuation">)</span>            <span class="token comment">#获取最新回答</span>            moedl_responce <span class="token operator">=</span> chat_complition<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AI："</span><span class="token punctuation">,</span>moedl_responce<span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">)</span>            <span class="token comment">#更新对话历史（添加AI模型的回复）</span>            chat_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span><span class="token string">"assistant"</span><span class="token punctuation">,</span><span class="token string">"content"</span><span class="token punctuation">:</span>moedl_responce<span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"发生错误："</span><span class="token punctuation">,</span>e<span class="token punctuation">)</span>            <span class="token keyword">break</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    run_chat_session<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ollama </tag>
            
            <tag> python </tag>
            
            <tag> linux </tag>
            
            <tag> LLaMa </tag>
            
            <tag> LoRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LLaMa3微调</title>
      <link href="/llama3-wei-diao/"/>
      <url>/llama3-wei-diao/</url>
      
        <content type="html"><![CDATA[<h1 id="LLaMa3微调"><a href="#LLaMa3微调" class="headerlink" title="LLaMa3微调"></a>LLaMa3微调</h1><h2 id="LoRA"><a href="#LoRA" class="headerlink" title="LoRA"></a>LoRA</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>LoRA（Low-Rank Adaptation）是一种用于大模型微调的技术，通过引入低秩矩阵来减少微调时的参数量。在预训练的模型中，LoRA通过添加两个小矩阵B和A来近似原始的大矩阵ΔW，从而减少需要更新的参数数量。具体来说，LoRA通过将全参微调的增量 参数矩阵ΔW表示为两个参数量更小的矩阵B和A的低秩近似来实现：</p><p>[ W_0 + \Delta W = W_0 + BA ] </p><p>其中，B和A的秩远小于原始矩阵的秩，从而大大减少了需要更新的参数数量。</p><h3 id="LoRA思想"><a href="#LoRA思想" class="headerlink" title="LoRA思想"></a>LoRA思想</h3><p>预训练模型中存在一个极小的内在维度，这个内在维度是发挥核心作用的地方。在继续训练的过程中，权重的更新依然也有如此特点，即也存在一个内在维度(内在秩)</p><p>权重更新：W=W+^W</p><p>因此，可以通过矩阵分解的方式，将原本要更新的大的矩阵变为两个小的矩阵</p><p>权重更新：W=W+^W=W+BA</p><p>具体做法，即在矩阵计算中增加一个旁系分支，旁系分支由两个 低秩矩阵A和B组成</p><h3 id="LoRA原理"><a href="#LoRA原理" class="headerlink" title="LoRA原理"></a>LoRA原理</h3><p>训练时，输入分别与原始权重和两个低秩矩阵进行计算，共同得 到最终结果，优化则仅优化A和B。</p><p>训练完成后，可以将两个低秩矩阵与原始模型中的权重进行合并， 合并后的模型与原始模型无异</p><h2 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h2><p>可以通过Hugging Face平台和国内魔塔社区进行下载，下面以<code>Llama-3.2-1B-Instruct</code>模型为示例：</p><p>魔塔社区下载模型，</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 模型下载</span><span class="token keyword">from</span> modelscope <span class="token keyword">import</span> snapshot_downloadmodel_dir <span class="token operator">=</span> snapshot_download<span class="token punctuation">(</span><span class="token string">'LLM-Research/Llama-3.2-1B-Instruct'</span><span class="token punctuation">,</span>cache_dir<span class="token operator">=</span><span class="token string">"/teacher_data/llm/"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="LLaMA-Factory"><a href="#LLaMA-Factory" class="headerlink" title="LLaMA-Factory"></a>LLaMA-Factory</h2><p>1.安装</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/hiyouga/LLaMA-Factory.git<span class="token builtin class-name">cd</span> LLaMA-Factorypip <span class="token function">install</span> <span class="token parameter variable">-e</span> <span class="token builtin class-name">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><div style="background-color: green; padding: 10px;">  这里执行安装包命令前，先执行 pip install auto-gptq 以及 pip install -e .["vllm"] 安装量化框架</div><p>2.准备训练数据</p><p>例：</p><p>训练数据：</p><ul><li>fintech.json</li><li>identity.json</li></ul><p>将训练数据放在目录 LLaMA-Factory/data/fintech.json </p><p>并且修改数据注册文件：LLaMA-Factory/data/dataset_info.json ,内容如下：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token property">"fintech"</span><span class="token operator">:</span> <span class="token punctuation">{</span><span class="token property">"file_name"</span><span class="token operator">:</span> <span class="token string">"fintech.json"</span><span class="token punctuation">,</span><span class="token property">"columns"</span><span class="token operator">:</span> <span class="token punctuation">{</span><span class="token property">"prompt"</span><span class="token operator">:</span> <span class="token string">"instruction"</span><span class="token punctuation">,</span><span class="token property">"query"</span><span class="token operator">:</span> <span class="token string">"input"</span><span class="token punctuation">,</span><span class="token property">"response"</span><span class="token operator">:</span> <span class="token string">"output"</span><span class="token punctuation">,</span><span class="token property">"history"</span><span class="token operator">:</span> <span class="token string">"history"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="通过界面进行训练"><a href="#通过界面进行训练" class="headerlink" title="通过界面进行训练"></a>通过界面进行训练</h3><p>启动Web UI</p><pre class="line-numbers language-none"><code class="language-none">cd LLaMA-Factoryllamafactory-cli webui<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>模型微调</p><ul><li>使用 Web UI 训练</li><li>使用命令行执行</li></ul><p>启动webui后界面如下：</p><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce81.png" alt="LLaMa3_00"></p><h3 id="设置训练模型路径"><a href="#设置训练模型路径" class="headerlink" title="设置训练模型路径"></a>设置训练模型路径</h3><p>将界面修改为中文，设置需要训练的模型名字，填入模型路径</p><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce7c.png" alt="LLaMa3_01"></p><p>其他参数：</p><ul><li>微调方法选择 lora</li><li>检查点路径：训练模型保存路径，训练好的模型权重路径，一般默认</li><li>最下面一排参数先默认</li></ul><h3 id="配置训练参数"><a href="#配置训练参数" class="headerlink" title="配置训练参数"></a>配置训练参数</h3><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce80.png" alt="LLaMa3_02"></p><p>参数配置：</p><ul><li>训练阶段：一般默认supervised Fine-Tuning</li><li>数据路径：我们要训练的数据集路径</li><li>数据集：我们要训练的数据集，可以多选</li><li>学习率：一般默认</li><li>训练轮数：一般设置大一点，因为可以随时中止</li><li>最大梯度范畴：一般默认</li><li>最大样本数：默认，可以根据数据集的大小来定</li><li>计算类型：bf16效果最好，但要看设备支不支持</li><li>截断长度：一般根据数据集来定</li><li>批处理大小：根据显卡配置来看</li><li>梯度积累：默认</li><li>验证集比例：验证集所占样本的大小</li><li>学习率调节器：默认</li></ul><h3 id="LoRA参数设置"><a href="#LoRA参数设置" class="headerlink" title="LoRA参数设置"></a>LoRA参数设置</h3><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce7e.png" alt="LLaMa3_04"></p><p>参数：一般默认</p><p>配置好所有参数后，准备开始训练</p><h3 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h3><p>将训练好的模型权重进行测试测试</p><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce7d.png" alt="LLaMa3_05"></p><p>点击加载模型，会加载模型对话框界面</p><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce7f.png" alt="LLaMa3_06"></p><p>和模型对话看给出的回答准确度高不高</p><h3 id="合并LoAR和原模型"><a href="#合并LoAR和原模型" class="headerlink" title="合并LoAR和原模型"></a>合并LoAR和原模型</h3><p>选择效果最好的训练权重和原模型，点击Export模式，设置好参数后就准备开始导出。</p><p><img src="https://pic1.imgdb.cn/item/680af5bd58cb8da5c8c9ce88.png" alt="LLaMa3_07"></p><h3 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h3><p>准备训练用的数据集，配置 <code>dataset_info</code> ，参数配置一般和训练时数据保持一致</p><p>评估模型前还需要装几个包</p><pre class="line-numbers language-none"><code class="language-none">pip install jiebapip install nltkpip install rouge_chinese<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="https://pic1.imgdb.cn/item/680af5be58cb8da5c8c9ce8a.png" alt="LLaMa3_08"></p><h3 id="通过配置文件开始训练"><a href="#通过配置文件开始训练" class="headerlink" title="通过配置文件开始训练"></a>通过配置文件开始训练</h3><p>配置文件位于：[cust/train_llama3_lora_sft.yaml] </p><p>构建 cust/train_llama3_lora_sft.yaml</p><pre class="line-numbers language-none"><code class="language-none">cutoff_len: 1024 dataset: fintech,identity dataset_dir: data do_train: true finetuning_type: lora flash_attn: auto fp16: true gradient_accumulation_steps: 8 learning_rate: 0.0002 logging_steps: 5 lora_alpha: 16 lora_dropout: 0 lora_rank: 8 lora_target: q_proj,v_proj lr_scheduler_type: cosine max_grad_norm: 1.0 max_samples: 1000 model_name_or_path: /root/autodl-tmp/models/Llama3-8B-Chinese-Chat num_train_epochs: 10.0 optim: adamw_torch output_dir: saves/LLaMA3-8B-Chinese-Chat/lora/train_2024-05-25-20-27-47 packing: false per_device_train_batch_size: 2 plot_loss: true preprocessing_num_workers: 16 report_to: none save_steps: 100 stage: sft template: llama3 use_unsloth: true warmup_steps: 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>命令行执行：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">llamafactory-cli train cust/train_llama3_lora_sft.yaml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="问题记录："><a href="#问题记录：" class="headerlink" title="问题记录："></a>问题记录：</h3><p>我在实际安装过程中由于懒得租服务器和安装Linux双系统，所以就直接使用Windows11系统来安装配置LLaMA-Factory，按照上面步骤配置好后，成功启动了webui界面，但是在配置好训练参数后，点击开始训练，结果报错：未找到cuda环境，随后程序报错中断服务了</p><p><img src="https://pic1.imgdb.cn/item/680af5be58cb8da5c8c9ce89.png" alt="LLaMa3_09"></p><p>原因推测是没有在使用的python环境中安装 CUDA + pytorch 环境导致的，或者安装的环境版本不对，安装 CUDA + pytorch 包</p><pre class="line-numbers language-none"><code class="language-none">conda install pytorch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 pytorch-cuda=12.1 -c pytorch -c nvidia<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>后续没有解决，准备还是在服务器上进行测试。</p><h2 id="文本生成模型评估方法"><a href="#文本生成模型评估方法" class="headerlink" title="文本生成模型评估方法"></a>文本生成模型评估方法</h2><p>OpenCompass采取客观评测与主观评测相结合的方法。针对具有确定性答案的能力维度和场景，通过构造丰富完善的评测集，对模型能力进行综合评价。针对体现模型能力的开放式或半开放式的问题、模型安全问题等，采用主客观相结合的评测方式。</p>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ollama </tag>
            
            <tag> python </tag>
            
            <tag> linux </tag>
            
            <tag> LLaMa </tag>
            
            <tag> LoRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo+github+Netlify+ClouldFlare搭建个人博客</title>
      <link href="/hexo-github-netlify-clouldflare-da-jian-ge-ren-bo-ke/"/>
      <url>/hexo-github-netlify-clouldflare-da-jian-ge-ren-bo-ke/</url>
      
        <content type="html"><![CDATA[<h2 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h2><p>这个教程使用的个人博客框架是hexo，博客文件拖管于github，博客网站用netlify生成，国内访问采用Cloudflare进行CDN加速。</p><h3 id="1-1-创建GitHub仓库"><a href="#1-1-创建GitHub仓库" class="headerlink" title="1.1 创建GitHub仓库"></a>1.1 创建GitHub仓库</h3><p>进入GitHub网站，在网站上新建一个代码仓库用于保存我们的网页</p><p>点击<code>Your repositories</code>，进入仓库页面。</p><p><img src="https://pic1.imgdb.cn/item/680aeb6b58cb8da5c8c97cee.png" alt="0"></p><p>点击<code>New</code>按钮，进入仓库创建页面。</p><p><img src="https://pic1.imgdb.cn/item/680aeb6b58cb8da5c8c97cec.png" alt="01"></p><p>填写<strong>Repository name</strong>仓库名，格式必须为<code>&lt;用户名&gt;.github.io</code>，我设置的用户名为<code>ismoyuai.github.io</code> 然后点击 <code>Create repository</code>。</p><p><img src="https://pic1.imgdb.cn/item/680aeb6b58cb8da5c8c97ceb.png" alt="02"></p><p>这样我们仓库初步准备已经好了，下面安装Node.js</p><h3 id="1-2-安装Node-js以及npm"><a href="#1-2-安装Node-js以及npm" class="headerlink" title="1.2 安装Node.js以及npm"></a>1.2 安装Node.js以及npm</h3><p>进入<a href="https://nodejs.org/en/download/">node.js官网</a>下载相应的版本，在Windows上安装一般按下图选择，最后点击下载</p><p><img src="https://pic1.imgdb.cn/item/680aeb6b58cb8da5c8c97ced.png" alt="03"></p><p>安装会连同包含的环境变量和<code>npm</code>一起安装，安装后，我们检测<code>Node.js</code>是否安装成功，打开终端，输入命令：</p><p>第一个：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">node</span> <span class="token parameter variable">-v</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行命令后，如果安装成功会显示<code>nodejs</code>版本号。</p><p>第二个：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token parameter variable">-v</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行成功后，如果安装成功会显示<code>npm</code>版本号。</p><h3 id="1-3-安装Git"><a href="#1-3-安装Git" class="headerlink" title="1.3 安装Git"></a>1.3 安装Git</h3><p>到<a href="https://git-scm.com/downloads/win">Git官网</a>下载最新版本，这里我下载的是64为的安装版本，下载完成后打开，然后按步骤默认安装即可。</p><p><img src="https://pic1.imgdb.cn/item/680aeb6b58cb8da5c8c97cef.png" alt="05"></p><h3 id="1-4-安装Hexo主题框架"><a href="#1-4-安装Hexo主题框架" class="headerlink" title="1.4 安装Hexo主题框架"></a>1.4 安装Hexo主题框架</h3><p>安装Hexo框架需要借助<code>npm</code>包管理器安装，打开终端执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> <span class="token parameter variable">-g</span> hexo-cli <span class="token comment"># 全局安装hexo命令行工具</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中<code>-g</code>参数表示全局安装，没有这个参数就只在当前目录下安装，建议全局安装。</p><p>安装完成后，执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo <span class="token parameter variable">-v</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个命令可以看安装hexo版本号</p><h2 id="二、搭建博客"><a href="#二、搭建博客" class="headerlink" title="二、搭建博客"></a>二、搭建博客</h2><h3 id="2-1-本地创建"><a href="#2-1-本地创建" class="headerlink" title="2.1 本地创建"></a>2.1 本地创建</h3><p>选一个你存放数据的盘，创建一个文件夹。这个文件夹用来存放我们所有博客内容和素材，后续的操作都在这个文件夹中进行，比如我在<strong>D盘</strong>创建一个<strong>MYBLOG</strong>文件夹，在<strong>D盘</strong>右键点击<code>Open Git Bash here</code>输入命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo init MYBLOG<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个命令用来初始化我们博客框架，需要等待一段时间让它进行下载。下载完成后文件夹内容如下：</p><p><img src="https://pic1.imgdb.cn/item/680aeb6a58cb8da5c8c97cea.png" alt="06"></p><p>进入<strong>MYBLOG</strong>文件夹</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> MYBLOG<span class="token function">npm</span> <span class="token function">install</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>本地部署启动</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo ghexo s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>完成后会在本地地址启动你的本地博客。浏览器访问 <a href="http://localhost:4000，页面默认主图风格如下">http://localhost:4000，页面默认主图风格如下</a><br><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cfa.png" alt="07"></p><h3 id="2-2-部署到GitHub仓库"><a href="#2-2-部署到GitHub仓库" class="headerlink" title="2.2 部署到GitHub仓库"></a>2.2 部署到GitHub仓库</h3><p>之前的步骤中，我们已经完成了对Github账户的注册以及Github Pages的创建，接下来是将本地博客发布至Github Pages。</p><p>（1）安装发布插件，在站点目录下执行下面的命令，也就是创建的博客目录下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-deployer-git <span class="token parameter variable">--save</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）git配置GitHub邮箱用户名</p><pre class="line-numbers language-none"><code class="language-none">git config --global user.email "xxx" //设置邮箱 你的Github邮箱git config --global user.name "xxx" //设置用户名 你的Github名称<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）将本地目录和GitHub关联起来，输入下面命令行：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ssh-keygen <span class="token parameter variable">-t</span> rsa <span class="token parameter variable">-C</span> <span class="token string">"你的邮箱地址"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输入后一直回车，然后在<code>C:/Users/[username]</code>目录下找到名为<code>.ssh</code>的文件夹， 文件夹内会有两个文件，一个<code>id_rsa.pub</code>一个<code>id_rsa</code>，用文本编辑器打开<code>id_rsa.pub</code>，复制里面的的内容。 然后打开Github，点击右上角的头像 <strong>Settings</strong> 选择<strong>SSH and GPG keys</strong></p><p><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cf8.png" alt="08"></p><p>（4）点击<strong>New SSH key</strong> 将之前复制的内容粘帖到Key的框中。 上面的<strong>Title</strong>可以随意，点击<strong>Add SSH key</strong> 完成添加。</p><p><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cf7.png" alt="09"></p><p>（5）然后回到Git的命令行界面，测试一下是否与GitHub连接成功。输入下面的命令行：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">ssh</span> <span class="token parameter variable">-T</span> git@github.com<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>点击回车，然后会出现一个询问内容，输入<code>yes</code>，回车，会出现一段内容，<code>Hi &lt;account name&gt;! You've successfully authenticated, but GitHub doesnot provide shell access.</code>。 说明连接成功。此处这个<code>&lt;account name&gt;</code>应该是你Github的用户名。</p><p>（6）进入博客站点目录，用文本编辑器打开<code>_config.yml</code>，这个<code>_config.yml</code>是博客的配置文件，在以后的博客修改，如个性化修改，博客SEO优化等都会使用到，修改如下图的几个地方：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> 你的博客名<span class="token key atrule">subtitle</span><span class="token punctuation">:</span> 博客的副标题，有些主题支持<span class="token key atrule">description</span><span class="token punctuation">:</span> 博客描述<span class="token key atrule">keywords</span><span class="token punctuation">:</span> 博客关键词<span class="token key atrule">author</span><span class="token punctuation">:</span> 作者，在文章中显示<span class="token key atrule">language</span><span class="token punctuation">:</span> 博客语言语种   <span class="token key atrule">timezone</span><span class="token punctuation">:</span> 时区<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cf6.png" alt="10"></p><p>（7）在文件最底部，有一个deploy，在deploy下面添加我们的GitHub站点仓库信息。填入如下代码，并如下图所示：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">deploy</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> git  <span class="token key atrule">repo</span><span class="token punctuation">:</span> git@github.com<span class="token punctuation">:</span>Github用户名/github用户名.github.io.git   <span class="token key atrule">branch</span><span class="token punctuation">:</span> master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>repo：也可使用https地址，如：<code>https://github.com/Github用户名/Github用户名.github.io.git</code></p><p><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cf5.png" alt="11"></p><p>（8）最后回到终端执行下面命令，准备将页面发布到GitHub</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 清除之前生成静态页面</span>hexo clean<span class="token comment"># 根据配置文件渲染出一套静态页面</span>hexo g<span class="token comment"># 将上一步渲染出的一系列文件上传至至Github Pages</span>hexo d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上传完成后，在浏览器中打开<strong>https://&lt;用户名&gt;.github.io</strong>，查看上传的网页。如果页面变成了之前本地调试时的样子，说明上传已经完成了。</p><h2 id="三、Netlify建站"><a href="#三、Netlify建站" class="headerlink" title="三、Netlify建站"></a>三、Netlify建站</h2><h3 id="3-1-介绍"><a href="#3-1-介绍" class="headerlink" title="3.1 介绍"></a>3.1 介绍</h3><p>Netlify是一个国外的免费的提供静态网站部署服务的平台，能够将托管 GitHub，GitLab 等上的静态网站部署上线。至于我们为什么不使用<code>github</code>自带的<code>gitpage</code>，原因很简单，访问速度慢。此外，Netlify还有很多别的功能支持。</p><h3 id="3-2-建站步骤"><a href="#3-2-建站步骤" class="headerlink" title="3.2 建站步骤"></a>3.2 建站步骤</h3><ol><li><p>首先注册并登陆 <a href="https://app.netlify.com/">Netlify</a></p><ul><li>这一步需要能够科学上网，因为这是一个国外的网站</li><li>我们的博客在开启cloundflare的CDN加速之前，也只能通过科学上网的方式访问</li></ul></li><li><p>新建站点：</p><p>点击<code>Import an existing project</code>新建站点</p></li></ol><p><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cf9.png" alt="12"></p><ol start="3"><li>连接GitHub</li></ol><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d05.png" alt="13"></p><ol start="4"><li>选择我们的博客项目仓库</li></ol><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d06.png" alt="14"></p><ol start="5"><li>一切默认，最后点击如下按钮完成导入</li></ol><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d03.png" alt="15"></p><ol start="6"><li>完成后会得到一个URL，打开这个网址就是我们的个人博客了</li></ol><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d04.png" alt="16"></p><p>接下来先配置域名</p><h3 id="3-3-配置域名"><a href="#3-3-配置域名" class="headerlink" title="3.3 配置域名"></a>3.3 配置域名</h3><p>配置域名的前提自然是要购买域名了，从任意域名服务商处购买一个域名。</p><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d07.png" alt="17"></p><p>然后设置域名解析，类型为<code>CNAME</code>，内容为<code>xxxxx.netlify.app</code>，也就是我们刚刚建站给的域名。</p><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d08.png" alt="18"></p><p>设置完毕之后需要等待一段时间，因为DNS服务器需要一段时间来进行同步。</p><p>然后，我们还需要回到netlify中配置一下自己的用户域名，这样的话可以在国外获得netlify本身的CDN支持。</p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d10.png" alt="19"></p><p>输入我们配置的域名后，进行相关的配置，由于我们的域名本身已经配置了解析，这里会显示出来，不用再额外添加记录，只需要一路默认即可。最后点击Done即可</p><p>我们下面设置一下netlify本身的对于国外CDN的支持。下面箭头位置出点击<code>Set up Netlify DNS</code>，这里我已经设置过了所以显示的按钮不是这个。</p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d12.png" alt="20"></p><p>之后，我们就可以通过自己配置的域名访问自己的个人博客，比如说我的博客地址是：<a href="https://blog.ismoyu.cn/">https://blog.ismoyu.cn</a></p><p>但是，此刻我们的博客访问依然需要科学上网，因为我们还没有国内的CDN的支持，下面，我们来解决这个问题。</p><h2 id="四、ClouldFlare加速-解决国内加速问题"><a href="#四、ClouldFlare加速-解决国内加速问题" class="headerlink" title="四、ClouldFlare加速(解决国内加速问题)"></a>四、ClouldFlare加速(解决国内加速问题)</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>Netlify 虽然已经提供了 CDN 加速，但在使用过程中发现国内访问还是比较慢，Cloudflare 相对于国内的七牛云、阿里云等云服务商的 CDN 速度会慢一些，但是它有免费版本，而且最重要的是域名不用备案。</p><h3 id="加速步骤"><a href="#加速步骤" class="headerlink" title="加速步骤"></a>加速步骤</h3><ol><li>注册<a href="https://www.cloudflare.com/zh-cn/">Clouldflare</a>并登陆</li><li>添加站点</li></ol><p>进入主页，点击添加域</p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d0f.png" alt="21"></p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d11.png" alt="22"></p><ol start="3"><li><p>选择免费套餐</p></li><li><p>添加DNS记录</p></li></ol><p>和上面配置阿里云域名一样</p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d14.png" alt="23"></p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d13.png" alt="24"></p><ol start="5"><li>更改名称服务器</li></ol><ul><li>主要步骤是在你的域名服务商那里修改 dns 解析服务器为 cloudflare 提供的地址，修改完成后点击完成。</li></ul><p><img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d19.png" alt="25"></p><ul><li><p>以阿里云为例</p><ol><li><p>进入域名管理配置界面</p><p><img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d1b.png" alt="26"></p></li><li><p>将域名服务器从阿里云的默认服务器改成clouldflare的服务器</p><p><img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d16.png" alt="27"></p></li></ol></li></ul><p>配置完成后等待一段时间即可</p><h3 id="配置https"><a href="#配置https" class="headerlink" title="配置https"></a>配置https</h3><p>在clouldflare配置完成之后，我们可以回到netlify去配置一下https访问。</p><ol><li><p>先确认一下dns解析:</p><p><img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d17.png" alt="28"></p></li><li><p>自动安装证书</p></li></ol><p>   <img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d1a.png" alt="29"></p><ol start="3"><li><p>最后看到如下的界面，就说明https配置完成了:</p><p><img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d18.png" alt="30"></p></li></ol><p>最后测试站点，我们可以试着用自己的浏览器去访问自己配置的域名地址，如果在不科学上网的情况下能够正常看到我们自己的博客界面，那就证明我们的个人博客就配置成功了。</p><p>接下来就是关于博客主题的设置和一些个性化修改部分。</p><h2 id="五、博客主题安装以及一些个性化修改"><a href="#五、博客主题安装以及一些个性化修改" class="headerlink" title="五、博客主题安装以及一些个性化修改"></a>五、博客主题安装以及一些个性化修改</h2><p>官方默认主题很丑，那我们别的不做，首先来替换一个好看点的主题。</p><blockquote><p><a href="https://hexo.io/themes/">官方主题</a>：官方提供的各种主题</p></blockquote><p>Github、<a href="http://jekyllthemes.org/page3/">Jekyll Themes</a>上都能找到各种主题，我用的是<a href="https://github.com/blinkfox/hexo-theme-matery">Hexo matery</a>，就以此作为例子。</p><h3 id="5-1-主题下载和安装"><a href="#5-1-主题下载和安装" class="headerlink" title="5.1 主题下载和安装"></a>5.1 主题下载和安装</h3><p>进入我们博客根目录，在 <code>git bash</code> 输入以下命令下载主题：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/blinkfox/hexo-theme-matery.git themes/matery<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下载完成后，修改 Hexo 根目录下的 <code>_config.yml</code> 的 <code>theme</code> 的值：<code>theme: matery</code></p><h4 id="config-yml-文件的其它修改建议"><a href="#config-yml-文件的其它修改建议" class="headerlink" title="_config.yml 文件的其它修改建议:"></a><code>_config.yml</code> 文件的其它修改建议:</h4><ul><li>请修改 <code>_config.yml</code> 的 <code>url</code> 的值为你的网站主 <code>URL</code>（如：<code>http://xxx.github.io</code>）。</li><li>建议修改两个 <code>per_page</code> 的分页条数值为 <code>6</code> 的倍数，如：<code>12</code>、<code>18</code> 等，这样文章列表在各个屏幕下都能较好的显示。</li><li>如果你是中文用户，则建议修改 <code>language</code> 的值为 <code>zh-CN</code>。</li></ul><h3 id="5-2-新建分类-categories-页"><a href="#5-2-新建分类-categories-页" class="headerlink" title="5.2 新建分类 categories 页"></a>5.2 新建分类 categories 页</h3><p><code>categories</code> 页是用来展示所有分类的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>categories/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"categories"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/categories/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> categories<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"categories"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"categories"</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-3-新建标签-tags-页"><a href="#5-3-新建标签-tags-页" class="headerlink" title="5.3 新建标签 tags 页"></a>5.3 新建标签 tags 页</h3><p><code>tags</code> 页是用来展示所有标签的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>tags/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"tags"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/tags/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> tags<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 17:25:40</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"tags"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"tags"</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-4-新建关于我-about-页"><a href="#5-4-新建关于我-about-页" class="headerlink" title="5.4 新建关于我 about 页"></a>5.4 新建关于我 about 页</h3><p><code>about</code> 页是用来展示<strong>关于我和我的博客</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>about/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"about"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/about/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> about<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 17:25:40</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"about"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"about"</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-5-新建留言板-contact-页（可选的）"><a href="#5-5-新建留言板-contact-页（可选的）" class="headerlink" title="5.5 新建留言板 contact 页（可选的）"></a>5.5 新建留言板 contact 页（可选的）</h3><p><code>contact</code> 页是用来展示<strong>留言板</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>contact/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"contact"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/contact/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> contact<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"contact"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"contact"</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><strong>注</strong>：本留言板功能依赖于第三方评论系统，请<strong>激活</strong>你的评论系统才有效果。并且在主题的 <code>_config.yml</code> 文件中，第 <code>19</code> 至 <code>21</code> 行的“<strong>菜单</strong>”配置，取消关于留言板的注释即可。</p></blockquote><h3 id="5-6-新建友情链接-friends-页（可选的）"><a href="#5-6-新建友情链接-friends-页（可选的）" class="headerlink" title="5.6 新建友情链接 friends 页（可选的）"></a>5.6 新建友情链接 friends 页（可选的）</h3><p><code>friends</code> 页是用来展示<strong>友情链接</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>friends/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"friends"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/friends/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> friends<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"friends"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"friends"</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>同时，在你的博客 <code>source</code> 目录下新建 <code>_data</code> 目录，在 <code>_data</code> 目录中新建 <code>friends.json</code> 文件，文件内容如下所示：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">[</span><span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/1_qq_27922023.jpg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"码酱"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"我不是大佬，只是在追寻大佬的脚步"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"http://luokangyuan.com/"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/4027734.jpeg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"闪烁之狐"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"https://blinkfox.github.io/"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/avatar.jpg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"ja_rome"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"平凡的脚步也可以走出伟大的行程"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"https://me.csdn.net/jlh912008548"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-7-新建-404-页"><a href="#5-7-新建-404-页" class="headerlink" title="5.7 新建 404 页"></a>5.7 新建 404 页</h3><p>如果在你的博客 <code>source</code> 目录下还没有 <code>404.md</code> 文件，那么你就需要新建一个。编辑你刚刚新建的页面文件 <code>/source/404.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> <span class="token number">404</span><span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"404"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"404"</span><span class="token key atrule">description</span><span class="token punctuation">:</span> <span class="token string">"Oops～，我崩溃了！找不到你想要的页面 :("</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-8-菜单导航配置"><a href="#5-8-菜单导航配置" class="headerlink" title="5.8 菜单导航配置"></a>5.8 菜单导航配置</h3><h4 id="5-8-1-配置基本菜单导航的名称、路径url和图标icon"><a href="#5-8-1-配置基本菜单导航的名称、路径url和图标icon" class="headerlink" title="5.8.1 配置基本菜单导航的名称、路径url和图标icon."></a>5.8.1 配置基本菜单导航的名称、路径url和图标icon.</h4><p>1.菜单导航名称可以是中文也可以是英文(如：<code>Index</code>或<code>主页</code>) </p><p>2.图标icon 可以在<a href="https://fontawesome.com/icons">Font Awesome</a> 中查找</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">menu</span><span class="token punctuation">:</span>  <span class="token key atrule">Index</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>home  <span class="token key atrule">Tags</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /tags    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>tags  <span class="token key atrule">Categories</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /categories    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>bookmark  <span class="token key atrule">Archives</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /archives    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>archive  <span class="token key atrule">About</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /about    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>user<span class="token punctuation">-</span>circle  <span class="token key atrule">Friends</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /friends    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>address<span class="token punctuation">-</span>book<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="5-8-2-二级菜单配置方法"><a href="#5-8-2-二级菜单配置方法" class="headerlink" title="5.8.2 二级菜单配置方法"></a>5.8.2 二级菜单配置方法</h4><p>如果你需要二级菜单则可以在原基本菜单导航的基础上如下操作</p><ol><li>在需要添加二级菜单的一级菜单下添加<code>children</code>关键字(如:<code>About</code>菜单下添加<code>children</code>)</li><li>在<code>children</code>下创建二级菜单的 名称name,路径url和图标icon.</li><li>注意每个二级菜单模块前要加 <code>-</code>.</li><li>注意缩进格式</li></ol><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">menu</span><span class="token punctuation">:</span>  <span class="token key atrule">Index</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>home  <span class="token key atrule">Tags</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /tags    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>tags  <span class="token key atrule">Categories</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /categories    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>bookmark  <span class="token key atrule">Archives</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /archives    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>archive  <span class="token key atrule">About</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /about    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>user<span class="token punctuation">-</span>circle<span class="token punctuation">-</span>o  <span class="token key atrule">Friends</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /friends    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>address<span class="token punctuation">-</span>book  <span class="token key atrule">Medias</span><span class="token punctuation">:</span>    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>list    <span class="token key atrule">children</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Music        <span class="token key atrule">url</span><span class="token punctuation">:</span> /music        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>music      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Movies        <span class="token key atrule">url</span><span class="token punctuation">:</span> /movies        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>film      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Books        <span class="token key atrule">url</span><span class="token punctuation">:</span> /books        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>book      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Galleries        <span class="token key atrule">url</span><span class="token punctuation">:</span> /galleries        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>image<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-9-代码高亮"><a href="#5-9-代码高亮" class="headerlink" title="5.9 代码高亮"></a>5.9 代码高亮</h3><p>从 Hexo5.0 版本开始自带了 <code>prismjs</code> 代码语法高亮的支持，Matery主题对此进行了改造支持。</p><p>如果你的博客中曾经安装过 <code>hexo-prism-plugin</code> 的插件，那么你须要执行 <code>npm uninstall hexo-prism-plugin</code> 来卸载掉它，否则生成的代码中会有 <code>{</code> 和 <code>}</code> 的转义字符。</p><p>然后，修改你博客根目录下 <code>_config.yml</code> 文件中 <code>highlight.enable</code> 的值为 <code>false</code>，并将 <code>prismjs.enable</code> 的值设置为 <code>true</code>，主要配置如下：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">highlight</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">line_number</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">auto_detect</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">tab_replace</span><span class="token punctuation">:</span> <span class="token string">''</span>  <span class="token key atrule">wrap</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">hljs</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">prismjs</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">preprocess</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">line_number</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">tab_replace</span><span class="token punctuation">:</span> <span class="token string">''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>主题中默认的 <code>prismjs</code> 主题是 <code>Tomorrow Night</code>，如果你想定制自己的主题，可以前往 <a href="https://prismjs.com/download.html">prismjs 下载页面</a> 定制下载自己喜欢的主题 <code>css</code> 文件，然后将此 css 主题文件取名为 <code>prism.css</code>，替换掉 <code>matery</code> 主题文件夹中的 <code>source/libs/prism/prism.css</code> 文件即可。</p><h3 id="5-10-搜索"><a href="#5-10-搜索" class="headerlink" title="5.10 搜索"></a>5.10 搜索</h3><p>matery主题中还使用到了 <a href="https://github.com/wzpan/hexo-generator-search">hexo-generator-search</a> 的 Hexo 插件来做内容搜索，安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-search <span class="token parameter variable">--save</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在你博客目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">search</span><span class="token punctuation">:</span>  <span class="token key atrule">path</span><span class="token punctuation">:</span> search.xml  <span class="token key atrule">field</span><span class="token punctuation">:</span> post<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="5-11-中文链接转拼音（建议安装）"><a href="#5-11-中文链接转拼音（建议安装）" class="headerlink" title="5.11 中文链接转拼音（建议安装）"></a>5.11 中文链接转拼音（建议安装）</h3><p>如果你的文章名称是中文的，那么 Hexo 默认生成的永久链接也会有中文，这样不利于 <code>SEO</code>，且 <code>gitment</code> 评论对中文链接也不支持。我们可以用 <a href="https://github.com/viko16/hexo-permalink-pinyin">hexo-permalink-pinyin</a> Hexo 插件使在生成文章时生成中文拼音的永久链接。</p><p>安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> i hexo-permalink-pinyin <span class="token parameter variable">--save</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在你博客根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">permalink_pinyin</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">separator</span><span class="token punctuation">:</span> <span class="token string">'-'</span> <span class="token comment"># default: '-'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p><strong>注</strong>：除了此插件外，<a href="https://github.com/rozbo/hexo-abbrlink">hexo-abbrlink</a> 插件也可以生成非中文的链接。</p></blockquote><h3 id="5-12-文章字数统计插件（建议安装）"><a href="#5-12-文章字数统计插件（建议安装）" class="headerlink" title="5.12 文章字数统计插件（建议安装）"></a>5.12 文章字数统计插件（建议安装）</h3><p>如果你想要在文章中显示文章字数、阅读时长信息，可以安装 <a href="https://github.com/willin/hexo-wordcount">hexo-wordcount</a>插件。</p><p>安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> i <span class="token parameter variable">--save</span> hexo-wordcount<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后只需在主题 themes文件夹的matery文件夹下的 <code>_config.yml</code> 文件中，将各个文章字数相关的配置激活即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">postInfo</span><span class="token punctuation">:</span>  <span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">update</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">wordCount</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 设置文章字数统计为 true.</span>  <span class="token key atrule">totalCount</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 设置站点文章总字数统计为 true.</span>  <span class="token key atrule">min2read</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 阅读时长.</span>  <span class="token key atrule">readCount</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 阅读次数.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-13-添加emoji表情支持（可选的）"><a href="#5-13-添加emoji表情支持（可选的）" class="headerlink" title="5.13 添加emoji表情支持（可选的）"></a>5.13 添加emoji表情支持（可选的）</h3><p>本主题新增了对<code>emoji</code>表情的支持，使用到了 <a href="https://npm.taobao.org/package/hexo-filter-github-emojis">hexo-filter-github-emojis</a> 的 Hexo 插件来支持 <code>emoji</code>表情的生成，把对应的<code>markdown emoji</code>语法（<code>::</code>,例如：<code>:smile:</code>）转变成会跳跃的<code>emoji</code>表情，安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-filter-github-emojis <span class="token parameter variable">--save</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在你博客目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">githubEmojis</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">className</span><span class="token punctuation">:</span> github<span class="token punctuation">-</span>emoji  <span class="token key atrule">inject</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">styles</span><span class="token punctuation">:</span>  customEmojis<span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后就可以在文章中对应位置看到你用<code>emoji</code>语法写的表情了。</p><h3 id="5-14-添加-RSS-订阅支持（可选的）"><a href="#5-14-添加-RSS-订阅支持（可选的）" class="headerlink" title="5.14 添加 RSS 订阅支持（可选的）"></a>5.14 添加 RSS 订阅支持（可选的）</h3><p>本主题中还使用到了 <a href="https://github.com/hexojs/hexo-generator-feed">hexo-generator-feed</a> 的 Hexo 插件来做 <code>RSS</code>，安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-feed <span class="token parameter variable">--save</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在你博客目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">feed</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> atom  <span class="token key atrule">path</span><span class="token punctuation">:</span> atom.xml  <span class="token key atrule">limit</span><span class="token punctuation">:</span> <span class="token number">20</span>  <span class="token key atrule">hub</span><span class="token punctuation">:</span>  <span class="token key atrule">content</span><span class="token punctuation">:</span>  <span class="token key atrule">content_limit</span><span class="token punctuation">:</span> <span class="token number">140</span>  <span class="token key atrule">content_limit_delim</span><span class="token punctuation">:</span> <span class="token string">' '</span>  <span class="token key atrule">order_by</span><span class="token punctuation">:</span> <span class="token punctuation">-</span>date<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后在 <code>public</code> 文件夹中即可看到 <code>atom.xml</code> 文件，说明你已经安装成功了。</p><h3 id="5-15-修改页脚"><a href="#5-15-修改页脚" class="headerlink" title="5.15 修改页脚"></a>5.15 修改页脚</h3><p>页脚信息可能需要做定制化修改，而且它不便于做成配置信息，所以可能需要你自己去再修改和加工。修改的地方在主题文件的 <code>/layout/_partial/footer.ejs</code> 文件中，包括站点、使用的主题、访问量等。</p><h3 id="5-16-添加中文繁简转换"><a href="#5-16-添加中文繁简转换" class="headerlink" title="5.16 添加中文繁简转换"></a>5.16 添加中文繁简转换</h3><p>在主题的 <code>_config.yml</code> 文件中，开启 translate 为 enable。</p><blockquote><p>开启中文繁简转换如下修改。默认不开启。 实例演示： <a href="https://blog.17lai.site/">繁简转换</a> 底下 footer 栏</p></blockquote><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">translate</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="5-17-修改社交链接"><a href="#5-17-修改社交链接" class="headerlink" title="5.17 修改社交链接"></a>5.17 修改社交链接</h3><p>在主题的 <code>_config.yml</code> 文件中，默认支持 <code>QQ</code>、<code>GitHub</code> 和邮箱等的配置，你可以在主题文件的 <code>/layout/_partial/social-link.ejs</code> 文件中，新增、修改你需要的社交链接地址，增加链接可参考如下代码：</p><pre class="line-numbers language-ejs" data-language="ejs"><code class="language-ejs"><span class="token ejs language-ejs"><span class="token delimiter punctuation">&lt;%</span><span class="token language-javascript"> <span class="token keyword">if</span> <span class="token punctuation">(</span>theme<span class="token punctuation">.</span>socialLink<span class="token punctuation">.</span>github<span class="token punctuation">)</span> <span class="token punctuation">{</span> </span><span class="token delimiter punctuation">%&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span><span class="token ejs language-ejs"><span class="token delimiter punctuation">&lt;%=</span><span class="token language-javascript"> theme<span class="token punctuation">.</span>socialLink<span class="token punctuation">.</span>github </span><span class="token delimiter punctuation">%&gt;</span></span><span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>tooltipped<span class="token punctuation">"</span></span> <span class="token attr-name">target</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>_blank<span class="token punctuation">"</span></span> <span class="token attr-name">data-tooltip</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>访问我的GitHub<span class="token punctuation">"</span></span> <span class="token attr-name">data-position</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>top<span class="token punctuation">"</span></span> <span class="token attr-name">data-delay</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>50<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>i</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>fab fa-github<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>i</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">&gt;</span></span><span class="token ejs language-ejs"><span class="token delimiter punctuation">&lt;%</span><span class="token language-javascript"> <span class="token punctuation">}</span> </span><span class="token delimiter punctuation">%&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中，社交图标（如：<code>fa-github</code>）你可以在 <a href="https://fontawesome.com/icons">Font Awesome</a> 中搜索找到。以下是常用社交图标的标识，供你参考：</p><ul><li>Facebook: <code>fab fa-facebook</code></li><li>Twitter: <code>fab fa-twitter</code></li><li>Google-plus: <code>fab fa-google-plus</code></li><li>Linkedin: <code>fab fa-linkedin</code></li><li>Tumblr: <code>fab fa-tumblr</code></li><li>Medium: <code>fab fa-medium</code></li><li>Slack: <code>fab fa-slack</code></li><li>Sina Weibo: <code>fab fa-weibo</code></li><li>Wechat: <code>fab fa-weixin</code></li><li>QQ: <code>fab fa-qq</code></li><li>Zhihu: <code>fab fa-zhihu</code></li></ul><blockquote><p><strong>注意</strong>: 本主题中使用的 <code>Font Awesome</code> 版本为 <code>5.11.0</code>。</p></blockquote><h3 id="5-18-修改打赏的二维码图片"><a href="#5-18-修改打赏的二维码图片" class="headerlink" title="5.18 修改打赏的二维码图片"></a>5.18 修改打赏的二维码图片</h3><p>在主题文件的 <code>source/medias/reward</code> 文件中，你可以替换成你的的微信和支付宝的打赏二维码图片。</p><h3 id="5-19-配置音乐播放器（可选的）"><a href="#5-19-配置音乐播放器（可选的）" class="headerlink" title="5.19 配置音乐播放器（可选的）"></a>5.19 配置音乐播放器（可选的）</h3><p>要支持音乐播放，在主题的 <code>_config.yml</code> 配置文件中激活music配置即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment"># 是否在首页显示音乐</span><span class="token key atrule">music</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">title</span><span class="token punctuation">:</span>         <span class="token comment"># 非吸底模式有效</span>    <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>    <span class="token key atrule">show</span><span class="token punctuation">:</span> 听听音乐  <span class="token key atrule">server</span><span class="token punctuation">:</span> netease   <span class="token comment"># require music platform: netease, tencent, kugou, xiami, baidu</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> playlist    <span class="token comment"># require song, playlist, album, search, artist</span>  <span class="token key atrule">id</span><span class="token punctuation">:</span> <span class="token number">503838841</span>     <span class="token comment"># require song id / playlist id / album id / search keyword</span>  <span class="token key atrule">fixed</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>      <span class="token comment"># 开启吸底模式</span>  <span class="token key atrule">autoplay</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>   <span class="token comment"># 是否自动播放</span>  <span class="token key atrule">theme</span><span class="token punctuation">:</span> <span class="token string">'#42b983'</span>  <span class="token key atrule">loop</span><span class="token punctuation">:</span> <span class="token string">'all'</span>       <span class="token comment"># 音频循环播放, 可选值: 'all', 'one', 'none'</span>  <span class="token key atrule">order</span><span class="token punctuation">:</span> <span class="token string">'random'</span>   <span class="token comment"># 音频循环顺序, 可选值: 'list', 'random'</span>  <span class="token key atrule">preload</span><span class="token punctuation">:</span> <span class="token string">'auto'</span>   <span class="token comment"># 预加载，可选值: 'none', 'metadata', 'auto'</span>  <span class="token key atrule">volume</span><span class="token punctuation">:</span> <span class="token number">0.7</span>       <span class="token comment"># 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效</span>  <span class="token key atrule">listFolded</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token comment"># 列表默认折叠</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><code>server</code>可选<code>netease</code>（网易云音乐），<code>tencent</code>（QQ音乐），<code>kugou</code>（酷狗音乐），<code>xiami</code>（虾米音乐），<code>baidu</code>（百度音乐）。</p><p><code>type</code>可选<code>song</code>（歌曲），<code>playlist</code>（歌单），<code>album</code>（专辑），<code>search</code>（搜索关键字），<code>artist</code>（歌手）。</p><p><code>id</code>获取方法示例: 浏览器打开网易云音乐，点击我喜欢的音乐歌单，浏览器地址栏后面会有一串数字，<code>playlist</code>的<code>id</code>即为这串数字。</p></blockquote><h3 id="5-20-文章-Front-matter-介绍"><a href="#5-20-文章-Front-matter-介绍" class="headerlink" title="5.20 文章 Front-matter 介绍"></a>5.20 文章 Front-matter 介绍</h3><p>Front-matter 选项详解</p><p><code>Front-matter</code> 选项中的所有内容均为<strong>非必填</strong>的。但我仍然建议至少填写 <code>title</code> 和 <code>date</code> 的值。</p><table><thead><tr><th>配置选项</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>title</td><td><code>Markdown</code> 的文件标题</td><td>文章标题，强烈建议填写此选项</td></tr><tr><td>date</td><td>文件创建时的日期时间</td><td>发布时间，强烈建议填写此选项，且最好保证全局唯一</td></tr><tr><td>author</td><td>根 <code>_config.yml</code> 中的 <code>author</code></td><td>文章作者</td></tr><tr><td>img</td><td><code>featureImages</code> 中的某个值</td><td>文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径.如: <code>http://xxx.com/xxx.jpg</code></td></tr><tr><td>top</td><td><code>true</code></td><td>推荐文章（文章是否置顶），如果 <code>top</code> 值为 <code>true</code>，则会作为首页推荐文章</td></tr><tr><td>hide</td><td><code>false</code></td><td>隐藏文章，如果<code>hide</code>值为<code>true</code>，则文章不会在首页显示</td></tr><tr><td>cover</td><td><code>false</code></td><td><code>v1.0.2</code>版本新增，表示该文章是否需要加入到首页轮播封面中</td></tr><tr><td>coverImg</td><td>无</td><td><code>v1.0.2</code>版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td></tr><tr><td>password</td><td>无</td><td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 <code>password</code> 的值，该值必须是用 <code>SHA256</code> 加密后的密码，防止被他人识破。前提是在主题的 <code>config.yml</code> 中激活了 <code>verifyPassword</code> 选项</td></tr><tr><td>toc</td><td><code>true</code></td><td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 <code>config.yml</code> 中激活了 <code>toc</code> 选项</td></tr><tr><td>mathjax</td><td><code>false</code></td><td>是否开启数学公式支持 ，本文章是否开启 <code>mathjax</code>，且需要在主题的 <code>_config.yml</code> 文件中也需要开启才行</td></tr><tr><td>summary</td><td>无</td><td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td></tr><tr><td>categories</td><td>无</td><td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td></tr><tr><td>tags</td><td>无</td><td>文章标签，一篇文章可以多个标签</td></tr><tr><td>keywords</td><td>文章标题</td><td>文章关键字，SEO 时需要</td></tr><tr><td>reprintPolicy</td><td>cc_by</td><td>文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td></tr></tbody></table><blockquote><p><strong>注意</strong>:</p><ol><li>如果 <code>img</code> 属性不填写的话，文章特色图会根据文章标题的 <code>hashcode</code> 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章的特色图<strong>各有特色</strong>。</li><li><code>date</code> 的值尽量保证每篇文章是唯一的，因为本主题中 <code>Gitalk</code> 和 <code>Gitment</code> 识别 <code>id</code> 是通过 <code>date</code> 的值来作为唯一标识的。</li><li>如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 <code>_config.yml</code> 中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：<a href="http://tool.oschina.net/encrypt?type=2">开源中国在线工具</a>、<a href="http://encode.chahuo.com/">chahuo</a>、<a href="http://tool.chinaz.com/tools/hash.aspx">站长工具</a>。</li><li>您可以在文章md文件的 front-matter 中指定 reprintPolicy 来给单个文章配置转载规则</li></ol></blockquote><p>以下为文章的 <code>Front-matter</code> 示例。</p><h4 id="最简示例"><a href="#最简示例" class="headerlink" title="最简示例"></a>最简示例</h4><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> typora<span class="token punctuation">-</span>vue<span class="token punctuation">-</span>theme主题介绍<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-07 09:25:00</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="最全示例"><a href="#最全示例" class="headerlink" title="最全示例"></a>最全示例</h4><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> hexo<span class="token punctuation">-</span>github搭建个人博客教程<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 09:25:00</span><span class="token key atrule">author</span><span class="token punctuation">:</span> 墨宇Logic<span class="token key atrule">img</span><span class="token punctuation">:</span> /source/images/xxx.jpg<span class="token key atrule">top</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">hide</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">cover</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">coverImg</span><span class="token punctuation">:</span> /images/1.jpg<span class="token key atrule">password</span><span class="token punctuation">:</span> 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92<span class="token key atrule">toc</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">mathjax</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">summary</span><span class="token punctuation">:</span> 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要<span class="token key atrule">categories</span><span class="token punctuation">:</span> Markdown<span class="token key atrule">tags</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> Typora  <span class="token punctuation">-</span> Markdown</span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="新建文章模板修改"><a href="#新建文章模板修改" class="headerlink" title="新建文章模板修改"></a>新建文章模板修改</h4><p>首先为了新建文章方便，我们可以修改一下文章模板，建议将<code>/scaffolds/post.md</code>修改为如下代码：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">{</span> title <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">{</span> date <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token key atrule">author</span><span class="token punctuation">:</span> <span class="token key atrule">img</span><span class="token punctuation">:</span> <span class="token key atrule">coverImg</span><span class="token punctuation">:</span> <span class="token key atrule">top</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">cover</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">toc</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">mathjax</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">password</span><span class="token punctuation">:</span><span class="token key atrule">summary</span><span class="token punctuation">:</span><span class="token key atrule">tags</span><span class="token punctuation">:</span><span class="token key atrule">categories</span><span class="token punctuation">:</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样新建文章后 一些<code>Front-matter</code>参数不用你自己补充了，修改对应信息就可以了。</p><h3 id="自定制修改"><a href="#自定制修改" class="headerlink" title="自定制修改"></a>自定制修改</h3><p>在本主题的 <code>_config.yml</code> 中可以修改部分自定义信息，有以下几个部分：</p><ul><li>菜单</li><li>我的梦想</li><li>首页的音乐播放器和视频播放器配置</li><li>是否显示推荐文章名称和按钮配置</li><li><code>favicon</code> 和 <code>Logo</code></li><li>个人信息</li><li>TOC 目录</li><li>文章打赏信息</li><li>复制文章内容时追加版权信息</li><li>MathJax</li><li>文章字数统计、阅读时长</li><li>点击页面的’爱心’效果</li><li>我的项目</li><li>我的技能</li><li>我的相册</li><li><code>Gitalk</code>、<code>Gitment</code>、<code>Valine</code> 和 <code>disqus</code> 评论配置</li><li><a href="http://busuanzi.ibruce.info/">不蒜子统计</a>和谷歌分析（<code>Google Analytics</code>）</li><li>默认特色图的集合。当文章没有设置特色图时，本主题会根据文章标题的 <code>hashcode</code> 值取余，来选择展示对应的特色图</li></ul><p><strong>我认为个人博客应该都有自己的风格和特色</strong>。如果本主题中的诸多功能和主题色彩你不满意，可以在主题中自定义修改，很多更自由的功能和细节点的修改难以在主题的 <code>_config.yml</code> 中完成，需要修改源代码才来完成。以下列出了可能对你有用的地方：</p><h3 id="修改主题颜色"><a href="#修改主题颜色" class="headerlink" title="修改主题颜色"></a>修改主题颜色</h3><p>在主题文件的 <code>/source/css/matery.css</code> 文件中，搜索 <code>.bg-color</code> 来修改背景颜色：</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token comment">/* 整体背景颜色，包括导航、移动端的导航、页尾、标签页等的背景颜色. */</span><span class="token selector">.bg-color</span> <span class="token punctuation">{</span>    <span class="token property">background-image</span><span class="token punctuation">:</span> <span class="token function">linear-gradient</span><span class="token punctuation">(</span>to right<span class="token punctuation">,</span> #4cbf30 0%<span class="token punctuation">,</span> #0f9d58 100%<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token atrule"><span class="token rule">@-webkit-keyframes</span> rainbow</span> <span class="token punctuation">{</span>   <span class="token comment">/* 动态切换背景颜色. */</span><span class="token punctuation">}</span><span class="token atrule"><span class="token rule">@keyframes</span> rainbow</span> <span class="token punctuation">{</span>    <span class="token comment">/* 动态切换背景颜色. */</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="修改-banner-图和文章特色图"><a href="#修改-banner-图和文章特色图" class="headerlink" title="修改 banner 图和文章特色图"></a>修改 banner 图和文章特色图</h3><p>你可以直接在 <code>/source/medias/banner</code> 文件夹中更换你喜欢的 <code>banner</code> 图片，主题代码中是每天动态切换一张，只需 <code>7</code> 张即可。如果你会 <code>JavaScript</code> 代码，可以修改成你自己喜欢切换逻辑，如：随机切换等，<code>banner</code> 切换的代码位置在 <code>/layout/_partial/bg-cover-content.ejs</code> 文件的 <code>&lt;script&gt;&lt;/script&gt;</code> 代码中：</p><pre class="line-numbers language-ejs" data-language="ejs"><code class="language-ejs">$('.bg-cover').css('background-image', 'url(/medias/banner/' + new Date().getDay() + '.jpg)');<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在 <code>/source/medias/featureimages</code> 文件夹中默认有 24 张特色图片，你可以再增加或者减少，并需要在 <code>_config.yml</code> 做同步修改。</p><h3 id="图床"><a href="#图床" class="headerlink" title="图床"></a>图床</h3><p>当博文中有图片时，若是少量图片，可以直接把图片存放在 <code>source</code> 文件夹中，但这显然不合理的，因为图片会占据大量的存储的空间，加载的时候相对缓慢 ，这时考虑把博文里的图片上传到某一网站，然后获得外部链接，使用 <code>Markdown</code> 语法，<code>![图片信息](外部链接)</code> 完成图片的插入，这种网站就被成为图床。</p><p>我用的图床：<a href="https://www.superbed.cn/">聚合图床</a></p><h2 id="六、博客维护"><a href="#六、博客维护" class="headerlink" title="六、博客维护"></a>六、博客维护</h2><p>到此为止，我们的个人博客就彻底搭建完成啦。后续我们只需要修改博客的配置文件和博客本身的markdown源文件，然后执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo clean <span class="token operator">&amp;&amp;</span> hexo g <span class="token operator">&amp;&amp;</span> hexo d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样我们就能将我们修改后的内容上传到GitHub，然后Netlify会自动同步，将生成在public文件夹中的静态网页部署出去。</p>]]></content>
      
      
      <categories>
          
          <category> 博客搭建教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> css </tag>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
