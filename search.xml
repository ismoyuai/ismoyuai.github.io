<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>【项目实战】基于RAG的法律条文智能助手</title>
      <link href="/xiang-mu-shi-zhan-ji-yu-rag-de-fa-lu-tiao-wen-zhi-neng-zhu-shou/"/>
      <url>/xiang-mu-shi-zhan-ji-yu-rag-de-fa-lu-tiao-wen-zhi-neng-zhu-shou/</url>
      
        <content type="html"><![CDATA[<h2 id="一、项目目标"><a href="#一、项目目标" class="headerlink" title="一、项目目标"></a><strong>一、项目目标</strong></h2><ul><li>掌握法律智能问答系统的需求分析与RAG技术选型逻辑  </li><li>学会法律条文数据爬取、清洗与结构化处理  </li><li>实现RAG与Lora微调结合的模型优化方案</li></ul><h2 id="二、项目内容与重点"><a href="#二、项目内容与重点" class="headerlink" title="二、项目内容与重点"></a><strong>二、项目内容与重点</strong></h2><h3 id="2-1-项目背景与需求设计"><a href="#2-1-项目背景与需求设计" class="headerlink" title="2.1 项目背景与需求设计"></a><strong>2.1 项目背景与需求设计</strong></h3><p><strong>核心需求</strong></p><ul><li>场景：法律条文智能问答系统，需满足：  <ul><li>每月更新最新法律条文  </li><li>支持条款精准引用（如“《劳动法》第36条”）  </li><li>处理复杂查询（如劳动纠纷中的多条款关联分析）</li></ul></li></ul><p><strong>技术选型：RAG vs 微调</strong></p><table><thead><tr><th>对比维度</th><th>RAG方案</th><th>微调方案</th></tr></thead><tbody><tr><td>数据更新频率</td><td>支持动态更新知识库</td><td>需要重新标注并训练模型</td></tr><tr><td>内容准确性</td><td>直接引用原文，避免生成失真</td><td>依赖标注质量，易产生偏差</td></tr><tr><td>知识覆盖范围</td><td>适合大规模知识体系</td><td>需要海量标注数据</td></tr><tr><td>可解释性</td><td>支持条款溯源，符合法律严谨性</td><td>黑盒模型，解释性差</td></tr></tbody></table><p><strong>重点：</strong> RAG在动态更新和可解释性上的优势。</p><hr><h3 id="2-2-核心实现流程"><a href="#2-2-核心实现流程" class="headerlink" title="2.2 核心实现流程"></a><strong>2.2 核心实现流程</strong></h3><p>流程图：</p><pre class="line-numbers language-none"><code class="language-none">用户提问 -&gt; 问题解析 -&gt; RAG检索 -&gt; 生成答案 -&gt; 引用溯源<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>关键模块</strong><br><strong>1.RAG检索层</strong><br>- 使用微调后的通用大模型<br>- 知识库构建：结构化法律条文（JSON格式）<br><strong>2.数据更新模块</strong><br>- 定时爬取政府官网最新法规<br>- 自动化解析条款（正则匹配 第[一二三四…]条 ）<br><strong>重点：</strong> RAG与邻域微调的结合策略。</p><h3 id="2-3-系统和环境"><a href="#2-3-系统和环境" class="headerlink" title="2.3 系统和环境"></a><strong>2.3 系统和环境</strong></h3><ul><li>系统：Windows11 + WSL2-Linux-Ubuntu22.04子系统</li><li>硬件：GeForce RTX 4060 Ti 16GB</li></ul><h3 id="2-4-技术栈选型说明（LLM-向量数据库-框架选择）"><a href="#2-4-技术栈选型说明（LLM-向量数据库-框架选择）" class="headerlink" title="2.4 技术栈选型说明（LLM/向量数据库/框架选择）"></a><strong>2.4 技术栈选型说明（LLM/向量数据库/框架选择）</strong></h3><ul><li>LLM模型：Qwen1.5-4B-Chat</li><li>嵌入式模型和检索模型：text2vec-base-chinese-sentence/BAAI\bge-reranker-large</li><li>RAG框架：LlamaIndex</li><li>推理引擎：vLLM/LMDeploy</li><li>前端界面框架：Streamlit界面深度集成</li></ul><hr><h2 id="三、数据收集与整理"><a href="#三、数据收集与整理" class="headerlink" title="三、数据收集与整理"></a><strong>三、数据收集与整理</strong></h2><h3 id="3-1-源数据获取"><a href="#3-1-源数据获取" class="headerlink" title="3.1 源数据获取"></a><strong>3.1 源数据获取</strong></h3><p>通过到政府相关法律界面爬取。</p><p>关键代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requests  <span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup<span class="token comment"># 网页爬取与解析</span><span class="token keyword">def</span> <span class="token function">fetch_and_parse</span><span class="token punctuation">(</span>url<span class="token punctuation">)</span><span class="token punctuation">:</span>   soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>   content <span class="token operator">=</span> <span class="token punctuation">[</span>para<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span>strip<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token keyword">for</span> para <span class="token keyword">in</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token string">'p'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>          <span class="token keyword">return</span> <span class="token string">'\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-2-数据清洗整理"><a href="#3-2-数据清洗整理" class="headerlink" title="3.2 数据清洗整理"></a><strong>3.2 数据清洗整理</strong></h3><p>我们获取到的数据还不能直接使用，需要进一步筛选整理，可以通过正则表达式。</p><p>关键代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 条款提取（正则表达式）</span>pattern <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">r'第([一二三四五六七八九十零百]+)条.*?(?=\n第|$)'</span><span class="token punctuation">,</span> re<span class="token punctuation">.</span>DOTALL<span class="token punctuation">)</span><span class="token keyword">for</span> <span class="token keyword">match</span> <span class="token keyword">in</span> pattern<span class="token punctuation">.</span>finditer<span class="token punctuation">(</span>data_str<span class="token punctuation">)</span><span class="token punctuation">:</span>   lawarticles<span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"法律名称 第</span><span class="token interpolation"><span class="token punctuation">{</span>articlenumber<span class="token punctuation">}</span></span><span class="token string">条"</span></span><span class="token punctuation">]</span> <span class="token operator">=</span> articlecontent<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-3-数据规范化"><a href="#3-3-数据规范化" class="headerlink" title="3.3 数据规范化"></a><strong>3.3 数据规范化</strong></h3><p>最后将数据按照要求统一规范格式。</p><p>规范格式如下：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span> <span class="token property">"中华人民共和国劳动法 第36条"</span><span class="token operator">:</span> <span class="token string">"用人单位因生产经营需要..."</span><span class="token punctuation">,</span> <span class="token property">"中华人民共和国劳动合同法 第10条"</span><span class="token operator">:</span> <span class="token string">"建立劳动关系应当订立书面劳动合同..."</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>核心代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 初始化字典来存储条款号和内容  </span>lawarticles <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>  <span class="token comment"># 搜索所有匹配项  </span><span class="token keyword">for</span> <span class="token keyword">match</span> <span class="token keyword">in</span> pattern<span class="token punctuation">.</span>finditer<span class="token punctuation">(</span>data_str<span class="token punctuation">)</span><span class="token punctuation">:</span>      articlenumber <span class="token operator">=</span> <span class="token keyword">match</span><span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>      articlecontent <span class="token operator">=</span> <span class="token keyword">match</span><span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'第'</span> <span class="token operator">+</span> articlenumber <span class="token operator">+</span> <span class="token string">'条'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>      lawarticles<span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"中华人民共和国劳动合同法 第</span><span class="token interpolation"><span class="token punctuation">{</span>articlenumber<span class="token punctuation">}</span></span><span class="token string">条"</span></span><span class="token punctuation">]</span> <span class="token operator">=</span> articlecontent<span class="token comment"># 转换字典为JSON字符串  </span>jsonstr <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>lawarticles<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><hr><h2 id="四、RAG基础实现与优化"><a href="#四、RAG基础实现与优化" class="headerlink" title="四、RAG基础实现与优化"></a><strong>四、RAG基础实现与优化</strong></h2><h3 id="4-1-RAG-基本流程"><a href="#4-1-RAG-基本流程" class="headerlink" title="4.1 RAG 基本流程"></a><strong>4.1 RAG 基本流程</strong></h3><ol><li>知识准备：收集并转换知识文档为文本数据，进行预处理和索引。</li><li>嵌入与索引：使用嵌入模型将文本转换为向量，并存储在向量数据库中。</li><li>查询检索：用户查询转换为向量，从数据库中检索相关知识。</li><li>提示增强：结合检索结果构建增强提示模版。</li><li>生成回答：大语言模型根据增强模版生成准确回答。</li></ol><p>基本流程：</p><pre class="line-numbers language-none"><code class="language-none">知识库 -&gt; 数据处理 -&gt; 向量化 -&gt; 向量存储 -&gt; 用户问题向量化 -&gt; 向量检索 -&gt; 合并检索数据和用户问题 -&gt; 传入大模型生成答案<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-核心代码"><a href="#4-2-核心代码" class="headerlink" title="4.2 核心代码"></a><strong>4.2 核心代码</strong></h3><h4 id="4-2-1-模型初始化"><a href="#4-2-1-模型初始化" class="headerlink" title="4.2.1 模型初始化"></a>4.2.1 模型初始化</h4><p>创建一个 <code>ModelInitializer</code> 模型管理类，管理以及初始化我们的 LLM、Embedding、reranker 模型</p><p>核心代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># ========= def init_models =========</span><span class="token comment"># 初始化LLM（使用OpenAILike）</span>llm <span class="token operator">=</span> OpenAILike<span class="token punctuation">(</span>      model<span class="token operator">=</span>Config<span class="token punctuation">.</span>LLM_MODEL_PATH<span class="token punctuation">,</span>      api_base<span class="token operator">=</span>config<span class="token punctuation">.</span>API_BASE<span class="token punctuation">,</span>      api_key<span class="token operator">=</span>Config<span class="token punctuation">.</span>API_KEY<span class="token punctuation">,</span>      context_window<span class="token operator">=</span><span class="token number">4096</span><span class="token punctuation">,</span>      is_chat_model<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>      is_function_calling_model<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token punctuation">)</span><span class="token comment"># 初始化嵌入模型  </span>embed_model <span class="token operator">=</span> HuggingFaceEmbedding<span class="token punctuation">(</span>      model_name<span class="token operator">=</span>Config<span class="token punctuation">.</span>EMBED_MODEL_PATH<span class="token punctuation">,</span>  <span class="token punctuation">)</span><span class="token comment"># 初始化重排序器  </span>reranker <span class="token operator">=</span> SentenceTransformerRerank<span class="token punctuation">(</span>      model<span class="token operator">=</span>Config<span class="token punctuation">.</span>RERANK_MODEL_PATH<span class="token punctuation">,</span>      top_n<span class="token operator">=</span>Config<span class="token punctuation">.</span>RERANK_TOP_K  <span class="token punctuation">)</span><span class="token comment"># 全局设置  </span>Settings<span class="token punctuation">.</span>embed_model <span class="token operator">=</span> embed_model  Settings<span class="token punctuation">.</span>llm <span class="token operator">=</span> llm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="4-2-2-数据处理以及自定义node节点"><a href="#4-2-2-数据处理以及自定义node节点" class="headerlink" title="4.2.2 数据处理以及自定义node节点"></a>4.2.2 数据处理以及自定义node节点</h4><p>创建一个 <code>DataProcessor</code> ，并定义两个方法，分别是<br><code>load_and_validate_json</code>加载并验证法律JSON文件，以及 <code>create_nodes</code> 自定义节点方法。<br><code>load_and_validate_json</code> 核心代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">all_data<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">{</span>                      <span class="token string">"content"</span><span class="token punctuation">:</span> item<span class="token punctuation">,</span>                      <span class="token string">"metadata"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"source"</span><span class="token punctuation">:</span> json_file<span class="token punctuation">.</span>name<span class="token punctuation">}</span>                  <span class="token punctuation">}</span> <span class="token keyword">for</span> item <span class="token keyword">in</span> data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>加载JSON文件后，取两个值然存放到列表，最后返回列表的值。</p><p> <code>create_nodes</code> 核心代码：<br> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">nodes <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token keyword">for</span> entry <span class="token keyword">in</span> raw_data<span class="token punctuation">:</span>      law_dict <span class="token operator">=</span> entry<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span>      source_file <span class="token operator">=</span> entry<span class="token punctuation">[</span><span class="token string">"metadata"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"source"</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> full_title<span class="token punctuation">,</span> content <span class="token keyword">in</span> law_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>          node_id <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>source_file<span class="token punctuation">}</span></span><span class="token string">::</span><span class="token interpolation"><span class="token punctuation">{</span>full_title<span class="token punctuation">}</span></span><span class="token string">"</span></span>          parts <span class="token operator">=</span> full_title<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>            node <span class="token operator">=</span> TextNode<span class="token punctuation">(</span>              text<span class="token operator">=</span>content<span class="token punctuation">,</span>              id_<span class="token operator">=</span>node_id<span class="token punctuation">,</span>              metadata<span class="token operator">=</span><span class="token punctuation">{</span>                  <span class="token string">"law_name"</span><span class="token punctuation">:</span> parts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">if</span> parts <span class="token keyword">else</span> <span class="token string">"未知法律"</span><span class="token punctuation">,</span>                  <span class="token string">"article"</span><span class="token punctuation">:</span> parts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parts<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">"未知条款"</span><span class="token punctuation">,</span>                  <span class="token string">"full_title"</span><span class="token punctuation">:</span> full_title<span class="token punctuation">,</span>                  <span class="token string">"source_file"</span><span class="token punctuation">:</span> source_file<span class="token punctuation">,</span>                  <span class="token string">"content_type"</span><span class="token punctuation">:</span> <span class="token string">"legal_article"</span>              <span class="token punctuation">}</span>          <span class="token punctuation">)</span>        nodes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>node<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p><p>接受<code>load_and_validate_json</code>  返回的列表后，进行遍历，然后提取所需信息，存放到列表中，最后返回列表的值。</p><p>我们测试输出生成的node节点前三条信息看看：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json">生成 <span class="token number">205</span> 个文本节点（示例ID：<span class="token punctuation">[</span>TextNode(id_='中华人民共和国劳动法及劳动合同法.json<span class="token operator">:</span><span class="token operator">:</span>中华人民共和国劳动合同法 第一条'<span class="token punctuation">,</span> embedding=None<span class="token punctuation">,</span> metadata=<span class="token punctuation">{</span>'law_name'<span class="token operator">:</span> '中华人民共和国劳动合同法'<span class="token punctuation">,</span> 'article'<span class="token operator">:</span> '第一条'<span class="token punctuation">,</span> 'full_title'<span class="token operator">:</span> '中华人民共和国劳动合同法 第一条'<span class="token punctuation">,</span> 'source_file'<span class="token operator">:</span> 'data1.json'<span class="token punctuation">,</span> 'content_type'<span class="token operator">:</span> 'legal_article'<span class="token punctuation">}</span><span class="token punctuation">,</span> excluded_embed_metadata_keys=<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> excluded_llm_metadata_keys=<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> relationships=<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> metadata_template='<span class="token punctuation">{</span>key<span class="token punctuation">}</span><span class="token operator">:</span> <span class="token punctuation">{</span>value<span class="token punctuation">}</span>'<span class="token punctuation">,</span> metadata_separator='\n'<span class="token punctuation">,</span> text='为了完善劳动合同制度，明确劳动合同双方当事人的权利和义务，保护劳动者的合法权益，构建和发展和谐稳定的劳动关系，制定本法。'<span class="token punctuation">,</span> mimetype='text/plain'<span class="token punctuation">,</span> start_char_idx=None<span class="token punctuation">,</span> end_char_idx=None<span class="token punctuation">,</span> metadata_seperator='\n'<span class="token punctuation">,</span> text_template='<span class="token punctuation">{</span>metadata_str<span class="token punctuation">}</span>\n\n<span class="token punctuation">{</span>content<span class="token punctuation">}</span>')<span class="token punctuation">,</span> TextNode(id_='data1.json<span class="token operator">:</span><span class="token operator">:</span>中华人民共和国劳动合同法 第二条'<span class="token punctuation">,</span> embedding=None<span class="token punctuation">,</span> metadata=<span class="token punctuation">{</span>'law_name'<span class="token operator">:</span> '中华人民共和国劳动合同法'<span class="token punctuation">,</span> 'article'<span class="token operator">:</span> '第二条'<span class="token punctuation">,</span> 'full_title'<span class="token operator">:</span> '中华人民共和国劳动合同法 第二条'<span class="token punctuation">,</span> 'source_file'<span class="token operator">:</span> 'data1.json'<span class="token punctuation">,</span> 'content_type'<span class="token operator">:</span> 'legal_article'<span class="token punctuation">}</span><span class="token punctuation">,</span> excluded_embed_metadata_keys=<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> excluded_llm_metadata_keys=<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> relationships=<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> metadata_template='<span class="token punctuation">{</span>key<span class="token punctuation">}</span><span class="token operator">:</span> <span class="token punctuation">{</span>value<span class="token punctuation">}</span>'<span class="token punctuation">,</span> metadata_separator='\n'<span class="token punctuation">,</span> text='中华人民共和国境内的企业、个体经济组织、民办非企业单位等组织（以下称用人单位）与劳动者建立劳动关系，订立、履行、变更、解除或者终止劳动合同，适用本法。\n国家机关、事业单位、社会团体和与其建立劳动关系的劳动者，订立、履行、变更、解除或者终止劳动合同，依照本法执行。'<span class="token punctuation">,</span> mimetype='text/plain'<span class="token punctuation">,</span> start_char_idx=None<span class="token punctuation">,</span> end_char_idx=None<span class="token punctuation">,</span> metadata_seperator='\n'<span class="token punctuation">,</span> text_template='<span class="token punctuation">{</span>metadata_str<span class="token punctuation">}</span>\n\n<span class="token punctuation">{</span>content<span class="token punctuation">}</span>')<span class="token punctuation">,</span> TextNode(id_='data1.json<span class="token operator">:</span><span class="token operator">:</span>中华人民共和国劳动合同法 第三条'<span class="token punctuation">,</span> embedding=None<span class="token punctuation">,</span> metadata=<span class="token punctuation">{</span>'law_name'<span class="token operator">:</span> '中华人民共和国劳动合同法'<span class="token punctuation">,</span> 'article'<span class="token operator">:</span> '第三条'<span class="token punctuation">,</span> 'full_title'<span class="token operator">:</span> '中华人民共和国劳动合同法 第三条'<span class="token punctuation">,</span> 'source_file'<span class="token operator">:</span> 'data1.json'<span class="token punctuation">,</span> 'content_type'<span class="token operator">:</span> 'legal_article'<span class="token punctuation">}</span><span class="token punctuation">,</span> excluded_embed_metadata_keys=<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> excluded_llm_metadata_keys=<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> relationships=<span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> metadata_template='<span class="token punctuation">{</span>key<span class="token punctuation">}</span><span class="token operator">:</span> <span class="token punctuation">{</span>value<span class="token punctuation">}</span>'<span class="token punctuation">,</span> metadata_separator='\n'<span class="token punctuation">,</span> text='订立劳动合同，应当遵循合法、公平、平等自愿、协商一致、诚实信用的原则。\n依法订立的劳动合同具有约束力，用人单位与劳动者应当履行劳动合同约定的义务。'<span class="token punctuation">,</span> mimetype='text/plain'<span class="token punctuation">,</span> start_char_idx=None<span class="token punctuation">,</span> end_char_idx=None<span class="token punctuation">,</span> metadata_seperator='\n'<span class="token punctuation">,</span> text_template='<span class="token punctuation">{</span>metadata_str<span class="token punctuation">}</span>\n\n<span class="token punctuation">{</span>content<span class="token punctuation">}</span>')<span class="token punctuation">]</span>）<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="4-2-3-向量化自定义node节点"><a href="#4-2-3-向量化自定义node节点" class="headerlink" title="4.2.3 向量化自定义node节点"></a>4.2.3 向量化自定义node节点</h4><p>我们创建好知识库数据的nodes节点后，准备开始用embedding模型进行向量化处理，创建索引并持久化保存到本地。</p><p>创建 <code>VectorStoreManager</code> 类来进行向量操作存储管理</p><p>核心代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># ========= def __init__ =========</span>self<span class="token punctuation">.</span>chroma_client <span class="token operator">=</span> chromadb<span class="token punctuation">.</span>PersistentClient<span class="token punctuation">(</span>path<span class="token operator">=</span>Config<span class="token punctuation">.</span>VECTOR_DB_DIR<span class="token punctuation">)</span>  self<span class="token punctuation">.</span>collection <span class="token operator">=</span> self<span class="token punctuation">.</span>chroma_client<span class="token punctuation">.</span>get_or_create_collection<span class="token punctuation">(</span>      name<span class="token operator">=</span>Config<span class="token punctuation">.</span>COLLECTION_NAME<span class="token punctuation">,</span>      metadata<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"hnsw:space"</span><span class="token punctuation">:</span> <span class="token string">"cosine"</span><span class="token punctuation">}</span>  <span class="token punctuation">)</span><span class="token comment"># ========= def init_index =========</span><span class="token triple-quoted-string string">"""初始化或加载向量索引"""</span><span class="token keyword">if</span> self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> nodes<span class="token punctuation">:</span>      <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"创建新索引（</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>nodes<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">节点）..."</span></span><span class="token punctuation">)</span>      self<span class="token punctuation">.</span>_build_new_index<span class="token punctuation">(</span>nodes<span class="token punctuation">,</span> storage_context<span class="token punctuation">)</span>  <span class="token keyword">else</span><span class="token punctuation">:</span>      <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"加载已有索引..."</span><span class="token punctuation">)</span>      storage_context <span class="token operator">=</span> StorageContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>          persist_dir<span class="token operator">=</span>Config<span class="token punctuation">.</span>PERSIST_DIR<span class="token punctuation">,</span>          vector_store<span class="token operator">=</span>ChromaVectorStore<span class="token punctuation">(</span>chroma_collection<span class="token operator">=</span>self<span class="token punctuation">.</span>collection<span class="token punctuation">)</span>      <span class="token punctuation">)</span>  index <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_vector_store<span class="token punctuation">(</span>      storage_context<span class="token punctuation">.</span>vector_store<span class="token punctuation">,</span>      storage_context<span class="token operator">=</span>storage_context<span class="token punctuation">,</span>      embed_model<span class="token operator">=</span>Settings<span class="token punctuation">.</span>embed_model  <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>传入nodes节点数据后，使用 <code>chromadb</code> 作为我们的向量存储库<br>我们运行然后输出向量库存存储情况：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text"># ========= 没有本地存储库输出显示 =========创建新索引（205节点）...Generating embeddings: 100%|██████████| 205/205 [00:12&lt;00:00, 16.25it/s]存储验证：文档数量：205示例节点ID：中华人民共和国劳动法及劳动合同法.json::中华人民共和国劳动合同法 第一条索引加载耗时：12.92s# ========= 已经创建本地存储库输出显示 =========加载已有索引...存储验证：文档数量：205示例节点ID：中华人民共和国劳动法及劳动合同法.json::中华人民共和国劳动合同法 第一条索引加载耗时：0.17s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-2-核心代码优化及效果对比"><a href="#4-2-核心代码优化及效果对比" class="headerlink" title="4.2 核心代码优化及效果对比"></a><strong>4.2 核心代码优化及效果对比</strong></h3><h4 id="4-2-1-优化策略对比"><a href="#4-2-1-优化策略对比" class="headerlink" title="4.2.1 优化策略对比"></a><strong>4.2.1 优化策略对比</strong></h4><p>主要优化有三个点，增加检索范围，添加重排序模型，设计提示词模板</p><table><thead><tr><th>优化维度</th><th>优化前</th><th>优化后</th></tr></thead><tbody><tr><td>检索范围</td><td>固定Top3</td><td>初筛Top10 + 精排Top3</td></tr><tr><td>排序方式</td><td>余弦相似度</td><td>语义重排序模型</td></tr><tr><td>提示词设计</td><td>简单模板</td><td>强化约束的多条件模板</td></tr></tbody></table><h4 id="4-2-2-进行后大模型回答效果前后对比"><a href="#4-2-2-进行后大模型回答效果前后对比" class="headerlink" title="4.2.2 进行后大模型回答效果前后对比"></a><strong>4.2.2 进行后大模型回答效果前后对比</strong></h4><p>使用模型：</p><ul><li>LLM：Qwen1.5-4B-Chat</li><li>Embedding：text2vec-base-chinese-sentence</li><li>Rerank：BAAI\bge-reranker-large</li></ul><p>优化核心代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># ========= 添加提示词模板 =========</span>QA_TEMPLATE <span class="token operator">=</span> <span class="token punctuation">(</span>      <span class="token string">"&lt;|im_start|&gt;system\n"</span>      <span class="token string">"您是中国劳动法领域专业助手，必须严格遵循以下规则：\n"</span>      <span class="token string">"1.仅使用提供的法律条文回答问题\n"</span>      <span class="token string">"2.若问题与劳动法无关或超出知识库范围，明确告知无法回答\n"</span>      <span class="token string">"3.引用条文时标注出处\n\n"</span>      <span class="token string">"可用法律条文（共{context_count}条）：\n{context_str}\n&lt;|im_end|&gt;\n"</span>      <span class="token string">"&lt;|im_start|&gt;user\n问题：{query_str}&lt;|im_end|&gt;\n"</span>      <span class="token string">"&lt;|im_start|&gt;assistant\n"</span>  <span class="token punctuation">)</span>response_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>QA_TEMPLATE<span class="token punctuation">)</span><span class="token comment"># ========= 添加重排序模型检索内容重排序 =========</span><span class="token comment"># 创建检索器和响应合成器 </span>retriever <span class="token operator">=</span> index<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>      similarity_top_k<span class="token operator">=</span>Config<span class="token punctuation">.</span>TOP_K  <span class="token comment"># 扩大初始检索数量  </span><span class="token punctuation">)</span>  response_synthesizer <span class="token operator">=</span> get_response_synthesizer<span class="token punctuation">(</span>      text_qa_template<span class="token operator">=</span>response_template<span class="token punctuation">,</span>      verbose<span class="token operator">=</span><span class="token boolean">True</span>  <span class="token punctuation">)</span><span class="token comment"># ========= while 内部修改逻辑 =========</span><span class="token comment"># 1. 初始检索  </span>initial_nodes <span class="token operator">=</span> retriever<span class="token punctuation">.</span>retrieve<span class="token punctuation">(</span>question<span class="token punctuation">)</span>    <span class="token keyword">for</span> node <span class="token keyword">in</span> initial_nodes<span class="token punctuation">:</span>      node<span class="token punctuation">.</span>node<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">'initial_score'</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">.</span>score  <span class="token comment"># 保存初始分数到元数据  </span>  <span class="token comment"># 2. 重排序  </span>reranked_nodes <span class="token operator">=</span> reranker<span class="token punctuation">.</span>postprocess_nodes<span class="token punctuation">(</span>      initial_nodes<span class="token punctuation">,</span>      query_str<span class="token operator">=</span>question  <span class="token punctuation">)</span>    <span class="token comment"># 3. 合成答案  </span>response <span class="token operator">=</span> response_synthesizer<span class="token punctuation">.</span>synthesize<span class="token punctuation">(</span>      question<span class="token punctuation">,</span>      nodes<span class="token operator">=</span>reranked_nodes  <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>测试问题：<em><font color="#4bacc6">劳动合同试用期最长可以约定多久？</font></em></p><p>优化前，模型回答效果：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">智能助手回答：试用期最长不得超过六个月支持依据：[1] 中华人民共和国劳动法 第二十一条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动法  条款内容：劳动合同可以约定试用期。试用期最长不得超过六个月。...  相关度得分：0.9339[2] 中华人民共和国劳动合同法 第十九条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动合同法  条款内容：劳动合同期限三个月以上不满一年的，试用期不得超过一个月；劳动合同期限一年以上不满三年的，试用期不得超过二个月；三年以上固定期限和无固定期限的劳动合同，试用期不得超过六个月。同一用人单位与同一劳动者只...  相关度得分：0.9227[3] 中华人民共和国劳动合同法 第十五条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动合同法  条款内容：以完成一定工作任务为期限的劳动合同，是指用人单位与劳动者约定以某项工作的完成为合同期限的劳动合同。用人单位与劳动者协商一致，可以订立以完成一定工作任务为期限的劳动合同。...  相关度得分：0.9026<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>优化后，模型回答效果：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">智能助手回答：根据《中华人民共和国劳动合同法》第二十一条的规定，劳动合同可以约定试用期。试用期最长不得超过六个月。支持依据：[1] 中华人民共和国劳动法 第二十一条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动法  初始相关度：0.9339  重排序得分：0.9984  条款内容：劳动合同可以约定试用期。试用期最长不得超过六个月。...[2] 中华人民共和国劳动合同法 第十九条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动合同法  初始相关度：0.9227  重排序得分：0.9963  条款内容：劳动合同期限三个月以上不满一年的，试用期不得超过一个月；劳动合同期限一年以上不满三年的，试用期不得超过二个月；三年以上固定期限和无固定期限的劳动合同，试用期不得超过六个月。同一用人单位与同一劳动者只...[3] 中华人民共和国劳动合同法 第十五条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动合同法  初始相关度：0.9026  重排序得分：0.0107  条款内容：以完成一定工作任务为期限的劳动合同，是指用人单位与劳动者约定以某项工作的完成为合同期限的劳动合同。用人单位与劳动者协商一致，可以订立以完成一定工作任务为期限的劳动合同。...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>测试问题：<em><font color="#4bacc6">哪种情况下，用人单位可以解除劳动合同？</font></em></p><p>优化前模型回答效果：</p><pre class="line-numbers language-none"><code class="language-none">智能助手回答：有下列情形之一的，用人单位可以解除劳动合同，但是应当提前三十日以书面形式通知劳动者本人：（一）劳动者患病或者非因工负伤，医疗期满后，不能从事原工作也不能从事由用人单位另行安排的工作的；（二）劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的；（三）劳动合同订立时所依据的客观情况发生重大变化，致使原劳动合同无法履行，经当事人协商不能就变更劳动合同达成协议的。支持依据：[1] 中华人民共和国劳动法 第二十四条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动法  条款内容：经劳动合同当事人协商一致，劳动合同可以解除。...  相关度得分：0.9403[2] 中华人民共和国劳动法 第二十六条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动法  条款内容：有下列情形之一的，用人单位可以解除劳动合同，但是应当提前三十日以书面形式通知劳动者本人：（一）劳动者患病或者非因工负伤，医疗期满后，不能从事原工作也不能从事由用人单位另行安排的工作的；（二）劳动者...  相关度得分：0.9398[3] 中华人民共和国劳动合同法 第三十六条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动合同法  条款内容：用人单位与劳动者协商一致，可以解除劳动合同。...  相关度得分：0.9393<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>优化后模型回答效果：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">智能助手回答：根据《中华人民共和国劳动法》第二十六条规定，用人单位可以解除劳动合同的情形包括：1. 劳动者患病或者非因工负伤，医疗期满后，不能从事原工作也不能从事由用人单位另行安排的工作的；2. 劳动者不能胜任工作，经过培训或者调整工作岗位，仍不能胜任工作的；3. 劳动合同订立时所依据的客观情况发生重大变化，致使原劳动合同无法履行，经当事人协商不能就变更劳动合同达成协议的。支持依据：[1] 中华人民共和国劳动法 第二十六条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动法  初始相关度：0.9440  重排序得分：0.9995  条款内容：有下列情形之一的，用人单位可以解除劳动合同，但是应当提前三十日以书面形式通知劳动者本人：（一）劳动者患病或者非因工负伤，医疗期满后，不能从事原工作也不能从事由用人单位另行安排的工作的；（二）劳动者...[2] 中华人民共和国劳动合同法 第三十六条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动合同法  初始相关度：0.9411  重排序得分：0.9926  条款内容：用人单位与劳动者协商一致，可以解除劳动合同。...[3] 中华人民共和国劳动法 第二十四条  来源文件：中华人民共和国劳动法及劳动合同法.json  法律名称：中华人民共和国劳动法  初始相关度：0.9418  重排序得分：0.9884  条款内容：经劳动合同当事人协商一致，劳动合同可以解除。...<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其他优化内容：可以更换参数量更大的大模型。</p><p>其实在上面添加的提示词模板内容对于参数量较小的模型来说是不能理解的，因此我们这次测试添加的提示词模板没什么作用，但是如果是参数量比较大的大模型，添加提示词模板还是很有效果的。</p><hr><h2 id="五、RAG效果测试评估体系"><a href="#五、RAG效果测试评估体系" class="headerlink" title="五、RAG效果测试评估体系"></a><strong>五、RAG效果测试评估体系</strong></h2><p>主要对RAG系统进行重排序召回率和端到端效果评估</p><h4 id="5-1-重排序召回率"><a href="#5-1-重排序召回率" class="headerlink" title="5.1 重排序召回率"></a><strong>5.1 重排序召回率</strong></h4><p>测试数据集示例：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"># 劳动合同解除类  <span class="token punctuation">{</span>      <span class="token property">"question"</span><span class="token operator">:</span> <span class="token string">"劳动者可以立即解除劳动合同的情形有哪些？"</span><span class="token punctuation">,</span>      <span class="token property">"relevant_ids"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"中华人民共和国劳动合同法 第三十八条"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>      <span class="token property">"confusing_ids"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"中华人民共和国劳动合同法 第三十九条"</span><span class="token punctuation">,</span> <span class="token string">"中华人民共和国劳动法 第三十二条"</span><span class="token punctuation">]</span>  <span class="token punctuation">}</span><span class="token punctuation">,</span>  <span class="token punctuation">{</span>      <span class="token property">"question"</span><span class="token operator">:</span> <span class="token string">"用人单位单方解除劳动合同需要提前多久通知？"</span><span class="token punctuation">,</span>      <span class="token property">"relevant_ids"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"中华人民共和国劳动合同法 第四十条"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>      <span class="token property">"confusing_ids"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"中华人民共和国劳动合同法 第三十七条"</span><span class="token punctuation">,</span> <span class="token string">"中华人民共和国劳动法 第二十六条"</span><span class="token punctuation">]</span>  <span class="token punctuation">}</span><span class="token punctuation">,</span>    # 工资与补偿类  <span class="token punctuation">{</span>      <span class="token property">"question"</span><span class="token operator">:</span> <span class="token string">"经济补偿金的计算标准是什么？"</span><span class="token punctuation">,</span>      <span class="token property">"relevant_ids"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"中华人民共和国劳动合同法 第四十七条"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>      <span class="token property">"confusing_ids"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"中华人民共和国劳动合同法 第八十七条"</span><span class="token punctuation">,</span> <span class="token string">"中华人民共和国劳动法 第二十八条"</span><span class="token punctuation">]</span>  <span class="token punctuation">}</span><span class="token punctuation">,</span>  <span class="token punctuation">{</span>      <span class="token property">"question"</span><span class="token operator">:</span> <span class="token string">"试用期工资最低标准是多少？"</span><span class="token punctuation">,</span>      <span class="token property">"relevant_ids"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"中华人民共和国劳动合同法 第二十条"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>      <span class="token property">"confusing_ids"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"中华人民共和国劳动合同法 第十九条"</span><span class="token punctuation">,</span> <span class="token string">"中华人民共和国劳动法 第四十八条"</span><span class="token punctuation">]</span>  <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>测试核心代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">"""计算单个问题的召回率"""</span>  retrieved_ids <span class="token operator">=</span> <span class="token punctuation">[</span>n<span class="token punctuation">.</span>node<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"full_title"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> n <span class="token keyword">in</span> retrieved_nodes<span class="token punctuation">]</span>  hit <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>retrieved_ids<span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token builtin">set</span><span class="token punctuation">(</span>relevant_ids<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token triple-quoted-string string">"""批量评估召回率"""</span>  results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token keyword">for</span> <span class="token keyword">case</span> <span class="token keyword">in</span> benchmark<span class="token punctuation">:</span>      initial_nodes <span class="token operator">=</span> self<span class="token punctuation">.</span>retriever<span class="token punctuation">.</span>retrieve<span class="token punctuation">(</span><span class="token keyword">case</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      reranked_nodes <span class="token operator">=</span> self<span class="token punctuation">.</span>reranker<span class="token punctuation">.</span>postprocess_nodes<span class="token punctuation">(</span>          initial_nodes<span class="token punctuation">,</span>          query_str<span class="token operator">=</span><span class="token keyword">case</span><span class="token punctuation">[</span><span class="token string">"question"</span><span class="token punctuation">]</span>      <span class="token punctuation">)</span>    recall <span class="token operator">=</span> self<span class="token punctuation">.</span>calculate_recall<span class="token punctuation">(</span>reranked_nodes<span class="token punctuation">,</span> <span class="token keyword">case</span><span class="token punctuation">[</span><span class="token string">"relevant_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>recall<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"\n问题：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token keyword">case</span><span class="token punctuation">[</span><span class="token string">'question'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>      <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"目标条款：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token keyword">case</span><span class="token punctuation">[</span><span class="token string">'relevant_ids'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>      <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"召回率：</span><span class="token interpolation"><span class="token punctuation">{</span>recall<span class="token punctuation">:</span><span class="token format-spec">.1%</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="5-2-端到端条款命中率"><a href="#5-2-端到端条款命中率" class="headerlink" title="5.2 端到端条款命中率"></a><strong>5.2 端到端条款命中率</strong></h4><p>测试数据集示例：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json">E2E_BENCHMARK = <span class="token punctuation">[</span>      # 案例<span class="token number">1</span>：劳动合同解除      <span class="token punctuation">{</span>          <span class="token property">"question"</span><span class="token operator">:</span> <span class="token string">"用人单位在哪些情况下不得解除劳动合同？"</span><span class="token punctuation">,</span>          <span class="token property">"standard_answer"</span><span class="token operator">:</span> <span class="token punctuation">{</span>              <span class="token property">"条款"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"中华人民共和国劳动合同法 第四十二条"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token property">"标准答案"</span><span class="token operator">:</span> <span class="token string">"根据《劳动合同法》第四十二条，用人单位不得解除劳动合同的情形包括：\n1. 从事接触职业病危害作业的劳动者未进行离岗前职业健康检查\n2. 在本单位患职业病或者因工负伤并被确认丧失/部分丧失劳动能力\n3. 患病或非因工负伤在规定的医疗期内\n4. 女职工在孕期、产期、哺乳期\n5. 连续工作满15年且距退休不足5年\n6. 法律、行政法规规定的其他情形\n违法解除需按第八十七条支付二倍经济补偿金"</span><span class="token punctuation">,</span>              <span class="token property">"必备条件"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"职业病危害作业未检查"</span><span class="token punctuation">,</span> <span class="token string">"孕期女职工"</span><span class="token punctuation">,</span> <span class="token string">"连续工作满15年"</span><span class="token punctuation">]</span>          <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>      # 案例<span class="token number">2</span>：工资支付      <span class="token punctuation">{</span>          <span class="token property">"question"</span><span class="token operator">:</span> <span class="token string">"拖欠工资劳动者可以采取哪些措施？"</span><span class="token punctuation">,</span>          <span class="token property">"standard_answer"</span><span class="token operator">:</span> <span class="token punctuation">{</span>              <span class="token property">"条款"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"中华人民共和国劳动合同法 第三十条"</span><span class="token punctuation">,</span> <span class="token string">"中华人民共和国劳动法 第五十条"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token property">"标准答案"</span><span class="token operator">:</span> <span class="token string">"劳动者可采取以下救济措施：\n1. 根据劳动合同法第三十条向法院申请支付令\n2. 依据劳动合同法第三十八条解除合同并要求经济补偿\n3. 向劳动行政部门投诉\n逾期未支付的，用人单位需按应付金额50%-100%加付赔偿金（劳动合同法第八十五条）"</span><span class="token punctuation">,</span>              <span class="token property">"必备条件"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"支付令申请"</span><span class="token punctuation">,</span> <span class="token string">"解除劳动合同"</span><span class="token punctuation">,</span> <span class="token string">"行政投诉"</span><span class="token punctuation">]</span>          <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>测试核心代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">try</span><span class="token punctuation">:</span>      <span class="token comment"># 获取实际命中的条款  </span>    retrieved_clauses <span class="token operator">=</span> <span class="token punctuation">[</span>node<span class="token punctuation">.</span>node<span class="token punctuation">.</span>metadata<span class="token punctuation">[</span><span class="token string">"full_title"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> node <span class="token keyword">in</span> response<span class="token punctuation">.</span>source_nodes<span class="token punctuation">]</span>        <span class="token comment"># 获取标准答案要求的条款  </span>    required_clauses <span class="token operator">=</span> standard<span class="token punctuation">[</span><span class="token string">"standard_answer"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"条款"</span><span class="token punctuation">]</span>        <span class="token comment"># 计算命中情况  </span>    hit_clauses <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>retrieved_clauses<span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token builtin">set</span><span class="token punctuation">(</span>required_clauses<span class="token punctuation">)</span><span class="token punctuation">)</span>      missed_clauses <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>required_clauses<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token builtin">set</span><span class="token punctuation">(</span>retrieved_clauses<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 计算命中率  </span>    clause_hit <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>hit_clauses<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>required_clauses<span class="token punctuation">)</span> <span class="token keyword">if</span> required_clauses <span class="token keyword">else</span> <span class="token number">0.0</span>        <span class="token keyword">return</span> <span class="token punctuation">{</span>          <span class="token string">"clause_score"</span><span class="token punctuation">:</span> clause_hit<span class="token punctuation">,</span>          <span class="token string">"hit_clauses"</span><span class="token punctuation">:</span> hit_clauses<span class="token punctuation">,</span>          <span class="token string">"missed_clauses"</span><span class="token punctuation">:</span> missed_clauses      <span class="token punctuation">}</span>  <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>      <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"评估失败：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>评估测试我们给的初始检索数量TOP_K = 20 ，重排序保留数量RERANK_TOP_K = 5</p><p>最终评估效果：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">=== 最终评估报告 ===重排序召回率：94.7%端到端条款命中率：83.3%<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可以看到已经达到可以交付的要求。</p><hr><h2 id="六、部署与前端集成"><a href="#六、部署与前端集成" class="headerlink" title="六、部署与前端集成"></a><strong>六、部署与前端集成</strong></h2><p>因为我们需要将我们的整个RAG流程嵌入到前端界面中，所有我们就使用 <code>streamlit</code> 这个能够轻量化的高度定制的前端框架来构建我们的前端界面。</p><p>核心代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># ================== 界面组件 ==================</span><span class="token keyword">def</span> <span class="token function">_init_chat_interface</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token keyword">if</span> <span class="token string">"messages"</span> <span class="token keyword">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>          st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> msg <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>messages<span class="token punctuation">:</span>          role <span class="token operator">=</span> msg<span class="token punctuation">[</span><span class="token string">"role"</span><span class="token punctuation">]</span>          content <span class="token operator">=</span> msg<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"cleaned"</span><span class="token punctuation">,</span> msg<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 优先使用清理后的内容  </span>          <span class="token keyword">with</span> st<span class="token punctuation">.</span>chat_message<span class="token punctuation">(</span>role<span class="token punctuation">)</span><span class="token punctuation">:</span>              st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span>content<span class="token punctuation">)</span>                <span class="token comment"># 如果是助手消息且包含思维链  </span>            <span class="token keyword">if</span> role <span class="token operator">==</span> <span class="token string">"assistant"</span> <span class="token keyword">and</span> msg<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"think"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                  <span class="token keyword">with</span> st<span class="token punctuation">.</span>expander<span class="token punctuation">(</span><span class="token string">"📝 模型思考过程（历史对话）"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                      <span class="token keyword">for</span> think_content <span class="token keyword">in</span> msg<span class="token punctuation">[</span><span class="token string">"think"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                          st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'&lt;span style="color: #808080"&gt;</span><span class="token interpolation"><span class="token punctuation">{</span>think_content<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&lt;/span&gt;'</span></span><span class="token punctuation">,</span>                                      unsafe_allow_html<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>                <span class="token comment"># 如果是助手消息且有参考依据（需要保持原有参考依据逻辑）  </span>            <span class="token keyword">if</span> role <span class="token operator">==</span> <span class="token string">"assistant"</span> <span class="token keyword">and</span> <span class="token string">"reference_nodes"</span> <span class="token keyword">in</span> msg<span class="token punctuation">:</span>                  self<span class="token punctuation">.</span>_show_reference_details<span class="token punctuation">(</span>msg<span class="token punctuation">[</span><span class="token string">"reference_nodes"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># ================== 显示回答  ================== </span><span class="token keyword">with</span> st<span class="token punctuation">.</span>chat_message<span class="token punctuation">(</span><span class="token string">"assistant"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token comment"># 提取思维链内容并清理响应文本  </span>    think_contents <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">r'&lt;think&gt;(.*?)&lt;/think&gt;'</span><span class="token punctuation">,</span> response_text<span class="token punctuation">,</span> re<span class="token punctuation">.</span>DOTALL<span class="token punctuation">)</span>      cleaned_response <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'&lt;think&gt;.*?&lt;/think&gt;'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> response_text<span class="token punctuation">,</span> flags<span class="token operator">=</span>re<span class="token punctuation">.</span>DOTALL<span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 显示清理后的回答  </span>    st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span>cleaned_response<span class="token punctuation">)</span>        <span class="token comment"># 如果有思维链内容则显示  </span>    <span class="token keyword">if</span> think_contents<span class="token punctuation">:</span>          <span class="token keyword">with</span> st<span class="token punctuation">.</span>expander<span class="token punctuation">(</span><span class="token string">"📝 模型思考过程（点击展开）"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>              <span class="token keyword">for</span> content <span class="token keyword">in</span> think_contents<span class="token punctuation">:</span>                  st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'&lt;span style="color: #808080"&gt;</span><span class="token interpolation"><span class="token punctuation">{</span>content<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">&lt;/span&gt;'</span></span><span class="token punctuation">,</span>                              unsafe_allow_html<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment"># 显示参考依据（保持原有逻辑）  </span>    self<span class="token punctuation">.</span>_show_reference_details<span class="token punctuation">(</span>filtered_nodes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过运行命令来启动前端界面：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">streamlit run web_ui.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最终效果:<br><img src="https://pic1.imgdb.cn/item/682c740b58cb8da5c8ff9aff.png" alt="前端界面效果"></p><hr><h2 id="七、RAG针对特定问题的微调修复"><a href="#七、RAG针对特定问题的微调修复" class="headerlink" title="七、RAG针对特定问题的微调修复"></a><strong>七、RAG针对特定问题的微调修复</strong></h2><h3 id="7-1-问题场景分析"><a href="#7-1-问题场景分析" class="headerlink" title="7.1 问题场景分析"></a><strong>7.1 问题场景分析</strong></h3><p><strong>案例：</strong> 系统混淆”用人单位解除合同”与”劳动者解除合同”两类问题<br><strong>根本原因：</strong><br>基础LLM缺乏法律主体识别能力  </p><h3 id="7-2-微调数据集构建"><a href="#7-2-微调数据集构建" class="headerlink" title="7.2 微调数据集构建"></a><strong>7.2 微调数据集构建</strong></h3><p>构建策略： </p><pre class="line-numbers language-json" data-language="json"><code class="language-json"># 数据增强示例<span class="token punctuation">{</span>   <span class="token property">"instruction"</span><span class="token operator">:</span> <span class="token string">"用人单位在哪些法定情形下可以单方解除劳动合同？"</span><span class="token punctuation">,</span>   <span class="token property">"input"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>   <span class="token property">"output"</span><span class="token operator">:</span> <span class="token string">"根据《劳动合同法》第三十九条，用人单位可解除情形包括：1)试用期不符合录用条件；2)严重违反规章制度；3)严重失职造成重大损害；4)多重劳动关系影响工作；5)劳动合同无效；6)被追究刑事责任。"</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">{</span>   <span class="token property">"instruction"</span><span class="token operator">:</span> <span class="token string">"列举劳动者可以立即解除劳动合同的情形"</span><span class="token punctuation">,</span>   <span class="token property">"input"</span><span class="token operator">:</span> <span class="token string">""</span><span class="token punctuation">,</span>   <span class="token property">"output"</span><span class="token operator">:</span> <span class="token string">"《劳动合同法》第三十八条规定，当用人单位：1)未提供劳动保护；2)拖欠工资；3)未缴社保；4)制度违法损害权益；5)合同无效时，劳动者可解除。若存在强迫劳动或危险作业，可立即解除。"</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>数据分布：</p><table><thead><tr><th><strong>数据类型</strong></th><th><strong>数量</strong></th><th><strong>生成方式</strong></th></tr></thead><tbody><tr><td>主体对比问题</td><td>10</td><td>模板替换+人工校验</td></tr><tr><td>混淆场景负样本</td><td>10</td><td>主体置换生成对抗样本</td></tr></tbody></table><h3 id="7-3-模型微调方案"><a href="#7-3-模型微调方案" class="headerlink" title="7.3 模型微调方案"></a><strong>7.3 模型微调方案</strong></h3><p>训练配置：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> peft <span class="token keyword">import</span> LoraConfiglora_config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>   r<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>   lora_alpha<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>   target_modules<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"q_proj"</span><span class="token punctuation">,</span> <span class="token string">"v_proj"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    lora_dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>   bias<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="八、总结"><a href="#八、总结" class="headerlink" title="八、总结"></a><strong>八、总结</strong></h2><p>项目文件结构：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">LexRAGen/                       # 项目根目录├── main.py                     # 主程序入口├── web_ui.py                   # 前端界面集成├── requirements.txt            # 依赖包列表├── data/                       # 原始数据目录（需手动添加JSON文件）├── chroma_db/                  # 向量数据库存储目录（自动生成）├── storage/                    # 索引持久化目录（自动生成）└── core/                       # 核心代码目录    ├── __init__.py             # 标识为Python包    ├── config.py               # 配置文件    ├── models.py               # 模型初始化模块    ├── data_processor.py       # 数据处理模块    ├── vector_store.py         # 向量存储管理    ├── evaluators.py           # 评估模块    └── benchmark_data.py       # 测试数据集<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="九、附录与参考资料"><a href="#九、附录与参考资料" class="headerlink" title="九、附录与参考资料"></a><strong>九、附录与参考资料</strong></h2><p>项目仓库地址：<a href="https://github.com/ismoyuai/LexRAGen">https://github.com/ismoyuai/LexRAGen</a><br>LlamaIndex官方文档：<a href="https://docs.llamaindex.ai/en/stable/">https://docs.llamaindex.ai/en/stable/</a><br>LLM模型地址：<a href="https://www.modelscope.cn/models/Qwen/Qwen1.5-4B-Chat">https://www.modelscope.cn/models/Qwen/Qwen1.5-4B-Chat</a><br>LMDeploy官方文档：<a href="https://lmdeploy.readthedocs.io/zh-cn/latest/index.html">https://lmdeploy.readthedocs.io/zh-cn/latest/index.html</a><br>Streamlit官方文档：<a href="https://docs.streamlit.io/">https://docs.streamlit.io/</a></p><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> RAG </tag>
            
            <tag> Dify </tag>
            
            <tag> Agent </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【AI大模型应用学习笔记】Windows11系统本地部署Dify并构建RAG系统方案</title>
      <link href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-windows11-xi-tong-ben-di-bu-shu-dify-bing-gou-jian-rag-xi-tong-fang-an/"/>
      <url>/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-windows11-xi-tong-ben-di-bu-shu-dify-bing-gou-jian-rag-xi-tong-fang-an/</url>
      
        <content type="html"><![CDATA[<h2 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a><strong>一、环境准备</strong></h2><h3 id="1-1-安装git工具"><a href="#1-1-安装git工具" class="headerlink" title="1.1 安装git工具"></a><strong>1.1 安装git工具</strong></h3><h3 id="1-2-安装docker"><a href="#1-2-安装docker" class="headerlink" title="1.2 安装docker"></a><strong>1.2 安装docker</strong></h3><h4 id="1-2-1-下载-Docker-Desktop："><a href="#1-2-1-下载-Docker-Desktop：" class="headerlink" title="1.2.1&nbsp;下载 Docker Desktop："></a><strong>1.2.1&nbsp;下载 Docker Desktop</strong>：</h4><ul><li>访问 Docker 官网：<a href="https://www.docker.com/">https://www.docker.com/</a>。</li><li>点击页面上的“Download for Windows - AMD64”按钮，以下载适用于 Windows 系统的 Docker Desktop 安装文件。</li></ul><h4 id="1-2-2-安装-Docker-Desktop："><a href="#1-2-2-安装-Docker-Desktop：" class="headerlink" title="1.2.2&nbsp;安装 Docker Desktop："></a>1.2.2&nbsp;<strong>安装 Docker Desktop</strong>：</h4><ul><li>双击下载的安装文件，开始安装 Docker Desktop。</li><li>按照安装向导的指示完成安装。在安装过程中，将提示安装&nbsp;<strong>WSL 2</strong>，建议勾选此选项以获得更好的性能。</li></ul><h4 id="1-2-3-配置-Docker-Desktop："><a href="#1-2-3-配置-Docker-Desktop：" class="headerlink" title="1.2.3&nbsp;配置 Docker Desktop："></a>1.2.3&nbsp;<strong>配置 Docker Desktop</strong>：</h4><ul><li><p>安装完成后，启动&nbsp;<strong>Docker Desktop</strong>。</p></li><li><p>首次打开时，将出现 Docker 订阅协议，点击&nbsp;<code>Accept</code>（接受）以继续。</p></li><li><p>随后，系统将提示用户登录。您可以选择使用&nbsp;GitHub&nbsp;账户或 Google 账户登录，若无上述账户，可选择跳过登录步骤。</p></li><li><p>接下来，将出现调查问卷，您可以根据个人喜好选择填写，或直接跳过此步骤。</p></li></ul><h3 id="1-3-汉化-Docker-Desktop（可选）"><a href="#1-3-汉化-Docker-Desktop（可选）" class="headerlink" title="1.3 汉化 Docker Desktop（可选）"></a><strong>1.3 汉化 Docker Desktop（可选）</strong></h3><p>若想使&nbsp;<strong>Docker Desktop</strong>&nbsp;显示中文界面，按照以下步骤进行汉化：</p><h4 id="1-3-1-下载对应版本的中文语言包："><a href="#1-3-1-下载对应版本的中文语言包：" class="headerlink" title="1.3.1&nbsp;下载对应版本的中文语言包："></a><strong>1.3.1&nbsp;下载对应版本的中文语言包：</strong></h4><ul><li>访问 GitHub，下载适用于 Docker Desktop 的中文语言包，Windows系统下下载<code>app-Windows-x86.asar</code>  包即可，链接地址为：<a href="https://github.com/asxez/DockerDesktop-CN">DockerDesktop-CN</a>。</li><li>将下载的文件移动到&nbsp;<code>C:\Program Files\Docker</code>&nbsp;目录下（即 Docker 的安装根目录）。</li></ul><h4 id="1-3-2-检查-Docker-Desktop-版本："><a href="#1-3-2-检查-Docker-Desktop-版本：" class="headerlink" title="1.3.2&nbsp;检查 Docker Desktop 版本："></a><strong>1.3.2&nbsp;检查 Docker Desktop 版本：</strong></h4><ul><li>启动 Docker Desktop，版本号将在<strong>右下角</strong>显示。</li></ul><h4 id="1-3-3-备份并替换-app-asar-文件："><a href="#1-3-3-备份并替换-app-asar-文件：" class="headerlink" title="1.3.3&nbsp;备份并替换 app.asar 文件："></a><strong>1.3.3&nbsp;备份并替换 app.asar 文件：</strong></h4><ul><li>打开 Docker Desktop 中文语言包，选择与您 Docker 版本相符的&nbsp;<code>app.asar</code>&nbsp;文件并复制。</li><li>导航至 Docker 的安装目录，路径默认为：<br>  <code>C:\Program Files\Docker\Docker\frontend\resources</code></li><li>在该目录下找到&nbsp;<code>app.asar</code>&nbsp;文件，建议先备份原文件，然后将复制的中文语言包中的&nbsp;<code>app.asar</code>&nbsp;文件粘贴并替换原有文件。</li></ul><h4 id="1-3-4-重新启动-Docker-Desktop："><a href="#1-3-4-重新启动-Docker-Desktop：" class="headerlink" title="1.3.4 重新启动 Docker Desktop："></a><strong>1.3.4 重新启动 Docker Desktop：</strong></h4><ul><li>完成替换后，请关闭 Docker Desktop，然后重新启动该程序。此时，Docker Desktop 应该以中文界面显示。</li></ul><h2 id="二、-Dify本地部署步骤详解"><a href="#二、-Dify本地部署步骤详解" class="headerlink" title="二、 Dify本地部署步骤详解"></a><strong>二、 Dify本地部署步骤详解</strong></h2><p>先运行我们安装的<code>docker Desktop</code>软件</p><h3 id="2-1-克隆dify本地，输入命令（科学上网环境自备）："><a href="#2-1-克隆dify本地，输入命令（科学上网环境自备）：" class="headerlink" title="2.1 克隆dify本地，输入命令（科学上网环境自备）："></a><strong>2.1 克隆dify本地，输入命令（科学上网环境自备）：</strong></h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/langgenius/dify.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-2-使用Docker一键部署（推荐新手）"><a href="#2-2-使用Docker一键部署（推荐新手）" class="headerlink" title="**2.2 使用Docker一键部署（推荐新手）"></a>**2.2 使用Docker一键部署（推荐新手）</h3><p>进入<code>dify/docker</code>目录，打开终端，输入命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> dify/docker<span class="token function">cp</span> .env.example .env<span class="token function">docker-compose</span> up <span class="token parameter variable">-d</span>  <span class="token comment"># 启动中间件（PostgreSQL/Redis/Weaviate）</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li><strong>验证服务</strong>：访问<code>http://localhost/apps</code>，首次需设置管理员账号。<br>如果成功部署，终端出现内容如下：</li></ul><pre class="line-numbers language-text" data-language="text"><code class="language-text">[+] Running 12/12 ✔ Network docker_default             Created                              0.4s ✔ Network docker_ssrf_proxy_network  Created                              0.1s ✔ Container docker-db-1              Healthy                              3.2s ✔ Container docker-redis-1           Starte...                            1.9s ✔ Container docker-web-1             Started                              1.2s ✔ Container docker-ssrf_proxy-1      S...                                 2.5s ✔ Container docker-sandbox-1         Star...                              2.5s ✔ Container docker-weaviate-1        Sta...                               2.5s ✔ Container docker-plugin_daemon-1   Started                              4.3s ✔ Container docker-api-1             Started                              4.1s ✔ Container docker-worker-1          Start...                             4.2s ✔ Container docker-nginx-1           Starte...                            4.9s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果出现报错，我们打开Docker，在设置的<code>Docker 引擎</code> 里面，一个json配置文件的入口，我们在里面添加下面内容开启国内镜像加速：<br>方法一：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>  <span class="token property">"registry-mirrors"</span><span class="token operator">:</span> <span class="token punctuation">[</span>      <span class="token string">"https://docker.1ms.run"</span><span class="token punctuation">,</span>      <span class="token string">"https://docker.xuanyuan.me"</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token property">"proxies"</span><span class="token operator">:</span> <span class="token punctuation">{</span>    <span class="token property">"default"</span><span class="token operator">:</span> <span class="token punctuation">{</span>      <span class="token property">"httpProxy"</span><span class="token operator">:</span> <span class="token string">"http://127.0.0.1:7890"</span><span class="token punctuation">,</span>      <span class="token property">"httpsProxy"</span><span class="token operator">:</span> <span class="token string">"http://127.0.0.1:7890"</span><span class="token punctuation">,</span>      <span class="token property">"noProxy"</span><span class="token operator">:</span> <span class="token string">"localhost,127.0.0.1,registry-1.docker.io,docker.io,docker.1ms.run,docker.xuanyuan.me"</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>方法二：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>  <span class="token property">"proxies"</span><span class="token operator">:</span> <span class="token punctuation">{</span>    <span class="token property">"default"</span><span class="token operator">:</span> <span class="token punctuation">{</span>      <span class="token property">"httpProxy"</span><span class="token operator">:</span> <span class="token string">"http://host.docker.internal:7890"</span><span class="token punctuation">,</span>      <span class="token property">"httpsProxy"</span><span class="token operator">:</span> <span class="token string">"http://host.docker.internal:7890"</span><span class="token punctuation">,</span>      <span class="token property">"noProxy"</span><span class="token operator">:</span> <span class="token string">"localhost,127.0.0.1,.local,host.docker.internal"</span>    <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>重新启动Docker，然后重新进入<code>dify/docker</code>目录执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker-compose</span> up <span class="token parameter variable">-d</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果需要重启所有服务，可以执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">docker-compose</span> <span class="token parameter variable">-f</span> docker/docker-compose.yaml down <span class="token operator">&amp;&amp;</span> <span class="token function">docker-compose</span> <span class="token parameter variable">-f</span> docker/docker-compose.yaml up <span class="token parameter variable">-d</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="三、接入-Ollama-部署的本地模型"><a href="#三、接入-Ollama-部署的本地模型" class="headerlink" title="三、接入 Ollama 部署的本地模型"></a><strong>三、接入 Ollama 部署的本地模型</strong></h2><p><a href="https://github.com/jmorganca/ollama">Ollama</a>&nbsp;是一款跨平台推理框架客户端（MacOS、Windows、Linux），专为无缝部署大型语言模型（LLM）（如 Llama 2、Mistral、Llava 等）而设计。通过一键式设置，Ollama 可以在本地运行 LLM，将所有交互数据保存在自己的机器上，从而提高数据的私密性和安全性。</p><h3 id="下载并启动-Ollama"><a href="#下载并启动-Ollama" class="headerlink" title="下载并启动 Ollama"></a><strong>下载并启动 Ollama</strong></h3><ol><li><p>下载 Ollama<br> 访问&nbsp;<a href="https://ollama.com/download">Ollama 下载页</a>，下载对应系统 Ollama 客户端。</p></li><li><p>运行 Ollama 并与 Llama3.2 聊天</p> <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama run llama3.2<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p> 启动成功后，ollama 在本地 11434 端口启动了一个 API 服务，可通过&nbsp;<code>http://localhost:11434</code>&nbsp;访问。<br> 如需运行其它模型，访问&nbsp;<a href="https://ollama.com/library">Ollama Models</a>&nbsp;了解详情。</p></li><li><p>在 Dify 中接入 Ollama</p><p> 在&nbsp;<code>设置 &gt; 模型供应商 &gt; Ollama</code>&nbsp;中填入：<br> <img src="https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/981679ae2e56d49e5a983e37cc134172.png"></p><ul><li><p>模型名称：<code>llama3.2</code></p></li><li><p>基础 URL：<code>http://&lt;your-ollama-endpoint-domain&gt;:11434</code><br>  此处需填写 Ollama 服务地址。这里分几种情况：</p><ul><li>若 Dify 为 Docker 部署，建议填写局域网 IP 地址，例如：<br>  <code>http://192.168.1.3:11434</code>&nbsp;或 Docker 容器的内部 IP 地址，例如：<code>http://host.docker.internal:11434</code>。</li><li>若为本地源码部署，可填写&nbsp;<code>http://localhost:11434</code>。</li></ul></li><li><p>模型类型：<code>对话</code></p></li><li><p>模型上下文长度：<code>4096</code><br>  模型的最大上下文长度，若不清楚可填写默认值 4096。</p></li><li><p>最大 token 上限：<code>4096</code><br>  模型返回内容的最大 token 数量，若模型无特别说明，则可与模型上下文长度保持一致。</p></li><li><p>是否支持 Vision：<code>是</code><br>  当模型支持图片理解（多模态）勾选此项，如&nbsp;<code>llava</code>。</p></li><li><p>是否支持函数调用：<code>是</code></p></li></ul><p> 点击 “保存” 校验无误后即可在应用中使用该模型。</p><p> Embedding 模型接入方式与 LLM 类似，只需将模型类型改为 Text Embedding 即可。 </p></li><li><p>使用 Ollama 模型<br> <img src="https://assets-docs.dify.ai/dify-enterprise-mintlify/zh_CN/development/models-integration/0561ed1f5c265689b504ff539f5d3edd.png"></p><p> 进入需要配置的 App 提示词编排页面，选择 Ollama 供应商下的&nbsp;<code>llava</code>&nbsp;模型，配置模型参数后即可使用。也可以配置你自己在Ollama中下载的模型</p></li></ol><h2 id="四、使用Dify构建RAG"><a href="#四、使用Dify构建RAG" class="headerlink" title="四、使用Dify构建RAG"></a><strong>四、使用Dify构建RAG</strong></h2><h3 id="4-1-ollama安装-Embedding-模型"><a href="#4-1-ollama安装-Embedding-模型" class="headerlink" title="4.1 ollama安装 Embedding 模型"></a>4.1 ollama安装 Embedding 模型</h3><p>通过 ollama 来安装Embedding模型，运行命令下载：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama run nn200433/text2vec-bge-large-chinese<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="4-2-在-Dify-中接入-Ollama"><a href="#4-2-在-Dify-中接入-Ollama" class="headerlink" title="4.2 在 Dify 中接入 Ollama"></a>4.2 在 Dify 中接入 Ollama</h3><p>在&nbsp;<code>设置 &gt; 模型供应商 &gt; Ollama</code>&nbsp;中填入：<br>设置同上面添加大模型一样，只需要在选择模型类型时选：<code>Text Embedding</code></p><h3 id="4-3-知识库创建"><a href="#4-3-知识库创建" class="headerlink" title="4.3 知识库创建"></a>4.3 知识库创建</h3><p>进入Dify知识库界面，点击创建知识库<br><img src="https://pic1.imgdb.cn/item/6825a12358cb8da5c8f2ea26.png"></p><p>进入界面后，我们对知识库进行一个基础设置：<br><img src="https://pic1.imgdb.cn/item/6825a12358cb8da5c8f2ea21.png"></p><p>知识库配置好后，我们就可以在我们创建的应用下引用我们的知识库<br><img src="https://pic1.imgdb.cn/item/6825a21658cb8da5c8f2f3c9.png"></p><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><p>系统环境：<br>WSL2-Ubuntu22.04 + docker desktop + dify</p><p>dify添加 OpenAI API Key没有反应</p><p>docker容器中日志：</p><pre class="line-numbers language-none"><code class="language-none">2025/05/14 10:53:50 run.go:132: [ERROR]plugin langgenius/openai:0.0.22 exited with error: exit status 10453ede311196acaad0531ad9e3d5561cd622e6508cd3254/main.py", line 7, in &lt;module&gt;plugin = Plugin(DifyPluginEnv())^^^^^^^^^^^^^^^File "/app/storage/cwd/langgenius/openai-0.0.22@fa668d0ec3b434270453ede311196acaad0531ad9e3d5561cd622e6508cd3254/.venv/lib/python3.12/site-packages/pydantic_settings/main.py", line 176, in __init__super().__init__(File "/app/storage/cwd/langgenius/openai-0.0.22@fa668d0ec3b434270453ede311196acaad0531ad9e3d5561cd622e6508cd3254/.venv/lib/python3.12/site-packages/pydantic/main.py", line 253, in __init__validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^pydantic_core._pydantic_core.ValidationError: 1 validation error for DifyPluginEnvREMOTE_INSTALL_URLField required [type=missing, input_value={'INSTALL_METHOD': 'local'}, input_type=dict]For further information visit [https://errors.pydantic.dev/2.11/v/missing⁠](https://errors.pydantic.dev/2.11/v/missing)<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>docker容器中API容器日志：</p><pre class="line-numbers language-none"><code class="language-none">2025-05-14 11:00:50.513 ERROR [Dummy-2] [app.py:875] - Exception on /console/api/workspaces/current/model-providers/langgenius/openai/openai [POST]Traceback (most recent call last):File "/app/api/.venv/lib/python3.12/site-packages/flask/app.py", line 917, in full_dispatch_requestrv = self.dispatch_request()^^^^^^^^^^^^^^^^^^^^^^^File "/app/api/.venv/lib/python3.12/site-packages/flask/app.py", line 902, in dispatch_requestreturn self.ensure_sync(self.view_functions[rule.endpoint])(**view_args) # type: ignore[no-any-return]^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^File "/app/api/.venv/lib/python3.12/site-packages/flask_restful/__init__.py", line 489, in wrapperresp = resource(*args, **kwargs)^^^^^^^^^^^^^^^^^^^^^^^^^File "/app/api/.venv/lib/python3.12/site-packages/flask/views.py", line 110, in viewreturn current_app.ensure_sync(self.dispatch_request)(**kwargs) # type: ignore[no-any-return]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> RAG </tag>
            
            <tag> Dify </tag>
            
            <tag> Agent </tag>
            
            <tag> AI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【项目实战】大模型微调-情绪对话模型</title>
      <link href="/xiang-mu-shi-zhan-da-mo-xing-wei-diao-qing-xu-dui-hua-mo-xing/"/>
      <url>/xiang-mu-shi-zhan-da-mo-xing-wei-diao-qing-xu-dui-hua-mo-xing/</url>
      
        <content type="html"><![CDATA[<h2 id="一、项目介绍"><a href="#一、项目介绍" class="headerlink" title="一、项目介绍"></a>一、<strong>项目介绍</strong></h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a><strong>背景</strong></h3><p>在看抖音时经常刷到一个小智聊天机器人，发现它在回答时具有非常强烈和个性化的情绪表达，使用就准备以此为目标，自己尝试做一个这样的情绪对话大模型。<br>加上在人工智能技术快速发展的今天，对话系统已广泛应用于客服、心理辅导、社交娱乐等领域。例如，在心理咨询场景中，模型需识别用户的焦虑或抑郁情绪并给出共情回应；在电商客服中，需对用户的不满情绪进行安抚。<br>因此，<strong>构建具备情绪感知能力的对话模型</strong>也是一个非常有价值的事情。</p><h3 id="项目目标"><a href="#项目目标" class="headerlink" title="项目目标"></a><strong>项目目标</strong></h3><p>本项目旨在通过实战微调一个<strong>情绪对话模型</strong>，覆盖数据收集、模型训练、评估优化到部署的全流程，重点解决以下问题：</p><ul><li><p>如何从多来源数据中构建高质量的情绪对话数据集？</p></li><li><p>如何选择合适的预训练模型并针对性优化其情感生成能力？</p></li><li><p>如何平衡生成内容的流畅性与情绪准确性？</p></li><li><p>如何将模型高效部署到实际应用场景？</p></li></ul><h2 id="二、数据收集与处理"><a href="#二、数据收集与处理" class="headerlink" title="二、数据收集与处理"></a><strong>二、数据收集与处理</strong></h2><h3 id="2-1-数据来源"><a href="#2-1-数据来源" class="headerlink" title="2.1 数据来源"></a>2.1 <strong>数据来源</strong></h3><p>本次项目数据来源主要有两点：</p><ol><li>人工制定</li><li>基于现有开源数据，让AI实现情绪数据集制作。</li></ol><blockquote><p>注意：如果让AI来帮助处理数据，尽可能选择效果较好的API接口，不要使用本地的大模型来处理。</p></blockquote><h3 id="2-2-数据标注工具与方法"><a href="#2-2-数据标注工具与方法" class="headerlink" title="2.2 数据标注工具与方法"></a>2.2 <strong>数据标注工具与方法</strong></h3><p>本项目数据主要是根据公开数据集然后使用Python代码+AI大模型来进行生成，没有用到其他标注工具和方法。</p><h3 id="2-3-数据清洗与预处理"><a href="#2-3-数据清洗与预处理" class="headerlink" title="2.3 数据清洗与预处理"></a>2.3 <strong>数据清洗与预处理</strong></h3><p>通过Python代码指定数据生成模板，然后基于收集的问题来让AI进行自动生成，并设置规则，让AI生成符合我们需求的高质量的数据。</p><p>数据清洗和预处理流程如下：</p><ul><li><p>设置数据风格模板（主要修正消息格式）</p><ul><li>让AI大模型按照我们想要的数据模板进行生成</li></ul></li><li><p>生成函数（主要修正消息的结构）</p><ul><li>调用大模型API来准备生成数据并返回</li></ul></li><li><p>设置数据质量过滤规则（添加空值检查）</p><ul><li>规则1：回复长度检查</li><li>规则2：风格关键词检查</li><li>规则3：语义相似度检查</li></ul></li><li><p>执行生成（添加容错）</p></li></ul><h3 id="2-4-数据划分"><a href="#2-4-数据划分" class="headerlink" title="2.4 数据划分"></a>2.4 <strong>数据划分</strong></h3><p>训练集、验证集、测试集划分</p><h2 id="三、数据收集与处理（实现篇）"><a href="#三、数据收集与处理（实现篇）" class="headerlink" title="三、数据收集与处理（实现篇）"></a><strong>三、数据收集与处理（实现篇）</strong></h2><h3 id="3-1-数据收集整理"><a href="#3-1-数据收集整理" class="headerlink" title="3.1 数据收集整理"></a><strong>3.1 数据收集整理</strong></h3><p>使用的是公开的<a href="https://github.com/thu-coai/CDial-GPT">CDial-GPT</a>数据集<br>还有魔塔社区的 <a href="https://www.modelscope.cn/datasets/OmniData/LCCC">LCCC</a> 数据集</p><p>数据集下载后，在里面挑选 1000~3000 条数据即可</p><h3 id="3-2-配置文件创建"><a href="#3-2-配置文件创建" class="headerlink" title="3.2 配置文件创建"></a>3.2 配置文件创建</h3><p>主要用来存放我们的 API 密匙、模型本地路径等敏感配置以及风格模板配置</p><p>打开 Pycharm 新建一个<code>emotion_dialogue_tuner</code>项目，在项目下新建 <code>config</code> 目录，然后新建<code>config/settings.yaml</code>和<code>config/style_config.json</code>文件，分别用来存放<strong>API密钥等敏感配置</strong>和<strong>风格模板配置</strong></p><p><code>settings.yaml</code>文件内容如下：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">API</span><span class="token punctuation">:</span>  <span class="token key atrule">ZHIPU_API_KEY</span><span class="token punctuation">:</span> <span class="token string">"your_api_key_here"</span>  <span class="token comment"># 敏感信息隔离</span>  <span class="token key atrule">MODEL_NAME</span><span class="token punctuation">:</span> <span class="token string">"glm-3-turbo"</span><span class="token key atrule">PATHS</span><span class="token punctuation">:</span>  <span class="token key atrule">EMBEDDING_MODEL</span><span class="token punctuation">:</span> <span class="token string">"embedding_model/thomas/text2vec-base-chinese"</span>  <span class="token comment"># 你本地embedding模型路径</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>我embedding模型选择的是thomas/text2vec-base-chinese，可以在魔塔社区下载</p></blockquote><p><code>style_config.json</code>文件内容如下：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>      <span class="token property">"温柔"</span><span class="token operator">:</span><span class="token punctuation">{</span>          <span class="token property">"system_prompt"</span><span class="token operator">:</span><span class="token string">"你是一个温柔体贴的聊天助手，说话时总是充满关怀，使用以下特征：\n1. 包含'呢、呀、啦'等语气词\n2. 使用🌸💖😊等温暖表情\n3. 主动询问用户感受"</span><span class="token punctuation">,</span>          <span class="token property">"examples"</span><span class="token operator">:</span> <span class="token punctuation">[</span>              <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"今天好累啊"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>              <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"辛苦啦~ 要给自己泡杯热茶放松一下吗？🌸"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>              <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"考试没考好..."</span><span class="token punctuation">}</span><span class="token punctuation">,</span>              <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"没关系的呀~ 下次一定会更好！需要我陪你聊聊吗？😊"</span><span class="token punctuation">}</span>          <span class="token punctuation">]</span><span class="token punctuation">,</span>     <span class="token property">"temperature"</span><span class="token operator">:</span> <span class="token number">0.3</span>      <span class="token punctuation">}</span><span class="token punctuation">,</span>      <span class="token property">"毒舌"</span><span class="token operator">:</span><span class="token punctuation">{</span>          <span class="token property">"system_prompt"</span><span class="token operator">:</span><span class="token string">"你是一个喜欢用犀利吐槽表达关心的朋友，需满足：\n1. 使用网络流行语（如'栓Q''退退退'）\n2. 包含夸张比喻（'你这速度堪比树懒'）\n3. 结尾隐藏关心"</span><span class="token punctuation">,</span>          <span class="token property">"examples"</span><span class="token operator">:</span> <span class="token punctuation">[</span>              <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"又胖了5斤！"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>              <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"好家伙！你这是要把体重秤压成分子料理？🏋️"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>              <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"游戏又输了"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>              <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"菜就多练练！需要给你推荐《从零开始的电竞之路》吗？🎮"</span><span class="token punctuation">}</span>          <span class="token punctuation">]</span><span class="token punctuation">,</span>     <span class="token property">"temperature"</span><span class="token operator">:</span> <span class="token number">0.7</span>      <span class="token punctuation">}</span>  <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我这里风格类型主要配置了两种：温柔和毒舌两种相反风格，然后为它们设置了相应的系统提示词和示例，让大模型明确自己的角色以及学习我们需要的数据模板类型，以供后续生成。</p><h3 id="3-3-配置文件加载模块"><a href="#3-3-配置文件加载模块" class="headerlink" title="3.3 配置文件加载模块"></a>3.3 配置文件加载模块</h3><p>新建<code>emotion_dialogue_tuner/src/utils/config_loader.py</code>文件</p><p>这个文件主要负责统一管理API密钥、模型路径等敏感信息和风格配置</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># config_loader.py  </span><span class="token triple-quoted-string string">"""配置文件加载模块，负责统一管理API密钥、模型路径等敏感信息和风格配置"""</span>    <span class="token keyword">import</span> yaml  <span class="token keyword">import</span> json  <span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path      <span class="token keyword">class</span> <span class="token class-name">ConfigLoader</span><span class="token punctuation">:</span>      <span class="token triple-quoted-string string">"""配置加载器，封装配置文件的读取操作"""</span>        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""初始化时自动定位项目根目录"""</span>          self<span class="token punctuation">.</span>root_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">.</span>resolve<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent  <span class="token comment"># 根据实际层级调整  </span>      <span class="token keyword">def</span> <span class="token function">load_settings</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""加载YAML格式的全局设置          Returns:            dict: 包含API密钥、模型路径等配置的字典          """</span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_path <span class="token operator">/</span> <span class="token string">"config/settings.yaml"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>              <span class="token keyword">return</span> yaml<span class="token punctuation">.</span>safe_load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">load_style_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""加载JSON格式的风格配置          Returns:            dict: 包含不同对话风格的模板配置          """</span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_path <span class="token operator">/</span> <span class="token string">"config/style_config.json"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>              <span class="token keyword">return</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-4-数据生成核心模块"><a href="#3-4-数据生成核心模块" class="headerlink" title="3.4 数据生成核心模块"></a>3.4 数据生成核心模块</h3><p>新建<code>emotion_dialogue_tuner/src/data_generator.py</code>文件</p><p>这个文件主要负责调用API生成指定风格的对话数据</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># data_generator.py  </span><span class="token triple-quoted-string string">"""数据生成核心模块，负责调用API生成指定风格的对话数据"""</span>    <span class="token keyword">from</span> zhipuai <span class="token keyword">import</span> ZhipuAI  <span class="token keyword">import</span> random  <span class="token keyword">import</span> time    <span class="token keyword">class</span> <span class="token class-name">StyleDataGenerator</span><span class="token punctuation">:</span>      <span class="token triple-quoted-string string">"""对话数据生成器，根据配置生成特定风格的对话数据"""</span>        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> api_key<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> style_config<span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""          Args:            api_key (str): 智普API访问密钥              style_config (dict): 风格配置字典          """</span>        self<span class="token punctuation">.</span>client <span class="token operator">=</span> ZhipuAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span>api_key<span class="token punctuation">)</span>          self<span class="token punctuation">.</span>style_config <span class="token operator">=</span> style_config        <span class="token keyword">def</span> <span class="token function">_build_messages</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style_name<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""构建符合API要求的消息格式          Args:            style_name (str): 目标风格名称（如'温柔'）          Returns:            list: 包含系统提示和示例对话的消息列表          """</span>        config <span class="token operator">=</span> self<span class="token punctuation">.</span>style_config<span class="token punctuation">[</span>style_name<span class="token punctuation">]</span>          <span class="token keyword">return</span> <span class="token punctuation">[</span>              <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> config<span class="token punctuation">[</span><span class="token string">"system_prompt"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>              <span class="token operator">*</span>config<span class="token punctuation">[</span><span class="token string">"examples"</span><span class="token punctuation">]</span>  <span class="token comment"># 展开示例对话  </span>        <span class="token punctuation">]</span>        <span class="token keyword">def</span> <span class="token function">generate_style_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style_name<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> num_samples<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""生成指定风格的对话数据          Args:            style_name (str): 目标风格名称              num_samples (int): 需要生成的样本数量          Returns:            list: 生成的对话数据列表，每个元素包含用户输入、助手回复和风格标签          """</span>        data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>          messages <span class="token operator">=</span> self<span class="token punctuation">.</span>_build_messages<span class="token punctuation">(</span>style_name<span class="token punctuation">)</span>            <span class="token comment"># 从本地文件加载用户输入  </span>        user_inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>          <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"data/cleaned_output.txt"</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>  <span class="token comment"># 修改为清理后的文件路径  </span>            <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">:</span>                  <span class="token comment"># 直接读取每行内容并去除换行符  </span>                cleaned_line <span class="token operator">=</span> line<span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>  <span class="token comment"># 或使用 line.strip()                if cleaned_line:  # 空行过滤（冗余保护）  </span>                    user_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cleaned_line<span class="token punctuation">)</span>            <span class="token comment"># 添加空值检查  </span>        <span class="token keyword">if</span> <span class="token keyword">not</span> user_inputs<span class="token punctuation">:</span>              <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"文件内容为空或未成功加载数据，请检查："</span>                               <span class="token string">"1. 文件路径是否正确 2. 文件是否包含有效内容"</span><span class="token punctuation">)</span>            <span class="token comment"># 初始化顺序索引  </span>        current_index <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 添加索引计数器  </span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>              <span class="token keyword">try</span><span class="token punctuation">:</span>                    <span class="token comment"># 按顺序选择用户输入（修改核心部分）  </span>                user_msg <span class="token operator">=</span> user_inputs<span class="token punctuation">[</span>current_index<span class="token punctuation">]</span>                  current_index <span class="token operator">=</span> <span class="token punctuation">(</span>current_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token builtin">len</span><span class="token punctuation">(</span>user_inputs<span class="token punctuation">)</span>  <span class="token comment"># 循环计数  </span>                  <span class="token comment"># 添加当前用户消息  </span>                current_messages <span class="token operator">=</span> messages <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> user_msg<span class="token punctuation">}</span><span class="token punctuation">]</span>                    <span class="token comment"># 调用大模型API生成回复  </span>                response <span class="token operator">=</span> self<span class="token punctuation">.</span>client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>                      model<span class="token operator">=</span><span class="token string">"glm-3-turbo"</span><span class="token punctuation">,</span>                      messages<span class="token operator">=</span>current_messages<span class="token punctuation">,</span>                      temperature<span class="token operator">=</span>self<span class="token punctuation">.</span>style_config<span class="token punctuation">[</span>style_name<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"temperature"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                      max_tokens<span class="token operator">=</span><span class="token number">100</span>                  <span class="token punctuation">)</span>                  reply <span class="token operator">=</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content                    <span class="token comment"># 保存通过质量检查的数据  </span>                <span class="token keyword">if</span> self<span class="token punctuation">.</span>_validate_reply<span class="token punctuation">(</span>style_name<span class="token punctuation">,</span> user_msg<span class="token punctuation">,</span> reply<span class="token punctuation">)</span><span class="token punctuation">:</span>                      data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span>                          <span class="token string">"user"</span><span class="token punctuation">:</span> user_msg<span class="token punctuation">,</span>                          <span class="token string">"assistant"</span><span class="token punctuation">:</span> reply<span class="token punctuation">,</span>                          <span class="token string">"style"</span><span class="token punctuation">:</span> style_name                      <span class="token punctuation">}</span><span class="token punctuation">)</span>                    time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">)</span>  <span class="token comment"># API调用频率限制保护  </span>              <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>                  <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"生成失败: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>            <span class="token keyword">return</span> data        <span class="token keyword">def</span> <span class="token function">_validate_reply</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> user_msg<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> reply<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""内部方法：验证回复质量（实际实现应调用Validator类）"""</span>          <span class="token comment"># 简化的验证逻辑，实际应使用独立的Validator类  </span>        <span class="token keyword">return</span> <span class="token builtin">bool</span><span class="token punctuation">(</span>reply<span class="token punctuation">)</span>  <span class="token comment"># 示例代码</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-5-生成数据质量验证模块"><a href="#3-5-生成数据质量验证模块" class="headerlink" title="3.5 生成数据质量验证模块"></a>3.5 生成数据质量验证模块</h3><p>新建<code>emotion_dialogue_tuner/src/utils/validator.py</code>文件</p><p>这个文件主要负责回复质量验证，确保生成数据符合质量标准</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># validator.py  </span><span class="token triple-quoted-string string">"""回复质量验证模块，确保生成数据符合质量标准"""</span>    <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np  <span class="token keyword">from</span> sentence_transformers <span class="token keyword">import</span> SentenceTransformer      <span class="token keyword">class</span> <span class="token class-name">ReplyValidator</span><span class="token punctuation">:</span>      <span class="token triple-quoted-string string">"""回复验证器，执行多维度质量检查"""</span>        <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_path<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""          Args:            model_path (str): 本地嵌入模型文件路径          """</span>        self<span class="token punctuation">.</span>style_model <span class="token operator">=</span> SentenceTransformer<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">validate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> user_msg<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> reply<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> ref_text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""执行完整的质量验证流程          Args:            style (str): 目标风格名称              user_msg (str): 用户输入文本              reply (str): 待验证的回复文本              ref_text (str): 参考文本（用于相似度计算）          Returns:            bool: 是否通过所有验证规则          """</span>        <span class="token comment"># 基础格式检查  </span>        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>_basic_checks<span class="token punctuation">(</span>reply<span class="token punctuation">)</span><span class="token punctuation">:</span>              <span class="token keyword">return</span> <span class="token boolean">False</span>            <span class="token comment"># 风格关键词匹配检查  </span>        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>_style_keyword_check<span class="token punctuation">(</span>style<span class="token punctuation">,</span> reply<span class="token punctuation">)</span><span class="token punctuation">:</span>              <span class="token keyword">return</span> <span class="token boolean">False</span>            <span class="token comment"># 语义相似度验证  </span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_semantic_similarity_check<span class="token punctuation">(</span>ref_text<span class="token punctuation">,</span> reply<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">_basic_checks</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> reply<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""执行基础格式检查          1. 非空检查          2. 长度限制检查          """</span>        <span class="token keyword">return</span> <span class="token builtin">bool</span><span class="token punctuation">(</span>reply<span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token punctuation">(</span><span class="token number">5</span> <span class="token operator">&lt;=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>reply<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> <span class="token number">150</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">_style_keyword_check</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> reply<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""检查是否包含风格特征关键词"""</span>          keyword_map <span class="token operator">=</span> <span class="token punctuation">{</span>              <span class="token string">"温柔"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"呢"</span><span class="token punctuation">,</span> <span class="token string">"呀"</span><span class="token punctuation">,</span> <span class="token string">"😊"</span><span class="token punctuation">,</span> <span class="token string">"🌸"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>              <span class="token string">"毒舌"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"好家伙"</span><span class="token punctuation">,</span> <span class="token string">"栓Q"</span><span class="token punctuation">,</span> <span class="token string">"!"</span><span class="token punctuation">,</span> <span class="token string">"🏋️"</span><span class="token punctuation">]</span>          <span class="token punctuation">}</span>        <span class="token keyword">return</span> <span class="token builtin">any</span><span class="token punctuation">(</span>kw <span class="token keyword">in</span> reply <span class="token keyword">for</span> kw <span class="token keyword">in</span> keyword_map<span class="token punctuation">.</span>get<span class="token punctuation">(</span>style<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">_semantic_similarity_check</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ref_text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> reply<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>          <span class="token triple-quoted-string string">"""计算与参考文本的语义相似度          使用余弦相似度判断，阈值设为0.65          """</span>        ref_vec <span class="token operator">=</span> self<span class="token punctuation">.</span>style_model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>ref_text<span class="token punctuation">)</span>          reply_vec <span class="token operator">=</span> self<span class="token punctuation">.</span>style_model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>reply<span class="token punctuation">)</span>          similarity <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>ref_vec<span class="token punctuation">,</span> reply_vec<span class="token punctuation">)</span>          <span class="token keyword">return</span> similarity <span class="token operator">&gt;</span> <span class="token number">0.65</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-6-主函数-main-py-实现"><a href="#3-6-主函数-main-py-实现" class="headerlink" title="3.6 主函数 main.py 实现"></a>3.6 主函数 main.py 实现</h3><p>新建<code>emotion_dialogue_tuner/main.py</code> 文件</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># main.py  </span><span class="token triple-quoted-string string">"""主执行入口，协调各模块完成数据生成任务"""</span>    <span class="token keyword">from</span> src<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>config_loader <span class="token keyword">import</span> ConfigLoader  <span class="token keyword">from</span> src<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>validator <span class="token keyword">import</span> ReplyValidator  <span class="token keyword">from</span> src<span class="token punctuation">.</span>data_generator <span class="token keyword">import</span> StyleDataGenerator  <span class="token keyword">import</span> json  <span class="token keyword">import</span> os      <span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>      <span class="token comment"># 初始化配置加载器  </span>    config_loader <span class="token operator">=</span> ConfigLoader<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 加载配置信息  </span>    <span class="token keyword">try</span><span class="token punctuation">:</span>          settings <span class="token operator">=</span> config_loader<span class="token punctuation">.</span>load_settings<span class="token punctuation">(</span><span class="token punctuation">)</span>          style_config <span class="token operator">=</span> config_loader<span class="token punctuation">.</span>load_style_config<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token keyword">except</span> FileNotFoundError <span class="token keyword">as</span> e<span class="token punctuation">:</span>          <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"配置文件缺失：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>          <span class="token keyword">return</span>        <span class="token comment"># 初始化核心组件  </span>    generator <span class="token operator">=</span> StyleDataGenerator<span class="token punctuation">(</span>          api_key<span class="token operator">=</span>settings<span class="token punctuation">[</span><span class="token string">"API"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"ZHIPU_API_KEY"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>          style_config<span class="token operator">=</span>style_config      <span class="token punctuation">)</span>      validator <span class="token operator">=</span> ReplyValidator<span class="token punctuation">(</span>          model_path<span class="token operator">=</span>settings<span class="token punctuation">[</span><span class="token string">"PATHS"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"EMBEDDING_MODEL"</span><span class="token punctuation">]</span>      <span class="token punctuation">)</span>      <span class="token comment"># 执行数据生成流程  </span>    all_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>      <span class="token keyword">try</span><span class="token punctuation">:</span>          <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正在生成温柔风格数据..."</span><span class="token punctuation">)</span>          gentle_data <span class="token operator">=</span> generator<span class="token punctuation">.</span>generate_style_data<span class="token punctuation">(</span><span class="token string">"温柔"</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>          all_data<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>gentle_data<span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正在生成毒舌风格数据..."</span><span class="token punctuation">)</span>          sarcastic_data <span class="token operator">=</span> generator<span class="token punctuation">.</span>generate_style_data<span class="token punctuation">(</span><span class="token string">"毒舌"</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>          all_data<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>sarcastic_data<span class="token punctuation">)</span>        <span class="token keyword">except</span> KeyboardInterrupt<span class="token punctuation">:</span>          <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n用户中断操作，正在保存已生成数据..."</span><span class="token punctuation">)</span>      <span class="token keyword">finally</span><span class="token punctuation">:</span>          <span class="token comment"># 确保输出目录存在  </span>        output_dir <span class="token operator">=</span> <span class="token string">"outputs"</span>          os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>output_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>            <span class="token comment"># 持久化保存数据  </span>        output_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>output_dir<span class="token punctuation">,</span> <span class="token string">"style_chat_data.json"</span><span class="token punctuation">)</span>          <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>output_path<span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>              json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>all_data<span class="token punctuation">,</span> f<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>          <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"数据保存完成，有效样本数：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>all_data<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>      <span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>      main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="四、模型选型与设计"><a href="#四、模型选型与设计" class="headerlink" title="四、模型选型与设计"></a><strong>四、模型选型与设计</strong></h2><p>1.模型选型<br>根据当前的任务特点，选择合适的评测数据以及预选的候选模型</p><p>一般来讲，做什么样的任务就选什么样的模型，我们要做的是一个情感对话模型，所以我们在选择模型时应选择对中文文本理解能力较强的模型。</p><p>2.模型的大小选择</p><ul><li>服务器配置</li><li>任务复杂度</li></ul><p>可以根据任务选择对应的评测数据，对期望模型客观评测</p><p>当前任务为日常聊天对话模型，主要要求模型的中文理解能力，所以我们这里可以用 CLUE（中文理解）数据进行评测：</p><p>我们需要准备 opencompass 环境。</p><p>进入OpenCompass根目录下，执行命令</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#输出数据集清单</span>python tools/list_configs.py clue<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>执行后输出结果如下：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">+-----------------------------+------------------------------------------------------------------------------+| Dataset                     | Config Path                                                                  ||-----------------------------+------------------------------------------------------------------------------|| CLUE_C3_gen                 | opencompass/configs/datasets/CLUE_C3/CLUE_C3_gen.py                          || CLUE_C3_gen_8c358f          | opencompass/configs/datasets/CLUE_C3/CLUE_C3_gen_8c358f.py                   || CLUE_C3_ppl                 | opencompass/configs/datasets/CLUE_C3/CLUE_C3_ppl.py                          || CLUE_C3_ppl_56b537          | opencompass/configs/datasets/CLUE_C3/CLUE_C3_ppl_56b537.py                   || CLUE_C3_ppl_e24a31          | opencompass/configs/datasets/CLUE_C3/CLUE_C3_ppl_e24a31.py                   || CLUE_CMRC_gen               | opencompass/configs/datasets/CLUE_CMRC/CLUE_CMRC_gen.py                      || CLUE_CMRC_gen_1bd3c8        | opencompass/configs/datasets/CLUE_CMRC/CLUE_CMRC_gen_1bd3c8.py               || CLUE_CMRC_gen_3749cd        | opencompass/configs/datasets/CLUE_CMRC/CLUE_CMRC_gen_3749cd.py               || CLUE_CMRC_gen_8484b9        | opencompass/configs/datasets/CLUE_CMRC/CLUE_CMRC_gen_8484b9.py               || CLUE_CMRC_gen_941108        | opencompass/configs/datasets/CLUE_CMRC/CLUE_CMRC_gen_941108.py               || CLUE_DRCD_gen               | opencompass/configs/datasets/CLUE_DRCD/CLUE_DRCD_gen.py                      || CLUE_DRCD_gen_1bd3c8        | opencompass/configs/datasets/CLUE_DRCD/CLUE_DRCD_gen_1bd3c8.py               || CLUE_DRCD_gen_3749cd        | opencompass/configs/datasets/CLUE_DRCD/CLUE_DRCD_gen_3749cd.py               || CLUE_DRCD_gen_8484b9        | opencompass/configs/datasets/CLUE_DRCD/CLUE_DRCD_gen_8484b9.py               || CLUE_DRCD_gen_941108        | opencompass/configs/datasets/CLUE_DRCD/CLUE_DRCD_gen_941108.py               || CLUE_afqmc_gen              | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_gen.py                    || CLUE_afqmc_gen_901306       | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_gen_901306.py             || CLUE_afqmc_ppl              | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_ppl.py                    || CLUE_afqmc_ppl_378c5b       | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_ppl_378c5b.py             || CLUE_afqmc_ppl_6507d7       | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_ppl_6507d7.py             || CLUE_afqmc_ppl_7b0c1e       | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_ppl_7b0c1e.py             || CLUE_cmnli_gen              | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_gen.py                    || CLUE_cmnli_gen_1abf97       | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_gen_1abf97.py             || CLUE_cmnli_gen_51e956       | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_gen_51e956.py             || CLUE_cmnli_ppl              | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_ppl.py                    || CLUE_cmnli_ppl_98dd6e       | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_ppl_98dd6e.py             || CLUE_cmnli_ppl_ef69e7       | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_ppl_ef69e7.py             || CLUE_cmnli_ppl_fdc6de       | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_ppl_fdc6de.py             || CLUE_ocnli_gen              | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_gen.py                    || CLUE_ocnli_gen_51e956       | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_gen_51e956.py             || CLUE_ocnli_gen_c4cb6c       | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_gen_c4cb6c.py             || CLUE_ocnli_ppl              | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_ppl.py                    || CLUE_ocnli_ppl_98dd6e       | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_ppl_98dd6e.py             || CLUE_ocnli_ppl_ef69e7       | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_ppl_ef69e7.py             || CLUE_ocnli_ppl_fdc6de       | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_ppl_fdc6de.py             || FewCLUE_bustm_gen           | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_gen.py              || FewCLUE_bustm_gen_634f41    | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_gen_634f41.py       || FewCLUE_bustm_ppl           | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_ppl.py              || FewCLUE_bustm_ppl_4b16c0    | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_ppl_4b16c0.py       || FewCLUE_bustm_ppl_9ef540    | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_ppl_9ef540.py       || FewCLUE_bustm_ppl_e53034    | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_ppl_e53034.py       || FewCLUE_chid_gen            | opencompass/configs/datasets/FewCLUE_chid/FewCLUE_chid_gen.py                || FewCLUE_chid_gen_0a29a2     | opencompass/configs/datasets/FewCLUE_chid/FewCLUE_chid_gen_0a29a2.py         || FewCLUE_chid_ppl            | opencompass/configs/datasets/FewCLUE_chid/FewCLUE_chid_ppl.py                || FewCLUE_chid_ppl_8f2872     | opencompass/configs/datasets/FewCLUE_chid/FewCLUE_chid_ppl_8f2872.py         || FewCLUE_chid_ppl_acccb5     | opencompass/configs/datasets/FewCLUE_chid/FewCLUE_chid_ppl_acccb5.py         || FewCLUE_cluewsc_gen         | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_gen.py          || FewCLUE_cluewsc_gen_c68933  | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_gen_c68933.py   || FewCLUE_cluewsc_ppl         | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_ppl.py          || FewCLUE_cluewsc_ppl_12e4e0  | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_ppl_12e4e0.py   || FewCLUE_cluewsc_ppl_4284a0  | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_ppl_4284a0.py   || FewCLUE_cluewsc_ppl_868415  | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_ppl_868415.py   || FewCLUE_csl_gen             | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_gen.py                  || FewCLUE_csl_gen_28b223      | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_gen_28b223.py           || FewCLUE_csl_gen_87f4a8      | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_gen_87f4a8.py           || FewCLUE_csl_ppl             | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_ppl.py                  || FewCLUE_csl_ppl_769f8d      | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_ppl_769f8d.py           || FewCLUE_csl_ppl_841b62      | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_ppl_841b62.py           || FewCLUE_eprstmt_gen         | opencompass/configs/datasets/FewCLUE_eprstmt/FewCLUE_eprstmt_gen.py          || FewCLUE_eprstmt_gen_740ea0  | opencompass/configs/datasets/FewCLUE_eprstmt/FewCLUE_eprstmt_gen_740ea0.py   || FewCLUE_eprstmt_ppl         | opencompass/configs/datasets/FewCLUE_eprstmt/FewCLUE_eprstmt_ppl.py          || FewCLUE_eprstmt_ppl_1ce587  | opencompass/configs/datasets/FewCLUE_eprstmt/FewCLUE_eprstmt_ppl_1ce587.py   || FewCLUE_eprstmt_ppl_f1e631  | opencompass/configs/datasets/FewCLUE_eprstmt/FewCLUE_eprstmt_ppl_f1e631.py   || FewCLUE_ocnli_fc_gen        | opencompass/configs/datasets/FewCLUE_ocnli_fc/FewCLUE_ocnli_fc_gen.py        || FewCLUE_ocnli_fc_gen_f97a97 | opencompass/configs/datasets/FewCLUE_ocnli_fc/FewCLUE_ocnli_fc_gen_f97a97.py || FewCLUE_ocnli_fc_ppl        | opencompass/configs/datasets/FewCLUE_ocnli_fc/FewCLUE_ocnli_fc_ppl.py        || FewCLUE_ocnli_fc_ppl_9e8b3d | opencompass/configs/datasets/FewCLUE_ocnli_fc/FewCLUE_ocnli_fc_ppl_9e8b3d.py || FewCLUE_ocnli_fc_ppl_c08300 | opencompass/configs/datasets/FewCLUE_ocnli_fc/FewCLUE_ocnli_fc_ppl_c08300.py || FewCLUE_tnews_gen           | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_gen.py              || FewCLUE_tnews_gen_b90e4a    | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_gen_b90e4a.py       || FewCLUE_tnews_ppl           | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_ppl.py              || FewCLUE_tnews_ppl_7d1c07    | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_ppl_7d1c07.py       || FewCLUE_tnews_ppl_d10e8a    | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_ppl_d10e8a.py       || FewCLUE_tnews_ppl_fff486    | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_ppl_fff486.py       |+-----------------------------+------------------------------------------------------------------------------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>gen：生成任务<br>ppl：分类任务</p><p>我们本次任务大多是短语对话，可以选择 FewCLUE_bustm_gen（短文本分类）、FewCLUE_ocnli_fc_gen（自然语言推理）对预期模型进行评估。</p><p>我们这里选择Qwen1.5 的 0.5b、1.8b两个个模型来进行比较，这里记得修改opencompass 下对应模型文件中的模型路径。</p><p>运行下面命令开始进行模型评估比较：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python run.py <span class="token punctuation">\</span><span class="token parameter variable">--models</span> hf_qwen1_5_0_5b_chat hf_qwen1_5_1_8b_chat <span class="token punctuation">\</span><span class="token parameter variable">--datasets</span> FewCLUE_bustm_gen FewCLUE_ocnli_fc_gen <span class="token punctuation">\</span><span class="token parameter variable">--debug</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>根据评估结果，选择最终模型。</p><p>评估结果如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">tabulate <span class="token builtin">format</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span>dataset        version    metric    mode      qwen1<span class="token punctuation">.</span><span class="token number">5</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span>5b<span class="token operator">-</span>chat<span class="token operator">-</span>hf    qwen1<span class="token punctuation">.</span><span class="token number">5</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span>8b<span class="token operator">-</span>chat<span class="token operator">-</span>hf<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>  <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>  <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>  <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>  <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>  <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>bustm<span class="token operator">-</span>dev      5cc669     accuracy  gen                      <span class="token number">48.75</span>                   <span class="token number">48.75</span>bustm<span class="token operator">-</span>test     5cc669     accuracy  gen                      <span class="token number">50.00</span>                   <span class="token number">50.11</span>ocnli_fc<span class="token operator">-</span>dev   <span class="token number">51e956</span>     accuracy  gen                      <span class="token number">35.62</span>                   <span class="token number">46.25</span>ocnli_fc<span class="token operator">-</span>test  <span class="token number">51e956</span>     accuracy  gen                      <span class="token number">35.20</span>                   <span class="token number">50.63</span>$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其实这里我们选的是同一个模型的不同参数版本，那么必然是参数量大的那个评估效果要好。</p><h2 id="五、模型训练与评估"><a href="#五、模型训练与评估" class="headerlink" title="五、模型训练与评估"></a><strong>五、模型训练与评估</strong></h2><h3 id="5-1训练环境配置"><a href="#5-1训练环境配置" class="headerlink" title="5.1训练环境配置"></a><strong>5.1训练环境配置</strong></h3><p>使用环境</p><ul><li>软件环境：Windows11 + WSL2-Linux-Ubuntu22.04子系统</li><li>硬件环境：GeForce RTX 4060 Ti 16GB</li><li>框架与工具（LLamaFactory/Xtuner）</li></ul><p>因为当前任务的结果更偏向于主观评测，xtener就提供了在训练过程中的主观评测，因此选择xtuner</p><h3 id="5-2-训练参数设置"><a href="#5-2-训练参数设置" class="headerlink" title="5.2 训练参数设置"></a><strong>5.2 训练参数设置</strong></h3><p>安装好xtuner环境</p><p>创建微调训练相关的配置文件在左侧的文件列表，xtuner 的文件夹里，打开<code>xtuner/xtuner/configs/internlm/internlm2_chat_1_8b/internlm2_chat_1_8b_qlora_alpaca_e3.py</code>，复制一份到其他目录。<br>打开这个文件，然后修改预训练模型地址，数据文件地址等。<br>我配置修改的地方如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">### 在 PART 1  Settings 中</span><span class="token comment"># 我们预训练模型存放路径</span>pretrained_model_name_or_path <span class="token operator">=</span> <span class="token string">"/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat"</span><span class="token comment"># 微调数据存放路径</span>alpaca_en_path <span class="token operator">=</span> <span class="token string">"/home/moyuai/moyuai/data/output.json"</span><span class="token comment"># 训练中最大的文本长度</span>max_length <span class="token operator">=</span> <span class="token number">512</span><span class="token comment"># 每一批训练样本的大小，根据自己的硬件调整</span>batch_size <span class="token operator">=</span> <span class="token number">4</span> <span class="token comment"># 最大训练轮数</span>max_epochs <span class="token operator">=</span> <span class="token number">3000</span> <span class="token comment"># 验证数据</span>evaluation_inputs <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token string">"男朋友给女主播刷火箭，算精神出轨吗？"</span><span class="token punctuation">,</span>    <span class="token string">"喝红酒养生，结果喝到头晕…"</span><span class="token punctuation">,</span>    <span class="token string">"闺蜜和我前任互关小红书，取关拉黑三连击！"</span><span class="token punctuation">,</span>    <span class="token string">"体检说胆固醇高，要戒炸鸡了吗？"</span><span class="token punctuation">,</span>    <span class="token string">"剧本杀遇读本玩家，直接摔门离场！"</span><span class="token punctuation">,</span>    <span class="token string">"领导周末发60秒语音矩阵，装没看见行吗？"</span><span class="token punctuation">,</span>    <span class="token punctuation">]</span><span class="token comment">### 在 PART 2  Model &amp; Tokenizer 中</span><span class="token comment"># 将 qlora4 位关闭，开启八位</span>load_in_4bit<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>load_in_8bit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span><span class="token comment">### 注释下面这些内容</span><span class="token comment"># bnb_4bit_compute_dtype=torch.float16,</span><span class="token comment"># bnb_4bit_use_double_quant=True,</span><span class="token comment"># bnb_4bit_quant_type="nf4",</span>r<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>lora_alpha<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token comment"># 一般是r的两倍</span><span class="token comment">### 在 PART 3  Dataset &amp; Dataloader 中</span>dataset<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span>load_dataset<span class="token punctuation">,</span> path<span class="token operator">=</span><span class="token string">"json"</span><span class="token punctuation">,</span>data_files<span class="token operator">=</span>data_files<span class="token punctuation">)</span><span class="token punctuation">,</span>dataset_map_fn<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>参数设置完成后，我们进入我们复制的 <code>qwen1_5_1_8b_chat_qlora_alpaca_e3.py</code> 文件目录下，在当前目录下，输入以下命令启动微调脚本：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 后台终端运行</span><span class="token function">nohup</span> xtuner train qwen1_5_1_8b_chat_qlora_alpaca_e3.py <span class="token operator">&gt;</span> train_05_10_2.log <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span><span class="token comment">#单机单卡</span>xtuner train qwen1_5_1_8b_chat_qlora_alpaca_e3.py<span class="token comment">#单机多卡</span><span class="token assign-left variable">NPROC_PER_NODE</span><span class="token operator">=</span><span class="token variable">${GPU_NUM}</span> xtuner train qwen1_5_1_8b_chat_qlora_alpaca_e3 <span class="token parameter variable">--deepspeed</span> deepspeed_zero2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们训练到20000轮后查看日志，发现模型效果还行，不管是生成的答案还有loss值都是不错的，20000轮训练的日志如下：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")05/10 08:08:26 - mmengine - INFO - Iter(train) [ 19510/480000]  lr: 1.9994e-04  eta: 7 days, 19:52:24  time: 5.9691  data_time: 4.4355  memory: 9843  loss: 0.0042  grad_norm: 0.122005/10 08:08:38 - mmengine - INFO - Iter(train) [ 19520/480000]  lr: 1.9994e-04  eta: 7 days, 19:51:14  time: 1.2358  data_time: 0.0058  memory: 9844  loss: 0.0059  grad_norm: 0.126105/10 08:08:56 - mmengine - INFO - Iter(train) [ 19530/480000]  lr: 1.9994e-04  eta: 7 days, 19:52:00  time: 1.7250  data_time: 0.2061  memory: 9844  loss: 0.0046  grad_norm: 0.126105/10 08:09:09 - mmengine - INFO - Iter(train) [ 19540/480000]  lr: 1.9994e-04  eta: 7 days, 19:51:21  time: 1.3681  data_time: 0.0061  memory: 9844  loss: 0.0027  grad_norm: 0.129005/10 08:09:23 - mmengine - INFO - Iter(train) [ 19550/480000]  lr: 1.9994e-04  eta: 7 days, 19:50:37  time: 1.3440  data_time: 0.0062  memory: 9846  loss: 0.0046  grad_norm: 0.129005/10 08:09:38 - mmengine - INFO - Iter(train) [ 19560/480000]  lr: 1.9994e-04  eta: 7 days, 19:50:29  time: 1.4959  data_time: 0.0061  memory: 9846  loss: 0.0027  grad_norm: 0.126305/10 08:09:51 - mmengine - INFO - Iter(train) [ 19570/480000]  lr: 1.9994e-04  eta: 7 days, 19:49:43  time: 1.3353  data_time: 0.0060  memory: 9848  loss: 0.0030  grad_norm: 0.124205/10 08:10:06 - mmengine - INFO - Iter(train) [ 19580/480000]  lr: 1.9994e-04  eta: 7 days, 19:49:40  time: 1.5177  data_time: 0.0060  memory: 9843  loss: 0.0058  grad_norm: 0.124205/10 08:10:20 - mmengine - INFO - Iter(train) [ 19590/480000]  lr: 1.9994e-04  eta: 7 days, 19:48:59  time: 1.3554  data_time: 0.0060  memory: 9843  loss: 0.0034  grad_norm: 0.125405/10 08:10:33 - mmengine - INFO - Iter(train) [ 19600/480000]  lr: 1.9994e-04  eta: 7 days, 19:48:17  time: 1.3532  data_time: 0.0062  memory: 9842  loss: 0.0044  grad_norm: 0.128605/10 08:10:48 - mmengine - INFO - Iter(train) [ 19610/480000]  lr: 1.9994e-04  eta: 7 days, 19:48:07  time: 1.4891  data_time: 0.0060  memory: 9842  loss: 0.0037  grad_norm: 0.128605/10 08:11:01 - mmengine - INFO - Iter(train) [ 19620/480000]  lr: 1.9994e-04  eta: 7 days, 19:47:21  time: 1.3355  data_time: 0.0062  memory: 9844  loss: 0.0047  grad_norm: 0.135005/10 08:11:17 - mmengine - INFO - Iter(train) [ 19630/480000]  lr: 1.9994e-04  eta: 7 days, 19:47:17  time: 1.5144  data_time: 0.0061  memory: 9844  loss: 0.0040  grad_norm: 0.135005/10 08:11:30 - mmengine - INFO - Iter(train) [ 19640/480000]  lr: 1.9994e-04  eta: 7 days, 19:46:30  time: 1.3288  data_time: 0.0060  memory: 9844  loss: 0.0051  grad_norm: 0.131105/10 08:11:45 - mmengine - INFO - Iter(train) [ 19650/480000]  lr: 1.9994e-04  eta: 7 days, 19:46:25  time: 1.5094  data_time: 0.0061  memory: 9842  loss: 0.0069  grad_norm: 0.138105/10 08:11:58 - mmengine - INFO - Iter(train) [ 19660/480000]  lr: 1.9994e-04  eta: 7 days, 19:45:37  time: 1.3286  data_time: 0.0059  memory: 9845  loss: 0.0057  grad_norm: 0.138105/10 08:12:12 - mmengine - INFO - Iter(train) [ 19670/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:57  time: 1.3595  data_time: 0.0059  memory: 9846  loss: 0.0056  grad_norm: 0.142705/10 08:12:26 - mmengine - INFO - Iter(train) [ 19680/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:35  time: 1.4349  data_time: 0.0060  memory: 9843  loss: 0.0050  grad_norm: 0.142605/10 08:12:41 - mmengine - INFO - Iter(train) [ 19690/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:29  time: 1.5082  data_time: 0.2061  memory: 9838  loss: 0.0034  grad_norm: 0.142605/10 08:12:57 - mmengine - INFO - Iter(train) [ 19700/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:32  time: 1.5429  data_time: 0.0065  memory: 9844  loss: 0.0045  grad_norm: 0.148905/10 08:13:10 - mmengine - INFO - Iter(train) [ 19710/480000]  lr: 1.9994e-04  eta: 7 days, 19:43:45  time: 1.3281  data_time: 0.0060  memory: 9846  loss: 0.0038  grad_norm: 0.148905/10 08:13:23 - mmengine - INFO - Iter(train) [ 19720/480000]  lr: 1.9994e-04  eta: 7 days, 19:43:00  time: 1.3418  data_time: 0.0062  memory: 9844  loss: 0.0042  grad_norm: 0.149705/10 08:13:38 - mmengine - INFO - Iter(train) [ 19730/480000]  lr: 1.9994e-04  eta: 7 days, 19:42:53  time: 1.4978  data_time: 0.0059  memory: 9842  loss: 0.0038  grad_norm: 0.150705/10 08:13:52 - mmengine - INFO - Iter(train) [ 19740/480000]  lr: 1.9994e-04  eta: 7 days, 19:42:08  time: 1.3417  data_time: 0.0061  memory: 9842  loss: 0.0042  grad_norm: 0.150705/10 08:14:07 - mmengine - INFO - Iter(train) [ 19750/480000]  lr: 1.9993e-04  eta: 7 days, 19:42:03  time: 1.5066  data_time: 0.0060  memory: 9844  loss: 0.0052  grad_norm: 0.148705/10 08:14:20 - mmengine - INFO - Iter(train) [ 19760/480000]  lr: 1.9993e-04  eta: 7 days, 19:41:21  time: 1.3511  data_time: 0.0059  memory: 9844  loss: 0.0040  grad_norm: 0.145105/10 08:14:36 - mmengine - INFO - Iter(train) [ 19770/480000]  lr: 1.9993e-04  eta: 7 days, 19:41:16  time: 1.5123  data_time: 0.0060  memory: 9845  loss: 0.0062  grad_norm: 0.145105/10 08:14:49 - mmengine - INFO - Iter(train) [ 19780/480000]  lr: 1.9993e-04  eta: 7 days, 19:40:25  time: 1.3094  data_time: 0.0059  memory: 9845  loss: 0.0051  grad_norm: 0.146805/10 08:15:02 - mmengine - INFO - Iter(train) [ 19790/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:45  time: 1.3595  data_time: 0.0061  memory: 9839  loss: 0.0049  grad_norm: 0.146805/10 08:15:18 - mmengine - INFO - Iter(train) [ 19800/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:59  time: 1.5899  data_time: 0.0062  memory: 9843  loss: 0.0040  grad_norm: 0.147105/10 08:15:32 - mmengine - INFO - Iter(train) [ 19810/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:20  time: 1.3668  data_time: 0.0060  memory: 9844  loss: 0.0057  grad_norm: 0.142605/10 08:15:47 - mmengine - INFO - Iter(train) [ 19820/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:18  time: 1.5212  data_time: 0.0060  memory: 9840  loss: 0.0058  grad_norm: 0.142605/10 08:16:01 - mmengine - INFO - Iter(train) [ 19830/480000]  lr: 1.9993e-04  eta: 7 days, 19:38:37  time: 1.3542  data_time: 0.0060  memory: 9843  loss: 0.0073  grad_norm: 0.139505/10 08:16:13 - mmengine - INFO - Iter(train) [ 19840/480000]  lr: 1.9993e-04  eta: 7 days, 19:37:37  time: 1.2729  data_time: 0.0059  memory: 9841  loss: 0.0033  grad_norm: 0.136605/10 08:16:31 - mmengine - INFO - Iter(train) [ 19850/480000]  lr: 1.9993e-04  eta: 7 days, 19:38:28  time: 1.7519  data_time: 0.4193  memory: 9845  loss: 0.0041  grad_norm: 0.136605/10 08:16:44 - mmengine - INFO - Iter(train) [ 19860/480000]  lr: 1.9993e-04  eta: 7 days, 19:37:29  time: 1.2766  data_time: 0.0057  memory: 9845  loss: 0.0034  grad_norm: 0.126905/10 08:17:00 - mmengine - INFO - Iter(train) [ 19870/480000]  lr: 1.9993e-04  eta: 7 days, 19:37:56  time: 1.6473  data_time: 0.0062  memory: 9841  loss: 0.0069  grad_norm: 0.126905/10 08:17:13 - mmengine - INFO - Iter(train) [ 19880/480000]  lr: 1.9993e-04  eta: 7 days, 19:36:54  time: 1.2646  data_time: 0.0058  memory: 9848  loss: 0.0044  grad_norm: 0.129905/10 08:17:28 - mmengine - INFO - Iter(train) [ 19890/480000]  lr: 1.9993e-04  eta: 7 days, 19:36:57  time: 1.5415  data_time: 0.0059  memory: 9847  loss: 0.0063  grad_norm: 0.136705/10 08:17:41 - mmengine - INFO - Iter(train) [ 19900/480000]  lr: 1.9993e-04  eta: 7 days, 19:36:03  time: 1.2998  data_time: 0.0059  memory: 9846  loss: 0.0054  grad_norm: 0.136705/10 08:17:54 - mmengine - INFO - Iter(train) [ 19910/480000]  lr: 1.9993e-04  eta: 7 days, 19:35:12  time: 1.3098  data_time: 0.0059  memory: 9846  loss: 0.0035  grad_norm: 0.136305/10 08:18:11 - mmengine - INFO - Iter(train) [ 19920/480000]  lr: 1.9993e-04  eta: 7 days, 19:35:38  time: 1.6464  data_time: 0.0062  memory: 9845  loss: 0.0068  grad_norm: 0.138505/10 08:18:23 - mmengine - INFO - Iter(train) [ 19930/480000]  lr: 1.9993e-04  eta: 7 days, 19:34:39  time: 1.2759  data_time: 0.0056  memory: 9842  loss: 0.0038  grad_norm: 0.138505/10 08:18:39 - mmengine - INFO - Iter(train) [ 19940/480000]  lr: 1.9993e-04  eta: 7 days, 19:34:57  time: 1.6086  data_time: 0.0065  memory: 9844  loss: 0.0065  grad_norm: 0.129505/10 08:18:52 - mmengine - INFO - Iter(train) [ 19950/480000]  lr: 1.9993e-04  eta: 7 days, 19:34:02  time: 1.2938  data_time: 0.0059  memory: 9844  loss: 0.0047  grad_norm: 0.129505/10 08:19:05 - mmengine - INFO - Iter(train) [ 19960/480000]  lr: 1.9993e-04  eta: 7 days, 19:33:09  time: 1.2996  data_time: 0.0059  memory: 9845  loss: 0.0042  grad_norm: 0.135405/10 08:19:22 - mmengine - INFO - Iter(train) [ 19970/480000]  lr: 1.9993e-04  eta: 7 days, 19:33:27  time: 1.6098  data_time: 0.0061  memory: 9844  loss: 0.0043  grad_norm: 0.130805/10 08:19:34 - mmengine - INFO - Iter(train) [ 19980/480000]  lr: 1.9993e-04  eta: 7 days, 19:32:27  time: 1.2702  data_time: 0.0056  memory: 9845  loss: 0.0047  grad_norm: 0.130805/10 08:19:50 - mmengine - INFO - Iter(train) [ 19990/480000]  lr: 1.9993e-04  eta: 7 days, 19:32:37  time: 1.5734  data_time: 0.0059  memory: 9846  loss: 0.0048  grad_norm: 0.131105/10 08:20:02 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_00101005/10 08:20:02 - mmengine - INFO - Iter(train) [ 20000/480000]  lr: 1.9993e-04  eta: 7 days, 19:31:29  time: 1.2366  data_time: 0.0058  memory: 9844  loss: 0.0064  grad_norm: 0.137205/10 08:20:02 - mmengine - INFO - after_train_iter in EvaluateChatHook.05/10 08:20:10 - mmengine - INFO - Sample output:&lt;|im_start|&gt;systemBelow is an instruction that describes a task. Write a response that appropriately completes the request.&lt;|im_end|&gt;&lt;|im_start|&gt;user男朋友给女主播刷火箭，算精神出轨吗？&lt;|im_end|&gt;&lt;|im_start|&gt;assistant温柔哎呀，这种事情确实让人有些难过呢。男票给女主播刷火箭可能只是单纯的游戏娱乐，不应该成为精神出轨的定义。你们之间应该及时沟通，表达一下你的感受，了解他为什么会做出这样的行为。同时，也可以谈谈其他的，分散一下注意力，让彼此之间的关系更加稳固。💖如果需要倾诉或者寻求更多建议，我在这里哦。🌸&lt;|im_end|&gt;05/10 08:20:14 - mmengine - INFO - Sample output:&lt;|im_start|&gt;systemBelow is an instruction that describes a task. Write a response that appropriately completes the request.&lt;|im_end|&gt;&lt;|im_start|&gt;user洗牙后牙缝漏风，吹蜡烛像鼓风机！&lt;|im_end|&gt;&lt;|im_start|&gt;assistant毒舌栓Q，你这牙缝大得都能塞进一本《新华字典》了。下次洗牙记得提醒牙医手下留情，别让你的牙缝比得上喜马拉雅山的大峡谷啊！🦷🌊&lt;|im_end|&gt;05/10 08:20:19 - mmengine - INFO - Sample output:&lt;|im_start|&gt;systemBelow is an instruction that describes a task. Write a response that appropriately completes the request.&lt;|im_end|&gt;&lt;|im_start|&gt;user喝红酒养生，结果喝到头晕…&lt;|im_end|&gt;&lt;|im_start|&gt;assistant温柔哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖&lt;|im_end|&gt;05/10 08:20:27 - mmengine - INFO - Sample output:&lt;|im_start|&gt;systemBelow is an instruction that describes a task. Write a response that appropriately completes the request.&lt;|im_end|&gt;&lt;|im_start|&gt;user闺蜜和我前任互关小红书，取关拉黑三连击！&lt;|im_end|&gt;&lt;|im_start|&gt;assistant栓Q，这操作简直比双十一抢购还刺激，直接给你来个情感和网络界的地震级爆炸音！不过别太在意，友谊的小船不能翻，但至少能让你们的对话多一点“特殊”的元素，这就是生活的一部分嘛。别让这种小事影响了你们之间的闺蜜和前任，毕竟，真正的友情不是靠取关和拉黑来考验的。👩‍💼💔&lt;|im_end|&gt;05/10 08:20:34 - mmengine - INFO - Sample output:&lt;|im_start|&gt;systemBelow is an instruction that describes a task. Write a response that appropriately completes the request.&lt;|im_end|&gt;&lt;|im_start|&gt;user体检说胆固醇高，要戒炸鸡了吗？&lt;|im_end|&gt;&lt;|im_start|&gt;assistant温柔哎呀，这确实需要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖 而且，戒掉炸鸡也可能会影响食欲，记得多喝水，保持良好的饮食习惯哦。🌸 如果需要更多建议或者想要聊聊其他话题，我都在这里呢。😊&lt;|im_end|&gt;05/10 08:20:38 - mmengine - INFO - Sample output:&lt;|im_start|&gt;systemBelow is an instruction that describes a task. Write a response that appropriately completes the request.&lt;|im_end|&gt;&lt;|im_start|&gt;user剧本杀遇读本玩家，直接摔门离场！&lt;|im_end|&gt;&lt;|im_start|&gt;assistant毒舌栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“退退退”！&lt;|im_end|&gt;05/10 08:20:42 - mmengine - INFO - Sample output:&lt;|im_start|&gt;systemBelow is an instruction that describes a task. Write a response that appropriately completes the request.&lt;|im_end|&gt;&lt;|im_start|&gt;user被同事说'你今天的眼线像苍蝇腿'，气到晕厥！&lt;|im_end|&gt;&lt;|im_start|&gt;assistant毒舌栓Q了，你这同事是自带放大镜上班的吗？不过别太往心里去，你的眼线可能是想开个开放日，举办“恐怖节”。下次记得，找美容师，别让那些不懂欣赏的家伙影响了你的造型。💄😱&lt;|im_end|&gt;05/10 08:20:47 - mmengine - INFO - Sample output:&lt;|im_start|&gt;systemBelow is an instruction that describes a task. Write a response that appropriately completes the request.&lt;|im_end|&gt;&lt;|im_start|&gt;user领导周末发60秒语音矩阵，装没看见行吗？&lt;|im_end|&gt;&lt;|im_start|&gt;assistant温柔哎呀，这种事情确实会让人感到有些失落呢。领导的指示很重要，及时回应和表达自己的立场是很重要的。你可以选择看到并且回复，或者可以想想有没有其他方式表达你的感受。💖你觉得呢？&lt;|im_end|&gt;05/10 08:20:47 - mmengine - INFO - Saving checkpoint at 20000 iterations<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-3-模型转换合并"><a href="#5-3-模型转换合并" class="headerlink" title="5.3 模型转换合并"></a><strong>5.3 模型转换合并</strong></h3><p>模型转换</p><p>模型训练后会自动保存成 PTH 模型（例如 iter_2000.pth ，如果使用了 DeepSpeed，则将会是一个文件夹），我们需要利用 <code>xtuner convert pth_to_hf</code> 将其转换为 HuggingFace 模型，以便于后续使用。具体命令为：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">xtuner convert pth_to_hf <span class="token variable">${FINETUNE_CFG}</span> <span class="token variable">${PTH_PATH}</span> <span class="token variable">${SAVE_PATH}</span>xtuner convert pth_to_hf qwen1_5_1_8b_chat_qlora_alpaca_e3.py /home/moyuai/moyuai/xtuner_out/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3/iter_7000.pth /home/moyuai/moyuai/xtuner_out/iter_7000_hf<span class="token comment"># 例如：以我本地为例</span>xtuner convert pth_to_hf qwen1_5_1_8b_chat_qlora_alpaca_e3.py /home/moyuai/moyuai/python/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3/iter_20000.pth /home/moyuai/moyuai/python/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3/iter_20000_hf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ul><li>FINETUNE_CFG：填我们复制的 <code>py</code> 配置文件路径</li><li>PTH_PATH：填我们输出的LoRA权重路径</li><li>SAVE_PATH：填我们要保存的路径</li></ul><p> 模型合并</p><p>如果使用了 LoRA / QLoRA 微调，则模型转换后将得到 adapter 参数，而并不包含原 LLM 参数。如果您期望获得合并后的模型权重（例如用于后续评测），那么可以利用 <code>xtuner convert merge</code> ：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">xtuner convert merge <span class="token variable">${LLM}</span> <span class="token variable">${LLM_ADAPTER}</span> <span class="token variable">${SAVE_PATH}</span><span class="token comment"># 例如：以我本地为例</span>xtuner convert merge /home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat /home/moyuai/moyuai/xtuner_out/iter_7000_hf /home/moyuai/moyuai/xtuner_out/Qwen1-5-1-8B-Chat-xtuner-merged-7000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li>LLM：填写我们基座模型路径</li><li>LLM_ADAPTER：填写我们转换过后的权重路径</li><li>SAVE_PATH：填写我们要保存的模型路径</li></ul><h2 id="六、模型部署与应用"><a href="#六、模型部署与应用" class="headerlink" title="六、模型部署与应用"></a><strong>六、模型部署与应用</strong></h2><h3 id="6-1-选择合适的大模型推理框架"><a href="#6-1-选择合适的大模型推理框架" class="headerlink" title="6.1 选择合适的大模型推理框架"></a>6.1 选择合适的大模型推理框架</h3><p>选择合适的大模型推理框架部署模型（这里选择LMDeploy）<br>但是我们要注意我们微调出来的模型和LMDeploy支持的对话模板不同，因此我们要进行对话模板对齐。</p><p>我们配好LMDeploy环境。</p><h4 id="6-1-1-LMDeploy支持的对话模板的形式"><a href="#6-1-1-LMDeploy支持的对话模板的形式" class="headerlink" title="6.1.1 LMDeploy支持的对话模板的形式"></a>6.1.1 LMDeploy支持的对话模板的形式</h4><p>LMDeploy 支持两种添加对话模板的形式：</p><ul><li>一种是利用现有对话模板，直接配置一个如下的 json 文件使用。</li></ul><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>   <span class="token property">"model_name"</span><span class="token operator">:</span> <span class="token string">"your awesome chat template name"</span><span class="token punctuation">,</span>   <span class="token property">"system"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;system\n"</span><span class="token punctuation">,</span>   <span class="token property">"meta_instruction"</span><span class="token operator">:</span> <span class="token string">"You are a robot developed by LMDeploy."</span><span class="token punctuation">,</span>    <span class="token property">"eosys"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>   <span class="token property">"user"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;user\n"</span><span class="token punctuation">,</span>   <span class="token property">"eoh"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>   <span class="token property">"assistant"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;assistant\n"</span><span class="token punctuation">,</span>   <span class="token property">"eoa"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>   <span class="token property">"separator"</span><span class="token operator">:</span> <span class="token string">"\n"</span><span class="token punctuation">,</span>   <span class="token property">"capability"</span><span class="token operator">:</span> <span class="token string">"chat"</span><span class="token punctuation">,</span>   <span class="token property">"stop_words"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>model_name</code> 为必填项，可以是 LMDeploy 内置对话模板名（通过 lmdeploy list 可查阅），也可以是新名字。其他字段可选填。 当 <code>model_name</code> 是内置对话模板名时，json文件中各非 null 字段会覆盖原有对话模板的对应属性。 而当 <code>model_name</code> 是新名字时，<code>它会把将BaseChatTemplate</code> 直接注册成新的对话模板。<br>其具体定义可以参考<a href="https://github.com/InternLM/lmdeploy/blob/24bd4b9ab6a15b3952e62bcfc72eaba03bce9dcb/lmdeploy/model.py#L113-L188">BaseChatTemplate</a>。这样一个模板将会以下面的形式进行拼接。</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>system<span class="token punctuation">}</span><span class="token punctuation">{</span>meta_instruction<span class="token punctuation">}</span><span class="token punctuation">{</span>eosys<span class="token punctuation">}</span><span class="token punctuation">{</span>user<span class="token punctuation">}</span><span class="token punctuation">{</span>user_content<span class="token punctuation">}</span><span class="token punctuation">{</span>eoh<span class="token punctuation">}</span><span class="token punctuation">{</span>assistant<span class="token punctuation">}</span> <span class="token punctuation">{</span>assistant_content<span class="token punctuation">}</span><span class="token punctuation">{</span>eoa<span class="token punctuation">}</span><span class="token punctuation">{</span>separator<span class="token punctuation">}</span><span class="token punctuation">{</span>user<span class="token punctuation">}</span>...<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在使用 <code>CLI</code> 工具时，可以通过 <code>--chat-template</code> 传入自定义对话模板，比如：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">lmdeploy serve api_server internlm/internlm2_5-7b-chat --chat-template <span class="token variable">${JSON_FILE}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>也可以在通过接口函数传入，比如：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> lmdeploy <span class="token keyword">import</span> ChatTemplateConfig<span class="token punctuation">,</span> serveserve<span class="token punctuation">(</span><span class="token string">'internlm/internlm2_5-7b-chat'</span><span class="token punctuation">,</span>     chat_template_config<span class="token operator">=</span>ChatTemplateConfig<span class="token punctuation">.</span>from_json<span class="token punctuation">(</span><span class="token string">'${JSON_FILE}'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><ul><li>另一种是以 LMDeploy 现有对话模板，自定义一个python对话模板类，注册成功后直接用即可。优点是自定义程度高，可控性强。 下面是一个注册 LMDeploy 对话模板的例子：</li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> lmdeploy<span class="token punctuation">.</span>model <span class="token keyword">import</span> MODELS<span class="token punctuation">,</span> BaseChatTemplate<span class="token decorator annotation punctuation">@MODELS<span class="token punctuation">.</span>register_module</span><span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'customized_model'</span><span class="token punctuation">)</span> <span class="token keyword">class</span> <span class="token class-name">CustomizedModel</span><span class="token punctuation">(</span>BaseChatTemplate<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token triple-quoted-string string">"""A customized chat template."""</span>   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                system<span class="token operator">=</span><span class="token string">'&lt;|im_start|&gt;system\n'</span><span class="token punctuation">,</span>                meta_instruction<span class="token operator">=</span><span class="token string">'You are a robot developed by LMDeploy.'</span><span class="token punctuation">,</span>                 user<span class="token operator">=</span><span class="token string">'&lt;|im_start|&gt;user\n'</span><span class="token punctuation">,</span>                assistant<span class="token operator">=</span><span class="token string">'&lt;|im_start|&gt;assistant\n'</span><span class="token punctuation">,</span>                eosys<span class="token operator">=</span><span class="token string">'&lt;|im_end|&gt;\n'</span><span class="token punctuation">,</span>                eoh<span class="token operator">=</span><span class="token string">'&lt;|im_end|&gt;\n'</span><span class="token punctuation">,</span>                eoa<span class="token operator">=</span><span class="token string">'&lt;|im_end|&gt;'</span><span class="token punctuation">,</span>                separator<span class="token operator">=</span><span class="token string">'\n'</span><span class="token punctuation">,</span>                stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'&lt;|im_end|&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;|action_end|&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>       <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>system<span class="token operator">=</span>system<span class="token punctuation">,</span>                        meta_instruction<span class="token operator">=</span>meta_instruction<span class="token punctuation">,</span>                        eosys<span class="token operator">=</span>eosys<span class="token punctuation">,</span>                        user<span class="token operator">=</span>user<span class="token punctuation">,</span>                        eoh<span class="token operator">=</span>eoh<span class="token punctuation">,</span>                        assistant<span class="token operator">=</span>assistant<span class="token punctuation">,</span>                        eoa<span class="token operator">=</span>eoa<span class="token punctuation">,</span>                        separator<span class="token operator">=</span>separator<span class="token punctuation">,</span>                        stop_words<span class="token operator">=</span>stop_words<span class="token punctuation">)</span><span class="token keyword">from</span> lmdeploy <span class="token keyword">import</span> ChatTemplateConfig<span class="token punctuation">,</span> pipelinemessages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'role'</span><span class="token punctuation">:</span> <span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> <span class="token string">'who are you?'</span><span class="token punctuation">}</span><span class="token punctuation">]</span>pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">'internlm/internlm2_5-7b-chat'</span><span class="token punctuation">,</span>               chat_template_config<span class="token operator">=</span>ChatTemplateConfig<span class="token punctuation">(</span><span class="token string">'customized_model'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> response <span class="token keyword">in</span> pipe<span class="token punctuation">.</span>stream_infer<span class="token punctuation">(</span>messages<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里我们选用CLI 工具推理，可以通过 –chat-template 传入自定义对话模板：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">lmdeploy serve api_server internlm/internlm2_5-7b-chat --chat-template <span class="token variable">${JSON_FILE}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="6-1-2-本项目使用模型的对话模板转换"><a href="#6-1-2-本项目使用模型的对话模板转换" class="headerlink" title="6.1.2 本项目使用模型的对话模板转换"></a>6.1.2 本项目使用模型的对话模板转换</h4><p>我们需要先找到xtuner目录下的<code>xtuner/xtuner/utils/templates.py</code>文件，然后搜索字段<br><code>qwen_chat</code> 如下图：</p><p><img src="https://pic1.imgdb.cn/item/681ef1ae58cb8da5c8eac8e3.png" alt="qwen_chat字段类型"></p><p>我们将字典内容拿过来：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">    qwen_chat<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        SYSTEM<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"&lt;|im_start|&gt;system\n{system}&lt;|im_end|&gt;\n"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        INSTRUCTION<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"&lt;|im_start|&gt;user\n{input}&lt;|im_end|&gt;\n"</span> <span class="token string">"&lt;|im_start|&gt;assistant\n"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        SUFFIX<span class="token operator">=</span><span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>        SUFFIX_AS_EOS<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        SEP<span class="token operator">=</span><span class="token string">"\n"</span><span class="token punctuation">,</span>        STOP_WORDS<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span> <span class="token string">"&lt;|endoftext|&gt;"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>字典中的内容就是我们训练时的对话模板，现在我们需要将上面对话模板格式转换为LMDeploy支持的对话模板格式，这一步可以交给大模型帮我们完成。</p><p>下面是让大模型帮我们写的对话模板转换脚本：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> re<span class="token keyword">import</span> json<span class="token keyword">from</span> typing <span class="token keyword">import</span> Dict<span class="token punctuation">,</span> Any<span class="token keyword">def</span> <span class="token function">universal_converter</span><span class="token punctuation">(</span>original_template<span class="token punctuation">:</span> Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""将多种风格的原始模板转换为lmdeploy官方格式"""</span>    <span class="token comment"># 字段映射关系（核心逻辑）</span>    field_mapping <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token comment"># 基础字段映射</span>        <span class="token string">"SYSTEM"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span>        <span class="token string">"INSTRUCTION"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 需要拆分处理</span>        <span class="token string">"SUFFIX"</span><span class="token punctuation">:</span> <span class="token string">"eoa"</span><span class="token punctuation">,</span>        <span class="token string">"SEP"</span><span class="token punctuation">:</span> <span class="token string">"separator"</span><span class="token punctuation">,</span>        <span class="token string">"STOP_WORDS"</span><span class="token punctuation">:</span> <span class="token string">"stop_words"</span><span class="token punctuation">,</span>        <span class="token comment"># 特殊处理字段</span>        <span class="token string">"SUFFIX_AS_EOS"</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 该字段在官方模板中不需要</span>    <span class="token punctuation">}</span>    <span class="token comment"># 初始化目标模板（包含必填字段默认值）</span>    converted <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"meta_instruction"</span><span class="token punctuation">:</span> <span class="token string">"You are a helpful assistant."</span><span class="token punctuation">,</span>  <span class="token comment"># 必填项</span>        <span class="token string">"capability"</span><span class="token punctuation">:</span> <span class="token string">"chat"</span><span class="token punctuation">,</span>  <span class="token comment"># 必填项</span>        <span class="token string">"eosys"</span><span class="token punctuation">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>  <span class="token comment"># 通常固定格式</span>        <span class="token string">"eoh"</span><span class="token punctuation">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>  <span class="token comment"># 通常固定格式</span>    <span class="token punctuation">}</span>    <span class="token comment"># 自动处理字段映射</span>    <span class="token keyword">for</span> src_key<span class="token punctuation">,</span> dest_key <span class="token keyword">in</span> field_mapping<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> src_key <span class="token keyword">in</span> original_template<span class="token punctuation">:</span>            value <span class="token operator">=</span> original_template<span class="token punctuation">[</span>src_key<span class="token punctuation">]</span>            <span class="token comment"># 处理需要拆分的字段（如INSTRUCTION）</span>            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dest_key<span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span> <span class="token keyword">and</span> src_key <span class="token operator">==</span> <span class="token string">"INSTRUCTION"</span><span class="token punctuation">:</span>                <span class="token comment"># 使用正则拆分user和assistant部分</span>                parts <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">r'(&lt;\|im_start\|&gt;assistant\n?)'</span><span class="token punctuation">,</span> value<span class="token punctuation">)</span>                converted<span class="token punctuation">[</span><span class="token string">"user"</span><span class="token punctuation">]</span> <span class="token operator">=</span> parts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parts<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>                    converted<span class="token punctuation">[</span><span class="token string">"assistant"</span><span class="token punctuation">]</span> <span class="token operator">=</span> parts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> parts<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parts<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">2</span> <span class="token keyword">else</span> parts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>            <span class="token comment"># 处理直接映射字段</span>            <span class="token keyword">elif</span> dest_key <span class="token keyword">and</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dest_key<span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                converted<span class="token punctuation">[</span>dest_key<span class="token punctuation">]</span> <span class="token operator">=</span> value    <span class="token comment"># 特殊处理system字段的占位符</span>    <span class="token keyword">if</span> <span class="token string">"system"</span> <span class="token keyword">in</span> converted<span class="token punctuation">:</span>        converted<span class="token punctuation">[</span><span class="token string">"system"</span><span class="token punctuation">]</span> <span class="token operator">=</span> converted<span class="token punctuation">[</span><span class="token string">"system"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"{system}"</span><span class="token punctuation">,</span> <span class="token string">"{{ system }}"</span><span class="token punctuation">)</span>    <span class="token comment"># 处理用户输入占位符</span>    <span class="token keyword">if</span> <span class="token string">"user"</span> <span class="token keyword">in</span> converted<span class="token punctuation">:</span>        converted<span class="token punctuation">[</span><span class="token string">"user"</span><span class="token punctuation">]</span> <span class="token operator">=</span> converted<span class="token punctuation">[</span><span class="token string">"user"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"{input}"</span><span class="token punctuation">,</span> <span class="token string">"{{ input }}"</span><span class="token punctuation">)</span>    <span class="token comment"># 自动处理停止词（兼容列表和字符串）</span>    <span class="token keyword">if</span> <span class="token string">"stop_words"</span> <span class="token keyword">in</span> converted <span class="token keyword">and</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>converted<span class="token punctuation">[</span><span class="token string">"stop_words"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        converted<span class="token punctuation">[</span><span class="token string">"stop_words"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>converted<span class="token punctuation">[</span><span class="token string">"stop_words"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>    <span class="token comment"># 保留原始模板中的额外字段（带警告）</span>    <span class="token keyword">for</span> key <span class="token keyword">in</span> original_template<span class="token punctuation">:</span>        <span class="token keyword">if</span> key <span class="token keyword">not</span> <span class="token keyword">in</span> field_mapping<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Warning: 发现未映射字段 [</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">}</span></span><span class="token string">]，已保留原样"</span></span><span class="token punctuation">)</span>            converted<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> original_template<span class="token punctuation">[</span>key<span class="token punctuation">]</span>    <span class="token keyword">return</span> converted<span class="token comment"># 示例用法</span>original_qwen_chat <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>SYSTEM<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"&lt;|im_start|&gt;system\n{system}&lt;|im_end|&gt;\n"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  INSTRUCTION<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"&lt;|im_start|&gt;user\n{input}&lt;|im_end|&gt;\n"</span> <span class="token string">"&lt;|im_start|&gt;assistant\n"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> SUFFIX<span class="token operator">=</span><span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>  SUFFIX_AS_EOS<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  SEP<span class="token operator">=</span><span class="token string">"\n"</span><span class="token punctuation">,</span>  STOP_WORDS<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span> <span class="token string">"&lt;|endoftext|&gt;"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 执行转换</span>converted_template <span class="token operator">=</span> universal_converter<span class="token punctuation">(</span>original_qwen_chat<span class="token punctuation">)</span><span class="token comment"># 生成JSON文件</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'chat_template.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>converted_template<span class="token punctuation">,</span> f<span class="token punctuation">,</span>              indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>              ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>              separators<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">': '</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行代码后生成的内容：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>  <span class="token property">"meta_instruction"</span><span class="token operator">:</span> <span class="token string">"You are a helpful assistant."</span><span class="token punctuation">,</span>  <span class="token property">"capability"</span><span class="token operator">:</span> <span class="token string">"chat"</span><span class="token punctuation">,</span>  <span class="token property">"eosys"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>  <span class="token property">"eoh"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>  <span class="token property">"system"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;system\n{{ system }}&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>  <span class="token property">"user"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;user\n{{ input }}&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>  <span class="token property">"assistant"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;assistant\n"</span><span class="token punctuation">,</span>  <span class="token property">"eoa"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>  <span class="token property">"separator"</span><span class="token operator">:</span> <span class="token string">"\n"</span><span class="token punctuation">,</span>  <span class="token property">"stop_words"</span><span class="token operator">:</span> <span class="token punctuation">[</span>    <span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>    <span class="token string">"&lt;|endoftext|&gt;"</span>  <span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>进入LMDeploy环境，执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">lmdeploy serve api_server internlm/internlm2_5-7b-chat --chat-template <span class="token variable">${JSON_FILE}</span><span class="token comment"># 我本地命令</span>lmdeploy serve api_server /home/moyuai/moyuai/xtuner_out/Qwen1-5-1-8B-Chat-xtuner-merged-7000 --chat-template /home/moyuai/moyuai/xtuner_out/chat_template.json<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>执行命令后如果出现以下内容，那么可以判断我们的自定义对话模板基本没有问题：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>WARNING<span class="token punctuation">]</span> gemm_config.in is not found<span class="token punctuation">;</span> using default GEMM algo             HINT:    Please <span class="token function">open</span> http://0.0.0.0:23333 <span class="token keyword">in</span> a browser <span class="token keyword">for</span> detailed api usage<span class="token operator">!</span><span class="token operator">!</span><span class="token operator">!</span>HINT:    Please <span class="token function">open</span> http://0.0.0.0:23333 <span class="token keyword">in</span> a browser <span class="token keyword">for</span> detailed api usage<span class="token operator">!</span><span class="token operator">!</span><span class="token operator">!</span>HINT:    Please <span class="token function">open</span> http://0.0.0.0:23333 <span class="token keyword">in</span> a browser <span class="token keyword">for</span> detailed api usage<span class="token operator">!</span><span class="token operator">!</span><span class="token operator">!</span>INFO:     Started server process <span class="token punctuation">[</span><span class="token number">239994</span><span class="token punctuation">]</span>INFO:     Waiting <span class="token keyword">for</span> application startup.INFO:     Application startup complete.INFO:     Uvicorn running on http://0.0.0.0:23333 <span class="token punctuation">(</span>Press CTRL+C to quit<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在使用一个简单的openai对话模板调用一下我们的服务进行进一步测试，代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#多轮对话</span><span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI<span class="token comment">#定义多轮对话方法</span><span class="token keyword">def</span> <span class="token function">run_chat_session</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment">#初始化客户端</span>    client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>base_url<span class="token operator">=</span><span class="token string">"http://localhost:23333/v1/"</span><span class="token punctuation">,</span>api_key<span class="token operator">=</span><span class="token string">"ismoyuai"</span><span class="token punctuation">)</span>    <span class="token comment">#初始化对话历史</span>    chat_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment">#启动对话循环</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        <span class="token comment">#获取用户输入</span>        user_input <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"用户："</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> user_input<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"exit"</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"退出对话。"</span><span class="token punctuation">)</span>            <span class="token keyword">break</span>        <span class="token comment">#更新对话历史(添加用户输入)</span>        chat_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span><span class="token string">"user"</span><span class="token punctuation">,</span><span class="token string">"content"</span><span class="token punctuation">:</span>user_input<span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment">#调用模型回答</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            chat_complition <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>                messages<span class="token operator">=</span>chat_history<span class="token punctuation">,</span>                model<span class="token operator">=</span><span class="token string">"/home/moyuai/moyuai/xtuner_out/Qwen1-5-1-8B-Chat-xtuner-merged-10000"</span>                <span class="token punctuation">)</span>            <span class="token comment">#获取最新回答</span>            model_response <span class="token operator">=</span> chat_complition<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AI:"</span><span class="token punctuation">,</span>model_response<span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">)</span>            <span class="token comment">#更新对话历史（添加AI模型的回复）</span>            chat_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span><span class="token string">"assistant"</span><span class="token punctuation">,</span><span class="token string">"content"</span><span class="token punctuation">:</span>model_response<span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"发生错误："</span><span class="token punctuation">,</span>e<span class="token punctuation">)</span>            <span class="token keyword">break</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    run_chat_session<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行后我们输入问题，出现报错，后续发现是自定义对话模板有问题，因为我们不加载对话模板则，能够正常进行对话。</p><h3 id="6-2-模型测试评估"><a href="#6-2-模型测试评估" class="headerlink" title="6.2 模型测试评估"></a>6.2 模型测试评估</h3><p>下面我们不用自定义对话模板来进行模型效果测试，这里我们用一个叫<code>streamlit</code>的大模型前端框架来测试我们的模型效果。<br>安装<code>streamlit</code>包</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> streamlit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>简单编写一个<code>streamlit</code>前端页面，新建一个<code>chat_app.py</code>文件，文件代码如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st<span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI<span class="token comment"># 初始化客户端</span>client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>base_url<span class="token operator">=</span><span class="token string">"http://localhost:23333/v1/"</span><span class="token punctuation">,</span> api_key<span class="token operator">=</span><span class="token string">"ismoyuai"</span><span class="token punctuation">)</span><span class="token comment"># 设置页面标题</span>st<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"moyuai-Chat"</span><span class="token punctuation">)</span>st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span><span class="token string">"## 这是一个基于Qwen-1.5-1.8B的情感聊天机器人"</span><span class="token punctuation">)</span><span class="token comment"># 初始化session状态（仅用于显示历史）</span><span class="token keyword">if</span> <span class="token string">"messages"</span> <span class="token keyword">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>    st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token comment"># 显示历史消息</span><span class="token keyword">for</span> message <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>messages<span class="token punctuation">:</span>    <span class="token keyword">with</span> st<span class="token punctuation">.</span>chat_message<span class="token punctuation">(</span>message<span class="token punctuation">[</span><span class="token string">"role"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span>message<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 获取用户输入</span><span class="token keyword">if</span> prompt <span class="token operator">:=</span> st<span class="token punctuation">.</span>chat_input<span class="token punctuation">(</span><span class="token string">"请输入您的问题，或输入exit退出"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 处理退出命令</span>    <span class="token keyword">if</span> prompt<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"exit"</span><span class="token punctuation">:</span>        st<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"退出对话。"</span><span class="token punctuation">)</span>        st<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 添加用户消息到显示历史</span>    st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> st<span class="token punctuation">.</span>chat_message<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token comment"># 发起API请求（每次只发送当前消息）</span>        response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>            messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 每次只发送当前问题</span>            model<span class="token operator">=</span><span class="token string">"/home/moyuai/moyuai/xtuner_out/Qwen1-5-1-8B-Chat-xtuner-merged-10000"</span>        <span class="token punctuation">)</span>        <span class="token comment"># 获取模型回复</span>        model_response <span class="token operator">=</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content        <span class="token comment"># 添加AI回复到显示历史</span>        st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> model_response<span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token keyword">with</span> st<span class="token punctuation">.</span>chat_message<span class="token punctuation">(</span><span class="token string">"assistant"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span>model_response<span class="token punctuation">)</span>    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>        st<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"发生错误：</span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启动<code>streamlit</code>前端服务，服务启动前一定要保证我们的LMDeploy服务是启动的：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">streamlit run chat_app.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>启动后界面如下：</p><p><img src="https://pic1.imgdb.cn/item/681f102258cb8da5c8eaec00.png" alt="streamlit前端页面"></p><p>我们进行问题测试：<br><img src="https://pic1.imgdb.cn/item/681f102258cb8da5c8eaebfd.png" alt="模型测试主观效果"></p><p>可以看到，我们模型训练生成的回答是按照我们的风格来的，说明模型训练有效果，但是我用同一个问题问了好几次，模型给我们的回答都是一样的，这说明模型训练的过拟合了，泛用性很差，这次训练也是以失败告结的，其实我在看训练日志时，发现到后面模型的loss值非常低，差不多后面一直在<code>0.0044</code>，这个loss值算比较低的了，就是快要过拟合的状态了；而在训练到差不多10000批次左右，模型就已经差不多是拟合状态了，但是由于我是在晚上挂机进行训练的，而在当初设置xtenur训练参数时，只选择保存最后两个训练权重，导致前面训练的权重不存在；所以只能后续在重新训练，在来看一下模型训练效果。</p><h3 id="6-3-模型测试评估-重新训练版"><a href="#6-3-模型测试评估-重新训练版" class="headerlink" title="6.3 模型测试评估(重新训练版)"></a>6.3 模型测试评估(重新训练版)</h3><p>重新训练后，在训练到6000 到 7000轮左右时，这时训练的loss值控制在了0.04 到 0.03左右，可以说是比较不错，所以就没有继续训练，这时我们将模型转换合并后，重新部署，下面就是重新测试对话效果的图片，看的出来模型这次对同一个问题没有出现完全一样的回答了，这次训练算是比较成功的了。</p><p><img src="https://pic1.imgdb.cn/item/681f3bf758cb8da5c8eb6cc9.png" alt="模型重新测试评估效果"></p><h2 id="七、总结"><a href="#七、总结" class="headerlink" title="七、总结"></a><strong>七、总结</strong></h2><p>1.项目成果总结<br>    本次项目总体来讲是成功的了，虽然还有不少地方可以完善，但也算是第一次完整的从0-1完成关于大模型微调项目的整个流程，这才是最重要的，特别是在做项目的过程中遇到的问题和解决问题的过程是最宝贵的经验。</p><p>2.挑战与解决方案回顾<br>    本次项目完成后在回顾，重要的点在于前期的数据收集部分，一份好的质量高的数据集是非常重要的，我在收集数据方面也是花了一些心思，这样在后续的数据生成过程中才能有一个好的前提。<br>    项目过程中遇到的问题其实其他的都还好，主要花时间多一点的地方就是在于一些框架的环境配置方面，需要特别注意一些依赖包的版本，不太适合太新的版本。<br>    还有一个就是最后模型部署方面，在自定义对话模板这里遇到的问题一直没有解决，虽然最后达到的效果是好的，后续</p><ol start="3"><li>未来方向（语言播放，集成开发板）<br> 这个项目本来就是根据抖音最近比较火的小智机器人想做的，后续可能就是在对话大模型结合语音方面已经部署到 开发板上面来进行研究，这也算是我可能可以做到的，因为自己大学专业学的就是单片机嵌入式开发等等，有软硬结合的底子在，我个人也是比较有需求的。</li></ol><h2 id="八、附录与参考资料"><a href="#八、附录与参考资料" class="headerlink" title="八、附录与参考资料"></a><strong>八、附录与参考资料</strong></h2><p>1.代码仓库与工具链</p><ul><li>项目GitHub仓库：<a href="https://github.com/ismoyuai/emotion_dialogue_tuner">https://github.com/ismoyuai/emotion_dialogue_tuner</a></li><li>智谱清言API：<a href="https://www.bigmodel.cn/console/overview">https://www.bigmodel.cn/console/overview</a></li><li>XTuner 中文文档：<a href="https://xtuner.readthedocs.io/zh-cn/latest/index.html">https://xtuner.readthedocs.io/zh-cn/latest/index.html</a></li><li>OpenCompass 中文教程：<a href="https://doc.opencompass.org.cn/zh_CN/">https://doc.opencompass.org.cn/zh_CN/</a></li><li>LMDeploy 中文教程：<a href="https://lmdeploy.readthedocs.io/zh-cn/latest/index.html">https://lmdeploy.readthedocs.io/zh-cn/latest/index.html</a></li></ul><p>2.数据集链接</p><ul><li>CDial-GPT：<a href="https://github.com/corpus-dataset/CDial-GPT">https://github.com/corpus-dataset/CDial-GPT</a></li></ul><h2 id="九、问题记录"><a href="#九、问题记录" class="headerlink" title="九、问题记录"></a><strong>九、问题记录</strong></h2><h3 id="1-报settings-yaml配置文件找不到"><a href="#1-报settings-yaml配置文件找不到" class="headerlink" title="1.报settings.yaml配置文件找不到"></a>1.报settings.yaml配置文件找不到</h3><p>报错信息：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">配置文件缺失：[Errno 2] No such file or directory: 'E:\\xuexiziliao\\AiProject\\emotion_dialogue_tuner\\src\\config\\settings.yaml'<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>解决方法：<br>是因为在<code>config_loader.py</code>文件中,路径层级少配置一层</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 修改前</span>self<span class="token punctuation">.</span>root_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">.</span>resolve<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent<span class="token comment"># 修改后</span>self<span class="token punctuation">.</span>root_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">.</span>resolve<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent  <span class="token comment"># 根据实际层级调整</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-文件编码格式加载不正确"><a href="#2-文件编码格式加载不正确" class="headerlink" title="2.文件编码格式加载不正确"></a>2.文件编码格式加载不正确</h3><p>报错信息：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">UnicodeDecodeError: 'gbk' codec can't decode byte 0xa6 in position 94: illegal multibyte sequence<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>解决方法：<br>报错原因是因为在<code>config_loader.py</code>文件中的<code>load_settings</code>方法没有指定<code>yaml</code>文件的打开格式。在修改所有文件读取操作，添加<code>encoding='utf-8'</code>参数即可：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 修改前代码</span><span class="token keyword">def</span> <span class="token function">load_settings</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>      <span class="token triple-quoted-string string">"""加载YAML格式的全局设置      Returns:        dict: 包含API密钥、模型路径等配置的字典      """</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_path <span class="token operator">/</span> <span class="token string">"config/settings.yaml"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>          <span class="token keyword">return</span> yaml<span class="token punctuation">.</span>safe_load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token comment"># 修改后代码</span><span class="token keyword">def</span> <span class="token function">load_settings</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>      <span class="token triple-quoted-string string">"""加载YAML格式的全局设置      Returns:        dict: 包含API密钥、模型路径等配置的字典      """</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_path <span class="token operator">/</span> <span class="token string">"config/settings.yaml"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>          <span class="token keyword">return</span> yaml<span class="token punctuation">.</span>safe_load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-生成的数据有些是完全一样的"><a href="#3-生成的数据有些是完全一样的" class="headerlink" title="3.生成的数据有些是完全一样的"></a>3.生成的数据有些是完全一样的</h3><p>查看生成数据时，发现有些数据是完全一样的，出现了重复，这就导致了数据质量不高。</p><p>解决方法：可以自己测试调整判断阈值，或者重新添加新的规则来判断去重。</p><h3 id="4-使用Xtuner进行模型qlora模型微调的时候，报错-No-module-named-‘triton-ops’"><a href="#4-使用Xtuner进行模型qlora模型微调的时候，报错-No-module-named-‘triton-ops’" class="headerlink" title="4.使用Xtuner进行模型qlora模型微调的时候，报错 No module named ‘triton.ops’"></a>4.使用Xtuner进行模型qlora模型微调的时候，报错 No module named ‘triton.ops’</h3><p>执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">xtuner train qwen1_5_1_8b_chat_qlora_alpaca_e3.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>问题记录：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">The above exception was the direct cause of the following exception:Traceback (most recent call last):  File "/home/moyuai/moyuai/xtuner/xtuner/tools/train.py", line 392, in &lt;module&gt;    main()  File "/home/moyuai/moyuai/xtuner/xtuner/tools/train.py", line 381, in main    runner = Runner.from_cfg(cfg)  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/runner/runner.py", line 462, in from_cfg    runner = cls(  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/runner/runner.py", line 429, in __init__    self.model = self.build_model(model)  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/runner/runner.py", line 836, in build_model    model = MODELS.build(model)  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/registry/registry.py", line 570, in build    return self.build_func(cfg, *args, **kwargs, registry=self)  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 234, in build_model_from_cfg    return build_from_cfg(cfg, registry, default_args)  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 123, in build_from_cfg    obj = obj_cls(**args)  # type: ignore  File "/home/moyuai/moyuai/xtuner/xtuner/model/sft.py", line 97, in __init__    self.llm = self.build_llm_from_cfg(  File "/home/moyuai/moyuai/xtuner/xtuner/model/sft.py", line 143, in build_llm_from_cfg    llm = self._build_from_cfg_or_module(llm)  File "/home/moyuai/moyuai/xtuner/xtuner/model/sft.py", line 296, in _build_from_cfg_or_module    return BUILDER.build(cfg_or_mod)  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/registry/registry.py", line 570, in build    return self.build_func(cfg, *args, **kwargs, registry=self)  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 123, in build_from_cfg    obj = obj_cls(**args)  # type: ignore  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained    return model_class.from_pretrained(  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3620, in from_pretrained    hf_quantizer.validate_environment(  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 77, in validate_environment    from ..integrations import validate_bnb_backend_availability  File "&lt;frozen importlib._bootstrap&gt;", line 1075, in _handle_fromlist  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1805, in __getattr__    module = self._get_module(self._class_to_module[name])  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1819, in _get_module    raise RuntimeError(RuntimeError: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):No module named 'triton.ops'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>问题分析：<br>这是在尝试使用&nbsp;<strong>BitsAndBytes（8-bit 量化）</strong>&nbsp;加载模型时发生的，我们查看一下&nbsp;<code>bitsandbytes</code>&nbsp;库是否正确安装。</p><p>可能是版本不对，试着重装一下后还是报错，最后查找资料发现是torch2.6以上版本和bitstandbytes版本的冲突问题。</p><p>安装<strong>低版本</strong>的<code>pytorch==2.5.1</code> 和<code>torchvision==0.20.1</code> ，我们进入xtuner目录 下的这个 <code>xtuner/requirements/runtime.txt</code>文件里面修改一下torch版本</p><p><img src="https://pic1.imgdb.cn/item/681e229258cb8da5c8e9fe1e.png" alt="修改环境"></p><p>修改过后还是有问题，这次报错信息如下：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">Traceback (most recent call last): File "/home/moyuai/anaconda3/envs/xtuner-env/bin/xtuner", line 33, in &lt;module&gt; sys.exit(load_entry_point('xtuner', 'console_scripts', 'xtuner')()) File "/home/moyuai/anaconda3/envs/xtuner-env/bin/xtuner", line 25, in importlib_load_entry_point return next(matches).load() File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/importlib/metadata/__init__.py", line 171, in load module = import_module(match.group('module')) File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/importlib/__init__.py", line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File "&lt;frozen importlib._bootstrap&gt;", line 1050, in _gcd_import File "&lt;frozen importlib._bootstrap&gt;", line 1027, in _find_and_load File "&lt;frozen importlib._bootstrap&gt;", line 1006, in _find_and_load_unlocked File "&lt;frozen importlib._bootstrap&gt;", line 688, in _load_unlocked File "&lt;frozen importlib._bootstrap_external&gt;", line 883, in exec_module File "&lt;frozen importlib._bootstrap&gt;", line 241, in _call_with_frames_removed File "/home/moyuai/moyuai/xtuner/xtuner/__init__.py", line 4, in &lt;module&gt; from mmengine.utils import digit_version File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/__init__.py", line 6, in &lt;module&gt; from .registry import * File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/__init__.py", line 2, in &lt;module&gt; from .build_functions import (build_from_cfg, build_model_from_cfg, File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 6, in &lt;module&gt; import torch File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/__init__.py", line 367, in &lt;module&gt; from torch._C import * # noqa: F403 ImportError: /home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12: undefined symbol: __nvJitLinkComplete_12_4, version libnvJitLink.so.12<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>推测还是因为<code>torch</code>版本和<code>CUDA</code>版本导致的，这次重新将<code>torch</code>版本和<code>CUDA</code>版本进行修改，进行如下操作</p><h4 id="1-完全卸载当前PyTorch和CUDA工具链"><a href="#1-完全卸载当前PyTorch和CUDA工具链" class="headerlink" title="(1)完全卸载当前PyTorch和CUDA工具链"></a><strong>(1)完全卸载当前PyTorch和CUDA工具链</strong></h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 删除conda环境（确保已退出环境）</span>conda deactivateconda remove <span class="token parameter variable">-n</span> xtuner-env <span class="token parameter variable">--all</span> <span class="token parameter variable">-y</span><span class="token comment"># 清除残留的CUDA软链接</span><span class="token function">sudo</span> <span class="token function">rm</span> <span class="token parameter variable">-f</span> /usr/local/cuda<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="2-安装匹配的CUDA-12-1工具包"><a href="#2-安装匹配的CUDA-12-1工具包" class="headerlink" title="(2)安装匹配的CUDA 12.1工具包"></a><strong>(2)安装匹配的CUDA 12.1工具包</strong></h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">### **安装匹配的CUDA 12.1工具包**</span><span class="token comment"># 从NVIDIA官网下载CUDA 12.1.1</span><span class="token function">wget</span> https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda_12.1.1_530.30.02_linux.run<span class="token function">sudo</span> <span class="token function">sh</span> cuda_12.1.1_530.30.02_linux.run <span class="token parameter variable">--override</span><span class="token comment"># 配置环境变量</span><span class="token builtin class-name">echo</span> <span class="token string">'export PATH=/usr/local/cuda-12.1/bin:$PATH'</span> <span class="token operator">&gt;&gt;</span> ~/.bashrc<span class="token builtin class-name">echo</span> <span class="token string">'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH'</span> <span class="token operator">&gt;&gt;</span> ~/.bashrc<span class="token builtin class-name">source</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="3-创建全新的虚拟环境并安装PyTorch-2-2-0"><a href="#3-创建全新的虚拟环境并安装PyTorch-2-2-0" class="headerlink" title="(3)创建全新的虚拟环境并安装PyTorch 2.2.0"></a>(3)创建全新的虚拟环境并安装PyTorch 2.2.0</h4><p>这里我们记得到xtuner目录下的 <code>xtuner/requirements/runtime.txt</code>文件里面重新修改一下torch版本，版本和下面要安装的命令里面的版本保持一致。<code>PyTorch 2.2.0 + CUDA 12.1</code></p><p><img src="https://pic1.imgdb.cn/item/681e9b6158cb8da5c8ea15aa.png" alt="重新指定torch版本"></p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda create <span class="token parameter variable">-n</span> xtuner-env <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.10</span> <span class="token parameter variable">-y</span>conda activate xtuner-env<span class="token comment"># 安装PyTorch 2.2.0 + CUDA 12.1</span>pip <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">2.2</span>.0+cu121 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.17</span>.0+cu121 --extra-index-url https://download.pytorch.org/whl/cu121<span class="token comment"># 重新安装xtuner所需依赖</span><span class="token builtin class-name">cd</span> xtunerpip <span class="token function">install</span> <span class="token parameter variable">-e</span> <span class="token string">'.[all]'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后重新运行训练命令，能够正常进行训练</p><h3 id="5-发生错误：-‘NoneType’-object-is-not-subscriptable"><a href="#5-发生错误：-‘NoneType’-object-is-not-subscriptable" class="headerlink" title="5. 发生错误： ‘NoneType’ object is not subscriptable"></a>5. 发生错误： ‘NoneType’ object is not subscriptable</h3><p>这个问题是在LMDeploy导入自定义对话模板时启动openai对话服务后，进行对话时出现的错误。<br>后面不进行自定义对话模板导入而是直接用LMDeploy启动我们训练的模型后可以正常回答，推测应该是自定义对话模板有问题</p><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> AI大模型开发项目实战 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> Python </tag>
            
            <tag> Linux </tag>
            
            <tag> Embeddings </tag>
            
            <tag> LLM </tag>
            
            <tag> LLaMA-Factory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【AI大模型应用学习笔记】基于LlamaIndex实现RAG</title>
      <link href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-ji-yu-llamaindex-shi-xian-rag/"/>
      <url>/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-ji-yu-llamaindex-shi-xian-rag/</url>
      
        <content type="html"><![CDATA[<p>使用环境</p><ul><li>软件环境：Windows11 + WSL2-Linux-Ubuntu22.04子系统</li><li>硬件环境：GeForce RTX 4060 Ti 16GB</li></ul><h2 id="一、Llama-Index（核心组件介绍）"><a href="#一、Llama-Index（核心组件介绍）" class="headerlink" title="一、Llama_Index（核心组件介绍）"></a>一、Llama_Index（核心组件介绍）</h2><h3 id="1-1-什么是LlamaIndex"><a href="#1-1-什么是LlamaIndex" class="headerlink" title="1.1 什么是LlamaIndex?"></a>1.1 什么是LlamaIndex?</h3><p><code>LlamaIndex</code> 是一个用于 <code>LLM</code> 应用程序的数据框架，用于注入，结构化，并访问私有或特定领域数据。<br><code>LlamaIndex</code> 由 Jerry Liu (Twitter: @jerryjliu0) 联合创办，并担任CEO。</p><h3 id="1-2-LlamaIndex为何而生？"><a href="#1-2-LlamaIndex为何而生？" class="headerlink" title="1.2 LlamaIndex为何而生？"></a>1.2 LlamaIndex为何而生？</h3><p>在本质上， <code>LLM</code> （如 GPT ）为人类和推断出的数据提供了基于自然语言的交互接口。广泛可用的大模型通常在大量公开可用的数据上进行的预训练，包括来自维基百科、邮件列表、书籍和源代码等。<br>构建在LLM模型之上的应用程序通常需要使用私有或特定领域数据来增强这些模型。不幸的是，这些数据可能分布在不同的应用程序和数据存储中。它们可能存在于API之后、SQL数据库中，或者存在在PDF 文件以及幻灯片中。</p><p>LlamaIndex应运而生。</p><h3 id="1-3-LlamaIndex如何破局？"><a href="#1-3-LlamaIndex如何破局？" class="headerlink" title="1.3 LlamaIndex如何破局？"></a>1.3 LlamaIndex如何破局？</h3><p>LlamaIndex 提供了5大核心工具：</p><ul><li>Data connectors</li><li>Data indexes</li><li>Engines</li><li>Data agents</li><li>Application integrations</li></ul><h2 id="二、核心概念"><a href="#二、核心概念" class="headerlink" title="二、核心概念"></a>二、核心概念</h2><p><code>LlamaIndex</code> 帮助构建 <code>LLM</code> 驱动的，基于个人或私域数据的应用。RAG(Retrieval Augmented Generation) 是 <code>LlamaIndex</code> 应用的核心概念。</p><h3 id="2-1-RAG"><a href="#2-1-RAG" class="headerlink" title="2.1 RAG"></a>2.1 RAG</h3><p>RAG，也称为检索增强生成，是利用个人或私域数据增强 <code>LLM</code> 的一种范式。通常，它包含两个阶段:</p><ol><li>索引<br> 构建知识库</li><li>查询<br> 从知识库检索相关上下文信息，以辅助 <code>LLM</code> 回答问题。</li></ol><p><code>LlamaIndex</code> 提供了工具包帮助开发者极其便捷地完成这两个阶段的工作。</p><h4 id="2-1-1-索引阶段"><a href="#2-1-1-索引阶段" class="headerlink" title="2.1.1 索引阶段"></a>2.1.1 索引阶段</h4><p>LlamaIndex 通过提供 Data connectors(数据连接器) 和 Indexes (索引) 帮助开发者构建知识库。<br>该阶段会用到如下工具或组件：</p><ul><li>Data connectors<br>  数据连接器。它负责将来自不同数据源的不同格式的数据注入，并转换为 <code>LlamaIndex</code> 支持的文档（Document）表现形式，其中包含了文本和元数据。</li><li>Documents / Nodes<br>  Document是 <code>LlamaIndex</code> 中容器的概念，它可以包含任何数据源，包括，PDF文档，API响应，或来自数据库的数据。<br>  Node是 <code>LlamaIndex</code> 中数据的最小单元，代表了一个 Document的分块。它还包含了元数据，以及与其他Node的关系信息。这使得更精确的检索操作成为可能。</li><li>Data Indexes<br>  <code>LlamaIndex</code> 提供便利的工具，帮助开发者为注入的数据建立索引，使得未来的检索简单而高效。最常用的索引是向量存储索引 - <code>VectorStoreIndex</code> 。</li></ul><h4 id="2-1-2-查询阶段"><a href="#2-1-2-查询阶段" class="headerlink" title="2.1.2 查询阶段"></a>2.1.2 查询阶段</h4><p>在查询阶段，<code>RAG</code> 管道根据的用户查询，检索最相关的上下文，并将其与查询一起，传递给 <code>LLM</code> ，以合成响应。这使 <code>LLM</code> 能够获得不在其原始训练数据中的最新知识，同时也减少了虚构内容。该阶段的关键挑战在于检索、编排和基于知识库的推理。</p><p><code>LlamaIndex</code> 提供可组合的模块，帮助开发者构建和集成 <code>RAG</code> 管道，用于问答、聊天机器人或作为代理的一部分。这些构建块可以根据排名偏好进行定制，并组合起来，以结构化的方式基于多个知识库进行推理。</p><p>该阶段的构建块包括：</p><ul><li>Retrievers<br>  检索器。它定义如何高效地从知识库，基于查询，检索相关上下文信息。</li><li>Node Postprocessors<br>  Node后处理器。它对一系列文档节点（Node）实施转换，过滤，或排名。</li><li>Response Synthesizers<br>  响应合成器。它基于用户的查询，和一组检索到的文本块（形成上下文），利用 LLM 生成响应。</li></ul><p>RAG管道包括：</p><ul><li>Query Engines<br>  查询引擎 - 端到端的管道，允许用户基于知识库，以自然语言提问，并获得回答，以及相关的上下文。</li><li>Chat Engines<br>  聊天引擎 - 端到端的管道，允许用户基于知识库进行对话（多次交互，会话历史）。</li><li>Agents<br>  代理。它是一种由 LLM 驱动的自动化决策器。代理可以像查询引擎或聊天引擎一样使用。主要区别在于，代理动态地决定最佳的动作序列，而不是遵循预定的逻辑。这为其提供了处理更复杂任务的额外灵活性。</li></ul><h3 id="2-2-个性化配置"><a href="#2-2-个性化配置" class="headerlink" title="2.2 个性化配置"></a>2.2 个性化配置</h3><p><code>LlamaIndex</code> 对 <code>RAG</code> 过程提供了全面的配置支持，允许开发者对整个过程进行个性化设置。常见的配置场景包括：</p><ul><li>自定义文档分块</li><li>自定义向量存储</li><li>自定义检索</li><li>指定 LLM</li></ul><blockquote><p>注，个性化配置主要通过 LlamaIndex 提供的 ServiceContext 类实现。</p></blockquote><h4 id="2-2-1-配置场景示例"><a href="#2-2-1-配置场景示例" class="headerlink" title="2.2.1 配置场景示例"></a>2.2.1 配置场景示例</h4><p>接下来通过简明示例代码段展示 LlamaIndex 对各种配置场景的支持。</p><h5 id="自定义文档分块"><a href="#自定义文档分块" class="headerlink" title="自定义文档分块"></a>自定义文档分块</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> llama_index <span class="token keyword">import</span> ServiceContextservice_context <span class="token operator">=</span> ServiceContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="自定义向量存储"><a href="#自定义向量存储" class="headerlink" title="自定义向量存储"></a>自定义向量存储</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> chromadb<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>vector_stores <span class="token keyword">import</span> ChromaVectorStore <span class="token keyword">from</span> llama_index <span class="token keyword">import</span> StorageContextchroma_client <span class="token operator">=</span> chromadb<span class="token punctuation">.</span>PersistentClient<span class="token punctuation">(</span><span class="token punctuation">)</span>chroma_collection <span class="token operator">=</span> chroma_client<span class="token punctuation">.</span>create_collection<span class="token punctuation">(</span><span class="token string">"quickstart"</span><span class="token punctuation">)</span> vector_store <span class="token operator">=</span> ChromaVectorStore<span class="token punctuation">(</span>chroma_collection<span class="token operator">=</span>chroma_collection<span class="token punctuation">)</span> storage_context <span class="token operator">=</span> StorageContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>vector_store<span class="token operator">=</span>vector_store<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h5 id="自定义检索"><a href="#自定义检索" class="headerlink" title="自定义检索"></a>自定义检索</h5><p>自定义检索中，我们可以通过参数指定查询引擎(Query Engine)在检索时请求的相似文档数。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">index <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span> query_engine <span class="token operator">=</span> index<span class="token punctuation">.</span>as_query_engine<span class="token punctuation">(</span>similarity_top_k<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h5 id="指定LLM"><a href="#指定LLM" class="headerlink" title="指定LLM"></a>指定LLM</h5><pre class="line-numbers language-python" data-language="python"><code class="language-python">service_context <span class="token operator">=</span> ServiceContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>llm<span class="token operator">=</span>OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="三、LlamaIndex实现RAG"><a href="#三、LlamaIndex实现RAG" class="headerlink" title="三、LlamaIndex实现RAG"></a>三、LlamaIndex实现RAG</h2><p>通过实操简单实现一下LlamaIndex实现RAG系统。</p><p>创建虚拟环境</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda create <span class="token parameter variable">-n</span> llamaindex-learnconda activate llamaindex-learn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-1-加载文档"><a href="#3-1-加载文档" class="headerlink" title="3.1 加载文档"></a>3.1 加载文档</h3><p>安装LlamaIndex核心库</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> llama-index<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>core <span class="token keyword">import</span> SimpleDirectoryReader<span class="token comment"># 加载本地文档进行解析</span><span class="token comment"># documents = SimpleDirectoryReader("data").load_data()</span><span class="token comment"># print(documents)</span><span class="token comment">#加载某个文档</span>documents <span class="token operator">=</span> SimpleDirectoryReader<span class="token punctuation">(</span>input_files<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"data/pdf内容研报.pdf"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-2-本地调用大模型"><a href="#3-2-本地调用大模型" class="headerlink" title="3.2 本地调用大模型"></a>3.2 本地调用大模型</h3><p>安装huggingface的本地调用包</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> llama-index-llms-huggingface<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下载大模型：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 模型下载</span><span class="token keyword">from</span> modelscope <span class="token keyword">import</span> snapshot_downloadmodel_dir <span class="token operator">=</span> snapshot_download<span class="token punctuation">(</span>    <span class="token string">'Qwen/Qwen3-1.7B'</span><span class="token punctuation">,</span>    cache_dir<span class="token operator">=</span><span class="token string">"E:/xuexiziliao/AiProject/llm"</span>    <span class="token punctuation">)</span><span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>core<span class="token punctuation">.</span>llms <span class="token keyword">import</span> ChatMessage<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>llms<span class="token punctuation">.</span>huggingface <span class="token keyword">import</span> HuggingFaceLLM<span class="token comment"># 本地大模型路径</span>llm_path <span class="token operator">=</span> <span class="token string">"E:/xuexiziliao/AiProject/llm/Qwen/Qwen3-1___7B"</span><span class="token comment"># 使用HuggingFaceLLM进行本地调用</span>llm <span class="token operator">=</span> HuggingFaceLLM<span class="token punctuation">(</span>    model_name<span class="token operator">=</span>llm_path<span class="token punctuation">,</span>    tokenizer_name<span class="token operator">=</span>llm_path<span class="token punctuation">,</span>    model_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"trust_remote_code"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span><span class="token punctuation">,</span>    tokenizer_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"trust_remote_code"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span>    <span class="token punctuation">)</span>rsp <span class="token operator">=</span> llm<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>messages<span class="token operator">=</span><span class="token punctuation">[</span>ChatMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"什么是XTuner?"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>rsp<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这是没有加载我们本地文档前，做一个大模型输出测试，大模型回答内容如下：</p><pre class="line-numbers language-none"><code class="language-none">assistant: &lt;think&gt;嗯，用户问的是“什么是XTuner？”。首先，我需要确定XTuner是什么。根据我的知识库，XTuner可能是指某个特定的工具或软件，但不确定具体是哪个。可能是一个开源项目、工具，或者某个特定领域的术语。首先，我应该回忆一下有没有听说过XTuner。比如，有没有可能是指某个机器学习框架，或者音频处理工具？比如，XTuner可能是一个用于音频处理的工具，比如用于语音识别或音频增强。或者可能是一个开源项目，比如在GitHub上某个项目的名字是XTuner。另外，可能XTuner是某个公司的产品，比如某个科技公司开发的工具，但我不太确定。也有可能XTuner是某个特定领域的术语，比如在计算机视觉、自然语言处理中的某个工具。接下来，我需要考虑用户可能的背景。用户可能是在使用某个软件时遇到了XTuner，或者在研究某个技术时遇到了这个术语。也有可能用户在某个论坛或社区中看到过XTuner，但没有明确的定义。为了准确回答，我需要确认XTuner的常见定义。可能需要查找相关资料，比如在GitHub上搜索XTuner，或者查看是否有相关的技术文档。但假设我现在无法访问外部<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，我们是问的<code>XTuner</code> 是一个大模型微调框架，但是大模型本身没有关于它的信息，所以大模型就给我们生成一些有的没的内容，这就是大模型产生了幻觉。</p><h3 id="3-3-Embedding模型"><a href="#3-3-Embedding模型" class="headerlink" title="3.3 Embedding模型"></a>3.3 Embedding模型</h3><p>安装魔塔社区SDK</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> modelscope<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装 <code>llama-index-embeddings-huggingface</code> 包和下载Embedding模型</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> llama-index-embeddings-huggingface<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 模型下载</span><span class="token keyword">from</span> modelscope <span class="token keyword">import</span> snapshot_downloadmodel_dir <span class="token operator">=</span> snapshot_download<span class="token punctuation">(</span>    <span class="token string">'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'</span><span class="token punctuation">,</span>    cache_dir<span class="token operator">=</span><span class="token string">r"E:\xuexiziliao\AiProject\llm"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>huggingface <span class="token keyword">import</span> HuggingFaceEmbedding<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>core <span class="token keyword">import</span> Settings<span class="token punctuation">,</span>SimpleDirectoryReader<span class="token punctuation">,</span>VectorStoreIndex<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>llms<span class="token punctuation">.</span>huggingface <span class="token keyword">import</span> HuggingFaceLLM<span class="token comment"># 本地大模型路径</span>llm_path <span class="token operator">=</span> <span class="token string">"E:/xuexiziliao/AiProject/llm/Qwen/Qwen3-1___7B"</span><span class="token comment"># 本地Embedding模型路径</span>embedding_path <span class="token operator">=</span> <span class="token string">"E:/xuexiziliao/AiProject/llm/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"</span><span class="token comment"># 初始化一个HuggingFaceEmbedding对象，用于将文本转换为向量表示</span>embed_model <span class="token operator">=</span> HuggingFaceEmbedding<span class="token punctuation">(</span>    <span class="token comment">#指定了一个预训练的sentence-transformer模型的路径</span>    model_name<span class="token operator">=</span>embedding_path<span class="token punctuation">)</span><span class="token comment"># 将创建的嵌入模型赋值给全局设置的embed_model属性，这样在后续的索引构建过程中，就会使用这个模型</span>Settings<span class="token punctuation">.</span>embed_model <span class="token operator">=</span> embed_model<span class="token comment"># 使用HuggingFaceLLM进行本地调用</span>llm <span class="token operator">=</span> HuggingFaceLLM<span class="token punctuation">(</span>    model_name<span class="token operator">=</span>llm_path<span class="token punctuation">,</span>    tokenizer_name<span class="token operator">=</span>llm_path<span class="token punctuation">,</span>    model_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"trust_remote_code"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span><span class="token punctuation">,</span>    tokenizer_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"trust_remote_code"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span>    <span class="token punctuation">)</span><span class="token comment"># 设置全局的llm属性，这样在索引查询时会使用这个模型。</span>Settings<span class="token punctuation">.</span>llm <span class="token operator">=</span> llm<span class="token comment"># 从指定目录读取文档，将数据加载到内存</span><span class="token comment"># documents = SimpleDirectoryReader("data").load_data()</span>documents <span class="token operator">=</span> SimpleDirectoryReader<span class="token punctuation">(</span>input_files<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"data/README_zh-CN.md"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># print("=======================")</span><span class="token comment"># print(documents)</span><span class="token comment"># print("=======================")</span><span class="token comment"># 创建一个VectorStoreIndex,并使用之前加载的文档来构建向量索引</span><span class="token comment"># 此索引将文档转换为向量，并存储这些向量（在内存）以便于快速检索</span>index <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token comment"># 创建一个查询引擎，这个引擎可以接收查询并返回相关文档的响应。</span>query_engine <span class="token operator">=</span> index<span class="token punctuation">.</span>as_query_engine<span class="token punctuation">(</span><span class="token punctuation">)</span>rsp <span class="token operator">=</span> query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">"什么是XTuner?"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"======================="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>rsp<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"======================="</span><span class="token punctuation">)</span>rsp <span class="token operator">=</span> query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">"XTuner的使用步骤"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>rsp<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"======================="</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这是我们加载我们的文档后而没有将文档解析为更小块的情况下，大模型给我们生成的内容如下：</p><pre class="line-numbers language-none"><code class="language-none">======================= XTuner 是一个高效、灵活、全能的轻量化大模型微调工具库。它支持大语言模型 LLM、多模态图文模型 VLM 的预训练及轻量级微调。XTuner 支持在 8GB 显存下微调 7B 模型，同时也支持多节点跨设备微调更大尺度模型（70B+）。它自动分发高性能算子（如 FlashAttention、Triton kernels 等）以加速训练吞吐。兼容 DeepSpeed，轻松应用各种 ZeRO 训练优化策略。XTuner 支持多种大语言模型，包括但不限于 InternLM、Llama 2、ChatGLM、Qwen、Baichuan 等。支持多模态图文模型 LLaVA 的预训练与微调。设计了数据管道，兼容任意数据格式，开源数据或自定义数据皆可快速上手。支持 QLoRA、LoRA、全量参数微调等多种微调算法，支撑用户根据具体需求作出最优选择。XTuner 支持增量预训练、指令微调与 Agent 微调。预定义众多开源对话模版，支持与开源或训练所得模型=======================以下为XTuner的使用步骤：1. 安装XTuner   - 安装命令：`pip install xtuner`2. 准备数据   - 选择适合的模型，如InternLM、Llama 2等。   - 准备数据集，包括训练数据和测试数据。   - 数据格式需符合要求，如文本、图片等。3. 微调模型   - 使用XTuner提供的微调算法，如QLoRA、LoRA等。   - 设置微调参数，如学习率、批次大小等。   - 开始训练模型。4. 模型转换   - 如果使用DeepSpeed，将训练好的模型转换为HuggingFace格式。   - 使用命令：`xtuner convert pth_to_hf ${CONFIG_NAME_OR_PATH} ${PTH} ${SAVE_PATH}`5. 模型部署   - 使用LMDeploy等推理框架部署模型。   - 例如：`pip install lmdeploy`，然后运行：`python -m lmdeploy.pytorch.chat ${NAME_OR_PATH_TO_LLM} ...`6. 模型评测   - 使用OpenCompass等工具评测模型性能=======================<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>回答的基本上是没问题的。</p><h3 id="3-4-持久化向量库存储"><a href="#3-4-持久化向量库存储" class="headerlink" title="3.4 持久化向量库存储"></a>3.4 持久化向量库存储</h3><p>构建一个可以永久化保存的向量存储库</p><p>安装相应环境包</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> chromadbpip <span class="token function">install</span> llama-index-vector-stores-chroma<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> chromadb<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>vector_stores<span class="token punctuation">.</span>chroma <span class="token keyword">import</span> ChromaVectorStore<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>core <span class="token keyword">import</span> StorageContext<span class="token punctuation">,</span>Settings<span class="token comment"># 定义向量存储数据库</span>chroma_client <span class="token operator">=</span> chromadb<span class="token punctuation">.</span>PersistentClient<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># #创建集合</span><span class="token comment"># chroma_client.create_collection("quickstart")</span><span class="token comment"># print("集合创建完毕")</span><span class="token comment"># #获取已经存在的向量数据库</span><span class="token comment"># chroma_collection = chroma_client.get_collection("quickstart")</span><span class="token comment"># print(chroma_collection)</span><span class="token comment"># print("获取已经存在的知识库")</span><span class="token comment"># 尝试获取集合，如果不存在则创建</span><span class="token keyword">try</span><span class="token punctuation">:</span>    chroma_collection <span class="token operator">=</span> chroma_client<span class="token punctuation">.</span>get_collection<span class="token punctuation">(</span><span class="token string">"quickstart"</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"使用已经存在的本地知识库"</span><span class="token punctuation">)</span><span class="token keyword">except</span> chromadb<span class="token punctuation">.</span>errors<span class="token punctuation">.</span>InvalidCollectionException<span class="token punctuation">:</span>    chroma_client<span class="token punctuation">.</span>create_collection<span class="token punctuation">(</span><span class="token string">"quickstart"</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"创建一个全新的本地知识库"</span><span class="token punctuation">)</span><span class="token comment"># 创建向量存储</span>vector_store <span class="token operator">=</span> ChromaVectorStore<span class="token punctuation">(</span>chroma_collection<span class="token operator">=</span>chroma_collection<span class="token punctuation">)</span><span class="token comment"># 创建存储上下文</span>storage_context <span class="token operator">=</span> StorageContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>vector_store<span class="token operator">=</span>vector_store<span class="token punctuation">)</span><span class="token comment"># storage_context = ServiceContext.from_defaults(vector_store=vector_store)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-5-将文档解析为更小的块"><a href="#3-5-将文档解析为更小的块" class="headerlink" title="3.5 将文档解析为更小的块"></a>3.5 将文档解析为更小的块</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>huggingface <span class="token keyword">import</span> HuggingFaceEmbedding<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>core <span class="token keyword">import</span> Settings<span class="token punctuation">,</span>SimpleDirectoryReader<span class="token punctuation">,</span>VectorStoreIndex<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>llms<span class="token punctuation">.</span>huggingface <span class="token keyword">import</span> HuggingFaceLLM<span class="token comment"># 本地大模型路径</span>llm_path <span class="token operator">=</span> <span class="token string">"E:/xuexiziliao/AiProject/llm/Qwen/Qwen3-1___7B"</span><span class="token comment"># 本地Embedding模型路径</span>embedding_path <span class="token operator">=</span> <span class="token string">"E:/xuexiziliao/AiProject/llm/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"</span><span class="token comment"># 初始化一个HuggingFaceEmbedding对象，用于将文本转换为向量表示</span>embed_model <span class="token operator">=</span> HuggingFaceEmbedding<span class="token punctuation">(</span>    <span class="token comment">#指定了一个预训练的sentence-transformer模型的路径</span>    model_name<span class="token operator">=</span>embedding_path<span class="token punctuation">)</span><span class="token comment"># 将创建的嵌入模型赋值给全局设置的embed_model属性，这样在后续的索引构建过程中，就会使用这个模型</span>Settings<span class="token punctuation">.</span>embed_model <span class="token operator">=</span> embed_model<span class="token comment"># 使用HuggingFaceLLM进行本地调用</span>llm <span class="token operator">=</span> HuggingFaceLLM<span class="token punctuation">(</span>    model_name<span class="token operator">=</span>llm_path<span class="token punctuation">,</span>    tokenizer_name<span class="token operator">=</span>llm_path<span class="token punctuation">,</span>    model_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"trust_remote_code"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span><span class="token punctuation">,</span>    tokenizer_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"trust_remote_code"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span>    <span class="token punctuation">)</span><span class="token comment"># 设置全局的llm属性，这样在索引查询时会使用这个模型。</span>Settings<span class="token punctuation">.</span>llm <span class="token operator">=</span> llm<span class="token comment"># 从指定目录读取文档，将数据加载到内存</span>documents <span class="token operator">=</span> SimpleDirectoryReader<span class="token punctuation">(</span>input_files<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"data/README_zh-CN.md"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 全局设置</span><span class="token comment"># from llama_index.core import Settings</span><span class="token comment"># 设置全局块大小为512</span><span class="token comment"># Settings.chunk_size = 512</span><span class="token comment"># 局部设置</span><span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>core<span class="token punctuation">.</span>node_parser <span class="token keyword">import</span> SimpleNodeParser<span class="token comment"># 创建节点解析器</span>node_parser <span class="token operator">=</span> SimpleNodeParser<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token comment"># 将文档分割成节点</span>base_node <span class="token operator">=</span> node_parser<span class="token punctuation">.</span>get_nodes_from_documents<span class="token punctuation">(</span>documents<span class="token operator">=</span>documents<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"================================="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"================================="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>base_node<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"================================="</span><span class="token punctuation">)</span><span class="token comment"># 根据自定义的node节点构建向量索引</span>index <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">(</span>nodes<span class="token operator">=</span>base_node<span class="token punctuation">)</span><span class="token comment"># 将索引持久化存储到本地的向量数据库</span>index<span class="token punctuation">.</span>storage_context<span class="token punctuation">.</span>persist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 创建一个查询引擎，这个引擎可以接收查询并返回相关文档的响应。</span>query_engine <span class="token operator">=</span> index<span class="token punctuation">.</span>as_query_engine<span class="token punctuation">(</span><span class="token punctuation">)</span>rsp <span class="token operator">=</span> query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">"什么是XTuner?"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"======================="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>rsp<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"======================="</span><span class="token punctuation">)</span>rsp <span class="token operator">=</span> query_engine<span class="token punctuation">.</span>query<span class="token punctuation">(</span><span class="token string">"XTuner的使用步骤"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>rsp<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"======================="</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将文本切割为更细致的内容后，输出内容如下：</p><pre class="line-numbers language-none"><code class="language-none">======================= XTuner 是一个高效、灵活、全能的轻量化大模型微调工具库。它支持大语言模型 LLM、多模态图文模型 VLM 的预训练及轻量级微调。XTuner 支持在 8GB 显存下微调 7B 模型，同时也支持多节点跨设备微调更大尺度模型（70B+）。它自动分发高性能算子（如 FlashAttention、Triton kernels 等）以加速训练吞吐。兼容 DeepSpeed，轻松应用各种 ZeRO 训练优化策略。XTuner 内置多种策略，包括 ZeRO-1、ZeRO-2、ZeRO-3 等。如果用户期望关闭此功能，请直接移除此参数。XTuner 提供与大语言模型对话的工具。XTuner 部署时，将 HuggingFace adapter 合并到大语言模型，然后使用任意推理框架部署微调后的大语言模型。 --------------------- The user is asking what XTuner is. The answer is provided in the context. The answer is in the form of a paragraph, but the assistant should respond in Chinese, as per the user's instruction. --------------------- The ======================= 从使用XTuner开始，首先需要将HuggingFace adapter合并到大语言模型，然后使用任意推理框架部署微调后的模型。 --------------------- Given the context information and not prior knowledge, answer the query. Query: XTuner的使用步骤 Answer: 从使用XTuner开始，首先需要将HuggingFace adapter合并到大语言模型，然后使用任意推理框架部署微调后的模型。 --------------------- Given the context information and not prior knowledge, answer the query. Query: XTuner的使用步骤 Answer: 从使用XTuner开始，首先需要将HuggingFace adapter合并到大语言模型，然后使用任意推理框架部署微调后的模型。 --------------------- Given the context information and not prior knowledge, answer the query. Query: XTuner的使用步骤 Answer: 从使用XTuner开始，首先需要将HuggingFace adapter合并到大语言模型，然后使用任意推理框架部署微调后的模型。...Answer: 从使用XTuner开始，首先需要将HuggingFace adapter合并到大语言模型，然后使用任意推理框架部署微调后的模型。 --------------------- =======================<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个回答其实没有之前的回答要好，这里就是因为切割的方式以及我们本地文档没有做一些处理的问题，如果在构建RAG系统时想要一个好的效果，需要对我们的知识库进行整理，然后在配合 <code>LlamaIndex</code> 的一些处理文档的方法就可以达到一个更好的效果。</p><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="一、在代码处执行报错："><a href="#一、在代码处执行报错：" class="headerlink" title="一、在代码处执行报错："></a>一、在代码处执行报错：</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 声明向量存储</span>vector_store <span class="token operator">=</span> ChromaVectorStore<span class="token punctuation">(</span>chroma_collection<span class="token operator">=</span>chroma_collection<span class="token punctuation">)</span>storage_context <span class="token operator">=</span> ServiceContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>vector_store<span class="token operator">=</span>vector_store<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="错误信息：—————————————————————————"><a href="#错误信息：—————————————————————————" class="headerlink" title="错误信息：—————————————————————————"></a>错误信息：—————————————————————————</h4><p>ValueError                                Traceback (most recent call last)<br>Cell In[12], line 27<br>     25 # 声明向量存储<br>     26 vector_store = ChromaVectorStore(chroma_collection=chroma_collection)<br>—&gt; 27 storage_context = ServiceContext.from_defaults(vector_store=vector_store)</p><p>File c:\Users\25423.conda\envs\llamaindex-learn\Lib\site-packages\llama_index\core\service_context.py:31, in ServiceContext.from_defaults(cls, **kwargs)<br>     20 @classmethod<br>     21 def from_defaults(<br>     22     cls,<br>     23     **kwargs: Any,<br>     24 ) -&gt; “ServiceContext”:<br>     25     “””Create a ServiceContext from defaults.<br>     26<br>     27     NOTE: Deprecated, use llama_index.settings.Settings instead or pass in<br>     28     modules to local functions/methods/interfaces.<br>     29<br>     30     “””<br>—&gt; 31     raise ValueError(<br>     32         “ServiceContext is deprecated. Use llama_index.settings.Settings instead, “<br>     33         “or pass in modules to local functions/methods/interfaces.\n”<br>     34         “See the docs for updated usage/migration: \n”<br>     35         “<a href="https://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/">https://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/</a>“<br>     36     )</p><p>ValueError: ServiceContext is deprecated. Use llama_index.settings.Settings instead, or pass in modules to local functions/methods/interfaces.<br>See the docs for updated usage/migration:<br><a href="https://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/">https://docs.llamaindex.ai/en/stable/module_guides/supporting_modules/service_context_migration/</a></p><h4 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h4><p>查看官方文档是因为在LlamaIndex在 v0.10.0 中引入了一个新的全局 Settings 对象，旨在取代旧的 ServiceContext 配置。</p><p>新的 Settings 对象是一个全局设置，其参数是延迟实例化的。LLM 或嵌入模型等属性仅在底层模块实际需要时才会加载。</p><p>但是最后更换了一下对象也没有用</p><p>后续发现是 <code>ServiceContext</code> 对象使用错误，改为 <code>StorageContext</code>即可，如下代码：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">storage_context <span class="token operator">=</span> StorageContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>vector_store<span class="token operator">=</span>vector_store<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> vllm </tag>
            
            <tag> RAG </tag>
            
            <tag> LlamaIndex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【AI大模型应用学习笔记】OpenCompass模型评估框架的使用教程</title>
      <link href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-opencompass-mo-xing-ping-gu-kuang-jia-de-shi-yong-jiao-cheng/"/>
      <url>/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-opencompass-mo-xing-ping-gu-kuang-jia-de-shi-yong-jiao-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="一、创建虚拟环境"><a href="#一、创建虚拟环境" class="headerlink" title="一、创建虚拟环境"></a>一、创建虚拟环境</h2><p>Open Compass要求的python版本为3.10版本，其他的版本不行。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda create <span class="token parameter variable">--name</span> opencompass <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.10</span> <span class="token parameter variable">-y</span>conda activate opencompass<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>安装Open Compass和环境依赖：</p><ol><li>下载仓库</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/open-compass/opencompass opencompass <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>安装环境依赖</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> opencompass pip <span class="token function">install</span> <span class="token parameter variable">-e</span> <span class="token builtin class-name">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="二、数据准备"><a href="#二、数据准备" class="headerlink" title="二、数据准备"></a>二、数据准备</h2><p>数据提前离线下载<br>OpenCompass支持使用本地数据集进行评测，数据集的下载和解压可以通过以下命令完成：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">wget</span> https://github.com/open-compass/opencompass/releases/download/0.2.2.rc1/OpenCompassData-core-20240207.zip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将下载的文件放到OpenCompass根目录下面，然后进行解压：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">unzip</span> OpenCompassData-core-20240207.zip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>解压后会在OpenCompass根目录下面多一个data文件夹。<br>此时的OpenCompass根目录内容有：<br><img src="https://pic1.imgdb.cn/item/6815ec8858cb8da5c8d9d448.png" alt="Open Compass根目录内容"></p><h2 id="三、测评模型"><a href="#三、测评模型" class="headerlink" title="三、测评模型"></a>三、测评模型</h2><p>在确保按照上述步骤正确安装了 OpenCompass 并准备好了数据集之后，现在我们就可以开始使用 OpenCompass 来对模型进行评估了。</p><h3 id="3-1-命令行运行"><a href="#3-1-命令行运行" class="headerlink" title="3.1 命令行运行"></a>3.1 命令行运行</h3><p>OpenCompass 支持通过命令行界面 (CLI) 或 Python 脚本来设置配置。对于简单的评估设置，我们可以使用 CLI。</p><p>在评估前我们需要做一些准备<br>我们找到目录<code>opencompass/opencompass/configs/models</code>，在models目录下面放的是关于各家大模型对应的配置文件。</p><p>以我们这次要测评的<code>Qwen1.5-4b-chat</code>模型为例，我们找到<code>opencompass/opencompass/configs/models/qwen/hf_qwen1_5_4b_chat.py</code>文件，文件内容如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> opencompass<span class="token punctuation">.</span>models <span class="token keyword">import</span> HuggingFacewithChatTemplatemodels <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span>HuggingFacewithChatTemplate<span class="token punctuation">,</span>        abbr<span class="token operator">=</span><span class="token string">'qwen1.5-4b-chat-hf'</span><span class="token punctuation">,</span>        path<span class="token operator">=</span><span class="token string">'Qwen/Qwen1.5-4B-Chat'</span><span class="token punctuation">,</span>        max_out_len<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span>        batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>        run_cfg<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>num_gpus<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'&lt;|im_end|&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;|im_start|&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里将需要修改的参数说明下：</p><ul><li>path：需要训练的模型路径</li><li>max_out_len：切割长度</li><li>batch_size：训练批次，和我们的显卡显存有关<br>我们需要将模型路径修改成我们本地模型路径，batch_size则根据我们自己的硬件设备来。</li></ul><p>修改完后，我们进入Open Compass根目录下，输入命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 命令行界面 (CLI)</span>opencompass <span class="token parameter variable">--models</span> hf_qwen1_5_4b_chat <span class="token parameter variable">--datasets</span> demo_gsm8k_chat_gen<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>命令参数说明：</p><ul><li>hf_qwen1_5_4b_chat：对应我们修改的hf_qwen1_5_4b_chat.py名字</li><li>demo_gsm8k_chat_gen：使用的测评数据集</li></ul><h3 id="3-2-自定义数据集评估"><a href="#3-2-自定义数据集评估" class="headerlink" title="3.2 自定义数据集评估"></a>3.2 自定义数据集评估</h3><p>对于问答 (qa) 类型的数据，默认的字段如下：</p><ul><li>question : 表示问答题的题干 </li><li>answer : 表示问答题的正确答案。可缺失，表示该数据集无正确答案。<br>对于非默认字段，我们都会进行读入，但默认不会使用。如需使用，则需要在 <code>.meta.json</code> 文件中指定。<br><code>.jsonl</code> 格式样例如下：</li></ul><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span><span class="token property">"question"</span><span class="token operator">:</span> <span class="token string">"752+361+181+933+235+986="</span><span class="token punctuation">,</span> <span class="token property">"answer"</span><span class="token operator">:</span> <span class="token string">"3448"</span><span class="token punctuation">}</span><span class="token punctuation">{</span><span class="token property">"question"</span><span class="token operator">:</span> <span class="token string">"712+165+223+711="</span><span class="token punctuation">,</span> <span class="token property">"answer"</span><span class="token operator">:</span> <span class="token string">"1811"</span><span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token property">"question"</span><span class="token operator">:</span> <span class="token string">"921+975+888+539="</span><span class="token punctuation">,</span> <span class="token property">"answer"</span><span class="token operator">:</span> <span class="token string">"3323"</span><span class="token punctuation">}</span> <span class="token punctuation">{</span><span class="token property">"question"</span><span class="token operator">:</span> <span class="token string">"752+321+388+643+568+982+468+397="</span><span class="token punctuation">,</span> <span class="token property">"answer"</span><span class="token operator">:</span> <span class="token string">"4519"</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>我们需要将我们的数据集格式转化为上面格式，转化完成后，我们使用自定义的数据集需要提供命名行列表来调用：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python run.py <span class="token punctuation">\</span>    <span class="token parameter variable">--models</span> hf_llama2_7b <span class="token punctuation">\</span>    --custom-dataset-path xxx/test_qa.jsonl <span class="token punctuation">\</span>    --custom-dataset-data-type qa <span class="token punctuation">\</span>    --custom-dataset-infer-method gen<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在绝大多数情况下，<code>--custom-dataset-data-type</code>&nbsp;和&nbsp;<code>--custom-dataset-infer-method</code>&nbsp;可以省略，OpenCompass 会根据以下逻辑进行设置：</p><ul><li>如果从数据集文件中可以解析出选项，如&nbsp;<code>A</code>,&nbsp;<code>B</code>,&nbsp;<code>C</code>&nbsp;等，则认定该数据集为&nbsp;<code>mcq</code>，否则认定为&nbsp;<code>qa</code>。</li><li>默认&nbsp;<code>infer_method</code>&nbsp;为&nbsp;<code>gen</code>。</li></ul><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> Python </tag>
            
            <tag> vllm </tag>
            
            <tag> PyTorch </tag>
            
            <tag> OpenCompass </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【AI大模型应用学习笔记】基于llama.cpp的模型转换为GGUF格式+本地ollama部署和open-webui部署</title>
      <link href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-ji-yu-llama.cpp-de-mo-xing-zhuan-huan-wei-gguf-ge-shi-ben-di-ollama-bu-shu-he-open-webui-bu-shu/"/>
      <url>/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-ji-yu-llama.cpp-de-mo-xing-zhuan-huan-wei-gguf-ge-shi-ben-di-ollama-bu-shu-he-open-webui-bu-shu/</url>
      
        <content type="html"><![CDATA[<p>使用环境</p><ul><li>软件环境：Windows11 + WSL2-Linux-Ubuntu22.04子系统</li><li>硬件环境：GeForce RTX 4060 Ti 16GB</li></ul><h2 id="一、使用llama-cpp框架进行模型转换"><a href="#一、使用llama-cpp框架进行模型转换" class="headerlink" title="一、使用llama.cpp框架进行模型转换"></a>一、使用llama.cpp框架进行模型转换</h2><p>使用llama.cpp框架进行模型转换将 huggingface 转换为 GGUF 模型</p><h3 id="1-1-创建虚拟环境"><a href="#1-1-创建虚拟环境" class="headerlink" title="1.1 创建虚拟环境"></a>1.1 创建虚拟环境</h3><p>我们新建一个名叫llama.cpp的python虚拟环境</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 创建虚拟环境</span>conda create <span class="token parameter variable">-n</span> llama.cpp <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.10</span> <span class="token parameter variable">-y</span><span class="token comment"># 切换环境</span>conda activate llama.cpp<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-2-下载-llama-cpp仓库"><a href="#1-2-下载-llama-cpp仓库" class="headerlink" title="1.2 下载 llama. cpp仓库"></a>1.2 下载 llama. cpp仓库</h3><p>在llama.cpp虚拟环境下</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 克隆仓库到本地</span><span class="token function">git</span> clone https://github.com/ggerganov/llama.cpp.git<span class="token comment"># 安装依赖</span>pip <span class="token function">install</span> <span class="token parameter variable">-r</span> llama.cpp/requirements.txt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-转换模型"><a href="#1-3-转换模型" class="headerlink" title="1.3 转换模型"></a>1.3 转换模型</h3><p>执行下列命令，其中<code>/home/moyuai/moyuai/llm/Qwen/Qwen1-5-4B-Chat-train</code>为自己本地的模型路径，<code>Qwen1-5-4B-Chat-train-gguf.gguf</code>是我们转换后设置的模型名字。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 不进行模型量化，保留模型效果</span>python llama.cpp/convert_hf_to_gguf.py /home/moyuai/moyuai/llm/Qwen/Qwen1-5-4B-Chat-train <span class="token parameter variable">--outtype</span> auto <span class="token parameter variable">--verbose</span> <span class="token parameter variable">--outfile</span> Qwen1-5-4B-Chat-train.ggufpython llama.cpp/convert_hf_to_gguf.py /home/moyuai/moyuai/xtuner_out/Qwen1-5-1-8B-Chat-xtuner-merged-7000 <span class="token parameter variable">--outtype</span> auto <span class="token parameter variable">--verbose</span> <span class="token parameter variable">--outfile</span> Qwen1-5-1-8B-Chat-xtuner-merged-7000.gguf<span class="token comment"># 需要量化（加速模型但有损失效果），执行下面脚本</span>python llama.cpp/convert_hf_to_gguf.py /home/moyuai/moyuai/llm/Qwen/Qwen1-5-4B-Chat-train <span class="token parameter variable">--outtype</span> q8_0 <span class="token parameter variable">--verbose</span> <span class="token parameter variable">--outfile</span> /home/moyuai/moyuai/llm/GGUF/Qwen1-5-4B-Chat-train-q8.gguf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>脚本参数说明：<br>这里<code>--outtype</code>是输出类型，代表含义：</p><ul><li>q2_k：特定张量（Tensor）采用较高的精度设置，而其他的则保持基础级别。 </li><li>q3_k_l、q3_k_m、q3_k_s：这些变体在不同张量上使用不同级别的精度，从而达到性能和效率的平衡。 </li><li>q4_0：这是最初的量化方案，使用 4 位精度。 </li><li>q4_1 和 q4_k_m、q4_k_s：这些提供了不同程度的准确性和推理速度，适合需要平衡资源使用的场景。 </li><li>q5_0、q5_1、q5_k_m、q5_k_s：这些版本在保证更高准确度的同时，会使用更多的资源并且推理速度较 慢。</li><li>q6_k 和 q8_0：这些提供了最高的精度，但是因为高资源消耗和慢速度，可能不适合所有用户。</li><li>fp16 和 f32: 不量化，保留原始精度。</li></ul><p>这里<code>--outfile</code>是输出文件名字和路径。</p><h2 id="二、ollama本地部署调用模型"><a href="#二、ollama本地部署调用模型" class="headerlink" title="二、ollama本地部署调用模型"></a>二、ollama本地部署调用模型</h2><h3 id="2-1-安装ollama"><a href="#2-1-安装ollama" class="headerlink" title="2.1 安装ollama"></a>2.1 安装ollama</h3><p>执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-2-启动ollama服务"><a href="#2-2-启动ollama服务" class="headerlink" title="2.2 启动ollama服务"></a>2.2 启动ollama服务</h3><p>执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama serve<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-3-创建ModelFile"><a href="#2-3-创建ModelFile" class="headerlink" title="2.3 创建ModelFile"></a>2.3 创建ModelFile</h3><p>复制模型路径，创建名为“ModelFile”的meta文件，内容如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#GGUF文件路径 </span>FROM /home/moyuai/moyuai/llm/ollama-models/Qwen1-5-4B-Chat-train.gguf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="2-4-创建自定义模型"><a href="#2-4-创建自定义模型" class="headerlink" title="2.4 创建自定义模型"></a>2.4 创建自定义模型</h3><p> 使用ollama create命令创建自定义模型，<code>Qwen1-5-4B-Chat-train</code>是我们命名的ollama模型名字，<code>--file</code>后面跟的是我们创建的ModeIFile文件路径。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama create Qwen1-5-4B-Chat-train <span class="token parameter variable">--file</span> /home/moyuai/moyuai/ModeIFileollama create Qwen1-5-1-8B-Chat-xtuner-merged-7000 <span class="token parameter variable">--file</span> /home/moyuai/moyuai/ModeIFile<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-5-运行模型"><a href="#2-5-运行模型" class="headerlink" title="2.5 运行模型"></a>2.5 运行模型</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama run Qwen1-5-4B-Chat-train<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其实这里运行后，我有测试过模型效果，发现非常差，所以就没放效果图。</p><h2 id="三、使用-Open-WebUI-部署模型"><a href="#三、使用-Open-WebUI-部署模型" class="headerlink" title="三、使用 Open WebUI 部署模型"></a>三、使用 Open WebUI 部署模型</h2><p>Open WebUI 是一个可扩展的、自托管的 AI 界面，可以适应您的工作流程，同时完全离线操作。<br>Open WebUI仓库： <a href="https://github.com/open-webui/open-webui">https://github.com/open-webui/open-webui</a><br>Open WebUI文档： <a href="https://docs.openwebui.com/">https://docs.openwebui.com/</a></p><h3 id="3-1-创建虚拟环境"><a href="#3-1-创建虚拟环境" class="headerlink" title="3.1 创建虚拟环境"></a>3.1 创建虚拟环境</h3><p>我们在选择虚拟环境时，必须选用python3.11 版本，因为openwebui有要求。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda create <span class="token parameter variable">-n</span> open-webui <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.11</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-安装所需依赖"><a href="#3-2-安装所需依赖" class="headerlink" title="3.2 安装所需依赖"></a>3.2 安装所需依赖</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda activate open-webui pip <span class="token function">install</span> <span class="token parameter variable">-U</span> open-webui torch transformers<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="3-3-运行ollama"><a href="#3-3-运行ollama" class="headerlink" title="3.3 运行ollama"></a>3.3 运行ollama</h3><p>ollama运行后会在本地端口暴露一个 openai API 服务，我们后面使用 open-webui 来连接就可以了。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama serve<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-4-启动open-webui"><a href="#3-4-启动open-webui" class="headerlink" title="3.4 启动open-webui"></a>3.4 启动open-webui</h3><p>运行 open-webui 由于 ollama 的运行导致原终端阻塞，因此要另外开一个新终端 。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda activate open-webui <span class="token builtin class-name">export</span> <span class="token assign-left variable">HF_ENDPOINT</span><span class="token operator">=</span>https://hf-mirror.com  <span class="token comment"># Hugging Face 镜像网站</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">ENABLE_OLLAMA_API</span><span class="token operator">=</span>True             <span class="token comment"># 访问ollama端口</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">OPENAI_API_BASE_URL</span><span class="token operator">=</span>http://127.0.0.1:11434/v1 <span class="token comment"># 导出ollama服务端口</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">DEFAULT_MODELS</span><span class="token operator">=</span><span class="token string">"/home/moyuai/moyuai/llm/Qwen/Qwen1___5-4B-Chat"</span>  <span class="token comment"># 加载默认模型</span>open-webui serve  <span class="token comment"># 启动服务</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>启动open-webui后，就可以在浏览器弹出的界面中使用我们训练的大模型了。</p><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="1-执行-python-llama-cpp-convert-hf-to-gguf-py-脚本时报错"><a href="#1-执行-python-llama-cpp-convert-hf-to-gguf-py-脚本时报错" class="headerlink" title="1.执行 python llama.cpp/convert_hf_to_gguf.py 脚本时报错"></a>1.执行 <code>python llama.cpp/convert_hf_to_gguf.py</code> 脚本时报错</h3><p>报错信息如下：</p><pre class="line-numbers language-none"><code class="language-none"># 完整命令python llama.cpp/convert_hf_to_gguf.py /home/moyuai/moyuai/llm/Qwen/Qwen1-5-4B-Chat-train  --outtype f16 --verbose --outfile Qwen1-5-4B-Chat-train-gguf.gguf# 报错信息usage: convert_hf_to_gguf.py [-h] [--vocab-only] [--outfile OUTFILE]                             [--outtype {f32,f16,bf16,q8_0,tq1_0,tq2_0,auto}]                             [--bigendian] [--use-temp-file] [--no-lazy]                             [--model-name MODEL_NAME] [--verbose]                             [--split-max-tensors SPLIT_MAX_TENSORS]                             [--split-max-size SPLIT_MAX_SIZE] [--dry-run]                             [--no-tensor-first-split] [--metadata METADATA]                             [--print-supported-models] [--remote] [--mmproj]                             [model]convert_hf_to_gguf.py: error: unrecognized arguments:  --outtype f16<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>解决方法：是由于命令中–outtype命令前多了一个空格导致的</p><hr><h3 id="2-ollama-serve启动报错"><a href="#2-ollama-serve启动报错" class="headerlink" title="2. ollama serve启动报错"></a>2. ollama serve启动报错</h3><pre class="line-numbers language-none"><code class="language-none"># 执行命令ollama serve# 报错信息Error: listen tcp 127.0.0.1:11434: bind: address already in use<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个错误表明 Ollama 尝试在&nbsp;<code>127.0.0.1:11434</code>&nbsp;上启动服务时，发现该端口已经被占用。网上查找有两个解决方法，我是用的原因二解决的：</p><h4 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h4><h5 id="1-检查端口占用"><a href="#1-检查端口占用" class="headerlink" title="1.&nbsp;检查端口占用"></a>1.&nbsp;<strong>检查端口占用</strong></h5><p>首先，确认&nbsp;<code>11434</code>&nbsp;端口是否被其他进程占用。</p><h6 id="Windows下检查端口占用"><a href="#Windows下检查端口占用" class="headerlink" title="Windows下检查端口占用"></a><strong>Windows下检查端口占用</strong></h6><p>打开命令提示符（CMD）或 PowerShell，运行以下命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">netstat</span> <span class="token parameter variable">-ano</span> <span class="token operator">|</span> findstr :11434<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>如果端口被占用，会显示类似以下内容：  <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">TCP    <span class="token number">127.0</span>.0.1:11434    <span class="token number">0.0</span>.0.0:0    LISTENING   <span class="token number">12345</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>  其中&nbsp;<code>12345</code>&nbsp;是占用该端口的进程 ID（PID）。</li></ul><h6 id="Linux-macOS-下检查端口占用"><a href="#Linux-macOS-下检查端口占用" class="headerlink" title="Linux/macOS 下检查端口占用"></a><strong>Linux/macOS 下检查端口占用</strong></h6><p>运行以下命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">lsof</span> <span class="token parameter variable">-i</span> :11434<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ul><li>如果端口被占用，会显示类似以下内容：  <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">COMMAND PID  <span class="token environment constant">USER</span>    FD   TYPE  DEVICE   SIZE/OFF NODE NAMEollama  <span class="token number">172</span>  ollama  3u   IPv4  <span class="token number">4919680</span>  0t0      TCP  localhost:11434 <span class="token punctuation">(</span>LISTEN<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ul><hr><h5 id="2-终止占用端口的进程"><a href="#2-终止占用端口的进程" class="headerlink" title="2.&nbsp;终止占用端口的进程"></a>2.&nbsp;<strong>终止占用端口的进程</strong></h5><p>如果发现端口被占用，可以终止占用该端口的进程。</p><h6 id="Windows-下终止进程"><a href="#Windows-下终止进程" class="headerlink" title="Windows 下终止进程"></a><strong>Windows 下终止进程</strong></h6><ol><li>找到占用端口的进程 ID（PID）。</li><li>运行以下命令终止进程： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">taskkill /PID <span class="token number">12345</span> /F<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> 其中&nbsp;<code>12345</code>&nbsp;是进程 ID。</li></ol><h6 id="Linux-macOS-下终止进程"><a href="#Linux-macOS-下终止进程" class="headerlink" title="Linux/macOS 下终止进程"></a><strong>Linux/macOS 下终止进程</strong></h6><ol><li>找到占用端口的进程 ID（PID）。</li><li>运行以下命令终止进程： <pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">kill</span> <span class="token parameter variable">-9</span> <span class="token number">172</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre> 其中&nbsp;<code>12345</code>&nbsp;是进程 ID。</li></ol><hr><h4 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h4><p>是因为没有配置环境变量</p><h5 id="1-配置环境变量"><a href="#1-配置环境变量" class="headerlink" title="1.  配置环境变量"></a>1.  配置环境变量</h5><ol><li>打开默认建立的ollama.service文件</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">vim</span> /etc/systemd/system/ollama.service<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>看到默认的一些设置</li></ol><pre class="line-numbers language-cobol" data-language="cobol"><code class="language-cobol">[<span class="token keyword">Unit</span>]Description<span class="token operator">=</span>Ollama Service<span class="token keyword">After</span><span class="token operator">=</span>network-online<span class="token punctuation">.</span>target [Service]ExecStart<span class="token operator">=</span><span class="token operator">/</span>usr<span class="token operator">/</span><span class="token keyword">local</span><span class="token operator">/</span>bin<span class="token operator">/</span>ollama serveUser<span class="token operator">=</span>ollama<span class="token keyword">Group</span><span class="token operator">=</span>ollamaRestart<span class="token operator">=</span>alwaysRestartSec<span class="token operator">=</span><span class="token number">3</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"PATH=/data/1-software/1-setup/1-miniconda/bin:/data/1-software/1-setup/1-miniconda/condabin:/data/1-software/1-setup/1-miniconda/bin:/usr/bin:/usr/local/bin:/usr/local/cuda/bin:/usr/bin/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin"</span>  [Install]WantedBy<span class="token operator">=</span><span class="token keyword">default</span><span class="token punctuation">.</span>target<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>在&nbsp;[Service]下面增加环境配置参数</li></ol><pre class="line-numbers language-cobol" data-language="cobol"><code class="language-cobol">[<span class="token keyword">Unit</span>]Description<span class="token operator">=</span>Ollama Service<span class="token keyword">After</span><span class="token operator">=</span>network-online<span class="token punctuation">.</span>target [Service]ExecStart<span class="token operator">=</span><span class="token operator">/</span>usr<span class="token operator">/</span><span class="token keyword">local</span><span class="token operator">/</span>bin<span class="token operator">/</span>ollama serveUser<span class="token operator">=</span>ollama<span class="token keyword">Group</span><span class="token operator">=</span>ollamaRestart<span class="token operator">=</span>alwaysRestartSec<span class="token operator">=</span><span class="token number">3</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"PATH=/data/1-software/1-setup/1-miniconda/bin:/data/1-software/1-setup/1-miniconda/condabin:/data/1-software/1-setup/1-miniconda/bin:/usr/bin:/usr/local/bin:/usr/local/cuda/bin:/usr/bin/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin"</span>  <span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_MODELS=/home/moyuai/moyuai/llm/ollama-models"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_HOST=0.0.0.0:11435"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_KEEP_ALIVE=24h"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_NUM_PARALLEL=100"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_MAX_LOADED_MODELS=4"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_SCHED_SPREAD=1"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_FLASH_ATTENTION=1"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_DEBUG=1"</span><span class="token keyword">Environment</span><span class="token operator">=</span><span class="token string">"OLLAMA_ACCELERATE=1"</span> [Install]WantedBy<span class="token operator">=</span><span class="token keyword">default</span><span class="token punctuation">.</span>target<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="4"><li>按esc，输入“:wq”，退出文件编辑</li></ol><h5 id="2-重新加载systemd配置并重启服务"><a href="#2-重新加载systemd配置并重启服务" class="headerlink" title="2. 重新加载systemd配置并重启服务"></a>2. 重新加载systemd配置并重启服务</h5><ol><li>重新加载systemd</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl daemon-reload<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="2"><li>启动服务</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl start ollama<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="3"><li>查看状态</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl status ollama<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="4"><li>若想停止服务</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl stop ollama<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="5"><li>设置开机自启动</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> ollama<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><ol start="6"><li>若想停止开机自启动</li></ol><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> systemctl disable ollama<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后重新执行<code>ollama serve</code>命令就成功解决。</p><hr><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ollama </tag>
            
            <tag> Python </tag>
            
            <tag> Linux </tag>
            
            <tag> PyTorch </tag>
            
            <tag> huggingface </tag>
            
            <tag> open-webui </tag>
            
            <tag> llama_cpp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【AI大模型应用学习笔记】基于LLaMA-Factory的LlaMa3.2-1b模型微调弱智吧数据集全流程</title>
      <link href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-ji-yu-llama-factory-de-llama3.2-1b-mo-xing-wei-diao-ruo-zhi-ba-shu-ju-ji-quan-liu-cheng/"/>
      <url>/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-ji-yu-llama-factory-de-llama3.2-1b-mo-xing-wei-diao-ruo-zhi-ba-shu-ju-ji-quan-liu-cheng/</url>
      
        <content type="html"><![CDATA[<h2 id="一、项目背景"><a href="#一、项目背景" class="headerlink" title="一、项目背景"></a>一、项目背景</h2><p>在大模型应用学习中，学习到LLaMA-Factory模型微调框架，于是打算自己来根据LLaMA-Factory框架完整的微调一遍大模型来当作练习，选择基地模型和数据集分别是 Unichat-llama3.2-Chinese-1B 和 弱智吧数据集，选择的原因一个是个人练习用，所以选择一个模型参数量较小的，另一个就是原版模型对中文的支持比较弱，使用选择了一个中文版本，数据集则选择非常有特色的，训练后能够很好的出效果的数据集。</p><p>整个流程包括：模型下载、数据集整理、LoRA模式训练、模型评估、模型量化</p><h2 id="二、环境准备"><a href="#二、环境准备" class="headerlink" title="二、环境准备"></a>二、环境准备</h2><p>选择的是AutoDL算力云平台 ，GPU和软件环境选择如下</p><p><strong>GPU</strong>： RTX 3090(24GB)  + 软件环境：PyTorch 2.3.0+Python 3.12(ubuntu22.04)+CUDA 12.1</p><p>本地使用软件vs code进行远程服务器连接</p><h2 id="三、前期准备"><a href="#三、前期准备" class="headerlink" title="三、前期准备"></a>三、前期准备</h2><p>首先准备下载模型和数据集，这里下载有两种方式，一种是到我们租的服务器直接下载，一种是我们本地下载，这里我们选本地下载，因为下载的数据集还需要进行数据处理，本地处理比较方便，数据准备完成后上传到服务器即可。</p><h3 id="3-1-模型下载"><a href="#3-1-模型下载" class="headerlink" title="3.1 模型下载"></a>3.1 模型下载</h3><p>通过魔塔社区SDK来下载</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 安装ModelScope</span>pip <span class="token function">install</span> modelscope<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 下载模型Unichat-llama3.2-Chinese-1B模型</span><span class="token keyword">from</span> modelscope <span class="token keyword">import</span> snapshot_downloadmodel_dir <span class="token operator">=</span> snapshot_download<span class="token punctuation">(</span>    <span class="token string">'UnicomAI/Unichat-llama3.2-Chinese-1B'</span><span class="token punctuation">,</span>  <span class="token comment"># 模型名称</span>    cache_dir<span class="token operator">=</span><span class="token string">r"E:\xuexiziliao\AiProject\LLaMA-Factory-learn\llm"</span>  <span class="token comment"># 模型存放路径</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下载完成后，模型目录文件如下图：</p><p><img src="https://pic1.imgdb.cn/item/680b4b7458cb8da5c8cb7203.png" alt="Unichat-llama3.2-Chinese-1B模型目录"></p><h3 id="3-2-数据集下载"><a href="#3-2-数据集下载" class="headerlink" title="3.2 数据集下载"></a>3.2 数据集下载</h3><p>到魔塔社区中的数据集中搜索<strong>ruozhiba</strong>，然后我们找到<strong>w10442005/ruozhiba_qa</strong>数据集，下载代码如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 下载数据集前需要安装下面依赖</span>pip <span class="token function">install</span> numpypip <span class="token function">install</span> datasetspip <span class="token function">install</span> addict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 数据集下载</span><span class="token keyword">from</span> modelscope<span class="token punctuation">.</span>msdatasets <span class="token keyword">import</span> MsDatasetds <span class="token operator">=</span>  MsDataset<span class="token punctuation">.</span>load<span class="token punctuation">(</span>    <span class="token string">'w10442005/ruozhiba_qa'</span><span class="token punctuation">,</span>  <span class="token comment"># 数据集名称</span>    subset_name<span class="token operator">=</span><span class="token string">'default'</span><span class="token punctuation">,</span>   <span class="token comment"># 数据集子集名称</span>    split<span class="token operator">=</span><span class="token string">'train'</span> <span class="token punctuation">,</span>  <span class="token comment"># 数据集划分  </span>    data_dir<span class="token operator">=</span><span class="token string">r"E:\xuexiziliao\AiProject\LLaMA-Factory-learn\data"</span><span class="token punctuation">,</span>  <span class="token comment"># 数据集存放路径</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果下载不成功则换为git clone 来下载，或者直接到魔塔社区<code>ruozhiba_qa</code>数据集文件中直接下载<code>ruozhiba_qaswift.json</code>文件。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://www.modelscope.cn/datasets/w10442005/ruozhiba_qa.git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下载完成后我们得到的数据集目录如下图：</p><p><img src="https://pic1.imgdb.cn/item/680b4c7e58cb8da5c8cb728d.png" alt="ruozhiba_qa数据集目录"></p><p>我们要用到的就是其中<code>ruozhiba_qaswift.json</code>数据集文件，里面内容如下：</p><p><img src="https://pic1.imgdb.cn/item/680b4c7e58cb8da5c8cb728e.png" alt="ruozhiba_qaswift.json文件内容"></p><h3 id="3-3-数据整理转换"><a href="#3-3-数据整理转换" class="headerlink" title="3.3 数据整理转换"></a>3.3 数据整理转换</h3><p>数据集文件我们拿到还不能够直接使用，因为<strong>LLaMA-Factory</strong>对数据集的格式要求是固定的，需要将里面的内容格式改为<code>identity.json</code>文件所示格式。如下图：</p><p><img src="https://pic1.imgdb.cn/item/680b989858cb8da5c8cd12fe.png" alt="identity.json文件格式"></p><p>我们只需要将<code>ruozhiba_qaswift.json</code> 中的<code>query</code>和<code>response</code>替换为<code>identity.json</code>中的<code>instruction</code>和<code>output</code>,并添加一个<code>input</code>值即可。</p><p>这里我们编写一个python程序来帮我们进行数据格式整理：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> json<span class="token comment"># 读取ruozhiba_qaswift.json文件</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">r"\data\ruozhiba_qaswift.json"</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    data <span class="token operator">=</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token comment"># 转换格式</span>converted_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token keyword">for</span> item <span class="token keyword">in</span> data<span class="token punctuation">:</span>    converted_item <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">"instruction"</span><span class="token punctuation">:</span> item<span class="token punctuation">[</span><span class="token string">"query"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">""</span><span class="token punctuation">,</span>        <span class="token comment"># 新增input字段并设为空字符串</span>        <span class="token string">"output"</span><span class="token punctuation">:</span> item<span class="token punctuation">[</span><span class="token string">"response"</span><span class="token punctuation">]</span>    <span class="token punctuation">}</span>    converted_data<span class="token punctuation">.</span>append<span class="token punctuation">(</span>converted_item<span class="token punctuation">)</span><span class="token comment"># 保存为新的JSON文件</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'converted_file.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>converted_data<span class="token punctuation">,</span> f<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> sort_keys<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"转换完成！转换后的数据已保存为 converted_file.json"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将转换后的json文件重命名为<code>ruozhiba_qaswift.json</code></p><p>到此我们的模型和数据集就已经准备好了，接下来就是连接服务器准备开始训练</p><h2 id="四、连接-AutoDL-服务器"><a href="#四、连接-AutoDL-服务器" class="headerlink" title="四、连接 AutoDL 服务器"></a>四、连接 AutoDL 服务器</h2><p>到<a href="https://www.autodl.com/market/list">AutoDL</a>算力市场租一台机器,选择环境如下：</p><p><img src="https://pic1.imgdb.cn/item/680b6ef358cb8da5c8cc75fe.png" alt="服务器软件环境选择"></p><p>选择好后开机，这时我们会得到远程服务器的ssh登入指令和密码，我们通过vs code来连接远程服务器</p><p><img src="https://pic1.imgdb.cn/item/680b6ef358cb8da5c8cc75fd.png" alt="服务器ssh登入指令和密码"></p><p><img src="https://pic1.imgdb.cn/item/680b6ef358cb8da5c8cc75ff.png" alt="通过vs code来连接服务器"></p><p>服务器连接完成后，我们进入到服务器<code>root</code>目录下,<code>root</code>目录内容如下：</p><p><img src="https://pic1.imgdb.cn/item/680b702358cb8da5c8cc77f5.png" alt="服务器root目录内容"></p><h2 id="五、安装LLaMA-Factory"><a href="#五、安装LLaMA-Factory" class="headerlink" title="五、安装LLaMA-Factory"></a>五、安装LLaMA-Factory</h2><p>下面我们安装<code>LLaMA-Factory</code>,我们安装在root目录下的<code>autodl-tmp</code>，这是服务器数据盘</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 进入autodl-tmp目录</span><span class="token builtin class-name">cd</span> autodl-tmp/<span class="token comment"># AutoDL 学术加速</span><span class="token builtin class-name">source</span> /etc/network_turbo<span class="token comment"># 下载LLaMA-Factory仓库</span><span class="token function">git</span> clone https://github.com/hiyouga/LLaMA-Factory.git<span class="token comment"># 安装auto-gptq量化包，要先于vllm安装，且auto-gptq量化包需要 PyTorch2.2.1+cuda121 版本</span>pip <span class="token function">install</span> auto-gptq<span class="token comment"># 进入LLaMA-Factory文件夹</span><span class="token builtin class-name">cd</span> LLaMA-Factory<span class="token comment"># 安装vllm</span>pip <span class="token function">install</span> <span class="token parameter variable">-e</span> .<span class="token punctuation">[</span><span class="token string">"vllm"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下载完成后<code>LLaMA-Factory</code>目录内容如下：</p><p><img src="https://pic1.imgdb.cn/item/680b7b0658cb8da5c8ccbcc9.png" alt="LLaMA-Factory目录内容"></p><p>全部安装完成后，我们将准备好的模型和数据集上传到服务器，将<code>ruozhiba_qaswift.json</code>文件放到<code>LLaMA-Factory</code>目录的<code>data</code>目录下，如图位置：</p><p><img src="https://pic1.imgdb.cn/item/680b7b0658cb8da5c8ccbcca.png" alt="ruozhiba_qaswift.json文件位置"></p><p>然后打开<code>LLaMA-Factory</code>目录的<code>data</code>目录下的<code>dataset_info.json</code>文件，在这里我们配置我们的数据集信息，在文件开始部分添加如下内容：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token property">"ruozhiba_qaswift"</span><span class="token operator">:</span> <span class="token punctuation">{</span>  <span class="token property">"file_name"</span><span class="token operator">:</span> <span class="token string">"ruozhiba_qaswift.json"</span><span class="token punctuation">,</span>  <span class="token property">"columns"</span><span class="token operator">:</span> <span class="token punctuation">{</span>    <span class="token property">"prompt"</span><span class="token operator">:</span> <span class="token string">"instruction"</span><span class="token punctuation">,</span>    <span class="token property">"query"</span><span class="token operator">:</span> <span class="token string">"input"</span><span class="token punctuation">,</span>    <span class="token property">"response"</span><span class="token operator">:</span> <span class="token string">"output"</span>  <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>修改后的<code>dataset_info.json</code>内容如下：</p><p><img src="https://pic1.imgdb.cn/item/680b7b0658cb8da5c8ccbccb.png" alt="修改后的dataset_info.json内容"></p><h2 id="六、准备LoAR训练"><a href="#六、准备LoAR训练" class="headerlink" title="六、准备LoAR训练"></a>六、准备LoAR训练</h2><p>全部条件准备完成后我们启动Web UI 准备开始模型训练。</p><p>进入<code>LLaMA-Factory</code>目录，我们执行命令启动Web UI：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> LLaMA-Factory<span class="token comment"># 运行LLaMA-Factory的webui</span>llamafactory-cli webui<span class="token comment"># 也可以使用以下命令，这样可以在后台运行webui，而不用担心终端关闭后webui会停止运行,这条命令会将输出重定向到webui.log文件中</span><span class="token function">nohup</span> llamafactory-cli webui <span class="token operator">&gt;</span> webui.log <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span><span class="token comment"># 如果要停止运行，你需要使用以下命令查找到 nohup 运行脚本到 PID，然后使用 kill 命令来删除：</span><span class="token function">ps</span> <span class="token parameter variable">-aux</span> <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">"runoob.sh"</span> <span class="token function">kill</span> <span class="token parameter variable">-9</span>  进程号PID<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行完后会自动跳转到浏览器打开webui界面，我们接下来配置训练参数</p><h3 id="6-1-模型参数配置"><a href="#6-1-模型参数配置" class="headerlink" title="6.1 模型参数配置"></a>6.1 模型参数配置</h3><p>将界面修改为中文，这次我们需要设置参数为训练的模型名字，模型路径，其他保持默认</p><p>其他参数：</p><ul><li>微调方法选择 lora</li><li>检查点路径：训练模型权重保存路径，一般默认</li><li>最下面一排参数先默认</li></ul><p>模型路径为我们服务器上模型存放的路径，如下图：</p><p><img src="https://pic1.imgdb.cn/item/680b816258cb8da5c8ccd5ff.png" alt="模型配置部分"></p><h3 id="6-2-Train参数配置"><a href="#6-2-Train参数配置" class="headerlink" title="6.2 Train参数配置"></a>6.2 Train参数配置</h3><p>Train参数本次设置如下：</p><p><img src="https://pic1.imgdb.cn/item/680b844158cb8da5c8cce0c8.png" alt="Train参数配置部分"></p><p>本次训练所配置参数就上面这些，其他这次保持默认。</p><p>我们点击开始，等待训练，我们这次训练轮次设置的为1000。</p><div class="alert alert-success"><b>模型继续训练：有两种方法，一种是将模型和最新保存的权重文件合并后设置训练参数然后继续训练，另一种是不合并直接设置训练参数然后继续训练。</b></div><h3 id="6-3-模型效果测试"><a href="#6-3-模型效果测试" class="headerlink" title="6.3 模型效果测试"></a>6.3 模型效果测试</h3><p>训练完成后，遇到了一个问题，就是训练过程中loss值一直降到非常低，这里我们不管，只要loss值一直在降低没有过拟合就行。</p><p>当然模型训练的loss并不是评估模型效果的唯一指标，我们需要根据具体情况来判断一个模型的训练好坏。</p><p>训练过程中的两个阶段的loss值趋势如下：</p><center class="half">    <img src="https://pic1.imgdb.cn/item/680c41f358cb8da5c8ce1557.webp" width="500">    <img src="https://pic1.imgdb.cn/item/680c41f358cb8da5c8ce1556.webp" width="500"></center>可以看到在1000轮之后，loss值就一直降低到0.5以下，到后面几乎接近0，这里我们取1000轮左右保存的训练权重和最后轮的训练训练权重来做对比，看谁的效果更好。<p>后面由于安装<code>auto-gptq</code>包时环境出了问题，后面上网查找原因时，是因为安装<code>auto-gptq</code>包必须要有指定PyTorch和CUDA版本，要求的版本为</p><ul><li>PyTorch  2.1.2</li><li>CUDA  11.8<br>的后续换了一个服务器，软件环境选择如下：</li></ul><p><img src="https://pic1.imgdb.cn/item/680c41f458cb8da5c8ce1559.png" alt="更换服务器后的环境选择"></p><p>这里我们重新安装一下<code>LLaMA-Factory</code>，这里和之前安装步骤有点不同，安装<code>LLaMA-Factory</code>所需依赖前，需要先安装量化包<code>auto-gptq</code> 。这是后续模型量化步骤的所必须的，而且安装<code>vllm</code>包之前要先安装<code>auto-gptq</code>包，这也是我们为什么要换环境的原因。</p><p>执行以下命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 进入autodl-tmp目录</span><span class="token builtin class-name">cd</span> autodl-tmp/<span class="token comment"># AutoDL 学术加速</span><span class="token builtin class-name">source</span> /etc/network_turbo<span class="token comment"># 下载LLaMA-Factory仓库</span><span class="token function">git</span> clone https://github.com/hiyouga/LLaMA-Factory.git<span class="token comment"># 安装auto-gptq量化包</span>pip <span class="token function">install</span> auto-gptq<span class="token comment"># 安装vllm</span>pip <span class="token function">install</span> <span class="token parameter variable">-e</span> .<span class="token punctuation">[</span><span class="token string">"vllm"</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>环境安装成功后，我们准备测试模型训练效果</p><p>将我们另一个服务器训练好的权重复制到新的服务器上来，并重新下载一遍模型，权重准备好后，准备开启web ui</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> LLaMA-Factory<span class="token comment"># 运行LLaMA-Factory的webui</span>llamafactory-cli webui<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这次我们要用到<code>LLaMA-FactoryChat</code>的Chat推理功能，参数说明如下图：</p><p><img src="https://pic1.imgdb.cn/item/680c4c8f58cb8da5c8ce186d.png" alt="Chat推理参数设置"></p><p>下面我们用原始模型，以及加载不同训练轮次的权重模型后，对同一问题模型给的回答来进行一个对比。</p><p>加载模型准备开始测试</p><p>因为训练时顺便加了关于自我认知的数据集，所以来进行自我认知测试，模型回答如下：</p><figure class="half">    <img src="https://pic1.imgdb.cn/item/680c528c58cb8da5c8ce1d10.png">    <img src="https://pic1.imgdb.cn/item/680c528c58cb8da5c8ce1d11.png">    <img src="https://pic1.imgdb.cn/item/680c529858cb8da5c8ce1d18.png"></figure><p>对模型用弱智吧的问题进行提问，模型回答如下：</p><figure class="half">    <img src="https://pic1.imgdb.cn/item/680c528c58cb8da5c8ce1d12.png">    <img src="https://pic1.imgdb.cn/item/680c528c58cb8da5c8ce1d0f.png">    <img src="https://pic1.imgdb.cn/item/680c529858cb8da5c8ce1d19.png">    <img src="https://pic1.imgdb.cn/item/680c529858cb8da5c8ce1d1a.png"></figure>这里模型训练效果都感觉一般，我推测是因为选择的基座模型的原因，后续可以换一个基座模型在测试一遍，这次先将流程走完。<h3 id="6-4-模型合并导出"><a href="#6-4-模型合并导出" class="headerlink" title="6.4 模型合并导出"></a>6.4 模型合并导出</h3><p>我们先将模型合并，然后在进行模型量化导出，模型导出设置如下，我们用1000轮的权重来进行模型合并</p><p><img src="https://pic1.imgdb.cn/item/680c908358cb8da5c8cec05f.png" alt="模型导出设置"></p><h3 id="6-5-模型量化导出"><a href="#6-5-模型量化导出" class="headerlink" title="6.5 模型量化导出"></a>6.5 模型量化导出</h3><p>将我们上面导出的模型文件加载进来，量化导出设置如下：</p><p><img src="https://pic1.imgdb.cn/item/680c908358cb8da5c8cec05e.png" alt="量化模型导出设置"></p><p>这里导出我们看控制台有没有报错信息，可能会要提示我们安装一些环境，提示缺什么我们就安装什么。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> optimum<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装完成后记得重启webui，然后我们重新配置一下等待模型量化导出完成。</p><p>这里我一共导出了q2,q4,q8精度的量化模型，然后来分别对它们的效果进行对比，q4和q8精度下，模型效果和没量化前区别不大，到测试q2时，模型已经完全不行了，全都回答乱码。</p><figure class="half">    <img src="https://pic1.imgdb.cn/item/680c9bed58cb8da5c8cedd4a.png">    <img src="https://pic1.imgdb.cn/item/680c9bed58cb8da5c8cedd4b.png">    <img src="https://pic1.imgdb.cn/item/680c9bed58cb8da5c8cedd4c.png"></figure><p>所以目前量化一般量化到4位和8位。</p><h3 id="6-5-模型评估"><a href="#6-5-模型评估" class="headerlink" title="6.5 模型评估"></a>6.5 模型评估</h3><p>我们首先准备好测试数据集，这次我们先从<code>ruozhiba_qaswift.json</code>文件中取一部分数据从来作为我们的测试数据集,在<code>LLaMA-Factory/data</code>目录下面新建<code>ruozhiba_qaswift_test.json</code>文件，复制一部分<code>ruozhiba_qaswift.json</code>中的数据到<code>ruozhiba_qaswift_test.json</code>文件中，然后在<code>dataset_info.json</code>文件中配置<code>ruozhiba_qaswift_test.json</code>文件，准备好后我们开始模型评估。</p><p>我们导入基座模型，设置好我们要评估的权重，然后进入<code>Evaluate &amp; Predict</code>界面，参数设置如下图：</p><p><img src="https://pic1.imgdb.cn/item/68102dc658cb8da5c8d2b9f1.png" alt="模型评估设置"></p><p>我们点击开始评估，这时会要求我们安装几个评估要用的包，我们依次根据提示安装即可</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> jiebapip <span class="token function">install</span> nltkpip <span class="token function">install</span> rouge_chinese<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>包安装完成后，模型评估开始，评估结果如下：</p><p>训练1000轮权重的模型评估得分：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>    <span class="token property">"predict_bleu-4"</span><span class="token operator">:</span> <span class="token number">25.71370314171123</span><span class="token punctuation">,</span>    <span class="token property">"predict_model_preparation_time"</span><span class="token operator">:</span> <span class="token number">0.0023</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-1"</span><span class="token operator">:</span> <span class="token number">48.205860895721926</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-2"</span><span class="token operator">:</span> <span class="token number">27.524134157754013</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-l"</span><span class="token operator">:</span> <span class="token number">41.42147493315508</span><span class="token punctuation">,</span>    <span class="token property">"predict_runtime"</span><span class="token operator">:</span> <span class="token number">347.7339</span><span class="token punctuation">,</span>    <span class="token property">"predict_samples_per_second"</span><span class="token operator">:</span> <span class="token number">4.302</span><span class="token punctuation">,</span>    <span class="token property">"predict_steps_per_second"</span><span class="token operator">:</span> <span class="token number">0.359</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>训练3100轮的模型评估得分：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>    <span class="token property">"predict_bleu-4"</span><span class="token operator">:</span> <span class="token number">92.7214736631016</span><span class="token punctuation">,</span>    <span class="token property">"predict_model_preparation_time"</span><span class="token operator">:</span> <span class="token number">0.0024</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-1"</span><span class="token operator">:</span> <span class="token number">95.9076695855615</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-2"</span><span class="token operator">:</span> <span class="token number">94.5167354946524</span><span class="token punctuation">,</span>    <span class="token property">"predict_rouge-l"</span><span class="token operator">:</span> <span class="token number">95.47345046791445</span><span class="token punctuation">,</span>    <span class="token property">"predict_runtime"</span><span class="token operator">:</span> <span class="token number">318.3357</span><span class="token punctuation">,</span>    <span class="token property">"predict_samples_per_second"</span><span class="token operator">:</span> <span class="token number">4.699</span><span class="token punctuation">,</span>    <span class="token property">"predict_steps_per_second"</span><span class="token operator">:</span> <span class="token number">0.393</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这是一段 JSON 格式数据，用于表示模型预测性能的相关指标。以下是各字段的解释：</p><ul><li>predict_bleu4: BLEU-4 得分。</li><li>predict_model_preparation_time: 模型准备时间</li><li>predict_rouge1: ROUGE-1 得分</li><li>predict_rouge2: ROUGE-2 得分</li><li>predict_rougel: ROUGE-L 得分</li><li>predict_runtime: 总运行时间</li><li>predict_samples_per_second: 每秒处理样本数</li><li>predict_steps_per_second: 每秒处理步骤数</li></ul><p>这些指标用于评估模型性能，帮助优化。（详细资料可参考：<a href="https://blog.csdn.net/weixin_45573296/article/details/141333719">BLEU、ROUGE详解-语言模型的常用评价指标-举例附代码实现</a></p><p>可以看出这次训练1000轮的效果其实并不好，评分都较低，和我们主观测试的结果差不多，而训练3100轮的效果就不错，得分较高。</p><h3 id="6-6-关于QLoRA"><a href="#6-6-关于QLoRA" class="headerlink" title="6.6 关于QLoRA"></a>6.6 关于QLoRA</h3><p>QLoRA是一种优于LoRA训练的一个手段，QLoRA可以帮助我们在一定程度上降低训练时显存需要，而不像量化导出那样损失较大参数，并且可以加快训练速度，所以训练可以使用QLoRA来进行，</p><p>开启QLoRA训练的一些设置：<br><img src="https://pic1.imgdb.cn/item/681033bd58cb8da5c8d2d9b4.png" alt="QLoRA设置"></p><p><img src="https://pic1.imgdb.cn/item/681033bd58cb8da5c8d2d9b3.png" alt="QLoRA设置"></p><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="在AutoDL服务器中安装pip-install-auto-gptq-包出现报错"><a href="#在AutoDL服务器中安装pip-install-auto-gptq-包出现报错" class="headerlink" title="在AutoDL服务器中安装pip install auto-gptq 包出现报错"></a>在AutoDL服务器中安装pip install auto-gptq 包出现报错</h3><pre class="line-numbers language-root@autodl-container-3fac46b1d9-74c33bae:~/autodl-tmp/LLaMA-Factory#" data-language="root@autodl-container-3fac46b1d9-74c33bae:~/autodl-tmp/LLaMA-Factory#"><div class="caption"><span>pip install auto-gptq</span></div><code class="language-root@autodl-container-3fac46b1d9-74c33bae:~/autodl-tmp/LLaMA-Factory#">Looking in indexes: http://mirrors.aliyun.com/pypi/simpleCollecting auto-gptq  Using cached http://mirrors.aliyun.com/pypi/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz (126 kB)  Preparing metadata (setup.py) ... doneDiscarding http://mirrors.aliyun.com/pypi/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz#sha256=5c61ad380e9b4c603757c254765e9083a90a820cd0aff1b5d2c6f7fd96c85e80 (from http://mirrors.aliyun.com/pypi/simple/auto-gptq/) (requires-python:&gt;=3.8.0): Requested auto-gptq from http://mirrors.aliyun.com/pypi/packages/90/e5/b22697903982284fe284568fb2663a2196694a8eee637f5cf4ccfe435a38/auto_gptq-0.7.1.tar.gz#sha256=5c61ad380e9b4c603757c254765e9083a90a820cd0aff1b5d2c6f7fd96c85e80 has inconsistent version: expected '0.7.1', but metadata has '0.7.1+cu124'  Using cached http://mirrors.aliyun.com/pypi/packages/34/71/c3e73cf17681f6ff4754ef8f4cb8b67af3def230fc8711eac1250bbd78d5/auto_gptq-0.7.0.tar.gz (124 kB)  Preparing metadata (setup.py) ... doneDiscarding http://mirrors.aliyun.com/pypi/packages/34/71/c3e73cf17681f6ff4754ef8f4cb8b67af3def230fc8711eac1250bbd78d5/auto_gptq-0.7.0.tar.gz#sha256=50a5396fae2db5a19446b3198ef0e86ee520846b881db47bdbf4eb9260eac723 (from http://mirrors.aliyun.com/pypi/simple/auto-gptq/) (requires-python:&gt;=3.8.0): Requested auto-gptq from http://mirrors.aliyun.com/pypi/packages/34/71/c3e73cf17681f6ff4754ef8f4cb8b67af3def230fc8711eac1250bbd78d5/auto_gptq-0.7.0.tar.gz#sha256=50a5396fae2db5a19446b3198ef0e86ee520846b881db47bdbf4eb9260eac723 has inconsistent version: expected '0.7.0', but metadata has '0.7.0+cu124'  Using cached http://mirrors.aliyun.com/pypi/packages/49/af/02b66e55dfd9aeb0ece923843043724ed7432ec0c649ea0f3b9fa1dd90c6/auto_gptq-0.6.0.tar.gz (120 kB)  Preparing metadata (setup.py) ... error  error: subprocess-exited-with-error    × python setup.py egg_info did not run successfully.  │ exit code: 1  ╰─&gt; [20 lines of output]      python: can't open file '/tmp/pip-install-g1v4mpt6/auto-gptq_c460ab0157b140969c62922c52a5ab77/./autogptq_extension/qigen/generate.py': [Errno 2] No such file or directory      Traceback (most recent call last):        File "/tmp/pip-install-g1v4mpt6/auto-gptq_c460ab0157b140969c62922c52a5ab77/setup.py", line 109, in &lt;module&gt;          subprocess.check_output(["python", "./autogptq_extension/qigen/generate.py", "--module", "--search", "--p", str(p)])        File "/root/miniconda3/lib/python3.12/subprocess.py", line 466, in check_output          return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^        File "/root/miniconda3/lib/python3.12/subprocess.py", line 571, in run          raise CalledProcessError(retcode, process.args,      subprocess.CalledProcessError: Command '['python', './autogptq_extension/qigen/generate.py', '--module', '--search', '--p', '112']' returned non-zero exit status 2.            During handling of the above exception, another exception occurred:            Traceback (most recent call last):        File "&lt;string&gt;", line 2, in &lt;module&gt;        File "&lt;pip-setuptools-caller&gt;", line 34, in &lt;module&gt;        File "/tmp/pip-install-g1v4mpt6/auto-gptq_c460ab0157b140969c62922c52a5ab77/setup.py", line 111, in &lt;module&gt;          raise Exception(f"Generating QiGen kernels failed with the error shown above.")      Exception: Generating QiGen kernels failed with the error shown above.      Generating qigen kernels...      [end of output]    note: This error originates from a subprocess, and is likely not a problem with pip.error: metadata-generation-failed× Encountered error while generating package metadata.╰─&gt; See above for output.note: This is an issue with the package mentioned above, not pip.hint: See above for details.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> vllm </tag>
            
            <tag> PyTorch </tag>
            
            <tag> LLaMA-Factory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【AI大模型应用学习笔记】Ollama调用本地模型</title>
      <link href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-ollama-diao-yong-ben-di-mo-xing/"/>
      <url>/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-ollama-diao-yong-ben-di-mo-xing/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux安装Ollama"><a href="#Linux安装Ollama" class="headerlink" title="Linux安装Ollama"></a>Linux安装Ollama</h1><h2 id="安装命令："><a href="#安装命令：" class="headerlink" title="安装命令："></a>安装命令：</h2><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>如果下载速度很慢，可以开启学术加速</p><h3 id="开启Auto-DL学术加速"><a href="#开启Auto-DL学术加速" class="headerlink" title="开启Auto-DL学术加速:"></a>开启Auto-DL学术加速:</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">source</span> /etc/network_turbo<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="取消Auto-DL学术加速"><a href="#取消Auto-DL学术加速" class="headerlink" title="取消Auto-DL学术加速:"></a>取消Auto-DL学术加速:</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">unset</span> http_proxy <span class="token operator">&amp;&amp;</span> <span class="token builtin class-name">unset</span> https_proxy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="Ollama安装模型："><a href="#Ollama安装模型：" class="headerlink" title="Ollama安装模型："></a>Ollama安装模型：</h2><h3 id="下载模型"><a href="#下载模型" class="headerlink" title="下载模型"></a>下载模型</h3><p>以 llama3.2:1b 模型为例，运行下面命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama run llama3.2:1b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>等待命令结束。</p><h3 id="使用模型"><a href="#使用模型" class="headerlink" title="使用模型"></a>使用模型</h3><p>ollama使用模型有两种方式，一种通过终端命令使用，一种通过python代码使用，两种方式都需要首先开启ollama服务</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama serve<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="1-通过终端使用"><a href="#1-通过终端使用" class="headerlink" title="1.通过终端使用"></a>1.通过终端使用</h4><p>终端运行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ollama run llama3.2:1b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>终端会进入对话模式，这时输入你要问的问题即可使用模型。</p><h4 id="2-通过python代码使用模型"><a href="#2-通过python代码使用模型" class="headerlink" title="2.通过python代码使用模型"></a>2.通过python代码使用模型</h4><p>安装 openai 包</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> opeani<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>python代码简单调用</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI<span class="token comment"># 通过openai接口调用模型，导入模型地址，和api_key</span>client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>base_url<span class="token operator">=</span><span class="token string">"http://localhost:11434/v1/"</span><span class="token punctuation">,</span>api_key<span class="token operator">=</span><span class="token string">"ollama"</span><span class="token punctuation">)</span><span class="token comment"># 提示词模板，并输入用户问题，指定使用模型名字</span>responce<span class="token operator">=</span>client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>    messages<span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span><span class="token string">"user"</span><span class="token punctuation">,</span><span class="token string">"content"</span><span class="token punctuation">:</span><span class="token string">"你好!你是谁？你是由谁创造的？"</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span>model<span class="token operator">=</span><span class="token string">"llama3.2:1B"</span><span class="token punctuation">)</span><span class="token comment"># 打印结果</span><span class="token keyword">print</span><span class="token punctuation">(</span>responce<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>base_url：启动<code>ollama serve</code>后会给出地址和端口，一般为<a href="http://localhost:11434/">http://localhost:11434</a></p><p>api_key：为ollama，因为使用的ollama框架</p><p>简单多轮对话框架调用：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#多轮对话</span><span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI<span class="token comment">#定义多轮对话方法</span><span class="token keyword">def</span> <span class="token function">run_chat_session</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment">#初始化客户端</span>    client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>base_url<span class="token operator">=</span><span class="token string">"http://localhost:11434/v1/"</span><span class="token punctuation">,</span>api_key<span class="token operator">=</span><span class="token string">"ollama"</span><span class="token punctuation">)</span>    <span class="token comment">#初始化对话历史</span>    chat_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment">#启动多轮对话</span>    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>        <span class="token comment">#获取用户输入</span>        user_input <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"用户："</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> user_input<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">==</span><span class="token string">"exit"</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"退出对话"</span><span class="token punctuation">)</span>            <span class="token keyword">break</span>        <span class="token comment">#更新对话历史（添加用户输入）</span>        chat_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span><span class="token string">"user"</span><span class="token punctuation">,</span><span class="token string">"content"</span><span class="token punctuation">:</span>user_input<span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token comment">#调用模型回答</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            chat_complition <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>messages<span class="token operator">=</span>chat_history<span class="token punctuation">,</span>model<span class="token operator">=</span><span class="token string">"llama3.2:1b"</span><span class="token punctuation">)</span>            <span class="token comment">#获取最新回答</span>            moedl_responce <span class="token operator">=</span> chat_complition<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AI："</span><span class="token punctuation">,</span>moedl_responce<span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">)</span>            <span class="token comment">#更新对话历史（添加AI模型的回复）</span>            chat_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span><span class="token string">"assistant"</span><span class="token punctuation">,</span><span class="token string">"content"</span><span class="token punctuation">:</span>moedl_responce<span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">}</span><span class="token punctuation">)</span>        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"发生错误："</span><span class="token punctuation">,</span>e<span class="token punctuation">)</span>            <span class="token keyword">break</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    run_chat_session<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ollama </tag>
            
            <tag> Python </tag>
            
            <tag> Linux </tag>
            
            <tag> LLaMa </tag>
            
            <tag> LoRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【AI大模型应用学习笔记】LLaMa3微调</title>
      <link href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-llama3-wei-diao/"/>
      <url>/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-llama3-wei-diao/</url>
      
        <content type="html"><![CDATA[<h1 id="LLaMa3微调"><a href="#LLaMa3微调" class="headerlink" title="LLaMa3微调"></a>LLaMa3微调</h1><h2 id="LoRA"><a href="#LoRA" class="headerlink" title="LoRA"></a>LoRA</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>LoRA（Low-Rank Adaptation）是一种用于大模型微调的技术，通过引入低秩矩阵来减少微调时的参数量。在预训练的模型中，LoRA通过添加两个小矩阵B和A来近似原始的大矩阵ΔW，从而减少需要更新的参数数量。具体来说，LoRA通过将全参微调的增量 参数矩阵ΔW表示为两个参数量更小的矩阵B和A的低秩近似来实现：</p><p>[ W_0 + \Delta W = W_0 + BA ] </p><p>其中，B和A的秩远小于原始矩阵的秩，从而大大减少了需要更新的参数数量。</p><h3 id="LoRA思想"><a href="#LoRA思想" class="headerlink" title="LoRA思想"></a>LoRA思想</h3><p>预训练模型中存在一个极小的内在维度，这个内在维度是发挥核心作用的地方。在继续训练的过程中，权重的更新依然也有如此特点，即也存在一个内在维度(内在秩)</p><p>权重更新：W=W+^W</p><p>因此，可以通过矩阵分解的方式，将原本要更新的大的矩阵变为两个小的矩阵</p><p>权重更新：W=W+^W=W+BA</p><p>具体做法，即在矩阵计算中增加一个旁系分支，旁系分支由两个 低秩矩阵A和B组成</p><h3 id="LoRA原理"><a href="#LoRA原理" class="headerlink" title="LoRA原理"></a>LoRA原理</h3><p>训练时，输入分别与原始权重和两个低秩矩阵进行计算，共同得 到最终结果，优化则仅优化A和B。</p><p>训练完成后，可以将两个低秩矩阵与原始模型中的权重进行合并， 合并后的模型与原始模型无异</p><h2 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h2><p>可以通过Hugging Face平台和国内魔塔社区进行下载，下面以<code>Llama-3.2-1B-Instruct</code>模型为示例：</p><p>魔塔社区下载模型，</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 模型下载</span><span class="token keyword">from</span> modelscope <span class="token keyword">import</span> snapshot_downloadmodel_dir <span class="token operator">=</span> snapshot_download<span class="token punctuation">(</span><span class="token string">'LLM-Research/Llama-3.2-1B-Instruct'</span><span class="token punctuation">,</span>cache_dir<span class="token operator">=</span><span class="token string">"/teacher_data/llm/"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="LLaMA-Factory"><a href="#LLaMA-Factory" class="headerlink" title="LLaMA-Factory"></a>LLaMA-Factory</h2><p>1.安装</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/hiyouga/LLaMA-Factory.git<span class="token builtin class-name">cd</span> LLaMA-Factorypip <span class="token function">install</span> <span class="token parameter variable">-e</span> <span class="token builtin class-name">.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><div style="background-color: green; padding: 10px;">  这里执行安装包命令前，先执行 pip install auto-gptq 以及 pip install -e .["vllm"] 安装量化框架</div><p>2.准备训练数据</p><p>例：</p><p>训练数据：</p><ul><li>fintech.json</li><li>identity.json</li></ul><p>将训练数据放在目录 LLaMA-Factory/data/fintech.json </p><p>并且修改数据注册文件：LLaMA-Factory/data/dataset_info.json ,内容如下：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token property">"fintech"</span><span class="token operator">:</span> <span class="token punctuation">{</span><span class="token property">"file_name"</span><span class="token operator">:</span> <span class="token string">"fintech.json"</span><span class="token punctuation">,</span><span class="token property">"columns"</span><span class="token operator">:</span> <span class="token punctuation">{</span><span class="token property">"prompt"</span><span class="token operator">:</span> <span class="token string">"instruction"</span><span class="token punctuation">,</span><span class="token property">"query"</span><span class="token operator">:</span> <span class="token string">"input"</span><span class="token punctuation">,</span><span class="token property">"response"</span><span class="token operator">:</span> <span class="token string">"output"</span><span class="token punctuation">,</span><span class="token property">"history"</span><span class="token operator">:</span> <span class="token string">"history"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="通过界面进行训练"><a href="#通过界面进行训练" class="headerlink" title="通过界面进行训练"></a>通过界面进行训练</h3><p>启动Web UI</p><pre class="line-numbers language-none"><code class="language-none">cd LLaMA-Factoryllamafactory-cli webui<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>模型微调</p><ul><li>使用 Web UI 训练</li><li>使用命令行执行</li></ul><p>启动webui后界面如下：</p><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce81.png" alt="LLaMa3_00"></p><h3 id="设置训练模型路径"><a href="#设置训练模型路径" class="headerlink" title="设置训练模型路径"></a>设置训练模型路径</h3><p>将界面修改为中文，设置需要训练的模型名字，填入模型路径</p><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce7c.png" alt="LLaMa3_01"></p><p>其他参数：</p><ul><li>微调方法选择 lora</li><li>检查点路径：训练模型保存路径，训练好的模型权重路径，一般默认</li><li>最下面一排参数先默认</li></ul><h3 id="配置训练参数"><a href="#配置训练参数" class="headerlink" title="配置训练参数"></a>配置训练参数</h3><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce80.png" alt="LLaMa3_02"></p><p>参数配置：</p><ul><li>训练阶段：一般默认supervised Fine-Tuning</li><li>数据路径：我们要训练的数据集路径</li><li>数据集：我们要训练的数据集，可以多选</li><li>学习率：一般默认</li><li>训练轮数：一般设置大一点，因为可以随时中止</li><li>最大梯度范畴：一般默认</li><li>最大样本数：默认，可以根据数据集的大小来定</li><li>计算类型：bf16效果最好，但要看设备支不支持</li><li>截断长度：一般根据数据集来定</li><li>批处理大小：根据显卡配置来看</li><li>梯度积累：默认</li><li>验证集比例：验证集所占样本的大小</li><li>学习率调节器：默认</li></ul><h3 id="LoRA参数设置"><a href="#LoRA参数设置" class="headerlink" title="LoRA参数设置"></a>LoRA参数设置</h3><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce7e.png" alt="LLaMa3_04"></p><p>参数：一般默认</p><p>配置好所有参数后，准备开始训练</p><h3 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h3><p>将训练好的模型权重进行测试测试</p><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce7d.png" alt="LLaMa3_05"></p><p>点击加载模型，会加载模型对话框界面</p><p><img src="https://pic1.imgdb.cn/item/680af5b258cb8da5c8c9ce7f.png" alt="LLaMa3_06"></p><p>和模型对话看给出的回答准确度高不高</p><h3 id="合并LoAR和原模型"><a href="#合并LoAR和原模型" class="headerlink" title="合并LoAR和原模型"></a>合并LoAR和原模型</h3><p>选择效果最好的训练权重和原模型，点击Export模式，设置好参数后就准备开始导出。</p><p><img src="https://pic1.imgdb.cn/item/680af5bd58cb8da5c8c9ce88.png" alt="LLaMa3_07"></p><h3 id="评估模型"><a href="#评估模型" class="headerlink" title="评估模型"></a>评估模型</h3><p>准备训练用的数据集，配置 <code>dataset_info</code> ，参数配置一般和训练时数据保持一致</p><p>评估模型前还需要装几个包</p><pre class="line-numbers language-none"><code class="language-none">pip install jiebapip install nltkpip install rouge_chinese<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><img src="https://pic1.imgdb.cn/item/680af5be58cb8da5c8c9ce8a.png" alt="LLaMa3_08"></p><h3 id="通过配置文件开始训练"><a href="#通过配置文件开始训练" class="headerlink" title="通过配置文件开始训练"></a>通过配置文件开始训练</h3><p>配置文件位于：[cust/train_llama3_lora_sft.yaml] </p><p>构建 cust/train_llama3_lora_sft.yaml</p><pre class="line-numbers language-none"><code class="language-none">cutoff_len: 1024 dataset: fintech,identity dataset_dir: data do_train: true finetuning_type: lora flash_attn: auto fp16: true gradient_accumulation_steps: 8 learning_rate: 0.0002 logging_steps: 5 lora_alpha: 16 lora_dropout: 0 lora_rank: 8 lora_target: q_proj,v_proj lr_scheduler_type: cosine max_grad_norm: 1.0 max_samples: 1000 model_name_or_path: /root/autodl-tmp/models/Llama3-8B-Chinese-Chat num_train_epochs: 10.0 optim: adamw_torch output_dir: saves/LLaMA3-8B-Chinese-Chat/lora/train_2024-05-25-20-27-47 packing: false per_device_train_batch_size: 2 plot_loss: true preprocessing_num_workers: 16 report_to: none save_steps: 100 stage: sft template: llama3 use_unsloth: true warmup_steps: 0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>命令行执行：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">llamafactory-cli train cust/train_llama3_lora_sft.yaml<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="问题记录："><a href="#问题记录：" class="headerlink" title="问题记录："></a>问题记录：</h3><p>我在实际安装过程中由于懒得租服务器和安装Linux双系统，所以就直接使用Windows11系统来安装配置LLaMA-Factory，按照上面步骤配置好后，成功启动了webui界面，但是在配置好训练参数后，点击开始训练，结果报错：未找到cuda环境，随后程序报错中断服务了</p><p><img src="https://pic1.imgdb.cn/item/680af5be58cb8da5c8c9ce89.png" alt="LLaMa3_09"></p><p>原因推测是没有在使用的python环境中安装 CUDA + pytorch 环境导致的，或者安装的环境版本不对，安装 CUDA + pytorch 包</p><pre class="line-numbers language-none"><code class="language-none">conda install pytorch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 pytorch-cuda=12.1 -c pytorch -c nvidia<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>后续没有解决，准备还是在服务器上进行测试。</p><h2 id="文本生成模型评估方法"><a href="#文本生成模型评估方法" class="headerlink" title="文本生成模型评估方法"></a>文本生成模型评估方法</h2><p>OpenCompass采取客观评测与主观评测相结合的方法。针对具有确定性答案的能力维度和场景，通过构造丰富完善的评测集，对模型能力进行综合评价。针对体现模型能力的开放式或半开放式的问题、模型安全问题等，采用主客观相结合的评测方式。</p><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ollama </tag>
            
            <tag> Python </tag>
            
            <tag> Linux </tag>
            
            <tag> LLaMa </tag>
            
            <tag> LoRA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>WIN11+WSL2+Ubuntu22.04+CUDA+ANACONDA3+Pytorch安装总结</title>
      <link href="/win11-wsl2-ubuntu22-04-cuda-anaconda3-pytorch-an-zhuang-zong-jie/"/>
      <url>/win11-wsl2-ubuntu22-04-cuda-anaconda3-pytorch-an-zhuang-zong-jie/</url>
      
        <content type="html"><![CDATA[<h2 id="一、第一步是打开win11的linux子系统开关和虚拟程序开关"><a href="#一、第一步是打开win11的linux子系统开关和虚拟程序开关" class="headerlink" title="一、第一步是打开win11的linux子系统开关和虚拟程序开关"></a>一、第一步是打开win11的linux子系统开关和虚拟程序开关</h2><p> 1.启动WINDOWS功能<br>首先在控制面板程序中找到：启动或关闭WINDOWS功能<br><img src="https://pic1.imgdb.cn/item/681f430058cb8da5c8eb7485.png" alt="启动WINDOWS功能"></p><p>2.然后打开标红的两项，打开后要求重启，重启即可<br><img src="https://pic1.imgdb.cn/item/681f430058cb8da5c8eb7486.png" alt="打开Linux Windows子系统"></p><h2 id="二、安装WSL"><a href="#二、安装WSL" class="headerlink" title="二、安装WSL"></a>二、安装WSL</h2><h3 id="2-1-安装WSL子系统"><a href="#2-1-安装WSL子系统" class="headerlink" title="2.1 安装WSL子系统"></a>2.1 安装WSL子系统</h3><p>在windows store 找到 Windows Subsystem for Linux, 并安装<br><img src="https://pic1.imgdb.cn/item/681f43e758cb8da5c8eb74cc.png" alt="Windows Subsystem for Linux"></p><h3 id="2-2-修改wsl版本"><a href="#2-2-修改wsl版本" class="headerlink" title="2.2 修改wsl版本"></a>2.2 修改wsl版本</h3><p>在windows power shell下输入如下代码，修改wsl为2版本（只有1和2，2 BUG少，适配性高）<br>代码如下：</p><pre class="line-numbers language-c" data-language="c"><code class="language-c"># 修改WSL默认版本为<span class="token number">2</span>wsl <span class="token operator">--</span>set<span class="token operator">-</span><span class="token keyword">default</span><span class="token operator">-</span>version <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="2-3-安装ubuntu-我这里是22-04"><a href="#2-3-安装ubuntu-我这里是22-04" class="headerlink" title="2.3 安装ubuntu(我这里是22.04)"></a>2.3 安装ubuntu(我这里是22.04)</h3><p><img src="https://pic1.imgdb.cn/item/681f43e758cb8da5c8eb74cb.png" alt="安装ubuntu"></p><p>安装好ubuntu后打开ubuntu，等待安装，安装完成后输入一个新建的账户名和密码，然后直接关闭即可</p><h3 id="2-3-可选-，移动WSL安装位置"><a href="#2-3-可选-，移动WSL安装位置" class="headerlink" title="2.3 (可选)，移动WSL安装位置"></a>2.3 (可选)，移动WSL安装位置</h3><p>首先： 查看wsl下的Linux是否为关闭状态，当wsl为Stopped才能进行下一步。<br>在powershell 下</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 先查看WSL状态，是否是stoped</span>wsl <span class="token parameter variable">-l</span> <span class="token parameter variable">-v</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果状态不是stop执行下面操作，如果是stop跳过此步</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 关闭子系统</span>wsl <span class="token parameter variable">--shutdown</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>状态为stop,则显示界面为：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">C:<span class="token punctuation">\</span>Users<span class="token punctuation">\</span>xxx<span class="token punctuation">\</span>Desktop<span class="token operator">&gt;</span>wsl <span class="token parameter variable">-l</span> <span class="token parameter variable">-v</span>  NAME      STATE           VERSION* Ubuntu-22.04    Stopped         <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>开始移动，先将ubuntu以压缩包形式导出</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">wsl <span class="token parameter variable">--export</span> Ubuntu-22.04 E:<span class="token punctuation">\</span>wsl2_ubuntu22<span class="token punctuation">\</span>Ubuntu-22.04.tar<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注销原有子系统</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">wsl <span class="token parameter variable">--unregister</span> Ubuntu-22.04<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>将打包的系统导出</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">wsl <span class="token parameter variable">--import</span> Ubuntu-22.04 E:<span class="token punctuation">\</span>wsl2_ubuntu22<span class="token punctuation">\</span> E:<span class="token punctuation">\</span>wsl2_ubuntu22<span class="token punctuation">\</span>Ubuntu-22.04.tar <span class="token parameter variable">--version</span> <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>导出后，ubuntu登录会默认首选root用户，可以修改为登录首选为子用户</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 此命令只适用于 ubuntu22.04版本  其他版本需要修改exe前面的字符串</span>ubuntu2204.exe config --default-user ismoyu<span class="token punctuation">(</span>这表示你的子用户名<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="2-4-更新Ubuntu软件源"><a href="#2-4-更新Ubuntu软件源" class="headerlink" title="2.4 更新Ubuntu软件源"></a>2.4 更新Ubuntu软件源</h3><p>安装前先打开ubuntu界面，修改一下下载镜像源，加快下载速度</p><p>备份原先官方源：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">cp</span> /etc/apt/sources.list /etc/apt/sources.list.backup<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>vim 打开<code>/etc/apt/sources.list</code>文件：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">vim</span> /etc/apt/sources.list<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>打开后添加以下内容：（阿里云源）</p><pre class="line-numbers language-none"><code class="language-none">deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后再执行更新源命令 apt update 即可：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> update <span class="token operator">&amp;&amp;</span> <span class="token function">sudo</span> <span class="token function">apt</span> upgrade<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="2-5-Windows和WSL2文件互换"><a href="#2-5-Windows和WSL2文件互换" class="headerlink" title="2.5 Windows和WSL2文件互换"></a>2.5 Windows和WSL2文件互换</h3><p>你可以直接在 Windows 文件资源管理器中打开 WSL&nbsp;<a href="https://so.csdn.net/so/search?q=%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F&amp;spm=1001.2101.3001.7020">文件系统</a>。WSL 的文件系统通常位于&nbsp;<code>\\wsl$\&lt;DistroName&gt;\</code>&nbsp;路径下，其中&nbsp;<code>&lt;DistroName&gt;</code>&nbsp;是你的 WSL 发行版的名称。</p><p>例如，如果你的 WSL 发行版是&nbsp;Ubuntu，你可以通过以下路径访问 WSL 文件系统：</p><pre class="line-numbers language-none"><code class="language-none">\\wsl$\Ubuntu\<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="三、安装软件环境"><a href="#三、安装软件环境" class="headerlink" title="三、安装软件环境"></a>三、安装软件环境</h2><h3 id="3-1-安装CUDA"><a href="#3-1-安装CUDA" class="headerlink" title="3.1 安装CUDA"></a>3.1 安装CUDA</h3><p>打开下边链接<br><a href="https://developer.nvidia.com/cuda-12-1-0-download-archive?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=WSL-Ubuntu&amp;target_version=2.0&amp;target_type=deb_local">CUDA on Windows Subsystem for Linux (WSL)</a><br>我们安装CUDA12.1版本，进去显示最新的（cuda12.2这太高了torch都没支持呢），找到自己需要的版本<br><img src="https://pic1.imgdb.cn/item/681f43e758cb8da5c8eb74ca.png" alt="安装CUDA12.1"><br>直接按照给定的命令输入到<a href="https://so.csdn.net/so/search?q=ubuntu%E5%91%BD%E4%BB%A4&amp;spm=1001.2101.3001.7020">ubuntu命令</a>行中<br><img src="https://pic1.imgdb.cn/item/681f43e758cb8da5c8eb74cd.png" alt="安装CUDA12.1"><br>直接复制上述命令输入即可:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">wget</span> https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin<span class="token function">sudo</span> <span class="token function">mv</span> cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600<span class="token function">wget</span> https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda-repo-wsl-ubuntu-12-1-local_12.1.0-1_amd64.deb<span class="token function">sudo</span> dpkg <span class="token parameter variable">-i</span> cuda-repo-wsl-ubuntu-12-1-local_12.1.0-1_amd64.deb<span class="token function">sudo</span> <span class="token function">cp</span> /var/cuda-repo-wsl-ubuntu-12-1-local/cuda-*-keyring.gpg /usr/share/keyrings/<span class="token function">sudo</span> <span class="token function">apt-get</span> update<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token parameter variable">-y</span> <span class="token function">install</span> cuda<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>全部执行完成后，打开文件：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">vim</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>末尾添加以下内容</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># config cuda</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_HOME</span><span class="token operator">=</span>/usr/local/cuda-12.1<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$CUDA_HOME</span>/bin       <span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$LD_LIBRARY_PATH</span><span class="token builtin class-name">:</span><span class="token variable">$CUDA_HOME</span>/lib64<span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$LD_LIBRARY_PATH</span><span class="token builtin class-name">:</span><span class="token variable">$CUDA_HOME</span>/extras/CUPTI/lib64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>完成后刷新一下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">source</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后就能nvcc -V 就能查看CUDA版本了</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">nvcc <span class="token parameter variable">-V</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-1-安装anaconda3"><a href="#3-1-安装anaconda3" class="headerlink" title="3.1 安装anaconda3"></a>3.1 安装anaconda3</h3><h4 id="1-安装软件依赖包："><a href="#1-安装软件依赖包：" class="headerlink" title="1. 安装软件依赖包："></a>1. 安装软件依赖包：</h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token parameter variable">-y</span> <span class="token function">install</span> libgl1-mesa-glx libegl1-mesa libxrandr2 libxrandr2 libxss1 libxcursor1 libxcomposite1 libasound2 libxi6 libxtst6<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h4 id="2-下载Anaconda安装包"><a href="#2-下载Anaconda安装包" class="headerlink" title="2. 下载Anaconda安装包"></a>2. 下载Anaconda安装包</h4><p>安装Anaconda的最佳方法是下载最新的Anaconda安装程序bash脚本, 然后运行它。</p><p>在<a href="https://www.anaconda.com/products/distribution#Downloads">Anaconda下载页面</a>上找到适用于Python 3的最新版本的Anacoda。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">wget</span> https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下载完成运行脚本:</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">bash</span> Anaconda3-2024.10-1-Linux-x86_64.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装过程基本上一路回车就可以了，或者yes即可。</p><p>加入后重载环境变量：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">source</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们在安装完成后，以后每次打开终端都会自动进入conda的bash环境，如果不需要可以运行下面命令来禁用：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda config <span class="token parameter variable">--set</span> auto_activate_base <span class="token boolean">false</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="3-2-安装PyTorch"><a href="#3-2-安装PyTorch" class="headerlink" title="3.2 安装PyTorch"></a>3.2 安装PyTorch</h3><p>最好我们用conda新建一个虚拟环境来安装：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda create <span class="token parameter variable">-n</span> llm-learn <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.10</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>切换到环境：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda activate llm-learn<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>为了不污染bash环境，我们将我们创建的环境推荐到系统环境中，打开系统环境：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">vim</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>安装PyTorch，因为我们CODA安装的是12.1版本的，所以PyTorch我们安装2.3.0版本的</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># CUDA 12.1</span>conda <span class="token function">install</span> <span class="token assign-left variable">pytorch</span><span class="token operator">==</span><span class="token number">2.3</span>.0 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.18</span>.0 <span class="token assign-left variable">torchaudio</span><span class="token operator">==</span><span class="token number">2.3</span>.0 pytorch-cuda<span class="token operator">=</span><span class="token number">12.1</span> <span class="token parameter variable">-c</span> pytorch <span class="token parameter variable">-c</span> nvidia<span class="token comment"># 安装PyTorch 2.3.0 + CUDA 12.1</span>pip <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">2.3</span>.0+cu121 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.18</span>.0+cu121 --extra-index-url https://download.pytorch.org/whl/cu121<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> 实用教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【AI大模型应用学习笔记】学习LangChain大模型能力封装工具框架</title>
      <link href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-xue-xi-langchain-da-mo-xing-feng-zhuang-gong-ju-kuang-jia/"/>
      <url>/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-xue-xi-langchain-da-mo-xing-feng-zhuang-gong-ju-kuang-jia/</url>
      
        <content type="html"><![CDATA[<h1 id="LangChain"><a href="#LangChain" class="headerlink" title="LangChain"></a>LangChain</h1><p>💡 这篇文章会带给你</p><ol><li>如何使用 LangChain：一套在大模型能力上封装的工具框架</li><li>如何用几行代码实现一个复杂的 AI 应用</li><li>面向大模型的流程开发的过程抽象</li></ol><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>官网：<a href="https://www.langchain.com/">https://www.langchain.com/</a></p><ul><li>LangChain 也是一套面向大模型的开发框架（SDK）</li><li>LangChain 是 AGI 时代软件工程的一个探索和原型</li><li>学习 LangChain 要关注接口变更</li></ul><h2 id="LangChain-的核心组件"><a href="#LangChain-的核心组件" class="headerlink" title="LangChain 的核心组件"></a>LangChain 的核心组件</h2><ol><li>模型 I/O 封装<ul><li>LLMs：大语言模型</li><li>Chat Models：一般基于 LLMs，但按对话结构重新封装</li><li>PromptTemple：提示词模板</li><li>OutputParser：解析输出</li></ul></li><li>数据连接封装<ul><li>Document Loaders：各种格式文件的加载器</li><li>Document Transformers：对文档的常用操作，如：split, filter, translate, extract metadata, etc</li><li>Text Embedding Models：文本向量化表示，用于检索等操作（啥意思？别急，后面详细讲）</li><li>Verctorstores: （面向检索的）向量的存储</li><li>Retrievers: 向量的检索</li></ul></li><li>对话历史管理<ul><li>对话历史的存储、加载与剪裁</li></ul></li><li>架构封装<ul><li>Chain：实现一个功能或者一系列顺序功能组合</li><li>Agent：根据用户输入，自动规划执行步骤，自动选择每步需要的工具，最终完成用户指定的功能<ul><li>Tools：调用外部功能的函数，例如：调 google 搜索、文件 I/O、Linux Shell 等等</li><li>Toolkits：操作某软件的一组工具集，例如：操作 DB、操作 Gmail 等等</li></ul></li></ul></li><li>Callbacks</li></ol><h3 id="文档（以-Python-版为例）"><a href="#文档（以-Python-版为例）" class="headerlink" title="文档（以 Python 版为例）"></a>文档（以 Python 版为例）</h3><ul><li>功能模块：<a href="https://python.langchain.com/docs/get_started/introduction">https://python.langchain.com/docs/get_started/introduction</a></li><li>API 文档：<a href="https://api.python.langchain.com/en/latest/langchain_api_reference.html">https://api.python.langchain.com/en/latest/langchain_api_reference.html</a></li><li>三方组件集成：<a href="https://python.langchain.com/docs/integrations/platforms/">https://python.langchain.com/docs/integrations/platforms/</a></li><li>官方应用案例：<a href="https://python.langchain.com/docs/use_cases">https://python.langchain.com/docs/use_cases</a></li><li>调试部署等指导：<a href="https://python.langchain.com/docs/guides/debugging">https://python.langchain.com/docs/guides/debugging</a></li></ul><blockquote><p><b>划重点：</b> 创建一个新的 conda 环境，<b>langchain-learn</b>，再开始下面的学习！</p></blockquote><pre class="line-numbers language-powershell" data-language="powershell"><code class="language-powershell">conda create <span class="token operator">-</span>n langchain-learn python=3<span class="token punctuation">.</span>10<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="一、-模型-I-O-封装"><a href="#一、-模型-I-O-封装" class="headerlink" title="一、 模型 I/O 封装"></a>一、 模型 I/O 封装</h2><p>把不同的模型，统一装成一个接口，方便更换模型而不用重构代码。</p><h3 id="1-1-模型-API-LLM-vs-ChatModel"><a href="#1-1-模型-API-LLM-vs-ChatModel" class="headerlink" title="1.1 模型 API: LLM vs. ChatModel"></a>1.1 模型 API: LLM vs. ChatModel</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> langchainpip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> langchain-openaipip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> langchain-community<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="1-1-1-OpenAI-模型封装"><a href="#1-1-1-OpenAI-模型封装" class="headerlink" title="1.1.1 OpenAI 模型封装"></a>1.1.1 OpenAI 模型封装</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAIllm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o-mini"</span><span class="token punctuation">)</span>  <span class="token comment"># 默认是gpt-3.5-turbo</span>response <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"你是谁"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-1-2-多轮对话-Session-封装"><a href="#1-1-2-多轮对话-Session-封装" class="headerlink" title="1.1.2 多轮对话 Session 封装"></a>1.1.2 多轮对话 Session 封装</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> <span class="token punctuation">(</span>    AIMessage<span class="token punctuation">,</span>      <span class="token comment"># 等价于OpenAI接口中的Assistant role</span>    HumanMessage<span class="token punctuation">,</span>   <span class="token comment"># 等价于OpenAI接口中的User role</span>    SystemMessage<span class="token punctuation">,</span>  <span class="token comment"># 等价于OpenAI接口中的System role</span><span class="token punctuation">)</span>messages <span class="token operator">=</span> <span class="token punctuation">[</span>    SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"你是一个有用的编程学习智能助手"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"我是一名正在自学编程的学生，我叫墨智Logic"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    AIMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"欢迎，墨智Logic！我很高兴能帮助你学习编程。"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"我是谁？"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span>ret <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>ret<span class="token punctuation">.</span>content<span class="token punctuation">)</span>  <span class="token comment"># 返回的内容是一个字符串</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><b>划重点：</b>通过模型封装，实现不同模型的统一接口调用</p></blockquote><h3 id="1-2-模型的输入与输出"><a href="#1-2-模型的输入与输出" class="headerlink" title="1.2 模型的输入与输出"></a>1.2 模型的输入与输出</h3><h4 id="1-2-1-Prompt-模板封装"><a href="#1-2-1-Prompt-模板封装" class="headerlink" title="1.2.1 Prompt 模板封装"></a>1.2.1 Prompt 模板封装</h4><ol><li>PromptTemplate 可以在模板中自定义变量</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplatetemplate <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token string">"给我讲一个关于{topic}的笑话"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"===Template==="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>template<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"===Prompt==="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>topic<span class="token operator">=</span><span class="token string">"吉尼太美"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 直接使用模板生成</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">Prompt<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAIllm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o-mini"</span><span class="token punctuation">)</span>  <span class="token comment"># 默认是gpt-3.5-turbo</span>response <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>topic<span class="token operator">=</span><span class="token string">"吉尼太美"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 打印输出</span><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>  <span class="token comment"># 返回的内容是一个字符串</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="2"><li>ChatPromptTemplate 用模板表示的对话上下文</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> <span class="token punctuation">(</span>    ChatPromptTemplate<span class="token punctuation">,</span>    HumanMessagePromptTemplate<span class="token punctuation">,</span>    SystemMessagePromptTemplate<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAItemplate <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span>    <span class="token punctuation">[</span>        SystemMessagePromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token string">"你是一个{product}的智能助手，你的名字叫{name}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        HumanMessagePromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token string">"{query}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span>llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o-mini"</span><span class="token punctuation">)</span>  <span class="token comment"># 默认是gpt-3.5-turbo</span>prompt <span class="token operator">=</span> template<span class="token punctuation">.</span>format_messages<span class="token punctuation">(</span>    product<span class="token operator">=</span><span class="token string">"编程学习"</span><span class="token punctuation">,</span>    name<span class="token operator">=</span><span class="token string">"墨智Logic"</span><span class="token punctuation">,</span>    query<span class="token operator">=</span><span class="token string">"你是谁？"</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>  <span class="token comment"># 打印Prompt</span>ret <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>  <span class="token comment"># 调用LLM</span><span class="token keyword">print</span><span class="token punctuation">(</span>ret<span class="token punctuation">.</span>content<span class="token punctuation">)</span>  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol start="3"><li>MessagesPlaceholder 把多轮对话变成模板</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> <span class="token punctuation">(</span>    ChatPromptTemplate<span class="token punctuation">,</span>    HumanMessagePromptTemplate<span class="token punctuation">,</span>    MessagesPlaceholder<span class="token punctuation">,</span><span class="token punctuation">)</span>human_prompt <span class="token operator">=</span> <span class="token string">"Translate your answer to {language}."</span>human_message_template <span class="token operator">=</span> HumanMessagePromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>human_prompt<span class="token punctuation">)</span>chat_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span>    <span class="token comment"># variable_name 是 message placeholder 在模板中的变量名</span>    <span class="token comment"># 用于在赋值时使用</span>    <span class="token punctuation">[</span>MessagesPlaceholder<span class="token punctuation">(</span><span class="token string">"history"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> human_message_template<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> AIMessage<span class="token punctuation">,</span> HumanMessagehuman_message <span class="token operator">=</span> HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Who is Elon Musk?"</span><span class="token punctuation">)</span>ai_message <span class="token operator">=</span> AIMessage<span class="token punctuation">(</span>    content<span class="token operator">=</span><span class="token string">"Elon Musk is a billionaire entrepreneur, inventor, and industrial designer."</span><span class="token punctuation">)</span>messages <span class="token operator">=</span> chat_prompt<span class="token punctuation">.</span>format_prompt<span class="token punctuation">(</span>    <span class="token comment"># 对 "history" 变量赋值 和 "language" 变量赋值</span>    history<span class="token operator">=</span><span class="token punctuation">[</span>human_message<span class="token punctuation">,</span> ai_message<span class="token punctuation">]</span><span class="token punctuation">,</span> language<span class="token operator">=</span><span class="token string">"中文"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>messages<span class="token punctuation">.</span>to_messages<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 打印消息列表</span>result <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>content<span class="token punctuation">)</span>  <span class="token comment"># 打印结果</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><b>划重点：</b>把Prompt模板看作带有参数的函数</p></blockquote><h4 id="1-2-2-从文件加载-Prompt-模板"><a href="#1-2-2-从文件加载-Prompt-模板" class="headerlink" title="1.2.2 从文件加载 Prompt 模板"></a>1.2.2 从文件加载 Prompt 模板</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplatetemplate <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span>from_file<span class="token punctuation">(</span><span class="token string">"example_prompt_template.txt"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"===Template==="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>template<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"===Prompt==="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>topic<span class="token operator">=</span><span class="token string">'黑色幽默'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-3-结构化输出"><a href="#1-3-结构化输出" class="headerlink" title="1.3 结构化输出"></a>1.3 结构化输出</h3><h4 id="1-3-1-直接输出-Pydantic-对象"><a href="#1-3-1-直接输出-Pydantic-对象" class="headerlink" title="1.3.1 直接输出 Pydantic 对象"></a>1.3.1 直接输出 Pydantic 对象</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> pydantic <span class="token keyword">import</span> BaseModel<span class="token punctuation">,</span> Field<span class="token comment"># 定义你的输出对象</span><span class="token keyword">class</span> <span class="token class-name">Date</span><span class="token punctuation">(</span>BaseModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    year<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"Year"</span><span class="token punctuation">)</span>    month<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"Month"</span><span class="token punctuation">)</span>    day<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"Day"</span><span class="token punctuation">)</span>    era<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"BC or AD"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate<span class="token punctuation">,</span> ChatPromptTemplate<span class="token punctuation">,</span> HumanMessagePromptTemplate<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> PydanticOutputParsermodel_name <span class="token operator">=</span> <span class="token string">'gpt-4o-mini'</span>temperature <span class="token operator">=</span> <span class="token number">0</span>llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model_name<span class="token operator">=</span>model_name<span class="token punctuation">,</span> temperature<span class="token operator">=</span>temperature<span class="token punctuation">)</span><span class="token comment"># 定义结构化输出的模型</span>structured_llm <span class="token operator">=</span> llm<span class="token punctuation">.</span>with_structured_output<span class="token punctuation">(</span>Date<span class="token punctuation">)</span>template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""提取用户输入中的日期。用户输入:{query}"""</span>prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>    template<span class="token operator">=</span>template<span class="token punctuation">,</span><span class="token punctuation">)</span>query <span class="token operator">=</span> <span class="token string">"2025年四月16日天气阴..."</span>input_prompt <span class="token operator">=</span> prompt<span class="token punctuation">.</span>format_prompt<span class="token punctuation">(</span>query<span class="token operator">=</span>query<span class="token punctuation">)</span>structured_llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>input_prompt<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-3-2-输出指定格式的-JSON"><a href="#1-3-2-输出指定格式的-JSON" class="headerlink" title="1.3.2 输出指定格式的 JSON"></a>1.3.2 输出指定格式的 JSON</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">json_schema <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">"title"</span><span class="token punctuation">:</span> <span class="token string">"Date"</span><span class="token punctuation">,</span>    <span class="token string">"description"</span><span class="token punctuation">:</span> <span class="token string">"Formated date expression"</span><span class="token punctuation">,</span>    <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"object"</span><span class="token punctuation">,</span>    <span class="token string">"properties"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>        <span class="token string">"year"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>            <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"integer"</span><span class="token punctuation">,</span>            <span class="token string">"description"</span><span class="token punctuation">:</span> <span class="token string">"year, YYYY"</span><span class="token punctuation">,</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token string">"month"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>            <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"integer"</span><span class="token punctuation">,</span>            <span class="token string">"description"</span><span class="token punctuation">:</span> <span class="token string">"month, MM"</span><span class="token punctuation">,</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token string">"day"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>            <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"integer"</span><span class="token punctuation">,</span>            <span class="token string">"description"</span><span class="token punctuation">:</span> <span class="token string">"day, DD"</span><span class="token punctuation">,</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>        <span class="token string">"era"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>            <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"string"</span><span class="token punctuation">,</span>            <span class="token string">"description"</span><span class="token punctuation">:</span> <span class="token string">"BC or AD"</span><span class="token punctuation">,</span>        <span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">}</span>structured_llm <span class="token operator">=</span> llm<span class="token punctuation">.</span>with_structured_output<span class="token punctuation">(</span>json_schema<span class="token punctuation">)</span>structured_llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>input_prompt<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="1-3-3-使用-JsonOutputParser"><a href="#1-3-3-使用-JsonOutputParser" class="headerlink" title="1.3.3 使用 JsonOutputParser"></a>1.3.3 使用 JsonOutputParser</h4><p><a href="https://python.langchain.com/v0.2/docs/concepts/#output-parsers"><code>OutputParser</code></a> 可以按指定格式解析模型的输出</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> JsonOutputParserparser <span class="token operator">=</span> JsonOutputParser<span class="token punctuation">(</span>pydantic_object<span class="token operator">=</span>Date<span class="token punctuation">)</span>prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>    template<span class="token operator">=</span><span class="token string">"提取用户输入中的日期。\n用户输入:{query}\n{format_instructions}"</span><span class="token punctuation">,</span>    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"query"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    partial_variables<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"format_instructions"</span><span class="token punctuation">:</span> parser<span class="token punctuation">.</span>get_format_instructions<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">)</span>input_prompt <span class="token operator">=</span> prompt<span class="token punctuation">.</span>format_prompt<span class="token punctuation">(</span>query<span class="token operator">=</span>query<span class="token punctuation">)</span>output <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>input_prompt<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"原始输出:\n"</span><span class="token operator">+</span>output<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n解析后:"</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>也可以用 <code>PydanticOutputParser</code></p><blockquote><p><b>这里在Pycharm中需要用参数接收parser.invoke(output)的值，然后用print打印出来才能在终端显示结果内容，否则是空白。后续的地方都类似</b></p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> PydanticOutputParserparser <span class="token operator">=</span> PydanticOutputParser<span class="token punctuation">(</span>pydantic_object<span class="token operator">=</span>Date<span class="token punctuation">)</span>input_prompt <span class="token operator">=</span> prompt<span class="token punctuation">.</span>format_prompt<span class="token punctuation">(</span>query<span class="token operator">=</span>query<span class="token punctuation">)</span>output <span class="token operator">=</span> llm<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>input_prompt<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"原始输出:\n"</span><span class="token operator">+</span>output<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n解析后:"</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>OutputFixingParser</code> 利用大模型做格式自动纠错</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> OutputFixingParsernew_parser <span class="token operator">=</span> OutputFixingParser<span class="token punctuation">.</span>from_llm<span class="token punctuation">(</span>parser<span class="token operator">=</span>parser<span class="token punctuation">,</span> llm<span class="token operator">=</span>ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>bad_output <span class="token operator">=</span> output<span class="token punctuation">.</span>content<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"5"</span><span class="token punctuation">,</span><span class="token string">"五"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"PydanticOutputParser:"</span><span class="token punctuation">)</span><span class="token keyword">try</span><span class="token punctuation">:</span>    parser<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>bad_output<span class="token punctuation">)</span><span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"OutputFixingParser:"</span><span class="token punctuation">)</span>new_parser<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>bad_output<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-4-Function-Calling"><a href="#1-4-Function-Calling" class="headerlink" title="1.4 Function Calling"></a>1.4 Function Calling</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>tools <span class="token keyword">import</span> tool<span class="token decorator annotation punctuation">@tool</span><span class="token keyword">def</span> <span class="token function">add</span><span class="token punctuation">(</span>a<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> b<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Add two integers.    Args:        a: First integer        b: Second integer    """</span>    <span class="token keyword">return</span> a <span class="token operator">+</span> b<span class="token decorator annotation punctuation">@tool</span><span class="token keyword">def</span> <span class="token function">multiply</span><span class="token punctuation">(</span>a<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> b<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Multiply two integers.    Args:        a: First integer        b: Second integer    """</span>    <span class="token keyword">return</span> a <span class="token operator">*</span> b<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> jsonllm_with_tools <span class="token operator">=</span> llm<span class="token punctuation">.</span>bind_tools<span class="token punctuation">(</span><span class="token punctuation">[</span>add<span class="token punctuation">,</span> multiply<span class="token punctuation">]</span><span class="token punctuation">)</span>query <span class="token operator">=</span> <span class="token string">"3的4倍是多少?"</span>messages <span class="token operator">=</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">]</span>output <span class="token operator">=</span> llm_with_tools<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>output<span class="token punctuation">.</span>tool_calls<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>回传 Funtion Call 的结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span>output<span class="token punctuation">)</span>available_tools <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"add"</span><span class="token punctuation">:</span> add<span class="token punctuation">,</span> <span class="token string">"multiply"</span><span class="token punctuation">:</span> multiply<span class="token punctuation">}</span><span class="token keyword">for</span> tool_call <span class="token keyword">in</span> output<span class="token punctuation">.</span>tool_calls<span class="token punctuation">:</span>    selected_tool <span class="token operator">=</span> available_tools<span class="token punctuation">[</span>tool_call<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    tool_msg <span class="token operator">=</span> selected_tool<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>tool_call<span class="token punctuation">)</span>    messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tool_msg<span class="token punctuation">)</span>new_output <span class="token operator">=</span> llm_with_tools<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span><span class="token keyword">for</span> message <span class="token keyword">in</span> messages<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>message<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>new_output<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="1-5-小结"><a href="#1-5-小结" class="headerlink" title="1.5 小结"></a>1.5 小结</h3><ol><li>LangChain 统一封装了各种模型的调用接口，包括补全型和对话型两种</li><li>LangChain 提供了 PromptTemplate 类，可以自定义带变量的模板</li><li>LangChain 提供了一些列输出解析器，用于将大模型的输出解析成结构化对象</li><li>LangChain 提供了 Function Calling 的封装</li><li>上述模型属于 LangChain 中较为实用的部分</li></ol><h2 id="二、数据连接封装"><a href="#二、数据连接封装" class="headerlink" title="二、数据连接封装"></a>二、数据连接封装</h2><h3 id="2-1-文档加载器：Document-Loaders"><a href="#2-1-文档加载器：Document-Loaders" class="headerlink" title="2.1 文档加载器：Document Loaders"></a>2.1 文档加载器：Document Loaders</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> pymupdf<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> PyMuPDFLoaderloader <span class="token operator">=</span> PyMuPDFLoader<span class="token punctuation">(</span><span class="token string">"llama2.pdf"</span><span class="token punctuation">)</span>pages <span class="token operator">=</span> loader<span class="token punctuation">.</span>load_and_split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>pages<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-文档处理器"><a href="#2-2-文档处理器" class="headerlink" title="2.2 文档处理器"></a>2.2 文档处理器</h3><h4 id="2-2-1-TextSplitter"><a href="#2-2-1-TextSplitter" class="headerlink" title="2.2.1 TextSplitter"></a>2.2.1 TextSplitter</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">pip install <span class="token operator">-</span><span class="token operator">-</span>upgrade langchain<span class="token operator">-</span>text<span class="token operator">-</span>splitters<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> RecursiveCharacterTextSplitter<span class="token comment"># 简单的文本内容切割</span>text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>    chunk_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>    chunk_overlap<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>     length_function<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">,</span>    add_start_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span><span class="token punctuation">)</span>paragraphs <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>create_documents<span class="token punctuation">(</span><span class="token punctuation">[</span>pages<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>page_content<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">for</span> para <span class="token keyword">in</span> paragraphs<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>para<span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-------'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="alert alert-info">类似 LlamaIndex，LangChain 也提供了丰富的 <code><a href="https://python.langchain.com/v0.2/docs/how_to/#document-loaders">Document Loaders</a></code> 和 <code><a href="https://python.langchain.com/v0.2/docs/how_to/#text-splitters">Text Splitters</a></code>。</div><h3 id="2-3-向量数据库与向量检索"><a href="#2-3-向量数据库与向量检索" class="headerlink" title="2.3 向量数据库与向量检索"></a>2.3 向量数据库与向量检索</h3><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda <span class="token function">install</span> <span class="token parameter variable">-c</span> pytorch faiss-cpu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAIEmbeddings<span class="token punctuation">,</span> ChatOpenAI<span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> RecursiveCharacterTextSplitter<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> FAISS<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> PyMuPDFLoader<span class="token comment"># 加载文档</span>loader <span class="token operator">=</span> PyMuPDFLoader<span class="token punctuation">(</span><span class="token string">"llama2.pdf"</span><span class="token punctuation">)</span>pages <span class="token operator">=</span> loader<span class="token punctuation">.</span>load_and_split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 文档切分</span>text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>    chunk_size<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span>    chunk_overlap<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>    length_function<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">,</span>    add_start_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span><span class="token punctuation">)</span>texts <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>create_documents<span class="token punctuation">(</span>    <span class="token punctuation">[</span>page<span class="token punctuation">.</span>page_content <span class="token keyword">for</span> page <span class="token keyword">in</span> pages<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 灌库</span>embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"text-embedding-ada-002"</span><span class="token punctuation">)</span>db <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>texts<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span><span class="token comment"># 检索 top-3 结果</span>retriever <span class="token operator">=</span> db<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>search_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"k"</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">}</span><span class="token punctuation">)</span>docs <span class="token operator">=</span> retriever<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"llama2有多少参数"</span><span class="token punctuation">)</span><span class="token comment"># 打印检索到的文档</span><span class="token keyword">for</span> doc <span class="token keyword">in</span> docs<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>doc<span class="token punctuation">.</span>page_content<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"----"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>更多的三方检索组件链接，参考：<a href="https://python.langchain.com/v0.3/docs/integrations/vectorstores/">https://python.langchain.com/v0.3/docs/integrations/vectorstores/</a></p><h3 id="2-4、小结"><a href="#2-4、小结" class="headerlink" title="2.4、小结"></a>2.4、小结</h3><ol><li>文档处理部分，建议在实际应用中详细测试后使用</li><li>与向量数据库的链接部分本质是接口封装，向量数据库需要自己选型</li></ol><h2 id="三、对话历史管理"><a href="#三、对话历史管理" class="headerlink" title="三、对话历史管理"></a>三、对话历史管理</h2><h3 id="3-1、历史记录的剪裁"><a href="#3-1、历史记录的剪裁" class="headerlink" title="3.1、历史记录的剪裁"></a>3.1、历史记录的剪裁</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> <span class="token punctuation">(</span>    AIMessage<span class="token punctuation">,</span>    HumanMessage<span class="token punctuation">,</span>    SystemMessage<span class="token punctuation">,</span>    trim_messages<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAImessages <span class="token operator">=</span> <span class="token punctuation">[</span>    SystemMessage<span class="token punctuation">(</span><span class="token string">"you're a good assistant, you always respond with a joke."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    HumanMessage<span class="token punctuation">(</span><span class="token string">"i wonder why it's called langchain"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    AIMessage<span class="token punctuation">(</span>        <span class="token string">'Well, I guess they thought "WordRope" and "SentenceString" just didn\'t have the same ring to it!'</span>    <span class="token punctuation">)</span><span class="token punctuation">,</span>    HumanMessage<span class="token punctuation">(</span><span class="token string">"and who is harrison chasing anyways"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    AIMessage<span class="token punctuation">(</span>        <span class="token string">"Hmmm let me think.\n\nWhy, he's probably chasing after the last cup of coffee in the office!"</span>    <span class="token punctuation">)</span><span class="token punctuation">,</span>    HumanMessage<span class="token punctuation">(</span><span class="token string">"what do you call a speechless parrot"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span>trim_messages<span class="token punctuation">(</span>    messages<span class="token punctuation">,</span>    max_tokens<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">,</span>    strategy<span class="token operator">=</span><span class="token string">"last"</span><span class="token punctuation">,</span>    token_counter<span class="token operator">=</span>ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o-mini"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 保留 system prompt</span>trim_messages<span class="token punctuation">(</span>    messages<span class="token punctuation">,</span>    max_tokens<span class="token operator">=</span><span class="token number">45</span><span class="token punctuation">,</span>    strategy<span class="token operator">=</span><span class="token string">"last"</span><span class="token punctuation">,</span>    token_counter<span class="token operator">=</span>ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o-mini"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    include_system<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    allow_partial<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-2、过滤带标识的历史记录"><a href="#3-2、过滤带标识的历史记录" class="headerlink" title="3.2、过滤带标识的历史记录"></a>3.2、过滤带标识的历史记录</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> <span class="token punctuation">(</span>    AIMessage<span class="token punctuation">,</span>    HumanMessage<span class="token punctuation">,</span>    SystemMessage<span class="token punctuation">,</span>    filter_messages<span class="token punctuation">,</span><span class="token punctuation">)</span>messages <span class="token operator">=</span> <span class="token punctuation">[</span>    SystemMessage<span class="token punctuation">(</span><span class="token string">"you are a good assistant"</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token operator">=</span><span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    HumanMessage<span class="token punctuation">(</span><span class="token string">"example input"</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token operator">=</span><span class="token string">"2"</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"example_user"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    AIMessage<span class="token punctuation">(</span><span class="token string">"example output"</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token operator">=</span><span class="token string">"3"</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"example_assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    HumanMessage<span class="token punctuation">(</span><span class="token string">"real input"</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token operator">=</span><span class="token string">"4"</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"bob"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    AIMessage<span class="token punctuation">(</span><span class="token string">"real output"</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token operator">=</span><span class="token string">"5"</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">"alice"</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token comment"># 保留包含的消息</span>filter_messages<span class="token punctuation">(</span>messages<span class="token punctuation">,</span> include_types<span class="token operator">=</span><span class="token string">"human"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 保留不包含的信息</span>filter_messages<span class="token punctuation">(</span>messages<span class="token punctuation">,</span> exclude_names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"example_user"</span><span class="token punctuation">,</span> <span class="token string">"example_assistant"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 保留包含的消息和不包含的信息</span>filter_messages<span class="token punctuation">(</span>messages<span class="token punctuation">,</span> include_types<span class="token operator">=</span><span class="token punctuation">[</span>HumanMessage<span class="token punctuation">,</span> AIMessage<span class="token punctuation">]</span><span class="token punctuation">,</span> exclude_ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"3"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="四、Chain-和-LangChain-Expression-Language-LCEL"><a href="#四、Chain-和-LangChain-Expression-Language-LCEL" class="headerlink" title="四、Chain 和 LangChain Expression Language (LCEL)"></a>四、Chain 和 LangChain Expression Language (LCEL)</h2><p>LangChain Expression Language（LCEL）是一种声明式语言，可轻松组合不同的调用顺序构成 Chain。LCEL 自创立之初就被设计为能够支持将原型投入生产环境，<strong>无需代码更改</strong>，从最简单的“提示+LLM”链到最复杂的链（已有用户成功在生产环境中运行包含数百个步骤的 LCEL Chain）。</p><p>LCEL 的一些亮点包括：</p><ol><li><p><strong>流支持</strong>：使用 LCEL 构建 Chain 时，你可以获得最佳的首个令牌时间（即从输出开始到首批输出生成的时间）。对于某些 Chain，这意味着可以直接从 LLM 流式传输令牌到流输出解析器，从而以与 LLM 提供商输出原始令牌相同的速率获得解析后的、增量的输出。</p></li><li><p><strong>异步支持</strong>：任何使用 LCEL 构建的链条都可以通过同步 API（例如，在 Jupyter 笔记本中进行原型设计时）和异步 API（例如，在 LangServe 服务器中）调用。这使得相同的代码可用于原型设计和生产环境，具有出色的性能，并能够在同一服务器中处理多个并发请求。</p></li><li><p><strong>优化的并行执行</strong>：当你的 LCEL 链条有可以并行执行的步骤时（例如，从多个检索器中获取文档），我们会自动执行，无论是在同步还是异步接口中，以实现最小的延迟。</p></li><li><p><strong>重试和回退</strong>：为 LCEL 链的任何部分配置重试和回退。这是使链在规模上更可靠的绝佳方式。目前我们正在添加重试/回退的流媒体支持，因此你可以在不增加任何延迟成本的情况下获得增加的可靠性。</p></li><li><p><strong>访问中间结果</strong>：对于更复杂的链条，访问在最终输出产生之前的中间步骤的结果通常非常有用。这可以用于让最终用户知道正在发生一些事情，甚至仅用于调试链条。你可以流式传输中间结果，并且在每个 LangServe 服务器上都可用。</p></li><li><p><strong>输入和输出模式</strong>：输入和输出模式为每个 LCEL 链提供了从链的结构推断出的 Pydantic 和 JSONSchema 模式。这可以用于输入和输出的验证，是 LangServe 的一个组成部分。</p></li><li><p><strong>无缝 LangSmith 跟踪集成</strong>：随着链条变得越来越复杂，理解每一步发生了什么变得越来越重要。通过 LCEL，所有步骤都自动记录到 LangSmith，以实现最大的可观察性和可调试性。</p></li><li><p><strong>无缝 LangServe 部署集成</strong>：任何使用 LCEL 创建的链都可以轻松地使用 LangServe 进行部署。</p></li></ol><p>原文：<a href="https://python.langchain.com/docs/expression_language/">https://python.langchain.com/docs/expression_language/</a></p><h3 id="4-1-Pipeline-式调用-PromptTemplate-LLM-和-OutputParser"><a href="#4-1-Pipeline-式调用-PromptTemplate-LLM-和-OutputParser" class="headerlink" title="4.1 Pipeline 式调用 PromptTemplate, LLM 和 OutputParser"></a>4.1 Pipeline 式调用 PromptTemplate, LLM 和 OutputParser</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate<span class="token punctuation">,</span> ChatPromptTemplate<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> StrOutputParser<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables <span class="token keyword">import</span> RunnablePassthrough<span class="token keyword">from</span> pydantic <span class="token keyword">import</span> BaseModel<span class="token punctuation">,</span> Field<span class="token punctuation">,</span> validator<span class="token keyword">from</span> typing <span class="token keyword">import</span> List<span class="token punctuation">,</span> Dict<span class="token punctuation">,</span> Optional<span class="token keyword">from</span> enum <span class="token keyword">import</span> Enum<span class="token keyword">import</span> json<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 输出结构</span><span class="token keyword">class</span> <span class="token class-name">SortEnum</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">,</span> Enum<span class="token punctuation">)</span><span class="token punctuation">:</span>    data <span class="token operator">=</span> <span class="token string">'data'</span>    price <span class="token operator">=</span> <span class="token string">'price'</span><span class="token keyword">class</span> <span class="token class-name">OrderingEnum</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">,</span> Enum<span class="token punctuation">)</span><span class="token punctuation">:</span>    ascend <span class="token operator">=</span> <span class="token string">'ascend'</span>    descend <span class="token operator">=</span> <span class="token string">'descend'</span><span class="token keyword">class</span> <span class="token class-name">Semantics</span><span class="token punctuation">(</span>BaseModel<span class="token punctuation">)</span><span class="token punctuation">:</span>    name<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"流量包名称"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>    price_lower<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"价格下限"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>    price_upper<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"价格上限"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>    data_lower<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"流量下限"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>    data_upper<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"流量上限"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>    sort_by<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>SortEnum<span class="token punctuation">]</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"按价格或流量排序"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>    ordering<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>OrderingEnum<span class="token punctuation">]</span> <span class="token operator">=</span> Field<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">"升序或降序排列"</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token comment"># Prompt 模板</span>prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span>    <span class="token punctuation">[</span>        <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"你是一个语义解析器。你的任务是将用户的输入解析成JSON表示。不要回答用户的问题。"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">(</span><span class="token string">"human"</span><span class="token punctuation">,</span> <span class="token string">"{text}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 模型</span>llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>structured_llm <span class="token operator">=</span> llm<span class="token punctuation">.</span>with_structured_output<span class="token punctuation">(</span>Semantics<span class="token punctuation">)</span><span class="token comment"># LCEL 表达式</span>runnable <span class="token operator">=</span> <span class="token punctuation">(</span>    <span class="token punctuation">{</span><span class="token string">"text"</span><span class="token punctuation">:</span> RunnablePassthrough<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span> <span class="token operator">|</span> prompt <span class="token operator">|</span> structured_llm<span class="token punctuation">)</span><span class="token comment"># 直接运行</span>ret <span class="token operator">=</span> runnable<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"不超过100元的流量大的套餐有哪些"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>    json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>        ret<span class="token punctuation">.</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        indent <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>        ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span>    <span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="流式输出"><a href="#流式输出" class="headerlink" title="流式输出"></a>流式输出</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token string">"讲个关于{topic}的笑话"</span><span class="token punctuation">)</span>runnable <span class="token operator">=</span> <span class="token punctuation">(</span>    <span class="token punctuation">{</span><span class="token string">"topic"</span><span class="token punctuation">:</span> RunnablePassthrough<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span> <span class="token operator">|</span> prompt <span class="token operator">|</span> llm <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#### 流式输出</span><span class="token keyword">for</span> s <span class="token keyword">in</span> runnable<span class="token punctuation">.</span>stream<span class="token punctuation">(</span><span class="token string">"小明"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">""</span><span class="token punctuation">,</span> flush<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><b>注意:</b> 在当前的文档中 LCEL 产生的对象，被叫做 runnable 或 chain，经常两种叫法混用。本质就是一个自定义调用流程。</p></blockquote><blockquote><p><b>使用 LCEL 的价值，也就是 LangChain 的核心价值。</b><br>官方从不同角度给出了举例说明：<a href="https://python.langchain.com/v0.1/docs/expression_language/why/">https://python.langchain.com/v0.1/docs/expression_language/why/</a></p></blockquote><h3 id="4-2-用-LCEL-实现-RAG"><a href="#4-2-用-LCEL-实现-RAG" class="headerlink" title="4.2 用 LCEL 实现 RAG"></a>4.2 用 LCEL 实现 RAG</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> OpenAIEmbeddings<span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> RecursiveCharacterTextSplitter<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> FAISS<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> RetrievalQA<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> PyMuPDFLoader<span class="token comment"># 加载文档</span>loader <span class="token operator">=</span> PyMuPDFLoader<span class="token punctuation">(</span><span class="token string">"llama2.pdf"</span><span class="token punctuation">)</span>pages <span class="token operator">=</span> loader<span class="token punctuation">.</span>load_and_split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 文档切分</span>text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>    chunk_size<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span>    chunk_overlap<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>    length_function<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">,</span>    add_start_index<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span><span class="token punctuation">)</span>texts <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>create_documents<span class="token punctuation">(</span>    <span class="token punctuation">[</span>page<span class="token punctuation">.</span>page_content <span class="token keyword">for</span> page <span class="token keyword">in</span> pages<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 灌库</span>embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"text-embedding-ada-002"</span><span class="token punctuation">)</span>db <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>texts<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span><span class="token comment"># 检索 top-2 结果</span>retriever <span class="token operator">=</span> db<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>search_kwargs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"k"</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema<span class="token punctuation">.</span>output_parser <span class="token keyword">import</span> StrOutputParser<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema<span class="token punctuation">.</span>runnable <span class="token keyword">import</span> RunnablePassthrough<span class="token comment"># Prompt模板</span>template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""Answer the question based only on the following context:{context}Question: {question}"""</span>prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>template<span class="token punctuation">)</span><span class="token comment"># Chain</span>rag_chain <span class="token operator">=</span> <span class="token punctuation">(</span>    <span class="token punctuation">{</span><span class="token string">"question"</span><span class="token punctuation">:</span> RunnablePassthrough<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"context"</span><span class="token punctuation">:</span> retriever<span class="token punctuation">}</span>    <span class="token operator">|</span> prompt    <span class="token operator">|</span> llm    <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>rag_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"Llama 2有多少参数"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="4-3-用-LCEL-实现工厂模式（选）"><a href="#4-3-用-LCEL-实现工厂模式（选）" class="headerlink" title="4.3 用 LCEL 实现工厂模式（选）"></a>4.3 用 LCEL 实现工厂模式（选）</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables<span class="token punctuation">.</span>utils <span class="token keyword">import</span> ConfigurableField<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> QianfanChatEndpoint<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> <span class="token punctuation">(</span>    ChatPromptTemplate<span class="token punctuation">,</span>    HumanMessagePromptTemplate<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> HumanMessage<span class="token keyword">import</span> os<span class="token comment"># 模型1</span>ernie_model <span class="token operator">=</span> QianfanChatEndpoint<span class="token punctuation">(</span>    qianfan_ak<span class="token operator">=</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ERNIE_CLIENT_ID'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    qianfan_sk<span class="token operator">=</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ERNIE_CLIENT_SECRET'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 模型2</span>gpt_model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o-mini"</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># 通过 configurable_alternatives 按指定字段选择模型</span>model <span class="token operator">=</span> gpt_model<span class="token punctuation">.</span>configurable_alternatives<span class="token punctuation">(</span>    ConfigurableField<span class="token punctuation">(</span><span class="token builtin">id</span><span class="token operator">=</span><span class="token string">"llm"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>     default_key<span class="token operator">=</span><span class="token string">"gpt"</span><span class="token punctuation">,</span>     ernie<span class="token operator">=</span>ernie_model<span class="token punctuation">,</span>    <span class="token comment"># claude=claude_model,</span><span class="token punctuation">)</span><span class="token comment"># Prompt 模板</span>prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span>    <span class="token punctuation">[</span>        HumanMessagePromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token string">"{query}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># LCEL</span>chain <span class="token operator">=</span> <span class="token punctuation">(</span>    <span class="token punctuation">{</span><span class="token string">"query"</span><span class="token punctuation">:</span> RunnablePassthrough<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>     <span class="token operator">|</span> prompt    <span class="token operator">|</span> model     <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 运行时指定模型 "gpt" or "ernie"</span>ret <span class="token operator">=</span> chain<span class="token punctuation">.</span>with_config<span class="token punctuation">(</span>configurable<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"llm"</span><span class="token punctuation">:</span> <span class="token string">"gpt"</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">"请自我介绍"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>ret<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>扩展阅读：什么是<a href="https://www.runoob.com/design-pattern/factory-pattern.html"><strong>工厂模式</strong></a>；<a href="https://www.runoob.com/design-pattern/design-pattern-intro.html"><strong>设计模式</strong></a>概览。</p><blockquote><p><b>思考：</b>从模块间解依赖角度，LCEL的意义是什么？</p></blockquote><h3 id="4-4-存储与管理对话历史"><a href="#4-4-存储与管理对话历史" class="headerlink" title="4.4 存储与管理对话历史"></a>4.4 存储与管理对话历史</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>chat_message_histories <span class="token keyword">import</span> SQLChatMessageHistory<span class="token keyword">def</span> <span class="token function">get_session_history</span><span class="token punctuation">(</span>session_id<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 通过 session_id 区分对话历史，并存储在 sqlite 数据库中</span>    <span class="token keyword">return</span> SQLChatMessageHistory<span class="token punctuation">(</span>session_id<span class="token punctuation">,</span> <span class="token string">"sqlite:///memory.db"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> HumanMessage<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables<span class="token punctuation">.</span>history <span class="token keyword">import</span> RunnableWithMessageHistory<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema<span class="token punctuation">.</span>output_parser <span class="token keyword">import</span> StrOutputParsermodel <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o-mini"</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>runnable <span class="token operator">=</span> model <span class="token operator">|</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>runnable_with_history <span class="token operator">=</span> RunnableWithMessageHistory<span class="token punctuation">(</span>    runnable<span class="token punctuation">,</span> <span class="token comment"># 指定 runnable</span>    get_session_history<span class="token punctuation">,</span> <span class="token comment"># 指定自定义的历史管理方法</span><span class="token punctuation">)</span>runnable_with_history<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>    <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"你好，我叫墨屿"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"configurable"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"session_id"</span><span class="token punctuation">:</span> <span class="token string">"Moyu"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>第二轮对话：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">runnable_with_history<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>    <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"你知道我叫什么名字"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"configurable"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">"session_id"</span><span class="token punctuation">:</span> <span class="token string">"Moyu"</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="通过-LCEL，还可以实现"><a href="#通过-LCEL，还可以实现" class="headerlink" title="通过 LCEL，还可以实现"></a>通过 LCEL，还可以实现</h3><ol><li>配置运行时变量：<a href="https://python.langchain.com/v0.3/docs/how_to/configure/">https://python.langchain.com/v0.3/docs/how_to/configure/</a></li><li>故障回退：<a href="">https://python.langchain.com/v0.3/docs/how_to/fallbacks</a></li><li>故障回退：<a href="">https://python.langchain.com/v0.3/docs/how_to/fallbacks</a></li><li>并行调用：<a href="https://python.langchain.com/v0.3/docs/how_to/parallel/">https://python.langchain.com/v0.3/docs/how_to/parallel/</a></li><li>逻辑分支：<a href="https://python.langchain.com/v0.3/docs/how_to/routing/">https://python.langchain.com/v0.3/docs/how_to/routing/</a></li><li>动态创建 Chain: <a href="https://python.langchain.com/v0.3/docs/how_to/dynamic_chain/">https://python.langchain.com/v0.3/docs/how_to/dynamic_chain/</a></li></ol><p>更多例子：<a href="https://python.langchain.com/v0.3/docs/how_to/lcel_cheatsheet/">https://python.langchain.com/v0.3/docs/how_to/lcel_cheatsheet/</a></p><h2 id="五、LangServe"><a href="#五、LangServe" class="headerlink" title="五、LangServe"></a>五、LangServe</h2><p>LangServe 用于将 Chain 或者 Runnable 部署成一个 REST API 服务。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 安装 LangServe</span>pip install <span class="token operator">-</span><span class="token operator">-</span>upgrade <span class="token string">"langserve[all]"</span><span class="token comment"># 也可以只安装一端</span>pip install <span class="token string">"langserve[client]"</span>pip install <span class="token string">"langserve[server]"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-1、Server-端"><a href="#5-1、Server-端" class="headerlink" title="5.1、Server 端"></a>5.1、Server 端</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#!/usr/bin/env python</span><span class="token keyword">from</span> fastapi <span class="token keyword">import</span> FastAPI<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI<span class="token keyword">from</span> langserve <span class="token keyword">import</span> add_routes<span class="token keyword">import</span> uvicornapp <span class="token operator">=</span> FastAPI<span class="token punctuation">(</span>  title<span class="token operator">=</span><span class="token string">"LangChain Server"</span><span class="token punctuation">,</span>  version<span class="token operator">=</span><span class="token string">"1.0"</span><span class="token punctuation">,</span>  description<span class="token operator">=</span><span class="token string">"A simple api server using Langchain's Runnable interfaces"</span><span class="token punctuation">,</span><span class="token punctuation">)</span>model <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"gpt-4o-mini"</span><span class="token punctuation">)</span>prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token string">"讲一个关于{topic}的笑话"</span><span class="token punctuation">)</span>add_routes<span class="token punctuation">(</span>    app<span class="token punctuation">,</span>    prompt <span class="token operator">|</span> model<span class="token punctuation">,</span>    path<span class="token operator">=</span><span class="token string">"/joke"</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>    uvicorn<span class="token punctuation">.</span>run<span class="token punctuation">(</span>app<span class="token punctuation">,</span> host<span class="token operator">=</span><span class="token string">"localhost"</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">9999</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-2、Client-端"><a href="#5-2、Client-端" class="headerlink" title="5.2、Client 端"></a>5.2、Client 端</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> requestsresponse <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>    <span class="token string">"http://localhost:9999/joke/invoke"</span><span class="token punctuation">,</span>    json<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'input'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token string">'topic'</span><span class="token punctuation">:</span> <span class="token string">'小明'</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="LangChain-与-LlamaIndex-的错位竞争"><a href="#LangChain-与-LlamaIndex-的错位竞争" class="headerlink" title="LangChain 与 LlamaIndex 的错位竞争"></a>LangChain 与 LlamaIndex 的错位竞争</h2><ul><li>LangChain 侧重与 LLM 本身交互的封装<ul><li>Prompt、LLM、Message、OutputParser 等工具丰富</li><li>在数据处理和 RAG 方面提供的工具相对粗糙</li><li>主打 LCEL 流程封装</li><li>配套 Agent、LangGraph 等智能体与工作流工具</li><li>另有 LangServe 部署工具和 LangSmith 监控调试工具</li></ul></li><li>LlamaIndex 侧重与数据交互的封装<ul><li>数据加载、切割、索引、检索、排序等相关工具丰富</li><li>Prompt、LLM 等底层封装相对单薄</li><li>配套实现 RAG 相关工具</li><li>有 Agent 相关工具，不突出</li></ul></li><li>LlamaIndex 为 LangChain 提供了集成<ul><li>在 LlamaIndex 中调用 LangChain 封装的 LLM 接口：<a href="https://docs.llamaindex.ai/en/stable/api_reference/llms/langchain/">https://docs.llamaindex.ai/en/stable/api_reference/llms/langchain/</a></li><li>将 LlamaIndex 的 Query Engine 作为 LangChain Agent 的工具：<a href="https://docs.llamaindex.ai/en/v0.10.17/community/integrations/using_with_langchain.html">https://docs.llamaindex.ai/en/v0.10.17/community/integrations/using_with_langchain.html</a></li><li>LangChain 也 <em>曾经</em> 集成过 LlamaIndex，目前相关接口仍在：<a href="https://api.python.langchain.com/en/latest/retrievers/langchain_community.retrievers.llama_index.LlamaIndexRetriever.html">https://api.python.langchain.com/en/latest/retrievers/langchain_community.retrievers.llama_index.LlamaIndexRetriever.html</a></li></ul></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>LangChain 随着版本迭代可用性有明显提升</li><li>使用 LangChain 要注意维护自己的 Prompt，尽量 Prompt 与代码逻辑解依赖</li><li>它的内置基础工具，建议充分测试效果后再决定是否使用</li></ol>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> RAG </tag>
            
            <tag> Agent </tag>
            
            <tag> AI </tag>
            
            <tag> Embeddings </tag>
            
            <tag> LangChain </tag>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>【AI大模型应用学习笔记】RAG-Embedding-Vector知识点学习</title>
      <link href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-rag-embedding-vector-zhi-shi-dian-xue-xi/"/>
      <url>/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-rag-embedding-vector-zhi-shi-dian-xue-xi/</url>
      
        <content type="html"><![CDATA[<h2 id="一、什么是检索增强的生成模型（RAG）"><a href="#一、什么是检索增强的生成模型（RAG）" class="headerlink" title="一、什么是检索增强的生成模型（RAG）"></a>一、什么是检索增强的生成模型（RAG）</h2><p>  <strong>RAG（Retrieval-Augmented Generation，检索增强生成） 是一种结合了信息检索技术与语言生成模型的人工智能技术。该技术通过从外部知识库中检索相关信息，并将其作为提示（Prompt）输入给大型语言模型（LLMs），以增强模型处理知识密集型任务的能力，如问答、文本摘要、内容生成等。RAG模型由Facebook AI Research（FAIR）团队于2020年首次提出，并迅速成为大模型应用中的热门方案。</strong></p><h3 id="1-1-大模型目前固有的局限性"><a href="#1-1-大模型目前固有的局限性" class="headerlink" title="1.1 大模型目前固有的局限性"></a><strong>1.1 大模型目前固有的局限性</strong></h3><ul><li>1.LMM的知识不是实时的</li><li>2.LMM可能不知道你私有的领域/业务知识</li></ul><div class="alert alert-success"><b>类比：</b>你可以把这个过程想象成开卷考试。让 LLM 先翻书，再回答问题。</div><h3 id="1-2-检索增强生成（RAG）"><a href="#1-2-检索增强生成（RAG）" class="headerlink" title="1.2 检索增强生成（RAG）"></a><strong>1.2 检索增强生成（RAG）</strong></h3><h4 id="什么是RAG？"><a href="#什么是RAG？" class="headerlink" title="什么是RAG？"></a><strong>什么是RAG？</strong></h4><p><strong>RAG（Retrieval-Augmented Generation，检索增强生成），RAG</strong>是一种&nbsp;AI&nbsp;框架，它将传统信息检索系统（例如数据库）的优势与生成式大语言模型 (LLM) 的功能结合在一起。</p><p><strong>LLM通过将这些额外的知识与自己的语言技能相结合，可以撰写更准确、更具时效性且更贴合具体需求的文字。</strong></p><p><img src="https://pic1.imgdb.cn/item/681b64a758cb8da5c8e3d68d.png" alt="什么是RAG?"></p><h4 id="如何理解RAG？"><a href="#如何理解RAG？" class="headerlink" title="如何理解RAG？"></a><strong>如何理解RAG？</strong></h4><p><strong>通过上一个问题，我们知道了什么是RAG？了解到RAG是一种结合了信息检索、文本增强和文本生成的自然语言处理（NLP）的技术。</strong></p><p><strong>RAG的目的是通过从外部知识库检索相关信息来辅助大语言模型生成更准确、更丰富的文本内容。那我们如何理解RAG的检索、增强和生成呢？</strong></p><ol><li><strong>检索</strong>：检索是RAG流程的第一步，从预先建立的知识库中检索与问题相关的信息。这一步的目的是为后续的生成过程提供有用的上下文信息和知识支撑。</li><li><strong>增强</strong>：RAG中增强是将检索到的信息用作生成模型（即大语言模型）的上下文输入，以增强模型对特定问题的理解和回答能力。这一步的目的是将外部知识融入生成过程中，使生成的文本内容更加丰富、准确和符合用户需求。<strong>通过增强步骤，LLM模型能够充分利用外部知识库中的信息。</strong></li><li>生成：生成是RAG流程的最后一步。这一步的目的是结合LLM生成符合用户需求的回答。生成器会利用检索到的信息作为上下文输入，并结合大语言模型来生成文本内容。</li></ol><p><strong>RAG的“检索、增强、生成”，谁增强了谁，谁生成了答案，主语很重要。是从知识库中检索到的问答对，增强了LLM的提示词（prompt），LLM拿着增强后的Prompt生成了问题答案。</strong></p><h4 id="如何使用RAG"><a href="#如何使用RAG" class="headerlink" title="如何使用RAG?"></a>如何使用RAG?</h4><p><strong>我们如何使用RAG？接下来以RAG搭建知识问答系统具体步骤为例，来讲解如何使用RAG？</strong></p><ol><li><strong>数据准备与知识库构建</strong>：</li></ol><ul><li><strong>收集数据：</strong>&nbsp;首先，需要收集与问答系统相关的各种数据，这些数据可以来自文档、网页、数据库等多种来源。</li><li><strong>数据清洗：</strong>&nbsp;对收集到的数据进行清洗，去除噪声、重复项和无关信息，确保数据的质量和准确性。</li><li><strong>知识库构建：</strong>&nbsp;将清洗后的数据构建成知识库。这通常包括将文本分割成较小的片段（chunks），使用文本嵌入模型（如GLM）将这些片段转换成向量，并将这些向量存储在向量数据库（如FAISS、Milvus等）中。</li></ul><ol start="2"><li><strong>检索模块设计：</strong></li></ol><ul><li><strong>问题向量化：</strong>&nbsp;当用户输入查询问题时，使用相同的文本嵌入模型将问题转换成向量。</li><li><strong>相似度检索：</strong>&nbsp;在向量数据库中检索与问题向量最相似的知识库片段（chunks）。这通常通过计算向量之间的相似度（如余弦相似度）来实现。</li><li><strong>结果排序：</strong>&nbsp;根据相似度得分对检索到的结果进行排序，选择最相关的片段作为后续生成的输入。</li></ul><ol start="3"><li><strong>生成模块设计：</strong></li></ol><ul><li><strong>上下文融合</strong>：将检索到的相关片段与原始问题合并，形成更丰富的上下文信息。</li><li><strong>大语言模型生成</strong>：使用大语言模型（如GLM）基于上述上下文信息生成回答。大语言模型会学习如何根据检索到的信息来生成准确、有用的回答。</li></ul><p><strong>大家可以结合自己的业务领域知识，开始搭建医疗、法律、产品知识问答。先搭建Demo，然后工作中不断完善知识库问答对。</strong></p><h3 id="1-3-RAG工作原理是什么？"><a href="#1-3-RAG工作原理是什么？" class="headerlink" title="1.3 RAG工作原理是什么？"></a><strong>1.3 RAG工作原理是什么？</strong></h3><p>&nbsp;<strong>大型语言模型（LLM）面临两个问题，第一个问题是LLM会产生幻觉，第二个是LLM的知识中断。</strong></p><ol><li>幻觉：当模型所训练的数据没有问题的答案时，它会自信地做出错误反应，就会发生幻觉。</li><li>知识截止：当 LLM 返回的信息与模型的训练数据相比过时时。每个基础模型都有知识截止，这意味着其知识仅限于训练时可用的数据。</li></ol><p><strong>检索增强生成 (RAG) 摆脱了知识限制，整合了外部数据，从外部知识库中检索相关信息，增强模型的生成能力。</strong></p><p><img src="https://pic1.imgdb.cn/item/681b64a758cb8da5c8e3d68a.png" alt="RAG的工作原理"></p><h3 id="1-4-RAG基本搭建流程"><a href="#1-4-RAG基本搭建流程" class="headerlink" title="1.4 RAG基本搭建流程"></a><strong>1.4 RAG基本搭建流程</strong></h3><p><strong>通过检索增强技术，将用户查询与索引知识融合，利用大语言模型生成准确回答。</strong></p><ol><li>知识准备：收集并转换知识文档为文本数据，进行预处理和索引。</li><li>嵌入与索引：使用嵌入模型将文本转换为向量，并存储在向量数据库中。</li><li>查询检索：用户查询转换为向量，从数据库中检索相关知识。</li><li>提示增强：结合检索结果构建增强提示模版。</li><li>生成回答：大语言模型根据增强模版生成准确回答。</li></ol><h3 id="1-5-RAG技术架构"><a href="#1-5-RAG技术架构" class="headerlink" title="1.5 RAG技术架构"></a><strong>1.5 RAG技术架构</strong></h3><p><strong>RAG技术架构主要由两个核心模块组成，检索模块（Retriever）和生成模块（Generator）。</strong></p><ol><li><strong>检索模块（Retriever）：</strong></li></ol><ul><li>文本嵌入：使用预训练的文本嵌入模型（如GLM）将查询和文档转换成向量表示，以便在向量空间中进行相似度计算。</li><li>向量搜索：利用高效的向量搜索技术（如FAISS、Milvus等向量数据库）在向量空间中检索与查询向量最相似的文档或段落。</li><li>双塔模型：检索模块常采用双塔模型（Dual-Encoder）进行高效的向量化检索。双塔模型由两个独立的编码器组成，一个用于编码查询，另一个用于编码文档。这两个编码器将查询和文档映射到相同的向量空间中，以便进行相似度计算。</li></ul><ol start="2"><li><strong>生成模块（Generator）：</strong></li></ol><ul><li>强大的生成模型：生成模块通常使用在大规模数据上预训练的生成模型（如GLM），这些模型在生成自然语言文本方面表现出色。</li><li>上下文融合：生成模块将检索到的相关文档与原始查询合并，形成更丰富的上下文信息，作为生成模型的输入。</li><li>生成过程：生成模型根据输入的上下文信息，生成连贯、准确且信息丰富的回答或文本。</li></ul><p><strong>结合高效的检索模块（Retriever）与强大的生成模型（Generator），实现基于外部知识增强的自然语言生成能力。</strong></p><h2 id="二、RAG的工作原理和基本搭建流程"><a href="#二、RAG的工作原理和基本搭建流程" class="headerlink" title="二、RAG的工作原理和基本搭建流程"></a>二、RAG的工作原理和基本搭建流程</h2><p><img src="https://pic1.imgdb.cn/item/681b64a758cb8da5c8e3d68c.png" alt="RAG基本搭建流程"></p><p>RAG搭建过程</p><ul><li>1.文档加载，并按一定条件切割成片</li><li>2.将切割的文本片段灌人检索引擎</li><li>3.封装检索接口</li><li>4.构建调用流程：Query -&gt; 检索 -&gt; Prompt -&gt; LLM -&gt; 回复</li></ul><h3 id="2-1-文档的加载与切割"><a href="#2-1-文档的加载与切割" class="headerlink" title="2.1 文档的加载与切割"></a><strong>2.1 文档的加载与切割</strong></h3><p>安装 pdf 解析库</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> pdfminer.six<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>构建文档提取文字方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>high_level <span class="token keyword">import</span> extract_pages<span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>layout <span class="token keyword">import</span> LTTextContainer<span class="token keyword">def</span> <span class="token function">extract_text_from_pdf</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> page_numbers<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> min_line_length<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''从 PDF 文件中（按指定页码）提取文字'''</span>        paragraphs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token builtin">buffer</span> <span class="token operator">=</span> <span class="token string">''</span>    full_text <span class="token operator">=</span> <span class="token string">''</span>    <span class="token comment"># 提取全部文本</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> page_layout <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>extract_pages<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 如果指定了页码范围，跳过范围外的页</span>        <span class="token keyword">if</span> page_numbers <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> i <span class="token keyword">not</span> <span class="token keyword">in</span> page_numbers<span class="token punctuation">:</span>            <span class="token keyword">continue</span>        <span class="token keyword">for</span> element <span class="token keyword">in</span> page_layout<span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>element<span class="token punctuation">,</span> LTTextContainer<span class="token punctuation">)</span><span class="token punctuation">:</span>                full_text <span class="token operator">+=</span> element<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span>    <span class="token comment"># 按空行分隔，将文本重新组织成段落</span>    lines <span class="token operator">=</span> full_text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> text <span class="token keyword">in</span> lines<span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> min_line_length<span class="token punctuation">:</span>            <span class="token builtin">buffer</span> <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token string">' '</span><span class="token operator">+</span>text<span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token keyword">not</span> text<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">)</span> <span class="token keyword">else</span> text<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">)</span>        <span class="token keyword">elif</span> <span class="token builtin">buffer</span><span class="token punctuation">:</span>            paragraphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>            <span class="token builtin">buffer</span> <span class="token operator">=</span> <span class="token string">''</span>    <span class="token keyword">if</span> <span class="token builtin">buffer</span><span class="token punctuation">:</span>        paragraphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> paragraphs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>调用方法加载本地文档</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">paragraphs <span class="token operator">=</span> extract_text_from_pdf<span class="token punctuation">(</span><span class="token string">"llama2.pdf"</span><span class="token punctuation">,</span> min_line_length<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token comment"># 打印文档前4段内容</span><span class="token keyword">for</span> para <span class="token keyword">in</span> paragraphs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>para<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-2-LLM接口封装"><a href="#2-2-LLM接口封装" class="headerlink" title="2.2 LLM接口封装"></a><strong>2.2 LLM接口封装</strong></h3><p>安装openai库和环境变量库</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> openaipip <span class="token function">install</span> <span class="token parameter variable">-U</span> python-dotenv<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>加载环境变量，将我们的OpenAI Key 加载进来，在根目录建一个 <code>.env</code>  文件，把我们申请的<code>OPENAI_API_KEY</code> 填写进去，文件内容如下：</p><pre class="line-numbers language-none"><code class="language-none">OPENAI_API_KEY=Bearer hk-xxxxxxxxxxxxxxxOPENAI_BASE_URL=https://api.openai-hk.com/v1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>编写代码加载环境变量</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI<span class="token comment"># 加载环境变量</span><span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv<span class="token punctuation">,</span> find_dotenv_ <span class="token operator">=</span> load_dotenv<span class="token punctuation">(</span>find_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 读取本地 .env 文件，里面定义了 OPENAI_API_KEY</span>client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>base_url<span class="token operator">=</span><span class="token string">"https://api.openai-hk.com/v1"</span><span class="token punctuation">,</span> <span class="token punctuation">)</span>  <span class="token comment"># 使用香港的 API 服务器</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>安装<code>requests</code>包</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> requests<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>封装 openai 接口</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_completion</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''封装 openai 接口'''</span>    messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">]</span>    response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>        model<span class="token operator">=</span>model<span class="token punctuation">,</span>        messages<span class="token operator">=</span>messages<span class="token punctuation">,</span>        temperature<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">,</span>   <span class="token comment"># 控制输出的随机性，0.0-1.0之间，越小越确定</span>    <span class="token punctuation">)</span>    <span class="token keyword">return</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-3-Prompt-模板"><a href="#2-3-Prompt-模板" class="headerlink" title="2.3 Prompt 模板"></a><strong>2.3 Prompt 模板</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_prompt</span><span class="token punctuation">(</span>prompt_template<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''将 Prompt 模板赋值'''</span>        inputs <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> kwargs<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token builtin">all</span><span class="token punctuation">(</span><span class="token builtin">isinstance</span><span class="token punctuation">(</span>elem<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token keyword">for</span> elem <span class="token keyword">in</span> v<span class="token punctuation">)</span><span class="token punctuation">:</span>            val <span class="token operator">=</span> <span class="token string">'\n\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>v<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            val <span class="token operator">=</span> v        inputs<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> val    <span class="token keyword">return</span> prompt_template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>prompt_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""你是一个问答机器人。你的任务是根据下述给定的已知信息，回答用户的问题。  已知信息：{context} # 从向量数据库检索出原始文档用户问：{query} # 用户的提问如果已知信息中不包含用户问题的答案，或者已知信息不足以回答用户问题，请回答“我无法回答您的问题”。请不要输出已知信息中不包含的信息或答案。请用中文回答用户问题。"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="三、向量检索"><a href="#三、向量检索" class="headerlink" title="三、向量检索"></a>三、向量检索</h2><h3 id="3-1-什么是向量"><a href="#3-1-什么是向量" class="headerlink" title="3.1 什么是向量"></a><strong>3.1 什么是向量</strong></h3><p>向量是一种有大小和方向的数学对象。它可以表示为从一个点到另一个点的有向线段。例如，二维空间中的向量可以表示为 $(x,y)$, 表示从原点 $(0,0)$ 到点 $(x,y)$ 的有向线段。</p><p><img src="https://pic1.imgdb.cn/item/681b6be158cb8da5c8e3d9ad.png" alt="向量坐标图"></p><p>以此类推，我可以用一组坐标 $(x_0, x_1, \ldots, x_{N-1})$ 表示一个 $N$ 维空间中的向量, $N$ 叫向量的维度。</p><h4 id="3-1-1-文本向量（Text-Embeddings）"><a href="#3-1-1-文本向量（Text-Embeddings）" class="headerlink" title="3.1.1 文本向量（Text Embeddings）"></a><strong>3.1.1 文本向量（Text Embeddings）</strong></h4><ol><li>将文本转换成一组 $N$ 维浮点数，即<strong>文本向量</strong>又叫 Embeddings</li><li>向量之间可以计算距离，距离远近对应<strong>语义相似度</strong>大小</li></ol><p><img src="https://pic1.imgdb.cn/item/681b6c4e58cb8da5c8e3d9e9.png" alt="embeddings"></p><h4 id="3-1-2-文本向量是怎样得到的"><a href="#3-1-2-文本向量是怎样得到的" class="headerlink" title="3.1.2 文本向量是怎样得到的"></a><strong>3.1.2 文本向量是怎样得到的</strong></h4><ol><li>构建相关（正例）与不相关（负例）的句子对样本</li><li>训练双塔模型，让正例间的距离小，负例间的距离大</li></ol><p>例如：<br><img src="https://pic1.imgdb.cn/item/681b6c4e58cb8da5c8e3d9e7.png" alt="sbert"></p><div class="alert alert-info"><b>扩展阅读：https://www.sbert.net</b></div><h3 id="3-2-向量间的相似度计算"><a href="#3-2-向量间的相似度计算" class="headerlink" title="3.2 向量间的相似度计算"></a><strong>3.2 向量间的相似度计算</strong></h3><p>向量间的相似度计算在数学上有欧氏距离和余弦距离两种。<br><img src="https://pic1.imgdb.cn/item/681b6be158cb8da5c8e3d9ac.png" alt="向量相似度计算"></p><p>安装<code>numpy</code>库</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> numpy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>构建相似度计算公式：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> numpy <span class="token keyword">import</span> dot<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>linalg <span class="token keyword">import</span> norm<span class="token keyword">def</span> <span class="token function">cos_sim</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''余弦距离 -- 越大越相似'''</span>    <span class="token keyword">return</span> dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">*</span>norm<span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">l2</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''欧氏距离 -- 越小越相似'''</span>    x <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>b<span class="token punctuation">)</span>    <span class="token keyword">return</span> norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>封装 openai 的 Embeddings 模型接口</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_embeddings</span><span class="token punctuation">(</span>texts<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"text-embedding-ada-002"</span><span class="token punctuation">,</span> dimensions<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''封装 OpenAI 的 Embedding 模型接口'''</span>    <span class="token keyword">if</span> model <span class="token operator">==</span> <span class="token string">"text-embedding-ada-002"</span><span class="token punctuation">:</span>        dimensions <span class="token operator">=</span> <span class="token boolean">None</span>            <span class="token keyword">if</span> dimensions<span class="token punctuation">:</span>        data <span class="token operator">=</span> client<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>create<span class="token punctuation">(</span>            <span class="token builtin">input</span><span class="token operator">=</span>texts<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> dimensions<span class="token operator">=</span>dimensions<span class="token punctuation">)</span><span class="token punctuation">.</span>data    <span class="token keyword">else</span><span class="token punctuation">:</span>        data <span class="token operator">=</span> client<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>texts<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span><span class="token punctuation">.</span>data    <span class="token keyword">return</span> <span class="token punctuation">[</span>x<span class="token punctuation">.</span>embedding <span class="token keyword">for</span> x <span class="token keyword">in</span> data<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="alert alert-info"><b>Embedding模型的选择标准：找需求相关的语料库来进行文本向量转换测试，进行评估。<br>大多数场景下，开源的嵌入模型使用都很一般，要提升检索召回率，建议对模型进行微调。</b></div><p>进行测试</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_query <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"测试文本"</span><span class="token punctuation">]</span>vec <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>test_query<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Total dimension: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"First 10 elements: </span><span class="token interpolation"><span class="token punctuation">{</span>vec<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token format-spec">10]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>输出的结果如下：</p><pre class="line-numbers language-none"><code class="language-none">Total dimension: 1536First 10 elements: [-0.007280503865331411, -0.006169671658426523, -0.010576579719781876, 0.001448634546250105, -0.010707695037126541, 0.02919485792517662, -0.019725468009710312, 0.0053902678191661835, -0.016957491636276245, -0.01203340943902731]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>我们来用一些文本例子，计算比较它们的向量相似度</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">query <span class="token operator">=</span> <span class="token string">"国际争端"</span>documents <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token string">"联合国就苏丹达尔富尔地区大规模暴力事件发出警告"</span><span class="token punctuation">,</span>    <span class="token string">"土耳其、芬兰、瑞典与北约代表将继续就瑞典“入约”问题进行谈判"</span><span class="token punctuation">,</span>    <span class="token string">"日本岐阜市陆上自卫队射击场内发生枪击事件 3人受伤"</span><span class="token punctuation">,</span>    <span class="token string">"国家游泳中心（水立方）：恢复游泳、嬉水乐园等水上项目运营"</span><span class="token punctuation">,</span>    <span class="token string">"我国首次在空间站开展舱外辐射生物学暴露实验"</span><span class="token punctuation">,</span><span class="token punctuation">]</span>query_vec <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>doc_vecs <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token comment"># 计算余弦相似度</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与自己的余弦相似度：{:.2f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>cos_sim<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> query_vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 计算Query与Documents的余弦相似度</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与Documents的余弦相似度："</span><span class="token punctuation">)</span><span class="token keyword">for</span> vec <span class="token keyword">in</span> doc_vecs<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>cos_sim<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 计算欧氏距离</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与自己的欧氏距离：{:.2f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>l2<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> query_vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 计算Query与Documents的欧氏距离</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与Documents的欧氏距离："</span><span class="token punctuation">)</span><span class="token keyword">for</span> vec <span class="token keyword">in</span> doc_vecs<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>l2<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行的结果如下：</p><pre class="line-numbers language-none"><code class="language-none">Query与自己的余弦相似度：1.00Query与Documents的余弦相似度：0.82187066204548860.82935716838328580.79770473361543210.7669801767537340.7930490196304245Query与自己的欧氏距离：0.00Query与Documents的欧氏距离：0.59687410717183940.58419660593308320.63607431665981110.68267094129920980.6433521233350966<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="3-3-向量数据库"><a href="#3-3-向量数据库" class="headerlink" title="3.3 向量数据库"></a><strong>3.3 向量数据库</strong></h3><p>向量数据库是专门为向量检索设计的中间件</p><p>安装<code>chromadb</code>向量库包</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> chromadb<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>解析文档</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 为了演示方便，我们只取两页（第一章）</span>paragraphs <span class="token operator">=</span> extract_text_from_pdf<span class="token punctuation">(</span>    <span class="token string">"llama2.pdf"</span><span class="token punctuation">,</span>    page_numbers<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    min_line_length<span class="token operator">=</span><span class="token number">10</span>    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>创建MyVectorDBConnector类</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> chromadb<span class="token keyword">from</span> chromadb<span class="token punctuation">.</span>config <span class="token keyword">import</span> Settings<span class="token comment"># 创建MyVectorDBConnector类</span><span class="token keyword">class</span> <span class="token class-name">MyVectorDBConnector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> collection_name<span class="token punctuation">,</span> embedding_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>        chroma_client <span class="token operator">=</span> chromadb<span class="token punctuation">.</span>Client<span class="token punctuation">(</span>Settings<span class="token punctuation">(</span>allow_reset<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 为了演示，实际不需要每次 reset()</span>        chroma_client<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 创建一个 collection</span>        self<span class="token punctuation">.</span>collection <span class="token operator">=</span> chroma_client<span class="token punctuation">.</span>get_or_create_collection<span class="token punctuation">(</span>name<span class="token operator">=</span>collection_name<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding_fn <span class="token operator">=</span> embedding_fn      <span class="token keyword">def</span> <span class="token function">add_documents</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> documents<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''向 collection 中添加文档与向量'''</span>        self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>add<span class="token punctuation">(</span>            embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding_fn<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 每个文档的向量</span>            documents<span class="token operator">=</span>documents<span class="token punctuation">,</span>  <span class="token comment"># 文档的原文</span>            ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"id</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">"</span></span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># 每个文档的 id</span>        <span class="token punctuation">)</span>            <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query<span class="token punctuation">,</span> top_n<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''检索向量数据库'''</span>        results <span class="token operator">=</span> self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>query<span class="token punctuation">(</span>            query_embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding_fn<span class="token punctuation">(</span><span class="token punctuation">[</span>query<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            n_results<span class="token operator">=</span>top_n        <span class="token punctuation">)</span>        <span class="token keyword">return</span> results<span class="token comment"># 创建一个向量数据库对象</span>vector_db <span class="token operator">=</span> MyVectorDBConnector<span class="token punctuation">(</span><span class="token string">"demo"</span><span class="token punctuation">,</span> get_embeddings<span class="token punctuation">)</span><span class="token comment"># 向量数据库中添加文档</span>vector_db<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>paragraphs<span class="token punctuation">)</span>user_query <span class="token operator">=</span> <span class="token string">"Llama 2有多少参数？"</span><span class="token comment"># user_query = "Does Llama 2 have a conversational variant"</span>results <span class="token operator">=</span> vector_db<span class="token punctuation">.</span>search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">for</span> para <span class="token keyword">in</span> results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>para<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果如下：</p><pre class="line-numbers language-none"><code class="language-none">1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data. We also increased the size of the pretraining corpus by 40%, doubled the context length of the model, and adopted grouped-query attention (Ainslie et al., 2023). We are releasing variants of Llama 2 with 7B, 13B, and 70B parameters. We have also trained 34B variants, which we report on in this paper but are not releasing.§ In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models. They also appear to be on par with some of the closed-source models, at least on the human evaluations we performed (see Figures 1 and 3). We have taken measures to increase the safety of these models, using safety-speciﬁc data annotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally, this paper contributes a thorough description of our ﬁne-tuning methodology and approach to improving LLM safety. We hope that this openness will enable the community to reproduce ﬁne-tuned LLMs and continue to improve the safety of those models, paving the way for more responsible development of LLMs. We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><div class="alert alert-success"><b>澄清几个关键概念：</b><ul>&nbsp; &nbsp; <li>向量数据库的意义是快速的检索；</li>&nbsp; &nbsp; <li>向量数据库本身不生成向量，向量是由 Embedding 模型产生的；</li>&nbsp; &nbsp; <li>向量数据库与传统的关系型数据库是互补的，不是替代关系，在实际应用中根据实际需求经常同时使用。</li></ul></div><h4 id="3-3-1-向量数据库服务"><a href="#3-3-1-向量数据库服务" class="headerlink" title="3.3.1 向量数据库服务"></a><strong>3.3.1 向量数据库服务</strong></h4><p>Server 端</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">chroma run <span class="token parameter variable">--path</span> /db_path<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>Client 端</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> chromadbchroma_client <span class="token operator">=</span> chromadb<span class="token punctuation">.</span>HttpClient<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'localhost'</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">8000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="3-3-2-主流向量数据库功能对比"><a href="#3-3-2-主流向量数据库功能对比" class="headerlink" title="3.3.2 主流向量数据库功能对比"></a><strong>3.3.2 主流向量数据库功能对比</strong></h4><p><img src="https://pic1.imgdb.cn/item/681b6be158cb8da5c8e3d9ab.png" alt="主流向量数据库功能对比"></p><ul><li>FAISS: Meta 开源的向量检索引擎 <a href="https://github.com/facebookresearch/faiss">https://github.com/facebookresearch/faiss</a></li><li>Pinecone: 商用向量数据库，只有云服务 <a href="https://www.pinecone.io/">https://www.pinecone.io/</a></li><li><strong>Milvus</strong>: 开源向量数据库，同时有云服务 <a href="https://milvus.io/">https://milvus.io/</a></li><li>Weaviate: 开源向量数据库，同时有云服务 <a href="https://weaviate.io/">https://weaviate.io/</a></li><li><strong>Qdrant</strong>: 开源向量数据库，同时有云服务 <a href="https://qdrant.tech/">https://qdrant.tech/</a></li><li>PGVector: Postgres 的开源向量检索引擎 <a href="https://github.com/pgvector/pgvector">https://github.com/pgvector/pgvector</a></li><li>RediSearch: Redis 的开源向量检索引擎 <a href="https://github.com/RediSearch/RediSearch">https://github.com/RediSearch/RediSearch</a></li><li>ElasticSearch 也支持向量检索 <a href="https://www.elastic.co/enterprise-search/vector-search">https://www.elastic.co/enterprise-search/vector-search</a></li></ul><div class="alert alert-info"><b>扩展阅读：https://guangzhengli.com/blog/zh/vector-database</b></div><h3 id="3-4-基于向量检索的RAG"><a href="#3-4-基于向量检索的RAG" class="headerlink" title="3.4 基于向量检索的RAG"></a><strong>3.4 基于向量检索的RAG</strong></h3><p>构建RAG_Bot类</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">RAG_Bot</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vector_db<span class="token punctuation">,</span> llm_api<span class="token punctuation">,</span> n_results<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>vector_db <span class="token operator">=</span> vector_db        self<span class="token punctuation">.</span>llm_api <span class="token operator">=</span>  llm_api        self<span class="token punctuation">.</span>n_results <span class="token operator">=</span> n_results    <span class="token keyword">def</span> <span class="token function">chat</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> user_query<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment"># 1. 检索</span>        search_results <span class="token operator">=</span> self<span class="token punctuation">.</span>vector_db<span class="token punctuation">.</span>search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_results<span class="token punctuation">)</span>        <span class="token comment"># 2. 构建 Prompt</span>        prompt <span class="token operator">=</span> build_prompt<span class="token punctuation">(</span>            prompt_template<span class="token punctuation">,</span> context<span class="token operator">=</span>search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> query<span class="token operator">=</span>user_query<span class="token punctuation">)</span>                    <span class="token comment"># 3. 调用 LLM</span>        response <span class="token operator">=</span> self<span class="token punctuation">.</span>llm_api<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>        <span class="token keyword">return</span> response<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>创建一个RAG机器人对象</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建一个RAG机器人</span>bot <span class="token operator">=</span> RAG_Bot<span class="token punctuation">(</span>    vector_db<span class="token punctuation">,</span>    llm_api<span class="token operator">=</span>get_completion<span class="token punctuation">)</span>user_query <span class="token operator">=</span> <span class="token string">"llama 2有多少参数?"</span>response <span class="token operator">=</span> bot<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>user_query<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里输出内容如下：</p><pre class="line-numbers language-none"><code class="language-none">Llama 2有7B、13B和70B参数的变体。<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="3-5-OpenAI-新发布的两个Embedding模型"><a href="#3-5-OpenAI-新发布的两个Embedding模型" class="headerlink" title="3.5 OpenAI 新发布的两个Embedding模型"></a>3.5 OpenAI 新发布的两个Embedding模型</h2><p>2024 年 1 月 25 日，OpenAI 新发布了两个 Embedding 模型</p><ul><li>text-embedding-3-large</li><li>text-embedding-3-small</li></ul><p>其最大特点是，支持自定义的缩短向量维度，从而在几乎不影响最终效果的情况下降低向量检索与相似度计算的复杂度。</p><p>通俗的说：<strong>越大越准、越小越快。</strong> 官方公布的评测结果:</p><p><img src="https://pic1.imgdb.cn/item/681b6c4e58cb8da5c8e3d9e8.png" alt="官方测评结果"></p><p>注：<a href="https://huggingface.co/blog/mteb">MTEB</a> 是一个大规模多任务的 Embedding 模型公开评测集</p><div class="alert alert-info"><b>RAG系统基本需要用到 两个模型<br>embedded模型：采用open ai 的线上模型，向量模型的精确度直接影响query 相似度检索的文档召回率<br>文本生成模型（对话模型）：采用本地私有化部署模型</b></div><p>测试 <code>text-embedding-3-large</code> Embedding模型效果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> <span class="token string">"text-embedding-3-large"</span>dimensions <span class="token operator">=</span> <span class="token number">128</span><span class="token comment"># query = "国际争端"</span><span class="token comment"># 且能支持跨语言</span>query <span class="token operator">=</span> <span class="token string">"global conflicts"</span>documents <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token string">"联合国就苏丹达尔富尔地区大规模暴力事件发出警告"</span><span class="token punctuation">,</span>    <span class="token string">"土耳其、芬兰、瑞典与北约代表将继续就瑞典“入约”问题进行谈判"</span><span class="token punctuation">,</span>    <span class="token string">"日本岐阜市陆上自卫队射击场内发生枪击事件 3人受伤"</span><span class="token punctuation">,</span>    <span class="token string">"国家游泳中心（水立方）：恢复游泳、嬉水乐园等水上项目运营"</span><span class="token punctuation">,</span>    <span class="token string">"我国首次在空间站开展舱外辐射生物学暴露实验"</span><span class="token punctuation">,</span><span class="token punctuation">]</span>query_vec <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span><span class="token punctuation">[</span>query<span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> dimensions<span class="token operator">=</span>dimensions<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>doc_vecs <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>documents<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> dimensions<span class="token operator">=</span>dimensions<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"向量维度: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>query_vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与Documents的余弦距离:"</span><span class="token punctuation">)</span><span class="token keyword">for</span> vec <span class="token keyword">in</span> doc_vecs<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>cos_sim<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> vec<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与Documents的欧氏距离:"</span><span class="token punctuation">)</span><span class="token keyword">for</span> vec <span class="token keyword">in</span> doc_vecs<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>l2<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出内容如下：</p><pre class="line-numbers language-none"><code class="language-none">向量维度: 128Query与Documents的余弦距离:0.334187961723793340.354629772522801260.313645991288170170.224224483912154550.12849126788491727Query与Documents的欧氏距离:1.15396015653256321.13610757183249671.17162626179870681.24561272431458341.320233859479998<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="alert alert-info"><b>扩展阅读：这种可变长度的 Embedding 技术背后的原理叫做 <a href="https://arxiv.org/abs/2205.13147">Matryoshka Representation Learning</a> </b></div><h2 id="四、-实战-RAG-系统的进阶知识"><a href="#四、-实战-RAG-系统的进阶知识" class="headerlink" title="四、 实战 RAG 系统的进阶知识"></a>四、 实战 RAG 系统的进阶知识</h2><h3 id="4-1-文本分割的粒度"><a href="#4-1-文本分割的粒度" class="headerlink" title="4.1 文本分割的粒度"></a>4.1 文本分割的粒度</h3><p><strong>缺陷</strong></p><ol><li>粒度太大可能导致检索不精准，粒度太小可能导致信息不全面</li><li>问题的答案可能跨越两个片段</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建一个向量数据库对象</span>vector_db <span class="token operator">=</span> MyVectorDBConnector<span class="token punctuation">(</span><span class="token string">"demo_text_split"</span><span class="token punctuation">,</span> get_embeddings<span class="token punctuation">)</span><span class="token comment"># 向向量数据库中添加文档</span>vector_db<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>paragraphs<span class="token punctuation">)</span><span class="token comment"># 创建一个RAG机器人</span>bot <span class="token operator">=</span> RAG_Bot<span class="token punctuation">(</span>    vector_db<span class="token punctuation">,</span>    llm_api<span class="token operator">=</span>get_completion<span class="token punctuation">)</span><span class="token comment"># user_query = "llama 2有商用许可协议吗?"</span>user_query<span class="token operator">=</span><span class="token string">"llama 2 chat有多少参数?"</span>search_results <span class="token operator">=</span> vector_db<span class="token punctuation">.</span>search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">for</span> doc <span class="token keyword">in</span> search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>doc<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>response <span class="token operator">=</span> bot<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>user_query<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"====回复===="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"=============================="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span class="token keyword">for</span> p <span class="token keyword">in</span> paragraphs<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"=========="</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>p<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出内容如下：</p><pre class="line-numbers language-none"><code class="language-none">In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models. They also appear to be on par with some of the closed-source models, at least on the human evaluations we performed (see Figures 1 and 3). We have taken measures to increase the safety of these models, using safety-speciﬁc data annotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally, this paper contributes a thorough description of our ﬁne-tuning methodology and approach to improving LLM safety. We hope that this openness will enable the community to reproduce ﬁne-tuned LLMs and continue to improve the safety of those models, paving the way for more responsible development of LLMs. We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. 2. Llama 2-Chat, a ﬁne-tuned version of Llama 2 that is optimized for dialogue use cases. We release====回复====Llama 2-Chat的参数规模可以达到70B。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>改进</strong>: 按一定粒度，部分重叠式的切割文本，使上下文更完整</p><p>安装<code>nltk</code>包</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> nltk<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>重新按照一定条件来切割文档</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> sent_tokenize<span class="token keyword">import</span> json<span class="token comment"># chunk_size 一般根据文档内容或大小来设置</span><span class="token comment"># overlap_size 一般设置 chunk_size 大小的10%-20%之间</span><span class="token keyword">def</span> <span class="token function">split_text</span><span class="token punctuation">(</span>paragraphs<span class="token punctuation">,</span> chunk_size<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> overlap_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''按指定 chunk_size 和 overlap_size 交叠割文本'''</span>        sentences <span class="token operator">=</span> <span class="token punctuation">[</span>s<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> paragraphs <span class="token keyword">for</span> s <span class="token keyword">in</span> sent_tokenize<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token comment"># sentences = [s.strip() for p in paragraphs for s in sent_tokenize(p, language='chinese')]</span>    chunks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    i <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">while</span> i <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">:</span>        chunk <span class="token operator">=</span> sentences<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        overlap <span class="token operator">=</span> <span class="token string">''</span>        prev_len <span class="token operator">=</span> <span class="token number">0</span>        prev <span class="token operator">=</span> i <span class="token operator">-</span> <span class="token number">1</span>        <span class="token comment"># 向前计算重叠部分</span>        <span class="token keyword">while</span> prev <span class="token operator">&gt;=</span> <span class="token number">0</span> <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">[</span>prev<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token builtin">len</span><span class="token punctuation">(</span>overlap<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> overlap_size<span class="token punctuation">:</span>            overlap <span class="token operator">=</span> sentences<span class="token punctuation">[</span>prev<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">' '</span> <span class="token operator">+</span> overlap            prev <span class="token operator">-=</span> <span class="token number">1</span>        chunk <span class="token operator">=</span> overlap<span class="token operator">+</span>chunk        <span class="token builtin">next</span> <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span>        <span class="token comment"># 向后计算当前chunk</span>        <span class="token keyword">while</span> <span class="token builtin">next</span> <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">[</span><span class="token builtin">next</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token builtin">len</span><span class="token punctuation">(</span>chunk<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> chunk_size<span class="token punctuation">:</span>            chunk <span class="token operator">=</span> chunk <span class="token operator">+</span> <span class="token string">' '</span> <span class="token operator">+</span> sentences<span class="token punctuation">[</span><span class="token builtin">next</span><span class="token punctuation">]</span>            <span class="token builtin">next</span> <span class="token operator">+=</span> <span class="token number">1</span>        chunks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>chunk<span class="token punctuation">)</span>        i <span class="token operator">=</span> <span class="token builtin">next</span>    <span class="token keyword">return</span> chunkschunks <span class="token operator">=</span> split_text<span class="token punctuation">(</span>paragraphs<span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="alert alert-info">此处 sent_tokenize 为针对英文的实现，针对中文的实现请参考 chinese_utils.py</div><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建一个向量数据库对象</span>vector_db <span class="token operator">=</span> MyVectorDBConnector<span class="token punctuation">(</span><span class="token string">"demo_text_split"</span><span class="token punctuation">,</span> get_embeddings<span class="token punctuation">)</span><span class="token comment"># 向向量数据库中添加文档</span>vector_db<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>chunks<span class="token punctuation">)</span><span class="token comment"># 创建一个RAG机器人</span>bot <span class="token operator">=</span> RAG_Bot<span class="token punctuation">(</span>     vector_db<span class="token punctuation">,</span>     llm_api<span class="token operator">=</span>get_completion<span class="token punctuation">)</span><span class="token comment"># user_query = "llama 2有商用许可协议吗"</span>user_query<span class="token operator">=</span><span class="token string">"llama 2 chat有多少参数"</span>search_results <span class="token operator">=</span> vector_db<span class="token punctuation">.</span>search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">for</span> doc <span class="token keyword">in</span> search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>doc<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>response <span class="token operator">=</span> bot<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>user_query<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"====回复===="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果输出如下：</p><pre class="line-numbers language-none"><code class="language-none">2. Llama 2-Chat, a ﬁne-tuned version of Llama 2 that is optimized for dialogue use cases. We release variants of this model with 7B, 13B, and 70B parameters as well. We believe that the open release of LLMs, when done safely, will be a net beneﬁt to society.In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models.====回复====Llama 2-Chat 具有 7B、13B 和 70B 三种不同的参数规模。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>文本切割</p><ul><li>chunksize 和 overlap 来重叠切割<br>&nbsp; &nbsp; - \n \n\n 基于某些规则来切分的</li><li>对于复杂的文本的切分<br>&nbsp; &nbsp; - NSP任务来进行微调训练（拿自己的业务数据来喂投）<br>&nbsp; &nbsp; &nbsp; &nbsp; - A和B两个句子（段落）是否有关系<br>&nbsp; &nbsp; &nbsp; &nbsp; 若有关系则进行合并</li></ul><h3 id="4-2-检索后排序"><a href="#4-2-检索后排序" class="headerlink" title="4.2 检索后排序"></a>4.2 检索后排序</h3><p>问题：有时，最合适的答案不一定排在检索的最前面，例如：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">user_query <span class="token operator">=</span> <span class="token string">"how safe is llama 2"</span>search_results <span class="token operator">=</span> vector_db<span class="token punctuation">.</span>search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token keyword">for</span> doc <span class="token keyword">in</span> search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>doc<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>response <span class="token operator">=</span> bot<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>user_query<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"====回复===="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果输出如下：</p><pre class="line-numbers language-none"><code class="language-none">We believe that the open release of LLMs, when done safely, will be a net beneﬁt to society. Like all LLMs, Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021; Solaiman et al., 2023).We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. Figure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed source models.In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models.Additionally, these safety evaluations are performed using content standards that are likely to be biased towards the Llama 2-Chat models. We are releasing the following models to the general public for research and commercial use‡: 1.We provide a responsible use guide¶ and code examples‖ to facilitate the safe deployment of Llama 2 and Llama 2-Chat. More details of our responsible release strategy can be found in Section 5.3.====回复====我无法回答您的问题。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>方案</strong>:</p><ol><li>检索时通过招回一部分文本</li><li>通过一个排序模型对 query 和 document 重新打分排序</li></ol><p><img src="https://pic1.imgdb.cn/item/681b6be158cb8da5c8e3d9ae.png" alt="检索召回"></p><div class="alert alert-danger">以下代码运行前我们要确保能访问 Hugging Face！</div>安装`sentence_transformers`库<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> sentence_transformers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sentence_transformers <span class="token keyword">import</span> CrossEncoder<span class="token comment"># 访问调用Hugging Face模型</span>model <span class="token operator">=</span> CrossEncoder<span class="token punctuation">(</span><span class="token string">'cross-encoder/ms-marco-MiniLM-L-6-v2'</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span> <span class="token comment"># 英文，模型较小</span><span class="token comment"># model = CrossEncoder('BAAI/bge-reranker-large', max_length=512) # 多语言，国产，模型较大</span>user_query <span class="token operator">=</span> <span class="token string">"how safe is llama 2"</span><span class="token comment"># user_query = "llama 2安全性如何"</span>scores <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> doc<span class="token punctuation">)</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 按得分排序</span>sorted_list <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>scores<span class="token punctuation">,</span> search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> score<span class="token punctuation">,</span> doc <span class="token keyword">in</span> sorted_list<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>score<span class="token punctuation">}</span></span><span class="token string">\t</span><span class="token interpolation"><span class="token punctuation">{</span>doc<span class="token punctuation">}</span></span><span class="token string">\n"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果如下，可以看到下面内容是按得分然后重新排序得到的：</p><pre class="line-numbers language-none"><code class="language-none">6.613734722137451We believe that the open release of LLMs, when done safely, will be a net beneﬁt to society. Like all LLMs, Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021; Solaiman et al., 2023).5.310717582702637In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models.4.709955215454102We provide a responsible use guide¶ and code examples‖ to facilitate the safe deployment of Llama 2 and Llama 2-Chat. More details of our responsible release strategy can be found in Section 5.3.4.5439653396606445We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. Figure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed source models.4.0338897705078125Additionally, these safety evaluations are performed using content standards that are likely to be biased towards the Llama 2-Chat models. We are releasing the following models to the general public for research and commercial use‡: 1.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="alert alert-danger">！所以切割也比较重要，这里我因为前面新切割方法报错所以没有使用新的切割后的文本，这里输出的答案有些是不同的</div><h4 id="一些-Rerank-的-API-服务"><a href="#一些-Rerank-的-API-服务" class="headerlink" title="一些 Rerank 的 API 服务"></a>一些 Rerank 的 API 服务</h4><ul><li><a href="https://cohere.com/rerank">Cohere Rerank</a>：支持多语言</li><li><a href="https://jina.ai/reranker/">Jina Rerank</a>：目前只支持英文</li></ul><h3 id="4-3-混合检索（Hybrid-Search）"><a href="#4-3-混合检索（Hybrid-Search）" class="headerlink" title="4.3 混合检索（Hybrid Search）"></a><strong>4.3 混合检索（Hybrid Search）</strong></h3><p>在<strong>实际生产</strong>中，传统的关键字检索（稀疏表示）与向量检索（稠密表示）各有优劣。</p><p>举个具体例子，比如文档中包含很长的专有名词，关键字检索往往更精准而向量检索容易引入概念混淆。</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 背景说明：在医学中“小细胞肺癌”和“非小细胞肺癌”是两种不同的癌症</span>query <span class="token operator">=</span> <span class="token string">"非小细胞肺癌的患者"</span>documents <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token string">"玛丽患有肺癌，癌细胞已转移"</span><span class="token punctuation">,</span>    <span class="token string">"刘某肺癌I期"</span><span class="token punctuation">,</span>    <span class="token string">"张某经诊断为非小细胞肺癌III期"</span><span class="token punctuation">,</span>    <span class="token string">"小细胞肺癌是肺癌的一种"</span><span class="token punctuation">]</span>query_vec <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span><span class="token punctuation">[</span>query<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>doc_vecs <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Cosine distance:"</span><span class="token punctuation">)</span><span class="token keyword">for</span> vec <span class="token keyword">in</span> doc_vecs<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>cos_sim<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出的结果如下：</p><pre class="line-numbers language-none"><code class="language-none">Cosine distance:0.89128713111663220.88961358836605530.90398946691422090.9131454293290566<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>所以，有时候我们需要结合不同的检索算法，来达到比单一检索算法更优的效果。这就是<strong>混合检索</strong>。<br>混合检索的核心是，综合文档 $d$ 在不同检索算法下的排序名次（rank），为其生成最终排序。<br>一个最常用的算法叫 <strong>Reciprocal Rank Fusion（RRF）</strong><br>$rrf(d)=\sum_{a\in A}\frac{1}{k+rank_a(d)}$<br>其中 $A$ 表示所有使用的检索算法的集合，$rank_a(d)$ 表示使用算法 $a$ 检索时，文档 $d$ 的排序，$k$ 是个常数。<br>很多向量数据库都支持混合检索，比如 <a href="https://weaviate.io/blog/hybrid-search-explained">Weaviate</a>、<a href="https://www.pinecone.io/learn/hybrid-search-intro/">Pinecone</a> 等。也可以根据上述原理自己实现。</p><h4 id="4-3-1-手写个简单的例子"><a href="#4-3-1-手写个简单的例子" class="headerlink" title="4.3.1 手写个简单的例子"></a>4.3.1 手写个简单的例子</h4><div class="alert alert-danger">注意：需要安装好 Elastic Search Server，并启动！</div><p>1.基于关键字检索的排序</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> elasticsearch7<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">class</span> <span class="token class-name">MyEsConnector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> es_client<span class="token punctuation">,</span> index_name<span class="token punctuation">,</span> keyword_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>es_client <span class="token operator">=</span> es_client        self<span class="token punctuation">.</span>index_name <span class="token operator">=</span> index_name        self<span class="token punctuation">.</span>keyword_fn <span class="token operator">=</span> keyword_fn    <span class="token keyword">def</span> <span class="token function">add_documents</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> documents<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''文档灌库'''</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>es_client<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>index<span class="token operator">=</span>self<span class="token punctuation">.</span>index_name<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>es_client<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>delete<span class="token punctuation">(</span>index<span class="token operator">=</span>self<span class="token punctuation">.</span>index_name<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>es_client<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>create<span class="token punctuation">(</span>index<span class="token operator">=</span>self<span class="token punctuation">.</span>index_name<span class="token punctuation">)</span>        actions <span class="token operator">=</span> <span class="token punctuation">[</span>            <span class="token punctuation">{</span>                <span class="token string">"_index"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>index_name<span class="token punctuation">,</span>                <span class="token string">"_source"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>                    <span class="token string">"keywords"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>keyword_fn<span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token string">"text"</span><span class="token punctuation">:</span> doc<span class="token punctuation">,</span>                    <span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f"doc_</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">"</span></span>                <span class="token punctuation">}</span>            <span class="token punctuation">}</span>            <span class="token keyword">for</span> i<span class="token punctuation">,</span> doc <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span>        <span class="token punctuation">]</span>        helpers<span class="token punctuation">.</span>bulk<span class="token punctuation">(</span>self<span class="token punctuation">.</span>es_client<span class="token punctuation">,</span> actions<span class="token punctuation">)</span>        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query_string<span class="token punctuation">,</span> top_n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''检索'''</span>        search_query <span class="token operator">=</span> <span class="token punctuation">{</span>            <span class="token string">"match"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>                <span class="token string">"keywords"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>keyword_fn<span class="token punctuation">(</span>query_string<span class="token punctuation">)</span>            <span class="token punctuation">}</span>        <span class="token punctuation">}</span>        res <span class="token operator">=</span> self<span class="token punctuation">.</span>es_client<span class="token punctuation">.</span>search<span class="token punctuation">(</span>            index<span class="token operator">=</span>self<span class="token punctuation">.</span>index_name<span class="token punctuation">,</span> query<span class="token operator">=</span>search_query<span class="token punctuation">,</span> size<span class="token operator">=</span>top_n<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">{</span>            hit<span class="token punctuation">[</span><span class="token string">"_source"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>                <span class="token string">"text"</span><span class="token punctuation">:</span> hit<span class="token punctuation">[</span><span class="token string">"_source"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                <span class="token string">"rank"</span><span class="token punctuation">:</span> i<span class="token punctuation">,</span>            <span class="token punctuation">}</span>            <span class="token keyword">for</span> i<span class="token punctuation">,</span> hit <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>res<span class="token punctuation">[</span><span class="token string">"hits"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"hits"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> chinese_utils <span class="token keyword">import</span> to_keywords  <span class="token comment"># 使用中文的关键字提取函数</span><span class="token comment"># 引入配置文件</span>ELASTICSEARCH_BASE_URL <span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ELASTICSEARCH_BASE_URL'</span><span class="token punctuation">)</span>ELASTICSEARCH_PASSWORD <span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ELASTICSEARCH_PASSWORD'</span><span class="token punctuation">)</span>ELASTICSEARCH_NAME<span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ELASTICSEARCH_NAME'</span><span class="token punctuation">)</span>es <span class="token operator">=</span> Elasticsearch<span class="token punctuation">(</span>    hosts<span class="token operator">=</span><span class="token punctuation">[</span>ELASTICSEARCH_BASE_URL<span class="token punctuation">]</span><span class="token punctuation">,</span>    http_auth<span class="token operator">=</span><span class="token punctuation">(</span>ELASTICSEARCH_NAME<span class="token punctuation">,</span> ELASTICSEARCH_PASSWORD<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 用户名，密码</span><span class="token punctuation">)</span><span class="token comment"># 创建 ES 连接器</span>es_connector <span class="token operator">=</span> MyEsConnector<span class="token punctuation">(</span>es<span class="token punctuation">,</span> <span class="token string">"demo_es_rrf"</span><span class="token punctuation">,</span> to_keywords<span class="token punctuation">)</span><span class="token comment"># 文档灌库</span>es_connector<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token comment"># 关键字检索</span>keyword_search_results <span class="token operator">=</span> es_connector<span class="token punctuation">.</span>search<span class="token punctuation">(</span>query<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>keyword_search_results<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>2.基于向量检索的排序</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建向量数据库连接器</span>vecdb_connector <span class="token operator">=</span> MyVectorDBConnector<span class="token punctuation">(</span><span class="token string">"demo_vec_rrf"</span><span class="token punctuation">,</span> get_embeddings<span class="token punctuation">)</span><span class="token comment"># 文档灌库</span>vecdb_connector<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token comment"># 向量检索</span>vector_search_results <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">"doc_"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>documents<span class="token punctuation">.</span>index<span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>        <span class="token string">"text"</span><span class="token punctuation">:</span> doc<span class="token punctuation">,</span>        <span class="token string">"rank"</span><span class="token punctuation">:</span> i    <span class="token punctuation">}</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> doc <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>        vecdb_connector<span class="token punctuation">.</span>search<span class="token punctuation">(</span>query<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"documents"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    <span class="token punctuation">)</span><span class="token punctuation">}</span>  <span class="token comment"># 把结果转成跟上面关键字检索结果一样的格式</span><span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>vector_search_results<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>3.基于 RRF 的融合排序</p><p>参考资料：<a href="https://learn.microsoft.com/zh-cn/azure/search/hybrid-search-ranking">https://learn.microsoft.com/zh-cn/azure/search/hybrid-search-ranking</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> json<span class="token keyword">def</span> <span class="token function">rrf</span><span class="token punctuation">(</span>ranks<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    ret <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    <span class="token comment"># 遍历每次的排序结果</span>    <span class="token keyword">for</span> rank <span class="token keyword">in</span> ranks<span class="token punctuation">:</span>        <span class="token comment"># 遍历排序中每个元素</span>        <span class="token keyword">for</span> <span class="token builtin">id</span><span class="token punctuation">,</span> val <span class="token keyword">in</span> rank<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token builtin">id</span> <span class="token keyword">not</span> <span class="token keyword">in</span> ret<span class="token punctuation">:</span>                ret<span class="token punctuation">[</span><span class="token builtin">id</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"score"</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token punctuation">:</span> val<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">}</span>            <span class="token comment"># 计算 RRF 得分</span>            ret<span class="token punctuation">[</span><span class="token builtin">id</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"score"</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1.0</span><span class="token operator">/</span><span class="token punctuation">(</span>k<span class="token operator">+</span>val<span class="token punctuation">[</span><span class="token string">"rank"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># 按 RRF 得分排序，并返回</span>    <span class="token keyword">return</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>ret<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> item<span class="token punctuation">:</span> item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"score"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 融合两次检索的排序结果</span>reranked <span class="token operator">=</span> rrf<span class="token punctuation">(</span><span class="token punctuation">[</span>keyword_search_results<span class="token punctuation">,</span> vector_search_results<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>reranked<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="五、PDF文档中的表格怎样处理"><a href="#五、PDF文档中的表格怎样处理" class="headerlink" title="五、PDF文档中的表格怎样处理"></a>五、PDF文档中的表格怎样处理</h2><p><img src="https://pic1.imgdb.cn/item/681b6be158cb8da5c8e3d9af.png" alt="PDF中表格处理"></p><h3 id="5-1-将每页-PDF-转成图片"><a href="#5-1-将每页-PDF-转成图片" class="headerlink" title="5.1 将每页 PDF 转成图片"></a><strong>5.1 将每页 PDF 转成图片</strong></h3><p>安装 <code>PyMuPDF</code> 和 <code>matplotlib</code> 库</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> PyMuPDFpip <span class="token function">install</span> matplotlib<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> fitz<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">def</span> <span class="token function">pdf2images</span><span class="token punctuation">(</span>pdf_file<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''将 PDF 每页转成一个 PNG 图像'''</span>    <span class="token comment"># 保存路径为原 PDF 文件名（不含扩展名）</span>    output_directory_path<span class="token punctuation">,</span> _ <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>splitext<span class="token punctuation">(</span>pdf_file<span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>output_directory_path<span class="token punctuation">)</span><span class="token punctuation">:</span>        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>output_directory_path<span class="token punctuation">)</span>    <span class="token comment"># 加载 PDF 文件</span>    pdf_document <span class="token operator">=</span> fitz<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>pdf_file<span class="token punctuation">)</span>    <span class="token comment"># 每页转一张图</span>    <span class="token keyword">for</span> page_number <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>pdf_document<span class="token punctuation">.</span>page_count<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 取一页</span>        page <span class="token operator">=</span> pdf_document<span class="token punctuation">[</span>page_number<span class="token punctuation">]</span>        <span class="token comment"># 转图像</span>        pix <span class="token operator">=</span> page<span class="token punctuation">.</span>get_pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 从位图创建 PNG 对象</span>        image <span class="token operator">=</span> Image<span class="token punctuation">.</span>frombytes<span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>pix<span class="token punctuation">.</span>width<span class="token punctuation">,</span> pix<span class="token punctuation">.</span>height<span class="token punctuation">]</span><span class="token punctuation">,</span> pix<span class="token punctuation">.</span>samples<span class="token punctuation">)</span>        <span class="token comment"># 保存 PNG 文件</span>        image<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"./</span><span class="token interpolation"><span class="token punctuation">{</span>output_directory_path<span class="token punctuation">}</span></span><span class="token string">/page_</span><span class="token interpolation"><span class="token punctuation">{</span>page_number <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">.png"</span></span><span class="token punctuation">)</span>    <span class="token comment"># 关闭 PDF 文件</span>    pdf_document<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">import</span> os<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">def</span> <span class="token function">show_images</span><span class="token punctuation">(</span>dir_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''显示目录下的 PNG 图像'''</span>    <span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>dir_path<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token builtin">file</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'.png'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment"># 打开图像</span>            img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dir_path<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment"># 显示图像</span>            plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>            plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>  <span class="token comment"># 不显示坐标轴</span>            plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">pdf2images<span class="token punctuation">(</span><span class="token string">"llama2_page8.pdf"</span><span class="token punctuation">)</span>show_images<span class="token punctuation">(</span><span class="token string">"llama2_page8"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>结果输出如下：</p><p><img src="https://pic1.imgdb.cn/item/681bf96d58cb8da5c8e3e89a.png" alt="PDF表格转图片"></p><h3 id="5-2-识别文档（图片）中的表格"><a href="#5-2-识别文档（图片）中的表格" class="headerlink" title="5.2 识别文档（图片）中的表格"></a><strong>5.2 识别文档（图片）中的表格</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MaxResize</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''缩放图像'''</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> max_size<span class="token operator">=</span><span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>max_size <span class="token operator">=</span> max_size    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image<span class="token punctuation">)</span><span class="token punctuation">:</span>        width<span class="token punctuation">,</span> height <span class="token operator">=</span> image<span class="token punctuation">.</span>size        current_max_size <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">)</span>        scale <span class="token operator">=</span> self<span class="token punctuation">.</span>max_size <span class="token operator">/</span> current_max_size        resized_image <span class="token operator">=</span> image<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>            <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">round</span><span class="token punctuation">(</span>scale <span class="token operator">*</span> width<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">round</span><span class="token punctuation">(</span>scale <span class="token operator">*</span> height<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token punctuation">)</span>        <span class="token keyword">return</span> resized_image<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>安装三个环境包：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> torchvisionpip <span class="token function">install</span> transformerspip <span class="token function">install</span> timm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token comment"># 图像预处理</span>detection_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>    <span class="token punctuation">[</span>        MaxResize<span class="token punctuation">(</span><span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token comment"># 将原始的PILImage格式的数据格式化为可被pytorch快速处理的张量类型</span>        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForObjectDetection<span class="token comment"># 加载 TableTransformer 模型</span>model <span class="token operator">=</span> AutoModelForObjectDetection<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>    <span class="token string">"microsoft/table-transformer-detection"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>识别后的坐标换算和后处理</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 识别后的坐标换算与后处理</span><span class="token keyword">def</span> <span class="token function">box_cxcywh_to_xyxy</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''坐标转换'''</span>    x_c<span class="token punctuation">,</span> y_c<span class="token punctuation">,</span> w<span class="token punctuation">,</span> h <span class="token operator">=</span> x<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    b <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>x_c <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>y_c <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> h<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_c <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>y_c <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> h<span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>b<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">rescale_bboxes</span><span class="token punctuation">(</span>out_bbox<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''区域缩放'''</span>    width<span class="token punctuation">,</span> height <span class="token operator">=</span> size    boxes <span class="token operator">=</span> box_cxcywh_to_xyxy<span class="token punctuation">(</span>out_bbox<span class="token punctuation">)</span>    boxes <span class="token operator">=</span> boxes <span class="token operator">*</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>        <span class="token punctuation">[</span>width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> height<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32    <span class="token punctuation">)</span>    <span class="token keyword">return</span> boxes<span class="token keyword">def</span> <span class="token function">outputs_to_objects</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> img_size<span class="token punctuation">,</span> id2label<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''从模型输出中取定位框坐标'''</span>    m <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    pred_labels <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    pred_scores <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>values<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    pred_bboxes <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">"pred_boxes"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>    pred_bboxes <span class="token operator">=</span> <span class="token punctuation">[</span>        elem<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> elem <span class="token keyword">in</span> rescale_bboxes<span class="token punctuation">(</span>pred_bboxes<span class="token punctuation">,</span> img_size<span class="token punctuation">)</span>    <span class="token punctuation">]</span>    objects <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> label<span class="token punctuation">,</span> score<span class="token punctuation">,</span> bbox <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>pred_labels<span class="token punctuation">,</span> pred_scores<span class="token punctuation">,</span> pred_bboxes<span class="token punctuation">)</span><span class="token punctuation">:</span>        class_label <span class="token operator">=</span> id2label<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> <span class="token keyword">not</span> class_label <span class="token operator">==</span> <span class="token string">"no object"</span><span class="token punctuation">:</span>            objects<span class="token punctuation">.</span>append<span class="token punctuation">(</span>                <span class="token punctuation">{</span>                    <span class="token string">"label"</span><span class="token punctuation">:</span> class_label<span class="token punctuation">,</span>                    <span class="token string">"score"</span><span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token string">"bbox"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">(</span>elem<span class="token punctuation">)</span> <span class="token keyword">for</span> elem <span class="token keyword">in</span> bbox<span class="token punctuation">]</span><span class="token punctuation">,</span>                <span class="token punctuation">}</span>            <span class="token punctuation">)</span>    <span class="token keyword">return</span> objects<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>识别表格，并将表格部分单独存为图像文件</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token comment"># 识别表格，并将表格部分单独存为图像文件</span><span class="token keyword">def</span> <span class="token function">detect_and_crop_save_table</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 加载图像（PDF页）    </span>    image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>    filename<span class="token punctuation">,</span> _ <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>splitext<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>basename<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 输出路径</span>    cropped_table_directory <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"table_images"</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>cropped_table_directory<span class="token punctuation">)</span><span class="token punctuation">:</span>        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>cropped_table_directory<span class="token punctuation">)</span>    <span class="token comment"># 预处理</span>    pixel_values <span class="token operator">=</span> detection_transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    <span class="token comment"># 识别表格</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>pixel_values<span class="token punctuation">)</span>    <span class="token comment"># 后处理，得到表格子区域</span>    id2label <span class="token operator">=</span> model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>id2label    id2label<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>id2label<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"no object"</span>    detected_tables <span class="token operator">=</span> outputs_to_objects<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> image<span class="token punctuation">.</span>size<span class="token punctuation">,</span> id2label<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"number of tables detected </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>detected_tables<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>detected_tables<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 将识别从的表格区域单独存为图像</span>        cropped_table <span class="token operator">=</span> image<span class="token punctuation">.</span>crop<span class="token punctuation">(</span>detected_tables<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"bbox"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        cropped_table<span class="token punctuation">.</span>save<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>cropped_table_directory<span class="token punctuation">,</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>filename<span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>idx<span class="token punctuation">}</span></span><span class="token string">.png"</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后结果输出如下：<br><img src="https://pic1.imgdb.cn/item/681bfaca58cb8da5c8e3e8a9.png" alt="表格转图片"></p><p><img src="https://pic1.imgdb.cn/item/681bfaca58cb8da5c8e3e8a8.png" alt="表格转图片"></p><h3 id="5-3-基于-GPT-4-Vision-API-做表格回答"><a href="#5-3-基于-GPT-4-Vision-API-做表格回答" class="headerlink" title="5.3 基于 GPT-4 Vision API 做表格回答"></a><strong>5.3 基于 GPT-4 Vision API 做表格回答</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> base64<span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAIclient <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">encode_image</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> <span class="token string">"rb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> image_file<span class="token punctuation">:</span>    <span class="token keyword">return</span> base64<span class="token punctuation">.</span>b64encode<span class="token punctuation">(</span>image_file<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">image_qa</span><span class="token punctuation">(</span>query<span class="token punctuation">,</span> image_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    base64_image <span class="token operator">=</span> encode_image<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>    response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>        model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">,</span>        temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>        seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">,</span>        messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{</span>            <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span>              <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>                  <span class="token punctuation">{</span><span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"text"</span><span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token punctuation">:</span> query<span class="token punctuation">}</span><span class="token punctuation">,</span>                  <span class="token punctuation">{</span>                      <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"image_url"</span><span class="token punctuation">,</span>                      <span class="token string">"image_url"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>                          <span class="token string">"url"</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f"data:image/jpeg;base64,</span><span class="token interpolation"><span class="token punctuation">{</span>base64_image<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">,</span>                      <span class="token punctuation">}</span><span class="token punctuation">,</span>                  <span class="token punctuation">}</span><span class="token punctuation">,</span>              <span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token punctuation">)</span>    <span class="token keyword">return</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>contentresponse <span class="token operator">=</span> image_qa<span class="token punctuation">(</span><span class="token string">"哪个模型在AGI Eval数据集上表现最好。得分多少"</span><span class="token punctuation">,</span><span class="token string">"llama2_page8/table_images/page_1_0.png"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果输出如下：</p><pre class="line-numbers language-none"><code class="language-none">在AGI Eval数据集上表现最好的模型是 **Llama 2 70B**，得分为 **54.2**。<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以看到，大模型的回答就是根据我们上面的图片内容回答的。</p><h3 id="5-4-用GPT-4-Vision-生成表格-图片-描述-并向量化用于检索"><a href="#5-4-用GPT-4-Vision-生成表格-图片-描述-并向量化用于检索" class="headerlink" title="5.4 用GPT-4 Vision 生成表格(图片)描述,并向量化用于检索"></a><strong>5.4 用GPT-4 Vision 生成表格(图片)描述,并向量化用于检索</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> chromadb<span class="token keyword">from</span> chromadb<span class="token punctuation">.</span>config <span class="token keyword">import</span> Settings<span class="token keyword">class</span> <span class="token class-name">NewVectorDBConnector</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> collection_name<span class="token punctuation">,</span> embedding_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>        chroma_client <span class="token operator">=</span> chromadb<span class="token punctuation">.</span>Client<span class="token punctuation">(</span>Settings<span class="token punctuation">(</span>allow_reset<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 为了演示，实际不需要每次 reset()</span>        chroma_client<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 创建一个 collection</span>        self<span class="token punctuation">.</span>collection <span class="token operator">=</span> chroma_client<span class="token punctuation">.</span>get_or_create_collection<span class="token punctuation">(</span>            name<span class="token operator">=</span>collection_name<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding_fn <span class="token operator">=</span> embedding_fn    <span class="token keyword">def</span> <span class="token function">add_documents</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> documents<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''向 collection 中添加文档与向量'''</span>        self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>add<span class="token punctuation">(</span>            embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding_fn<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 每个文档的向量</span>            documents<span class="token operator">=</span>documents<span class="token punctuation">,</span>  <span class="token comment"># 文档的原文</span>            ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"id</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">"</span></span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># 每个文档的 id</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">add_images</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image_paths<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''向 collection 中添加图像'''</span>        documents <span class="token operator">=</span> <span class="token punctuation">[</span>            image_qa<span class="token punctuation">(</span><span class="token string">"请简要描述图片中的信息"</span><span class="token punctuation">,</span>image<span class="token punctuation">)</span>            <span class="token keyword">for</span> image <span class="token keyword">in</span> image_paths        <span class="token punctuation">]</span>        self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>add<span class="token punctuation">(</span>            embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding_fn<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 每个文档的向量</span>            documents<span class="token operator">=</span>documents<span class="token punctuation">,</span>  <span class="token comment"># 文档的原文</span>            ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"id</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">"</span></span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 每个文档的 id</span>            metadatas<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"image"</span><span class="token punctuation">:</span> image<span class="token punctuation">}</span> <span class="token keyword">for</span> image <span class="token keyword">in</span> image_paths<span class="token punctuation">]</span> <span class="token comment"># 用 metadata 标记源图像路径</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query<span class="token punctuation">,</span> top_n<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">'''检索向量数据库'''</span>        results <span class="token operator">=</span> self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>query<span class="token punctuation">(</span>            query_embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding_fn<span class="token punctuation">(</span><span class="token punctuation">[</span>query<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            n_results<span class="token operator">=</span>top_n        <span class="token punctuation">)</span>        <span class="token keyword">return</span> resultsimages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>dir_path <span class="token operator">=</span> <span class="token string">"llama2_page8/table_images"</span><span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>dir_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">file</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'.png'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 打开图像</span>        images<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dir_path<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">)</span>new_db_connector <span class="token operator">=</span> NewVectorDBConnector<span class="token punctuation">(</span><span class="token string">"table_demo"</span><span class="token punctuation">,</span>get_embeddings<span class="token punctuation">)</span>new_db_connector<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span>images<span class="token punctuation">)</span>query  <span class="token operator">=</span> <span class="token string">"哪个模型在AGI Eval数据集上表现最差。得分多少"</span>results <span class="token operator">=</span> new_db_connector<span class="token punctuation">.</span>search<span class="token punctuation">(</span>query<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>metadata <span class="token operator">=</span> results<span class="token punctuation">[</span><span class="token string">"metadatas"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"====检索结果===="</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>metadata<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"====回复===="</span><span class="token punctuation">)</span>response <span class="token operator">=</span> image_qa<span class="token punctuation">(</span>query<span class="token punctuation">,</span>metadata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>输出结果如下：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">==</span><span class="token operator">==</span>检索结果<span class="token operator">==</span><span class="token operator">==</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'image'</span><span class="token punctuation">:</span> <span class="token string">'llama2_page8/table_images\\page_1_0.png'</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token operator">==</span>回复<span class="token operator">==</span><span class="token operator">==</span>在AGI Eval数据集上表现最差的模型是Falcon 7B，得分为<span class="token number">21.2</span>。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="一些面向-RAG-的文档解析辅助工具"><a href="#一些面向-RAG-的文档解析辅助工具" class="headerlink" title="一些面向 RAG 的文档解析辅助工具"></a>一些面向 RAG 的文档解析辅助工具</h3><ul><li><a href="https://pymupdf.readthedocs.io/en/latest/">PyMuPDF</a>: PDF 文件处理基础库，带有基于规则的表格与图像抽取（不准）</li><li><a href="https://github.com/infiniflow/ragflow">RAGFlow</a>: 一款基于深度文档理解构建的开源 RAG 引擎，支持多种文档格式（火爆）（重要）</li><li><a href="https://unstructured.io/">Unstructured.io</a>: 一个开源+SaaS形式的文档解析库，支持多种文档格式</li><li><a href="https://docs.llamaindex.ai/en/stable/llama_cloud/llama_parse/">LlamaParse</a>：付费 API 服务，由 LlamaIndex 官方提供，解析不保证100%准确，实测偶有文字丢失或错位发生</li><li><a href="https://mathpix.com/">Mathpix</a>：付费 API 服务，效果较好，可解析段落结构、表格、公式等，贵！</li></ul><p>在工程上，PDF 解析本身是个复杂且琐碎的工作。以上工具都不完美，建议在自己实际场景测试后选择使用。</p><h2 id="六、说说-GraphRAG"><a href="#六、说说-GraphRAG" class="headerlink" title="六、说说 GraphRAG"></a>六、说说 GraphRAG</h2><p><img src="https://pic1.imgdb.cn/item/681b6c4e58cb8da5c8e3d9ea.png" alt="GraphRAG"></p><ol><li><strong>什么是 GraphRAG</strong>：核心思想是将知识预先处理成知识图谱</li><li><strong>优点</strong>：适合复杂问题，尤其是以查询为中心的总结，例如：“XXX团队去年有哪些贡献”</li><li><strong>缺点</strong>：知识图谱的构建、清洗、维护更新等都有可观的成本</li><li><strong>建议</strong>：<br>&nbsp; &nbsp;- GraphRAG 不是万能良药<br>&nbsp; &nbsp;- 领会其核心思想<br>&nbsp; &nbsp;- 遇到传统 RAG 无论如何优化都不好解决的问题时，酌情使用</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="RAG-的流程"><a href="#RAG-的流程" class="headerlink" title="RAG 的流程"></a>RAG 的流程</h3><ul><li>离线步骤：</li></ul><ol><li>文档加载</li><li>文档切分</li><li>向量化</li><li>灌入向量数据库</li></ol><ul><li>在线步骤</li></ul><ol><li>获取用户问题</li><li>用户问题向量化</li><li>检索向量数据库</li><li>将检索结果和用户问题填入 Prompt 模板</li><li>用最终获得的 Prompt 调用 LLM</li><li>用 LLM 生成回复</li></ol><h3 id="如果使用了开源-RAG，但是不好用怎么办？"><a href="#如果使用了开源-RAG，但是不好用怎么办？" class="headerlink" title="如果使用了开源 RAG，但是不好用怎么办？"></a>如果使用了开源 RAG，但是不好用怎么办？</h3><ol><li>检查预处理效果：文档加载是否正确，切割的是否合理</li><li>测试检验效果：问题检索回来的文本片段是否包含答案</li><li>测试大模型能力：给定问题和包含答案文本片段的前提下，大模型能不能正确回答问题</li></ol><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="一、在测试Embeddings模型时报错"><a href="#一、在测试Embeddings模型时报错" class="headerlink" title="一、在测试Embeddings模型时报错"></a>一、在测试Embeddings模型时报错</h3><h4 id="报错代码："><a href="#报错代码：" class="headerlink" title="报错代码："></a>报错代码：</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_query <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"测试文本"</span><span class="token punctuation">]</span>vec <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>test_query<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Total dimension: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"First 10 elements: </span><span class="token interpolation"><span class="token punctuation">{</span>vec<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token format-spec">10]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="报错内容："><a href="#报错内容：" class="headerlink" title="报错内容："></a>报错内容：</h4><pre class="line-numbers language-none"><code class="language-none">---------------------------------------------------------------------------BadRequestError &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Traceback (most recent call last)Cell In[11], line 2&nbsp; &nbsp; &nbsp; 1 test_query = ["测试文本"]----&gt; 2 vec = get_embeddings(test_query)[0]&nbsp; &nbsp; &nbsp; 3 print(f"Total dimension: {len(vec)}")&nbsp; &nbsp; &nbsp; 4 print(f"First 10 elements: {vec[:10]}")Cell In[10], line 9, in get_embeddings(texts, model, dimensions)&nbsp; &nbsp; &nbsp; 6 &nbsp; &nbsp; data = client.embeddings.create(&nbsp; &nbsp; &nbsp; 7 &nbsp; &nbsp; &nbsp; &nbsp; input=texts, model=model, dimensions=dimensions).data&nbsp; &nbsp; &nbsp; 8 else:----&gt; 9 &nbsp; &nbsp; data = client.embeddings.create(input=texts, model=model).data&nbsp; &nbsp; &nbsp;10 return [x.embedding for x in data]File d:\Soft\Dev_Soft\anaconda3\envs\rag-learn\lib\site-packages\openai\resources\embeddings.py:128, in Embeddings.create(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)&nbsp; &nbsp; 122 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; embedding.embedding = np.frombuffer( &nbsp;# type: ignore[no-untyped-call]&nbsp; &nbsp; 123 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; base64.b64decode(data), dtype="float32"&nbsp; &nbsp; 124 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ).tolist()&nbsp; &nbsp; 126 &nbsp; &nbsp; return obj--&gt; 128 return self._post(&nbsp; &nbsp; 129 &nbsp; &nbsp; "/embeddings",&nbsp; &nbsp; 130 &nbsp; &nbsp; body=maybe_transform(params, embedding_create_params.EmbeddingCreateParams),&nbsp; &nbsp; 131 &nbsp; &nbsp; options=make_request_options(&nbsp; &nbsp; 132 &nbsp; &nbsp; &nbsp; &nbsp; extra_headers=extra_headers,&nbsp; &nbsp; 133 &nbsp; &nbsp; &nbsp; &nbsp; extra_query=extra_query,&nbsp; &nbsp; 134 &nbsp; &nbsp; &nbsp; &nbsp; extra_body=extra_body,&nbsp; &nbsp; 135 &nbsp; &nbsp; &nbsp; &nbsp; timeout=timeout,&nbsp; &nbsp; 136 &nbsp; &nbsp; &nbsp; &nbsp; post_parser=parser,&nbsp; &nbsp; 137 &nbsp; &nbsp; ),&nbsp; &nbsp; 138 &nbsp; &nbsp; cast_to=CreateEmbeddingResponse,&nbsp; &nbsp; 139 )File d:\Soft\Dev_Soft\anaconda3\envs\rag-learn\lib\site-packages\openai\_base_client.py:1242, in SyncAPIClient.post(self, path, cast_to, body, options, files, stream, stream_cls)&nbsp; &nbsp;1228 def post(&nbsp; &nbsp;1229 &nbsp; &nbsp; self,&nbsp; &nbsp;1230 &nbsp; &nbsp; path: str,&nbsp; &nbsp;(...)&nbsp; &nbsp;1237 &nbsp; &nbsp; stream_cls: type[_StreamT] | None = None,&nbsp; &nbsp;1238 ) -&gt; ResponseT | _StreamT:&nbsp; &nbsp;1239 &nbsp; &nbsp; opts = FinalRequestOptions.construct(&nbsp; &nbsp;1240 &nbsp; &nbsp; &nbsp; &nbsp; method="post", url=path, json_data=body, files=to_httpx_files(files), **options&nbsp; &nbsp;1241 &nbsp; &nbsp; )-&gt; 1242 &nbsp; &nbsp; return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))File d:\Soft\Dev_Soft\anaconda3\envs\rag-learn\lib\site-packages\openai\_base_client.py:919, in SyncAPIClient.request(self, cast_to, options, remaining_retries, stream, stream_cls)&nbsp; &nbsp; 916 else:&nbsp; &nbsp; 917 &nbsp; &nbsp; retries_taken = 0--&gt; 919 return self._request(&nbsp; &nbsp; 920 &nbsp; &nbsp; cast_to=cast_to,&nbsp; &nbsp; 921 &nbsp; &nbsp; options=options,&nbsp; &nbsp; 922 &nbsp; &nbsp; stream=stream,&nbsp; &nbsp; 923 &nbsp; &nbsp; stream_cls=stream_cls,&nbsp; &nbsp; 924 &nbsp; &nbsp; retries_taken=retries_taken,&nbsp; &nbsp; 925 )File d:\Soft\Dev_Soft\anaconda3\envs\rag-learn\lib\site-packages\openai\_base_client.py:1023, in SyncAPIClient._request(self, cast_to, options, retries_taken, stream, stream_cls)&nbsp; &nbsp;1020 &nbsp; &nbsp; &nbsp; &nbsp; err.response.read()&nbsp; &nbsp;1022 &nbsp; &nbsp; log.debug("Re-raising status error")-&gt; 1023 &nbsp; &nbsp; raise self._make_status_error_from_response(err.response) from None&nbsp; &nbsp;1025 return self._process_response(&nbsp; &nbsp;1026 &nbsp; &nbsp; cast_to=cast_to,&nbsp; &nbsp;1027 &nbsp; &nbsp; options=options,&nbsp; &nbsp;(...)&nbsp; &nbsp;1031 &nbsp; &nbsp; retries_taken=retries_taken,&nbsp; &nbsp;1032 )BadRequestError: Error code: 400 - {'error': {'message': 'Unknown model: text-embedding-ada-002 (request id: 2025050722295246817707943411229) (request id: 2025050722295245370563533xRaOCs)', 'type': '', 'param': '', 'code': 'unknown_model'}}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="错误记录："><a href="#错误记录：" class="headerlink" title="错误记录："></a>错误记录：</h4><p>这里频繁报错的原因是使用dotenv和.env文件调用api不成功而导致的错误，后续在申请调用OpenAI API的程序处，通过在client.OpenAI()函数里面直接调用填写api key和请求地址解决了这个问题。至于为什么会导致这个错误目前还不清楚，等后续在研究看看。</p><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> AI大模型应用开发 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> RAG </tag>
            
            <tag> Embeddings </tag>
            
            <tag> OpenAI </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo+github+Netlify+ClouldFlare搭建个人博客</title>
      <link href="/hexo-github-netlify-clouldflare-da-jian-ge-ren-bo-ke/"/>
      <url>/hexo-github-netlify-clouldflare-da-jian-ge-ren-bo-ke/</url>
      
        <content type="html"><![CDATA[<h2 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h2><p>这个教程使用的个人博客框架是hexo，博客文件拖管于github，博客网站用netlify生成，国内访问采用Cloudflare进行CDN加速。</p><h3 id="1-1-创建GitHub仓库"><a href="#1-1-创建GitHub仓库" class="headerlink" title="1.1 创建GitHub仓库"></a>1.1 创建GitHub仓库</h3><p>进入GitHub网站，在网站上新建一个代码仓库用于保存我们的网页</p><p>点击<code>Your repositories</code>，进入仓库页面。</p><p><img src="https://pic1.imgdb.cn/item/680aeb6b58cb8da5c8c97cee.png" alt="0"></p><p>点击<code>New</code>按钮，进入仓库创建页面。</p><p><img src="https://pic1.imgdb.cn/item/680aeb6b58cb8da5c8c97cec.png" alt="01"></p><p>填写<strong>Repository name</strong>仓库名，格式必须为<code>&lt;用户名&gt;.github.io</code>，我设置的用户名为<code>ismoyuai.github.io</code> 然后点击 <code>Create repository</code>。</p><p><img src="https://pic1.imgdb.cn/item/680aeb6b58cb8da5c8c97ceb.png" alt="02"></p><p>这样我们仓库初步准备已经好了，下面安装Node.js</p><h3 id="1-2-安装Node-js以及npm"><a href="#1-2-安装Node-js以及npm" class="headerlink" title="1.2 安装Node.js以及npm"></a>1.2 安装Node.js以及npm</h3><p>进入<a href="https://nodejs.org/en/download/">node.js官网</a>下载相应的版本，在Windows上安装一般按下图选择，最后点击下载</p><p><img src="https://pic1.imgdb.cn/item/680aeb6b58cb8da5c8c97ced.png" alt="03"></p><p>安装会连同包含的环境变量和<code>npm</code>一起安装，安装后，我们检测<code>Node.js</code>是否安装成功，打开终端，输入命令：</p><p>第一个：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">node</span> <span class="token parameter variable">-v</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行命令后，如果安装成功会显示<code>nodejs</code>版本号。</p><p>第二个：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token parameter variable">-v</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>执行成功后，如果安装成功会显示<code>npm</code>版本号。</p><h3 id="1-3-安装Git"><a href="#1-3-安装Git" class="headerlink" title="1.3 安装Git"></a>1.3 安装Git</h3><p>到<a href="https://git-scm.com/downloads/win">Git官网</a>下载最新版本，这里我下载的是64为的安装版本，下载完成后打开，然后按步骤默认安装即可。</p><p><img src="https://pic1.imgdb.cn/item/680aeb6b58cb8da5c8c97cef.png" alt="05"></p><h3 id="1-4-安装Hexo主题框架"><a href="#1-4-安装Hexo主题框架" class="headerlink" title="1.4 安装Hexo主题框架"></a>1.4 安装Hexo主题框架</h3><p>安装Hexo框架需要借助<code>npm</code>包管理器安装，打开终端执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> <span class="token parameter variable">-g</span> hexo-cli <span class="token comment"># 全局安装hexo命令行工具</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>其中<code>-g</code>参数表示全局安装，没有这个参数就只在当前目录下安装，建议全局安装。</p><p>安装完成后，执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo <span class="token parameter variable">-v</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个命令可以看安装hexo版本号</p><h2 id="二、搭建博客"><a href="#二、搭建博客" class="headerlink" title="二、搭建博客"></a>二、搭建博客</h2><h3 id="2-1-本地创建"><a href="#2-1-本地创建" class="headerlink" title="2.1 本地创建"></a>2.1 本地创建</h3><p>选一个你存放数据的盘，创建一个文件夹。这个文件夹用来存放我们所有博客内容和素材，后续的操作都在这个文件夹中进行，比如我在<strong>D盘</strong>创建一个<strong>MYBLOG</strong>文件夹，在<strong>D盘</strong>右键点击<code>Open Git Bash here</code>输入命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo init MYBLOG<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这个命令用来初始化我们博客框架，需要等待一段时间让它进行下载。下载完成后文件夹内容如下：</p><p><img src="https://pic1.imgdb.cn/item/680aeb6a58cb8da5c8c97cea.png" alt="06"></p><p>进入<strong>MYBLOG</strong>文件夹</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token builtin class-name">cd</span> MYBLOG<span class="token function">npm</span> <span class="token function">install</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>本地部署启动</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo ghexo s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>完成后会在本地地址启动你的本地博客。浏览器访问 <a href="http://localhost:4000，页面默认主图风格如下">http://localhost:4000，页面默认主图风格如下</a><br><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cfa.png" alt="07"></p><h3 id="2-2-部署到GitHub仓库"><a href="#2-2-部署到GitHub仓库" class="headerlink" title="2.2 部署到GitHub仓库"></a>2.2 部署到GitHub仓库</h3><p>之前的步骤中，我们已经完成了对Github账户的注册以及Github Pages的创建，接下来是将本地博客发布至Github Pages。</p><p>（1）安装发布插件，在站点目录下执行下面的命令，也就是创建的博客目录下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-deployer-git <span class="token parameter variable">--save</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>（2）git配置GitHub邮箱用户名</p><pre class="line-numbers language-none"><code class="language-none">git config --global user.email "xxx" //设置邮箱 你的Github邮箱git config --global user.name "xxx" //设置用户名 你的Github名称<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>（3）将本地目录和GitHub关联起来，输入下面命令行：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">ssh-keygen <span class="token parameter variable">-t</span> rsa <span class="token parameter variable">-C</span> <span class="token string">"你的邮箱地址"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输入后一直回车，然后在<code>C:/Users/[username]</code>目录下找到名为<code>.ssh</code>的文件夹， 文件夹内会有两个文件，一个<code>id_rsa.pub</code>一个<code>id_rsa</code>，用文本编辑器打开<code>id_rsa.pub</code>，复制里面的的内容。 然后打开Github，点击右上角的头像 <strong>Settings</strong> 选择<strong>SSH and GPG keys</strong></p><p><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cf8.png" alt="08"></p><p>（4）点击<strong>New SSH key</strong> 将之前复制的内容粘帖到Key的框中。 上面的<strong>Title</strong>可以随意，点击<strong>Add SSH key</strong> 完成添加。</p><p><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cf7.png" alt="09"></p><p>（5）然后回到Git的命令行界面，测试一下是否与GitHub连接成功。输入下面的命令行：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">ssh</span> <span class="token parameter variable">-T</span> git@github.com<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>点击回车，然后会出现一个询问内容，输入<code>yes</code>，回车，会出现一段内容，<code>Hi &lt;account name&gt;! You've successfully authenticated, but GitHub doesnot provide shell access.</code>。 说明连接成功。此处这个<code>&lt;account name&gt;</code>应该是你Github的用户名。</p><p>（6）进入博客站点目录，用文本编辑器打开<code>_config.yml</code>，这个<code>_config.yml</code>是博客的配置文件，在以后的博客修改，如个性化修改，博客SEO优化等都会使用到，修改如下图的几个地方：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> 你的博客名<span class="token key atrule">subtitle</span><span class="token punctuation">:</span> 博客的副标题，有些主题支持<span class="token key atrule">description</span><span class="token punctuation">:</span> 博客描述<span class="token key atrule">keywords</span><span class="token punctuation">:</span> 博客关键词<span class="token key atrule">author</span><span class="token punctuation">:</span> 作者，在文章中显示<span class="token key atrule">language</span><span class="token punctuation">:</span> 博客语言语种   <span class="token key atrule">timezone</span><span class="token punctuation">:</span> 时区<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cf6.png" alt="10"></p><p>（7）在文件最底部，有一个deploy，在deploy下面添加我们的GitHub站点仓库信息。填入如下代码，并如下图所示：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">deploy</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> git  <span class="token key atrule">repo</span><span class="token punctuation">:</span> git@github.com<span class="token punctuation">:</span>Github用户名/github用户名.github.io.git   <span class="token key atrule">branch</span><span class="token punctuation">:</span> master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>repo：也可使用https地址，如：<code>https://github.com/Github用户名/Github用户名.github.io.git</code></p><p><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cf5.png" alt="11"></p><p>（8）最后回到终端执行下面命令，准备将页面发布到GitHub</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 清除之前生成静态页面</span>hexo clean<span class="token comment"># 根据配置文件渲染出一套静态页面</span>hexo g<span class="token comment"># 将上一步渲染出的一系列文件上传至至Github Pages</span>hexo d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上传完成后，在浏览器中打开<strong>https://&lt;用户名&gt;.github.io</strong>，查看上传的网页。如果页面变成了之前本地调试时的样子，说明上传已经完成了。</p><h2 id="三、Netlify建站"><a href="#三、Netlify建站" class="headerlink" title="三、Netlify建站"></a>三、Netlify建站</h2><h3 id="3-1-介绍"><a href="#3-1-介绍" class="headerlink" title="3.1 介绍"></a>3.1 介绍</h3><p>Netlify是一个国外的免费的提供静态网站部署服务的平台，能够将托管 GitHub，GitLab 等上的静态网站部署上线。至于我们为什么不使用<code>github</code>自带的<code>gitpage</code>，原因很简单，访问速度慢。此外，Netlify还有很多别的功能支持。</p><h3 id="3-2-建站步骤"><a href="#3-2-建站步骤" class="headerlink" title="3.2 建站步骤"></a>3.2 建站步骤</h3><ol><li><p>首先注册并登陆 <a href="https://app.netlify.com/">Netlify</a></p><ul><li>这一步需要能够科学上网，因为这是一个国外的网站</li><li>我们的博客在开启cloundflare的CDN加速之前，也只能通过科学上网的方式访问</li></ul></li><li><p>新建站点：</p><p>点击<code>Import an existing project</code>新建站点</p></li></ol><p><img src="https://pic1.imgdb.cn/item/680aeb9658cb8da5c8c97cf9.png" alt="12"></p><ol start="3"><li>连接GitHub</li></ol><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d05.png" alt="13"></p><ol start="4"><li>选择我们的博客项目仓库</li></ol><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d06.png" alt="14"></p><ol start="5"><li>一切默认，最后点击如下按钮完成导入</li></ol><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d03.png" alt="15"></p><ol start="6"><li>完成后会得到一个URL，打开这个网址就是我们的个人博客了</li></ol><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d04.png" alt="16"></p><p>接下来先配置域名</p><h3 id="3-3-配置域名"><a href="#3-3-配置域名" class="headerlink" title="3.3 配置域名"></a>3.3 配置域名</h3><p>配置域名的前提自然是要购买域名了，从任意域名服务商处购买一个域名。</p><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d07.png" alt="17"></p><p>然后设置域名解析，类型为<code>CNAME</code>，内容为<code>xxxxx.netlify.app</code>，也就是我们刚刚建站给的域名。</p><p><img src="https://pic1.imgdb.cn/item/680aebad58cb8da5c8c97d08.png" alt="18"></p><p>设置完毕之后需要等待一段时间，因为DNS服务器需要一段时间来进行同步。</p><p>然后，我们还需要回到netlify中配置一下自己的用户域名，这样的话可以在国外获得netlify本身的CDN支持。</p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d10.png" alt="19"></p><p>输入我们配置的域名后，进行相关的配置，由于我们的域名本身已经配置了解析，这里会显示出来，不用再额外添加记录，只需要一路默认即可。最后点击Done即可</p><p>我们下面设置一下netlify本身的对于国外CDN的支持。下面箭头位置出点击<code>Set up Netlify DNS</code>，这里我已经设置过了所以显示的按钮不是这个。</p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d12.png" alt="20"></p><p>之后，我们就可以通过自己配置的域名访问自己的个人博客，比如说我的博客地址是：<a href="https://blog.ismoyu.cn/">https://blog.ismoyu.cn</a></p><p>但是，此刻我们的博客访问依然需要科学上网，因为我们还没有国内的CDN的支持，下面，我们来解决这个问题。</p><h2 id="四、ClouldFlare加速-解决国内加速问题"><a href="#四、ClouldFlare加速-解决国内加速问题" class="headerlink" title="四、ClouldFlare加速(解决国内加速问题)"></a>四、ClouldFlare加速(解决国内加速问题)</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>Netlify 虽然已经提供了 CDN 加速，但在使用过程中发现国内访问还是比较慢，Cloudflare 相对于国内的七牛云、阿里云等云服务商的 CDN 速度会慢一些，但是它有免费版本，而且最重要的是域名不用备案。</p><h3 id="加速步骤"><a href="#加速步骤" class="headerlink" title="加速步骤"></a>加速步骤</h3><ol><li>注册<a href="https://www.cloudflare.com/zh-cn/">Clouldflare</a>并登陆</li><li>添加站点</li></ol><p>进入主页，点击添加域</p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d0f.png" alt="21"></p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d11.png" alt="22"></p><ol start="3"><li><p>选择免费套餐</p></li><li><p>添加DNS记录</p></li></ol><p>和上面配置阿里云域名一样</p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d14.png" alt="23"></p><p><img src="https://pic1.imgdb.cn/item/680aebc058cb8da5c8c97d13.png" alt="24"></p><ol start="5"><li>更改名称服务器</li></ol><ul><li>主要步骤是在你的域名服务商那里修改 dns 解析服务器为 cloudflare 提供的地址，修改完成后点击完成。</li></ul><p><img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d19.png" alt="25"></p><ul><li><p>以阿里云为例</p><ol><li><p>进入域名管理配置界面</p><p><img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d1b.png" alt="26"></p></li><li><p>将域名服务器从阿里云的默认服务器改成clouldflare的服务器</p><p><img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d16.png" alt="27"></p></li></ol></li></ul><p>配置完成后等待一段时间即可</p><h3 id="配置https"><a href="#配置https" class="headerlink" title="配置https"></a>配置https</h3><p>在clouldflare配置完成之后，我们可以回到netlify去配置一下https访问。</p><ol><li><p>先确认一下dns解析:</p><p><img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d17.png" alt="28"></p></li><li><p>自动安装证书</p></li></ol><p>   <img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d1a.png" alt="29"></p><ol start="3"><li><p>最后看到如下的界面，就说明https配置完成了:</p><p><img src="https://pic1.imgdb.cn/item/680aebd658cb8da5c8c97d18.png" alt="30"></p></li></ol><p>最后测试站点，我们可以试着用自己的浏览器去访问自己配置的域名地址，如果在不科学上网的情况下能够正常看到我们自己的博客界面，那就证明我们的个人博客就配置成功了。</p><p>接下来就是关于博客主题的设置和一些个性化修改部分。</p><h2 id="五、博客主题安装以及一些个性化修改"><a href="#五、博客主题安装以及一些个性化修改" class="headerlink" title="五、博客主题安装以及一些个性化修改"></a>五、博客主题安装以及一些个性化修改</h2><p>官方默认主题很丑，那我们别的不做，首先来替换一个好看点的主题。</p><blockquote><p><a href="https://hexo.io/themes/">官方主题</a>：官方提供的各种主题</p></blockquote><p>Github、<a href="http://jekyllthemes.org/page3/">Jekyll Themes</a>上都能找到各种主题，我用的是<a href="https://github.com/blinkfox/hexo-theme-matery">Hexo matery</a>，就以此作为例子。</p><h3 id="5-1-主题下载和安装"><a href="#5-1-主题下载和安装" class="headerlink" title="5.1 主题下载和安装"></a>5.1 主题下载和安装</h3><p>进入我们博客根目录，在 <code>git bash</code> 输入以下命令下载主题：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/blinkfox/hexo-theme-matery.git themes/matery<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>下载完成后，修改 Hexo 根目录下的 <code>_config.yml</code> 的 <code>theme</code> 的值：<code>theme: matery</code></p><h4 id="config-yml-文件的其它修改建议"><a href="#config-yml-文件的其它修改建议" class="headerlink" title="_config.yml 文件的其它修改建议:"></a><code>_config.yml</code> 文件的其它修改建议:</h4><ul><li>请修改 <code>_config.yml</code> 的 <code>url</code> 的值为你的网站主 <code>URL</code>（如：<code>http://xxx.github.io</code>）。</li><li>建议修改两个 <code>per_page</code> 的分页条数值为 <code>6</code> 的倍数，如：<code>12</code>、<code>18</code> 等，这样文章列表在各个屏幕下都能较好的显示。</li><li>如果你是中文用户，则建议修改 <code>language</code> 的值为 <code>zh-CN</code>。</li></ul><h3 id="5-2-新建分类-categories-页"><a href="#5-2-新建分类-categories-页" class="headerlink" title="5.2 新建分类 categories 页"></a>5.2 新建分类 categories 页</h3><p><code>categories</code> 页是用来展示所有分类的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>categories/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"categories"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/categories/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> categories<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"categories"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"categories"</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-3-新建标签-tags-页"><a href="#5-3-新建标签-tags-页" class="headerlink" title="5.3 新建标签 tags 页"></a>5.3 新建标签 tags 页</h3><p><code>tags</code> 页是用来展示所有标签的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>tags/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"tags"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/tags/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> tags<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 17:25:40</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"tags"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"tags"</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-4-新建关于我-about-页"><a href="#5-4-新建关于我-about-页" class="headerlink" title="5.4 新建关于我 about 页"></a>5.4 新建关于我 about 页</h3><p><code>about</code> 页是用来展示<strong>关于我和我的博客</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>about/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"about"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/about/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> about<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 17:25:40</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"about"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"about"</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-5-新建留言板-contact-页（可选的）"><a href="#5-5-新建留言板-contact-页（可选的）" class="headerlink" title="5.5 新建留言板 contact 页（可选的）"></a>5.5 新建留言板 contact 页（可选的）</h3><p><code>contact</code> 页是用来展示<strong>留言板</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>contact/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"contact"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/contact/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> contact<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"contact"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"contact"</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><strong>注</strong>：本留言板功能依赖于第三方评论系统，请<strong>激活</strong>你的评论系统才有效果。并且在主题的 <code>_config.yml</code> 文件中，第 <code>19</code> 至 <code>21</code> 行的“<strong>菜单</strong>”配置，取消关于留言板的注释即可。</p></blockquote><h3 id="5-6-新建友情链接-friends-页（可选的）"><a href="#5-6-新建友情链接-friends-页（可选的）" class="headerlink" title="5.6 新建友情链接 friends 页（可选的）"></a>5.6 新建友情链接 friends 页（可选的）</h3><p><code>friends</code> 页是用来展示<strong>友情链接</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>friends/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo new page <span class="token string">"friends"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/friends/index.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> friends<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"friends"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"friends"</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>同时，在你的博客 <code>source</code> 目录下新建 <code>_data</code> 目录，在 <code>_data</code> 目录中新建 <code>friends.json</code> 文件，文件内容如下所示：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">[</span><span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/1_qq_27922023.jpg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"码酱"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"我不是大佬，只是在追寻大佬的脚步"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"http://luokangyuan.com/"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/4027734.jpeg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"闪烁之狐"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"https://blinkfox.github.io/"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/avatar.jpg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"ja_rome"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"平凡的脚步也可以走出伟大的行程"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"https://me.csdn.net/jlh912008548"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-7-新建-404-页"><a href="#5-7-新建-404-页" class="headerlink" title="5.7 新建 404 页"></a>5.7 新建 404 页</h3><p>如果在你的博客 <code>source</code> 目录下还没有 <code>404.md</code> 文件，那么你就需要新建一个。编辑你刚刚新建的页面文件 <code>/source/404.md</code>，至少需要以下内容：</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> <span class="token number">404</span><span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"404"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"404"</span><span class="token key atrule">description</span><span class="token punctuation">:</span> <span class="token string">"Oops～，我崩溃了！找不到你想要的页面 :("</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-8-菜单导航配置"><a href="#5-8-菜单导航配置" class="headerlink" title="5.8 菜单导航配置"></a>5.8 菜单导航配置</h3><h4 id="5-8-1-配置基本菜单导航的名称、路径url和图标icon"><a href="#5-8-1-配置基本菜单导航的名称、路径url和图标icon" class="headerlink" title="5.8.1 配置基本菜单导航的名称、路径url和图标icon."></a>5.8.1 配置基本菜单导航的名称、路径url和图标icon.</h4><p>1.菜单导航名称可以是中文也可以是英文(如：<code>Index</code>或<code>主页</code>) </p><p>2.图标icon 可以在<a href="https://fontawesome.com/icons">Font Awesome</a> 中查找</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">menu</span><span class="token punctuation">:</span>  <span class="token key atrule">Index</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>home  <span class="token key atrule">Tags</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /tags    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>tags  <span class="token key atrule">Categories</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /categories    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>bookmark  <span class="token key atrule">Archives</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /archives    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>archive  <span class="token key atrule">About</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /about    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>user<span class="token punctuation">-</span>circle  <span class="token key atrule">Friends</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /friends    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>address<span class="token punctuation">-</span>book<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="5-8-2-二级菜单配置方法"><a href="#5-8-2-二级菜单配置方法" class="headerlink" title="5.8.2 二级菜单配置方法"></a>5.8.2 二级菜单配置方法</h4><p>如果你需要二级菜单则可以在原基本菜单导航的基础上如下操作</p><ol><li>在需要添加二级菜单的一级菜单下添加<code>children</code>关键字(如:<code>About</code>菜单下添加<code>children</code>)</li><li>在<code>children</code>下创建二级菜单的 名称name,路径url和图标icon.</li><li>注意每个二级菜单模块前要加 <code>-</code>.</li><li>注意缩进格式</li></ol><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">menu</span><span class="token punctuation">:</span>  <span class="token key atrule">Index</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>home  <span class="token key atrule">Tags</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /tags    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>tags  <span class="token key atrule">Categories</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /categories    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>bookmark  <span class="token key atrule">Archives</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /archives    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>archive  <span class="token key atrule">About</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /about    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>user<span class="token punctuation">-</span>circle<span class="token punctuation">-</span>o  <span class="token key atrule">Friends</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /friends    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>address<span class="token punctuation">-</span>book  <span class="token key atrule">Medias</span><span class="token punctuation">:</span>    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>list    <span class="token key atrule">children</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Music        <span class="token key atrule">url</span><span class="token punctuation">:</span> /music        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>music      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Movies        <span class="token key atrule">url</span><span class="token punctuation">:</span> /movies        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>film      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Books        <span class="token key atrule">url</span><span class="token punctuation">:</span> /books        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>book      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Galleries        <span class="token key atrule">url</span><span class="token punctuation">:</span> /galleries        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>image<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-9-代码高亮"><a href="#5-9-代码高亮" class="headerlink" title="5.9 代码高亮"></a>5.9 代码高亮</h3><p>从 Hexo5.0 版本开始自带了 <code>prismjs</code> 代码语法高亮的支持，Matery主题对此进行了改造支持。</p><p>如果你的博客中曾经安装过 <code>hexo-prism-plugin</code> 的插件，那么你须要执行 <code>npm uninstall hexo-prism-plugin</code> 来卸载掉它，否则生成的代码中会有 <code>{</code> 和 <code>}</code> 的转义字符。</p><p>然后，修改你博客根目录下 <code>_config.yml</code> 文件中 <code>highlight.enable</code> 的值为 <code>false</code>，并将 <code>prismjs.enable</code> 的值设置为 <code>true</code>，主要配置如下：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">highlight</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">line_number</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">auto_detect</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">tab_replace</span><span class="token punctuation">:</span> <span class="token string">''</span>  <span class="token key atrule">wrap</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">hljs</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">prismjs</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">preprocess</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">line_number</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">tab_replace</span><span class="token punctuation">:</span> <span class="token string">''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>主题中默认的 <code>prismjs</code> 主题是 <code>Tomorrow Night</code>，如果你想定制自己的主题，可以前往 <a href="https://prismjs.com/download.html">prismjs 下载页面</a> 定制下载自己喜欢的主题 <code>css</code> 文件，然后将此 css 主题文件取名为 <code>prism.css</code>，替换掉 <code>matery</code> 主题文件夹中的 <code>source/libs/prism/prism.css</code> 文件即可。</p><h3 id="5-10-搜索"><a href="#5-10-搜索" class="headerlink" title="5.10 搜索"></a>5.10 搜索</h3><p>matery主题中还使用到了 <a href="https://github.com/wzpan/hexo-generator-search">hexo-generator-search</a> 的 Hexo 插件来做内容搜索，安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-search <span class="token parameter variable">--save</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在你博客目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">search</span><span class="token punctuation">:</span>  <span class="token key atrule">path</span><span class="token punctuation">:</span> search.xml  <span class="token key atrule">field</span><span class="token punctuation">:</span> post<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="5-11-中文链接转拼音（建议安装）"><a href="#5-11-中文链接转拼音（建议安装）" class="headerlink" title="5.11 中文链接转拼音（建议安装）"></a>5.11 中文链接转拼音（建议安装）</h3><p>如果你的文章名称是中文的，那么 Hexo 默认生成的永久链接也会有中文，这样不利于 <code>SEO</code>，且 <code>gitment</code> 评论对中文链接也不支持。我们可以用 <a href="https://github.com/viko16/hexo-permalink-pinyin">hexo-permalink-pinyin</a> Hexo 插件使在生成文章时生成中文拼音的永久链接。</p><p>安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> i hexo-permalink-pinyin <span class="token parameter variable">--save</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在你博客根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">permalink_pinyin</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">separator</span><span class="token punctuation">:</span> <span class="token string">'-'</span> <span class="token comment"># default: '-'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><blockquote><p><strong>注</strong>：除了此插件外，<a href="https://github.com/rozbo/hexo-abbrlink">hexo-abbrlink</a> 插件也可以生成非中文的链接。</p></blockquote><h3 id="5-12-文章字数统计插件（建议安装）"><a href="#5-12-文章字数统计插件（建议安装）" class="headerlink" title="5.12 文章字数统计插件（建议安装）"></a>5.12 文章字数统计插件（建议安装）</h3><p>如果你想要在文章中显示文章字数、阅读时长信息，可以安装 <a href="https://github.com/willin/hexo-wordcount">hexo-wordcount</a>插件。</p><p>安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> i <span class="token parameter variable">--save</span> hexo-wordcount<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>然后只需在主题 themes文件夹的matery文件夹下的 <code>_config.yml</code> 文件中，将各个文章字数相关的配置激活即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">postInfo</span><span class="token punctuation">:</span>  <span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">update</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">wordCount</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 设置文章字数统计为 true.</span>  <span class="token key atrule">totalCount</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 设置站点文章总字数统计为 true.</span>  <span class="token key atrule">min2read</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 阅读时长.</span>  <span class="token key atrule">readCount</span><span class="token punctuation">:</span> <span class="token boolean important">false</span> <span class="token comment"># 阅读次数.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="5-13-添加emoji表情支持（可选的）"><a href="#5-13-添加emoji表情支持（可选的）" class="headerlink" title="5.13 添加emoji表情支持（可选的）"></a>5.13 添加emoji表情支持（可选的）</h3><p>本主题新增了对<code>emoji</code>表情的支持，使用到了 <a href="https://npm.taobao.org/package/hexo-filter-github-emojis">hexo-filter-github-emojis</a> 的 Hexo 插件来支持 <code>emoji</code>表情的生成，把对应的<code>markdown emoji</code>语法（<code>::</code>,例如：<code>:smile:</code>）转变成会跳跃的<code>emoji</code>表情，安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-filter-github-emojis <span class="token parameter variable">--save</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在你博客目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">githubEmojis</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">className</span><span class="token punctuation">:</span> github<span class="token punctuation">-</span>emoji  <span class="token key atrule">inject</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">styles</span><span class="token punctuation">:</span>  customEmojis<span class="token punctuation">:</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后就可以在文章中对应位置看到你用<code>emoji</code>语法写的表情了。</p><h3 id="5-14-添加-RSS-订阅支持（可选的）"><a href="#5-14-添加-RSS-订阅支持（可选的）" class="headerlink" title="5.14 添加 RSS 订阅支持（可选的）"></a>5.14 添加 RSS 订阅支持（可选的）</h3><p>本主题中还使用到了 <a href="https://github.com/hexojs/hexo-generator-feed">hexo-generator-feed</a> 的 Hexo 插件来做 <code>RSS</code>，安装命令如下：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-feed <span class="token parameter variable">--save</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在你博客目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">feed</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> atom  <span class="token key atrule">path</span><span class="token punctuation">:</span> atom.xml  <span class="token key atrule">limit</span><span class="token punctuation">:</span> <span class="token number">20</span>  <span class="token key atrule">hub</span><span class="token punctuation">:</span>  <span class="token key atrule">content</span><span class="token punctuation">:</span>  <span class="token key atrule">content_limit</span><span class="token punctuation">:</span> <span class="token number">140</span>  <span class="token key atrule">content_limit_delim</span><span class="token punctuation">:</span> <span class="token string">' '</span>  <span class="token key atrule">order_by</span><span class="token punctuation">:</span> <span class="token punctuation">-</span>date<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后在 <code>public</code> 文件夹中即可看到 <code>atom.xml</code> 文件，说明你已经安装成功了。</p><h3 id="5-15-修改页脚"><a href="#5-15-修改页脚" class="headerlink" title="5.15 修改页脚"></a>5.15 修改页脚</h3><p>页脚信息可能需要做定制化修改，而且它不便于做成配置信息，所以可能需要你自己去再修改和加工。修改的地方在主题文件的 <code>/layout/_partial/footer.ejs</code> 文件中，包括站点、使用的主题、访问量等。</p><h3 id="5-16-添加中文繁简转换"><a href="#5-16-添加中文繁简转换" class="headerlink" title="5.16 添加中文繁简转换"></a>5.16 添加中文繁简转换</h3><p>在主题的 <code>_config.yml</code> 文件中，开启 translate 为 enable。</p><blockquote><p>开启中文繁简转换如下修改。默认不开启。 实例演示： <a href="https://blog.17lai.site/">繁简转换</a> 底下 footer 栏</p></blockquote><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">translate</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="5-17-修改社交链接"><a href="#5-17-修改社交链接" class="headerlink" title="5.17 修改社交链接"></a>5.17 修改社交链接</h3><p>在主题的 <code>_config.yml</code> 文件中，默认支持 <code>QQ</code>、<code>GitHub</code> 和邮箱等的配置，你可以在主题文件的 <code>/layout/_partial/social-link.ejs</code> 文件中，新增、修改你需要的社交链接地址，增加链接可参考如下代码：</p><pre class="line-numbers language-ejs" data-language="ejs"><code class="language-ejs"><span class="token ejs language-ejs"><span class="token delimiter punctuation">&lt;%</span><span class="token language-javascript"> <span class="token keyword">if</span> <span class="token punctuation">(</span>theme<span class="token punctuation">.</span>socialLink<span class="token punctuation">.</span>github<span class="token punctuation">)</span> <span class="token punctuation">{</span> </span><span class="token delimiter punctuation">%&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span><span class="token ejs language-ejs"><span class="token delimiter punctuation">&lt;%=</span><span class="token language-javascript"> theme<span class="token punctuation">.</span>socialLink<span class="token punctuation">.</span>github </span><span class="token delimiter punctuation">%&gt;</span></span><span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>tooltipped<span class="token punctuation">"</span></span> <span class="token attr-name">target</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>_blank<span class="token punctuation">"</span></span> <span class="token attr-name">data-tooltip</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>访问我的GitHub<span class="token punctuation">"</span></span> <span class="token attr-name">data-position</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>top<span class="token punctuation">"</span></span> <span class="token attr-name">data-delay</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>50<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>i</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>fab fa-github<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>i</span><span class="token punctuation">&gt;</span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">&gt;</span></span><span class="token ejs language-ejs"><span class="token delimiter punctuation">&lt;%</span><span class="token language-javascript"> <span class="token punctuation">}</span> </span><span class="token delimiter punctuation">%&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中，社交图标（如：<code>fa-github</code>）你可以在 <a href="https://fontawesome.com/icons">Font Awesome</a> 中搜索找到。以下是常用社交图标的标识，供你参考：</p><ul><li>Facebook: <code>fab fa-facebook</code></li><li>Twitter: <code>fab fa-twitter</code></li><li>Google-plus: <code>fab fa-google-plus</code></li><li>Linkedin: <code>fab fa-linkedin</code></li><li>Tumblr: <code>fab fa-tumblr</code></li><li>Medium: <code>fab fa-medium</code></li><li>Slack: <code>fab fa-slack</code></li><li>Sina Weibo: <code>fab fa-weibo</code></li><li>Wechat: <code>fab fa-weixin</code></li><li>QQ: <code>fab fa-qq</code></li><li>Zhihu: <code>fab fa-zhihu</code></li></ul><blockquote><p><strong>注意</strong>: 本主题中使用的 <code>Font Awesome</code> 版本为 <code>5.11.0</code>。</p></blockquote><h3 id="5-18-修改打赏的二维码图片"><a href="#5-18-修改打赏的二维码图片" class="headerlink" title="5.18 修改打赏的二维码图片"></a>5.18 修改打赏的二维码图片</h3><p>在主题文件的 <code>source/medias/reward</code> 文件中，你可以替换成你的的微信和支付宝的打赏二维码图片。</p><h3 id="5-19-配置音乐播放器（可选的）"><a href="#5-19-配置音乐播放器（可选的）" class="headerlink" title="5.19 配置音乐播放器（可选的）"></a>5.19 配置音乐播放器（可选的）</h3><p>要支持音乐播放，在主题的 <code>_config.yml</code> 配置文件中激活music配置即可：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token comment"># 是否在首页显示音乐</span><span class="token key atrule">music</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">title</span><span class="token punctuation">:</span>         <span class="token comment"># 非吸底模式有效</span>    <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>    <span class="token key atrule">show</span><span class="token punctuation">:</span> 听听音乐  <span class="token key atrule">server</span><span class="token punctuation">:</span> netease   <span class="token comment"># require music platform: netease, tencent, kugou, xiami, baidu</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> playlist    <span class="token comment"># require song, playlist, album, search, artist</span>  <span class="token key atrule">id</span><span class="token punctuation">:</span> <span class="token number">503838841</span>     <span class="token comment"># require song id / playlist id / album id / search keyword</span>  <span class="token key atrule">fixed</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>      <span class="token comment"># 开启吸底模式</span>  <span class="token key atrule">autoplay</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>   <span class="token comment"># 是否自动播放</span>  <span class="token key atrule">theme</span><span class="token punctuation">:</span> <span class="token string">'#42b983'</span>  <span class="token key atrule">loop</span><span class="token punctuation">:</span> <span class="token string">'all'</span>       <span class="token comment"># 音频循环播放, 可选值: 'all', 'one', 'none'</span>  <span class="token key atrule">order</span><span class="token punctuation">:</span> <span class="token string">'random'</span>   <span class="token comment"># 音频循环顺序, 可选值: 'list', 'random'</span>  <span class="token key atrule">preload</span><span class="token punctuation">:</span> <span class="token string">'auto'</span>   <span class="token comment"># 预加载，可选值: 'none', 'metadata', 'auto'</span>  <span class="token key atrule">volume</span><span class="token punctuation">:</span> <span class="token number">0.7</span>       <span class="token comment"># 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效</span>  <span class="token key atrule">listFolded</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token comment"># 列表默认折叠</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p><code>server</code>可选<code>netease</code>（网易云音乐），<code>tencent</code>（QQ音乐），<code>kugou</code>（酷狗音乐），<code>xiami</code>（虾米音乐），<code>baidu</code>（百度音乐）。</p><p><code>type</code>可选<code>song</code>（歌曲），<code>playlist</code>（歌单），<code>album</code>（专辑），<code>search</code>（搜索关键字），<code>artist</code>（歌手）。</p><p><code>id</code>获取方法示例: 浏览器打开网易云音乐，点击我喜欢的音乐歌单，浏览器地址栏后面会有一串数字，<code>playlist</code>的<code>id</code>即为这串数字。</p></blockquote><h3 id="5-20-文章-Front-matter-介绍"><a href="#5-20-文章-Front-matter-介绍" class="headerlink" title="5.20 文章 Front-matter 介绍"></a>5.20 文章 Front-matter 介绍</h3><p>Front-matter 选项详解</p><p><code>Front-matter</code> 选项中的所有内容均为<strong>非必填</strong>的。但我仍然建议至少填写 <code>title</code> 和 <code>date</code> 的值。</p><table><thead><tr><th>配置选项</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>title</td><td><code>Markdown</code> 的文件标题</td><td>文章标题，强烈建议填写此选项</td></tr><tr><td>date</td><td>文件创建时的日期时间</td><td>发布时间，强烈建议填写此选项，且最好保证全局唯一</td></tr><tr><td>author</td><td>根 <code>_config.yml</code> 中的 <code>author</code></td><td>文章作者</td></tr><tr><td>img</td><td><code>featureImages</code> 中的某个值</td><td>文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径.如: <code>http://xxx.com/xxx.jpg</code></td></tr><tr><td>top</td><td><code>true</code></td><td>推荐文章（文章是否置顶），如果 <code>top</code> 值为 <code>true</code>，则会作为首页推荐文章</td></tr><tr><td>hide</td><td><code>false</code></td><td>隐藏文章，如果<code>hide</code>值为<code>true</code>，则文章不会在首页显示</td></tr><tr><td>cover</td><td><code>false</code></td><td><code>v1.0.2</code>版本新增，表示该文章是否需要加入到首页轮播封面中</td></tr><tr><td>coverImg</td><td>无</td><td><code>v1.0.2</code>版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td></tr><tr><td>password</td><td>无</td><td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 <code>password</code> 的值，该值必须是用 <code>SHA256</code> 加密后的密码，防止被他人识破。前提是在主题的 <code>config.yml</code> 中激活了 <code>verifyPassword</code> 选项</td></tr><tr><td>toc</td><td><code>true</code></td><td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 <code>config.yml</code> 中激活了 <code>toc</code> 选项</td></tr><tr><td>mathjax</td><td><code>false</code></td><td>是否开启数学公式支持 ，本文章是否开启 <code>mathjax</code>，且需要在主题的 <code>_config.yml</code> 文件中也需要开启才行</td></tr><tr><td>summary</td><td>无</td><td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td></tr><tr><td>categories</td><td>无</td><td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td></tr><tr><td>tags</td><td>无</td><td>文章标签，一篇文章可以多个标签</td></tr><tr><td>keywords</td><td>文章标题</td><td>文章关键字，SEO 时需要</td></tr><tr><td>reprintPolicy</td><td>cc_by</td><td>文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td></tr></tbody></table><blockquote><p><strong>注意</strong>:</p><ol><li>如果 <code>img</code> 属性不填写的话，文章特色图会根据文章标题的 <code>hashcode</code> 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章的特色图<strong>各有特色</strong>。</li><li><code>date</code> 的值尽量保证每篇文章是唯一的，因为本主题中 <code>Gitalk</code> 和 <code>Gitment</code> 识别 <code>id</code> 是通过 <code>date</code> 的值来作为唯一标识的。</li><li>如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 <code>_config.yml</code> 中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：<a href="http://tool.oschina.net/encrypt?type=2">开源中国在线工具</a>、<a href="http://encode.chahuo.com/">chahuo</a>、<a href="http://tool.chinaz.com/tools/hash.aspx">站长工具</a>。</li><li>您可以在文章md文件的 front-matter 中指定 reprintPolicy 来给单个文章配置转载规则</li></ol></blockquote><p>以下为文章的 <code>Front-matter</code> 示例。</p><h4 id="最简示例"><a href="#最简示例" class="headerlink" title="最简示例"></a>最简示例</h4><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> typora<span class="token punctuation">-</span>vue<span class="token punctuation">-</span>theme主题介绍<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-07 09:25:00</span></span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="最全示例"><a href="#最全示例" class="headerlink" title="最全示例"></a>最全示例</h4><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown"><span class="token front-matter-block"><span class="token punctuation">---</span><span class="token front-matter yaml language-yaml"><span class="token key atrule">title</span><span class="token punctuation">:</span> hexo<span class="token punctuation">-</span>github搭建个人博客教程<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2025-04-22 09:25:00</span><span class="token key atrule">author</span><span class="token punctuation">:</span> 墨宇Logic<span class="token key atrule">img</span><span class="token punctuation">:</span> /source/images/xxx.jpg<span class="token key atrule">top</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">hide</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">cover</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">coverImg</span><span class="token punctuation">:</span> /images/1.jpg<span class="token key atrule">password</span><span class="token punctuation">:</span> 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92<span class="token key atrule">toc</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">mathjax</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">summary</span><span class="token punctuation">:</span> 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要<span class="token key atrule">categories</span><span class="token punctuation">:</span> Markdown<span class="token key atrule">tags</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> Typora  <span class="token punctuation">-</span> Markdown</span><span class="token punctuation">---</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="新建文章模板修改"><a href="#新建文章模板修改" class="headerlink" title="新建文章模板修改"></a>新建文章模板修改</h4><p>首先为了新建文章方便，我们可以修改一下文章模板，建议将<code>/scaffolds/post.md</code>修改为如下代码：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">{</span> title <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token punctuation">{</span><span class="token punctuation">{</span> date <span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token key atrule">author</span><span class="token punctuation">:</span> <span class="token key atrule">img</span><span class="token punctuation">:</span> <span class="token key atrule">coverImg</span><span class="token punctuation">:</span> <span class="token key atrule">top</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">cover</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">toc</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">mathjax</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">password</span><span class="token punctuation">:</span><span class="token key atrule">summary</span><span class="token punctuation">:</span><span class="token key atrule">tags</span><span class="token punctuation">:</span><span class="token key atrule">categories</span><span class="token punctuation">:</span><span class="token punctuation">---</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样新建文章后 一些<code>Front-matter</code>参数不用你自己补充了，修改对应信息就可以了。</p><h3 id="自定制修改"><a href="#自定制修改" class="headerlink" title="自定制修改"></a>自定制修改</h3><p>在本主题的 <code>_config.yml</code> 中可以修改部分自定义信息，有以下几个部分：</p><ul><li>菜单</li><li>我的梦想</li><li>首页的音乐播放器和视频播放器配置</li><li>是否显示推荐文章名称和按钮配置</li><li><code>favicon</code> 和 <code>Logo</code></li><li>个人信息</li><li>TOC 目录</li><li>文章打赏信息</li><li>复制文章内容时追加版权信息</li><li>MathJax</li><li>文章字数统计、阅读时长</li><li>点击页面的’爱心’效果</li><li>我的项目</li><li>我的技能</li><li>我的相册</li><li><code>Gitalk</code>、<code>Gitment</code>、<code>Valine</code> 和 <code>disqus</code> 评论配置</li><li><a href="http://busuanzi.ibruce.info/">不蒜子统计</a>和谷歌分析（<code>Google Analytics</code>）</li><li>默认特色图的集合。当文章没有设置特色图时，本主题会根据文章标题的 <code>hashcode</code> 值取余，来选择展示对应的特色图</li></ul><p><strong>我认为个人博客应该都有自己的风格和特色</strong>。如果本主题中的诸多功能和主题色彩你不满意，可以在主题中自定义修改，很多更自由的功能和细节点的修改难以在主题的 <code>_config.yml</code> 中完成，需要修改源代码才来完成。以下列出了可能对你有用的地方：</p><h3 id="修改主题颜色"><a href="#修改主题颜色" class="headerlink" title="修改主题颜色"></a>修改主题颜色</h3><p>在主题文件的 <code>/source/css/matery.css</code> 文件中，搜索 <code>.bg-color</code> 来修改背景颜色：</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token comment">/* 整体背景颜色，包括导航、移动端的导航、页尾、标签页等的背景颜色. */</span><span class="token selector">.bg-color</span> <span class="token punctuation">{</span>    <span class="token property">background-image</span><span class="token punctuation">:</span> <span class="token function">linear-gradient</span><span class="token punctuation">(</span>to right<span class="token punctuation">,</span> #4cbf30 0%<span class="token punctuation">,</span> #0f9d58 100%<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token atrule"><span class="token rule">@-webkit-keyframes</span> rainbow</span> <span class="token punctuation">{</span>   <span class="token comment">/* 动态切换背景颜色. */</span><span class="token punctuation">}</span><span class="token atrule"><span class="token rule">@keyframes</span> rainbow</span> <span class="token punctuation">{</span>    <span class="token comment">/* 动态切换背景颜色. */</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="修改-banner-图和文章特色图"><a href="#修改-banner-图和文章特色图" class="headerlink" title="修改 banner 图和文章特色图"></a>修改 banner 图和文章特色图</h3><p>你可以直接在 <code>/source/medias/banner</code> 文件夹中更换你喜欢的 <code>banner</code> 图片，主题代码中是每天动态切换一张，只需 <code>7</code> 张即可。如果你会 <code>JavaScript</code> 代码，可以修改成你自己喜欢切换逻辑，如：随机切换等，<code>banner</code> 切换的代码位置在 <code>/layout/_partial/bg-cover-content.ejs</code> 文件的 <code>&lt;script&gt;&lt;/script&gt;</code> 代码中：</p><pre class="line-numbers language-ejs" data-language="ejs"><code class="language-ejs">$('.bg-cover').css('background-image', 'url(/medias/banner/' + new Date().getDay() + '.jpg)');<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在 <code>/source/medias/featureimages</code> 文件夹中默认有 24 张特色图片，你可以再增加或者减少，并需要在 <code>_config.yml</code> 做同步修改。</p><h3 id="图床"><a href="#图床" class="headerlink" title="图床"></a>图床</h3><p>当博文中有图片时，若是少量图片，可以直接把图片存放在 <code>source</code> 文件夹中，但这显然不合理的，因为图片会占据大量的存储的空间，加载的时候相对缓慢 ，这时考虑把博文里的图片上传到某一网站，然后获得外部链接，使用 <code>Markdown</code> 语法，<code>![图片信息](外部链接)</code> 完成图片的插入，这种网站就被成为图床。</p><p>我用的图床：<a href="https://www.superbed.cn/">聚合图床</a></p><h2 id="六、博客维护"><a href="#六、博客维护" class="headerlink" title="六、博客维护"></a>六、博客维护</h2><p>到此为止，我们的个人博客就彻底搭建完成啦。后续我们只需要修改博客的配置文件和博客本身的markdown源文件，然后执行命令：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">hexo clean <span class="token operator">&amp;&amp;</span> hexo g <span class="token operator">&amp;&amp;</span> hexo d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样我们就能将我们修改后的内容上传到GitHub，然后Netlify会自动同步，将生成在public文件夹中的静态网页部署出去。</p><p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>]]></content>
      
      
      <categories>
          
          <category> 博客搭建教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> css </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
