<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="【AI大模型应用学习笔记】RAG-Embedding-Vector知识点学习, AI,Python,C,C++,Linux">
    <meta name="description" content="关于RAG-Embedding-Vector知识点，以及RAG实现的基本流程实操记录">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>【AI大模型应用学习笔记】RAG-Embedding-Vector知识点学习 | 墨宇Logic</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    
    <style>
        body{
            background-image: url(https://pic1.imgdb.cn/item/680901b758cb8da5c8c6b23f.webp);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


 
    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: #FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: #49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: #2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>
 
<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    

    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">墨宇Logic</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">墨宇Logic</div>
        <div class="logo-desc">
            
            这里是墨宇的个人博客
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/ismoyuai" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/ismoyuai" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/2.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">【AI大模型应用学习笔记】RAG-Embedding-Vector知识点学习</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Markdown/">
                                <span class="chip bg-color">Markdown</span>
                            </a>
                        
                            <a href="/tags/RAG/">
                                <span class="chip bg-color">RAG</span>
                            </a>
                        
                            <a href="/tags/Embeddings/">
                                <span class="chip bg-color">Embeddings</span>
                            </a>
                        
                            <a href="/tags/OpenAI/">
                                <span class="chip bg-color">OpenAI</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/" class="post-category">
                                AI大模型应用开发
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-15
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    9.9k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    44 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="一、什么是检索增强的生成模型（RAG）"><a href="#一、什么是检索增强的生成模型（RAG）" class="headerlink" title="一、什么是检索增强的生成模型（RAG）"></a>一、什么是检索增强的生成模型（RAG）</h2><p>  <strong>RAG（Retrieval-Augmented Generation，检索增强生成） 是一种结合了信息检索技术与语言生成模型的人工智能技术。该技术通过从外部知识库中检索相关信息，并将其作为提示（Prompt）输入给大型语言模型（LLMs），以增强模型处理知识密集型任务的能力，如问答、文本摘要、内容生成等。RAG模型由Facebook AI Research（FAIR）团队于2020年首次提出，并迅速成为大模型应用中的热门方案。</strong></p>
<h3 id="1-1-大模型目前固有的局限性"><a href="#1-1-大模型目前固有的局限性" class="headerlink" title="1.1 大模型目前固有的局限性"></a><strong>1.1 大模型目前固有的局限性</strong></h3><ul>
<li>1.LMM的知识不是实时的</li>
<li>2.LMM可能不知道你私有的领域/业务知识</li>
</ul>
<div class="alert alert-success">
<b>类比：</b>你可以把这个过程想象成开卷考试。让 LLM 先翻书，再回答问题。
</div>

<h3 id="1-2-检索增强生成（RAG）"><a href="#1-2-检索增强生成（RAG）" class="headerlink" title="1.2 检索增强生成（RAG）"></a><strong>1.2 检索增强生成（RAG）</strong></h3><h4 id="什么是RAG？"><a href="#什么是RAG？" class="headerlink" title="什么是RAG？"></a><strong>什么是RAG？</strong></h4><p><strong>RAG（Retrieval-Augmented Generation，检索增强生成），RAG</strong>是一种&nbsp;AI&nbsp;框架，它将传统信息检索系统（例如数据库）的优势与生成式大语言模型 (LLM) 的功能结合在一起。</p>
<p><strong>LLM通过将这些额外的知识与自己的语言技能相结合，可以撰写更准确、更具时效性且更贴合具体需求的文字。</strong></p>
<p><img src="https://pic1.imgdb.cn/item/681b64a758cb8da5c8e3d68d.png" alt="什么是RAG?"></p>
<h4 id="如何理解RAG？"><a href="#如何理解RAG？" class="headerlink" title="如何理解RAG？"></a><strong>如何理解RAG？</strong></h4><p><strong>通过上一个问题，我们知道了什么是RAG？了解到RAG是一种结合了信息检索、文本增强和文本生成的自然语言处理（NLP）的技术。</strong></p>
<p><strong>RAG的目的是通过从外部知识库检索相关信息来辅助大语言模型生成更准确、更丰富的文本内容。那我们如何理解RAG的检索、增强和生成呢？</strong></p>
<ol>
<li><strong>检索</strong>：检索是RAG流程的第一步，从预先建立的知识库中检索与问题相关的信息。这一步的目的是为后续的生成过程提供有用的上下文信息和知识支撑。</li>
<li><strong>增强</strong>：RAG中增强是将检索到的信息用作生成模型（即大语言模型）的上下文输入，以增强模型对特定问题的理解和回答能力。这一步的目的是将外部知识融入生成过程中，使生成的文本内容更加丰富、准确和符合用户需求。<strong>通过增强步骤，LLM模型能够充分利用外部知识库中的信息。</strong></li>
<li>生成：生成是RAG流程的最后一步。这一步的目的是结合LLM生成符合用户需求的回答。生成器会利用检索到的信息作为上下文输入，并结合大语言模型来生成文本内容。</li>
</ol>
<p><strong>RAG的“检索、增强、生成”，谁增强了谁，谁生成了答案，主语很重要。是从知识库中检索到的问答对，增强了LLM的提示词（prompt），LLM拿着增强后的Prompt生成了问题答案。</strong></p>
<h4 id="如何使用RAG"><a href="#如何使用RAG" class="headerlink" title="如何使用RAG?"></a>如何使用RAG?</h4><p><strong>我们如何使用RAG？接下来以RAG搭建知识问答系统具体步骤为例，来讲解如何使用RAG？</strong></p>
<ol>
<li><strong>数据准备与知识库构建</strong>：</li>
</ol>
<ul>
<li><strong>收集数据：</strong>&nbsp;首先，需要收集与问答系统相关的各种数据，这些数据可以来自文档、网页、数据库等多种来源。</li>
<li><strong>数据清洗：</strong>&nbsp;对收集到的数据进行清洗，去除噪声、重复项和无关信息，确保数据的质量和准确性。</li>
<li><strong>知识库构建：</strong>&nbsp;将清洗后的数据构建成知识库。这通常包括将文本分割成较小的片段（chunks），使用文本嵌入模型（如GLM）将这些片段转换成向量，并将这些向量存储在向量数据库（如FAISS、Milvus等）中。</li>
</ul>
<ol start="2">
<li><strong>检索模块设计：</strong></li>
</ol>
<ul>
<li><strong>问题向量化：</strong>&nbsp;当用户输入查询问题时，使用相同的文本嵌入模型将问题转换成向量。</li>
<li><strong>相似度检索：</strong>&nbsp;在向量数据库中检索与问题向量最相似的知识库片段（chunks）。这通常通过计算向量之间的相似度（如余弦相似度）来实现。</li>
<li><strong>结果排序：</strong>&nbsp;根据相似度得分对检索到的结果进行排序，选择最相关的片段作为后续生成的输入。</li>
</ul>
<ol start="3">
<li><strong>生成模块设计：</strong></li>
</ol>
<ul>
<li><strong>上下文融合</strong>：将检索到的相关片段与原始问题合并，形成更丰富的上下文信息。</li>
<li><strong>大语言模型生成</strong>：使用大语言模型（如GLM）基于上述上下文信息生成回答。大语言模型会学习如何根据检索到的信息来生成准确、有用的回答。</li>
</ul>
<p><strong>大家可以结合自己的业务领域知识，开始搭建医疗、法律、产品知识问答。先搭建Demo，然后工作中不断完善知识库问答对。</strong></p>
<h3 id="1-3-RAG工作原理是什么？"><a href="#1-3-RAG工作原理是什么？" class="headerlink" title="1.3 RAG工作原理是什么？"></a><strong>1.3 RAG工作原理是什么？</strong></h3><p>&nbsp;<strong>大型语言模型（LLM）面临两个问题，第一个问题是LLM会产生幻觉，第二个是LLM的知识中断。</strong></p>
<ol>
<li>幻觉：当模型所训练的数据没有问题的答案时，它会自信地做出错误反应，就会发生幻觉。</li>
<li>知识截止：当 LLM 返回的信息与模型的训练数据相比过时时。每个基础模型都有知识截止，这意味着其知识仅限于训练时可用的数据。</li>
</ol>
<p><strong>检索增强生成 (RAG) 摆脱了知识限制，整合了外部数据，从外部知识库中检索相关信息，增强模型的生成能力。</strong></p>
<p><img src="https://pic1.imgdb.cn/item/681b64a758cb8da5c8e3d68a.png" alt="RAG的工作原理"></p>
<h3 id="1-4-RAG基本搭建流程"><a href="#1-4-RAG基本搭建流程" class="headerlink" title="1.4 RAG基本搭建流程"></a><strong>1.4 RAG基本搭建流程</strong></h3><p><strong>通过检索增强技术，将用户查询与索引知识融合，利用大语言模型生成准确回答。</strong></p>
<ol>
<li>知识准备：收集并转换知识文档为文本数据，进行预处理和索引。</li>
<li>嵌入与索引：使用嵌入模型将文本转换为向量，并存储在向量数据库中。</li>
<li>查询检索：用户查询转换为向量，从数据库中检索相关知识。</li>
<li>提示增强：结合检索结果构建增强提示模版。</li>
<li>生成回答：大语言模型根据增强模版生成准确回答。</li>
</ol>
<h3 id="1-5-RAG技术架构"><a href="#1-5-RAG技术架构" class="headerlink" title="1.5 RAG技术架构"></a><strong>1.5 RAG技术架构</strong></h3><p><strong>RAG技术架构主要由两个核心模块组成，检索模块（Retriever）和生成模块（Generator）。</strong></p>
<ol>
<li><strong>检索模块（Retriever）：</strong></li>
</ol>
<ul>
<li>文本嵌入：使用预训练的文本嵌入模型（如GLM）将查询和文档转换成向量表示，以便在向量空间中进行相似度计算。</li>
<li>向量搜索：利用高效的向量搜索技术（如FAISS、Milvus等向量数据库）在向量空间中检索与查询向量最相似的文档或段落。</li>
<li>双塔模型：检索模块常采用双塔模型（Dual-Encoder）进行高效的向量化检索。双塔模型由两个独立的编码器组成，一个用于编码查询，另一个用于编码文档。这两个编码器将查询和文档映射到相同的向量空间中，以便进行相似度计算。</li>
</ul>
<ol start="2">
<li><strong>生成模块（Generator）：</strong></li>
</ol>
<ul>
<li>强大的生成模型：生成模块通常使用在大规模数据上预训练的生成模型（如GLM），这些模型在生成自然语言文本方面表现出色。</li>
<li>上下文融合：生成模块将检索到的相关文档与原始查询合并，形成更丰富的上下文信息，作为生成模型的输入。</li>
<li>生成过程：生成模型根据输入的上下文信息，生成连贯、准确且信息丰富的回答或文本。</li>
</ul>
<p><strong>结合高效的检索模块（Retriever）与强大的生成模型（Generator），实现基于外部知识增强的自然语言生成能力。</strong></p>
<h2 id="二、RAG的工作原理和基本搭建流程"><a href="#二、RAG的工作原理和基本搭建流程" class="headerlink" title="二、RAG的工作原理和基本搭建流程"></a>二、RAG的工作原理和基本搭建流程</h2><p><img src="https://pic1.imgdb.cn/item/681b64a758cb8da5c8e3d68c.png" alt="RAG基本搭建流程"></p>
<p>RAG搭建过程</p>
<ul>
<li>1.文档加载，并按一定条件切割成片</li>
<li>2.将切割的文本片段灌人检索引擎</li>
<li>3.封装检索接口</li>
<li>4.构建调用流程：Query -&gt; 检索 -&gt; Prompt -&gt; LLM -&gt; 回复</li>
</ul>
<h3 id="2-1-文档的加载与切割"><a href="#2-1-文档的加载与切割" class="headerlink" title="2.1 文档的加载与切割"></a><strong>2.1 文档的加载与切割</strong></h3><p>安装 pdf 解析库</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> pdfminer.six<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>构建文档提取文字方法</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>high_level <span class="token keyword">import</span> extract_pages
<span class="token keyword">from</span> pdfminer<span class="token punctuation">.</span>layout <span class="token keyword">import</span> LTTextContainer

<span class="token keyword">def</span> <span class="token function">extract_text_from_pdf</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> page_numbers<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> min_line_length<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''从 PDF 文件中（按指定页码）提取文字'''</span>
    
    paragraphs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token builtin">buffer</span> <span class="token operator">=</span> <span class="token string">''</span>
    full_text <span class="token operator">=</span> <span class="token string">''</span>

    <span class="token comment"># 提取全部文本</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> page_layout <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>extract_pages<span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 如果指定了页码范围，跳过范围外的页</span>
        <span class="token keyword">if</span> page_numbers <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> i <span class="token keyword">not</span> <span class="token keyword">in</span> page_numbers<span class="token punctuation">:</span>
            <span class="token keyword">continue</span>
        <span class="token keyword">for</span> element <span class="token keyword">in</span> page_layout<span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>element<span class="token punctuation">,</span> LTTextContainer<span class="token punctuation">)</span><span class="token punctuation">:</span>
                full_text <span class="token operator">+=</span> element<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'\n'</span>

    <span class="token comment"># 按空行分隔，将文本重新组织成段落</span>
    lines <span class="token operator">=</span> full_text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> text <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> min_line_length<span class="token punctuation">:</span>
            <span class="token builtin">buffer</span> <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token string">' '</span><span class="token operator">+</span>text<span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token keyword">not</span> text<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">)</span> <span class="token keyword">else</span> text<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> <span class="token builtin">buffer</span><span class="token punctuation">:</span>
            paragraphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>
            <span class="token builtin">buffer</span> <span class="token operator">=</span> <span class="token string">''</span>
    <span class="token keyword">if</span> <span class="token builtin">buffer</span><span class="token punctuation">:</span>
        paragraphs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> paragraphs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>调用方法加载本地文档</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">paragraphs <span class="token operator">=</span> extract_text_from_pdf<span class="token punctuation">(</span><span class="token string">"llama2.pdf"</span><span class="token punctuation">,</span> min_line_length<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

<span class="token comment"># 打印文档前4段内容</span>
<span class="token keyword">for</span> para <span class="token keyword">in</span> paragraphs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>para<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-2-LLM接口封装"><a href="#2-2-LLM接口封装" class="headerlink" title="2.2 LLM接口封装"></a><strong>2.2 LLM接口封装</strong></h3><p>安装openai库和环境变量库</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> openai
pip <span class="token function">install</span> <span class="token parameter variable">-U</span> python-dotenv<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>加载环境变量，将我们的OpenAI Key 加载进来，在根目录建一个 <code>.env</code>  文件，把我们申请的<code>OPENAI_API_KEY</code> 填写进去，文件内容如下：</p>
<pre class="line-numbers language-none"><code class="language-none">OPENAI_API_KEY=Bearer hk-xxxxxxxxxxxxxxx
OPENAI_BASE_URL=https://api.openai-hk.com/v1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>编写代码加载环境变量</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI

<span class="token comment"># 加载环境变量</span>
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv<span class="token punctuation">,</span> find_dotenv
_ <span class="token operator">=</span> load_dotenv<span class="token punctuation">(</span>find_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 读取本地 .env 文件，里面定义了 OPENAI_API_KEY</span>

client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>
	api_key<span class="token operator">=</span>os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
	base_url<span class="token operator">=</span><span class="token string">"https://api.openai-hk.com/v1"</span><span class="token punctuation">,</span> <span class="token punctuation">)</span>  <span class="token comment"># 使用香港的 API 服务器</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>安装<code>requests</code>包</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> requests<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>封装 openai 接口</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_completion</span><span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''封装 openai 接口'''</span>

    messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">]</span>
    response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
        model<span class="token operator">=</span>model<span class="token punctuation">,</span>
        messages<span class="token operator">=</span>messages<span class="token punctuation">,</span>
        temperature<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">,</span>   <span class="token comment"># 控制输出的随机性，0.0-1.0之间，越小越确定</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-3-Prompt-模板"><a href="#2-3-Prompt-模板" class="headerlink" title="2.3 Prompt 模板"></a><strong>2.3 Prompt 模板</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_prompt</span><span class="token punctuation">(</span>prompt_template<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''将 Prompt 模板赋值'''</span>
    
    inputs <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> kwargs<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token builtin">all</span><span class="token punctuation">(</span><span class="token builtin">isinstance</span><span class="token punctuation">(</span>elem<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token keyword">for</span> elem <span class="token keyword">in</span> v<span class="token punctuation">)</span><span class="token punctuation">:</span>
            val <span class="token operator">=</span> <span class="token string">'\n\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>v<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            val <span class="token operator">=</span> v
        inputs<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> val

    <span class="token keyword">return</span> prompt_template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>

prompt_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
你是一个问答机器人。
你的任务是根据下述给定的已知信息，回答用户的问题。
  
已知信息：
{context} # 从向量数据库检索出原始文档

用户问：
{query} # 用户的提问

如果已知信息中不包含用户问题的答案，或者已知信息不足以回答用户问题，请回答“我无法回答您的问题”。
请不要输出已知信息中不包含的信息或答案。
请用中文回答用户问题。
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="三、向量检索"><a href="#三、向量检索" class="headerlink" title="三、向量检索"></a>三、向量检索</h2><h3 id="3-1-什么是向量"><a href="#3-1-什么是向量" class="headerlink" title="3.1 什么是向量"></a><strong>3.1 什么是向量</strong></h3><p>向量是一种有大小和方向的数学对象。它可以表示为从一个点到另一个点的有向线段。例如，二维空间中的向量可以表示为 $(x,y)$, 表示从原点 $(0,0)$ 到点 $(x,y)$ 的有向线段。</p>
<p><img src="https://pic1.imgdb.cn/item/681b6be158cb8da5c8e3d9ad.png" alt="向量坐标图"></p>
<p>以此类推，我可以用一组坐标 $(x_0, x_1, \ldots, x_{N-1})$ 表示一个 $N$ 维空间中的向量, $N$ 叫向量的维度。</p>
<h4 id="3-1-1-文本向量（Text-Embeddings）"><a href="#3-1-1-文本向量（Text-Embeddings）" class="headerlink" title="3.1.1 文本向量（Text Embeddings）"></a><strong>3.1.1 文本向量（Text Embeddings）</strong></h4><ol>
<li>将文本转换成一组 $N$ 维浮点数，即<strong>文本向量</strong>又叫 Embeddings</li>
<li>向量之间可以计算距离，距离远近对应<strong>语义相似度</strong>大小</li>
</ol>
<p><img src="https://pic1.imgdb.cn/item/681b6c4e58cb8da5c8e3d9e9.png" alt="embeddings"></p>
<h4 id="3-1-2-文本向量是怎样得到的"><a href="#3-1-2-文本向量是怎样得到的" class="headerlink" title="3.1.2 文本向量是怎样得到的"></a><strong>3.1.2 文本向量是怎样得到的</strong></h4><ol>
<li>构建相关（正例）与不相关（负例）的句子对样本</li>
<li>训练双塔模型，让正例间的距离小，负例间的距离大</li>
</ol>
<p>例如：<br><img src="https://pic1.imgdb.cn/item/681b6c4e58cb8da5c8e3d9e7.png" alt="sbert"></p>
<div class="alert alert-info">
<b>扩展阅读：https://www.sbert.net</b>
</div>

<h3 id="3-2-向量间的相似度计算"><a href="#3-2-向量间的相似度计算" class="headerlink" title="3.2 向量间的相似度计算"></a><strong>3.2 向量间的相似度计算</strong></h3><p>向量间的相似度计算在数学上有欧氏距离和余弦距离两种。<br><img src="https://pic1.imgdb.cn/item/681b6be158cb8da5c8e3d9ac.png" alt="向量相似度计算"></p>
<p>安装<code>numpy</code>库</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> numpy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>构建相似度计算公式：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> numpy <span class="token keyword">import</span> dot
<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>linalg <span class="token keyword">import</span> norm

<span class="token keyword">def</span> <span class="token function">cos_sim</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''余弦距离 -- 越大越相似'''</span>
    <span class="token keyword">return</span> dot<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>norm<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">*</span>norm<span class="token punctuation">(</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">l2</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''欧氏距离 -- 越小越相似'''</span>
    x <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>b<span class="token punctuation">)</span>
    <span class="token keyword">return</span> norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>封装 openai 的 Embeddings 模型接口</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_embeddings</span><span class="token punctuation">(</span>texts<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"text-embedding-ada-002"</span><span class="token punctuation">,</span> dimensions<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''封装 OpenAI 的 Embedding 模型接口'''</span>
    <span class="token keyword">if</span> model <span class="token operator">==</span> <span class="token string">"text-embedding-ada-002"</span><span class="token punctuation">:</span>
        dimensions <span class="token operator">=</span> <span class="token boolean">None</span>
        
    <span class="token keyword">if</span> dimensions<span class="token punctuation">:</span>
        data <span class="token operator">=</span> client<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
            <span class="token builtin">input</span><span class="token operator">=</span>texts<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> dimensions<span class="token operator">=</span>dimensions<span class="token punctuation">)</span><span class="token punctuation">.</span>data
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> client<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>texts<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">)</span><span class="token punctuation">.</span>data

    <span class="token keyword">return</span> <span class="token punctuation">[</span>x<span class="token punctuation">.</span>embedding <span class="token keyword">for</span> x <span class="token keyword">in</span> data<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<div class="alert alert-info">
<b>
Embedding模型的选择标准：找需求相关的语料库来进行文本向量转换测试，进行评估。<br>
大多数场景下，开源的嵌入模型使用都很一般，要提升检索召回率，建议对模型进行微调。
</b>
</div>

<p>进行测试</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">test_query <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"测试文本"</span><span class="token punctuation">]</span>
vec <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>test_query<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Total dimension: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"First 10 elements: </span><span class="token interpolation"><span class="token punctuation">{</span>vec<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token format-spec">10]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出的结果如下：</p>
<pre class="line-numbers language-none"><code class="language-none">Total dimension: 1536
First 10 elements: [-0.007280503865331411, -0.006169671658426523, -0.010576579719781876, 0.001448634546250105, -0.010707695037126541, 0.02919485792517662, -0.019725468009710312, 0.0053902678191661835, -0.016957491636276245, -0.01203340943902731]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>我们来用一些文本例子，计算比较它们的向量相似度</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">query <span class="token operator">=</span> <span class="token string">"国际争端"</span>

documents <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"联合国就苏丹达尔富尔地区大规模暴力事件发出警告"</span><span class="token punctuation">,</span>
    <span class="token string">"土耳其、芬兰、瑞典与北约代表将继续就瑞典“入约”问题进行谈判"</span><span class="token punctuation">,</span>
    <span class="token string">"日本岐阜市陆上自卫队射击场内发生枪击事件 3人受伤"</span><span class="token punctuation">,</span>
    <span class="token string">"国家游泳中心（水立方）：恢复游泳、嬉水乐园等水上项目运营"</span><span class="token punctuation">,</span>
    <span class="token string">"我国首次在空间站开展舱外辐射生物学暴露实验"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

query_vec <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
doc_vecs <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>

<span class="token comment"># 计算余弦相似度</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与自己的余弦相似度：{:.2f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>cos_sim<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> query_vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 计算Query与Documents的余弦相似度</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与Documents的余弦相似度："</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> vec <span class="token keyword">in</span> doc_vecs<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>cos_sim<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> vec<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 计算欧氏距离</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与自己的欧氏距离：{:.2f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>l2<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> query_vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 计算Query与Documents的欧氏距离</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与Documents的欧氏距离："</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> vec <span class="token keyword">in</span> doc_vecs<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>l2<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>运行的结果如下：</p>
<pre class="line-numbers language-none"><code class="language-none">Query与自己的余弦相似度：1.00
Query与Documents的余弦相似度：
0.8218706620454886
0.8293571683832858
0.7977047336154321
0.766980176753734
0.7930490196304245

Query与自己的欧氏距离：0.00
Query与Documents的欧氏距离：
0.5968741071718394
0.5841966059330832
0.6360743166598111
0.6826709412992098
0.6433521233350966<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-3-向量数据库"><a href="#3-3-向量数据库" class="headerlink" title="3.3 向量数据库"></a><strong>3.3 向量数据库</strong></h3><p>向量数据库是专门为向量检索设计的中间件</p>
<p>安装<code>chromadb</code>向量库包</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> chromadb<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>解析文档</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 为了演示方便，我们只取两页（第一章）</span>
paragraphs <span class="token operator">=</span> extract_text_from_pdf<span class="token punctuation">(</span>
    <span class="token string">"llama2.pdf"</span><span class="token punctuation">,</span>
    page_numbers<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    min_line_length<span class="token operator">=</span><span class="token number">10</span>
    <span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>创建MyVectorDBConnector类</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> chromadb
<span class="token keyword">from</span> chromadb<span class="token punctuation">.</span>config <span class="token keyword">import</span> Settings

<span class="token comment"># 创建MyVectorDBConnector类</span>
<span class="token keyword">class</span> <span class="token class-name">MyVectorDBConnector</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> collection_name<span class="token punctuation">,</span> embedding_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
        chroma_client <span class="token operator">=</span> chromadb<span class="token punctuation">.</span>Client<span class="token punctuation">(</span>Settings<span class="token punctuation">(</span>allow_reset<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 为了演示，实际不需要每次 reset()</span>
        chroma_client<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 创建一个 collection</span>
        self<span class="token punctuation">.</span>collection <span class="token operator">=</span> chroma_client<span class="token punctuation">.</span>get_or_create_collection<span class="token punctuation">(</span>name<span class="token operator">=</span>collection_name<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>embedding_fn <span class="token operator">=</span> embedding_fn
  
    <span class="token keyword">def</span> <span class="token function">add_documents</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> documents<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''向 collection 中添加文档与向量'''</span>
        self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>add<span class="token punctuation">(</span>
            embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding_fn<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 每个文档的向量</span>
            documents<span class="token operator">=</span>documents<span class="token punctuation">,</span>  <span class="token comment"># 文档的原文</span>
            ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"id</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">"</span></span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># 每个文档的 id</span>
        <span class="token punctuation">)</span>
        
    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query<span class="token punctuation">,</span> top_n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''检索向量数据库'''</span>
        results <span class="token operator">=</span> self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>query<span class="token punctuation">(</span>
            query_embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding_fn<span class="token punctuation">(</span><span class="token punctuation">[</span>query<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            n_results<span class="token operator">=</span>top_n
        <span class="token punctuation">)</span>

        <span class="token keyword">return</span> results

<span class="token comment"># 创建一个向量数据库对象</span>
vector_db <span class="token operator">=</span> MyVectorDBConnector<span class="token punctuation">(</span><span class="token string">"demo"</span><span class="token punctuation">,</span> get_embeddings<span class="token punctuation">)</span>
<span class="token comment"># 向量数据库中添加文档</span>
vector_db<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>paragraphs<span class="token punctuation">)</span>

user_query <span class="token operator">=</span> <span class="token string">"Llama 2有多少参数？"</span>

<span class="token comment"># user_query = "Does Llama 2 have a conversational variant"</span>
results <span class="token operator">=</span> vector_db<span class="token punctuation">.</span>search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> para <span class="token keyword">in</span> results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>para<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出结果如下：</p>
<pre class="line-numbers language-none"><code class="language-none">1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data. We also increased the size of the pretraining corpus by 40%, doubled the context length of the model, and adopted grouped-query attention (Ainslie et al., 2023). We are releasing variants of Llama 2 with 7B, 13B, and 70B parameters. We have also trained 34B variants, which we report on in this paper but are not releasing.§

 In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models. They also appear to be on par with some of the closed-source models, at least on the human evaluations we performed (see Figures 1 and 3). We have taken measures to increase the safety of these models, using safety-speciﬁc data annotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally, this paper contributes a thorough description of our ﬁne-tuning methodology and approach to improving LLM safety. We hope that this openness will enable the community to reproduce ﬁne-tuned LLMs and continue to improve the safety of those models, paving the way for more responsible development of LLMs. We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>


<div class="alert alert-success">
<b>澄清几个关键概念：</b><ul>
&nbsp; &nbsp; <li>向量数据库的意义是快速的检索；</li>
&nbsp; &nbsp; <li>向量数据库本身不生成向量，向量是由 Embedding 模型产生的；</li>
&nbsp; &nbsp; <li>向量数据库与传统的关系型数据库是互补的，不是替代关系，在实际应用中根据实际需求经常同时使用。</li>
</ul>
</div>

<h4 id="3-3-1-向量数据库服务"><a href="#3-3-1-向量数据库服务" class="headerlink" title="3.3.1 向量数据库服务"></a><strong>3.3.1 向量数据库服务</strong></h4><p>Server 端</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">chroma run <span class="token parameter variable">--path</span> /db_path<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>Client 端</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> chromadb

chroma_client <span class="token operator">=</span> chromadb<span class="token punctuation">.</span>HttpClient<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'localhost'</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">8000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h4 id="3-3-2-主流向量数据库功能对比"><a href="#3-3-2-主流向量数据库功能对比" class="headerlink" title="3.3.2 主流向量数据库功能对比"></a><strong>3.3.2 主流向量数据库功能对比</strong></h4><p><img src="https://pic1.imgdb.cn/item/681b6be158cb8da5c8e3d9ab.png" alt="主流向量数据库功能对比"></p>
<ul>
<li>FAISS: Meta 开源的向量检索引擎 <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/faiss">https://github.com/facebookresearch/faiss</a></li>
<li>Pinecone: 商用向量数据库，只有云服务 <a target="_blank" rel="noopener" href="https://www.pinecone.io/">https://www.pinecone.io/</a></li>
<li><strong>Milvus</strong>: 开源向量数据库，同时有云服务 <a target="_blank" rel="noopener" href="https://milvus.io/">https://milvus.io/</a></li>
<li>Weaviate: 开源向量数据库，同时有云服务 <a target="_blank" rel="noopener" href="https://weaviate.io/">https://weaviate.io/</a></li>
<li><strong>Qdrant</strong>: 开源向量数据库，同时有云服务 <a target="_blank" rel="noopener" href="https://qdrant.tech/">https://qdrant.tech/</a></li>
<li>PGVector: Postgres 的开源向量检索引擎 <a target="_blank" rel="noopener" href="https://github.com/pgvector/pgvector">https://github.com/pgvector/pgvector</a></li>
<li>RediSearch: Redis 的开源向量检索引擎 <a target="_blank" rel="noopener" href="https://github.com/RediSearch/RediSearch">https://github.com/RediSearch/RediSearch</a></li>
<li>ElasticSearch 也支持向量检索 <a target="_blank" rel="noopener" href="https://www.elastic.co/enterprise-search/vector-search">https://www.elastic.co/enterprise-search/vector-search</a></li>
</ul>
<div class="alert alert-info">
<b>扩展阅读：https://guangzhengli.com/blog/zh/vector-database</b>
</div>

<h3 id="3-4-基于向量检索的RAG"><a href="#3-4-基于向量检索的RAG" class="headerlink" title="3.4 基于向量检索的RAG"></a><strong>3.4 基于向量检索的RAG</strong></h3><p>构建RAG_Bot类</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">RAG_Bot</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vector_db<span class="token punctuation">,</span> llm_api<span class="token punctuation">,</span> n_results<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>vector_db <span class="token operator">=</span> vector_db
        self<span class="token punctuation">.</span>llm_api <span class="token operator">=</span>  llm_api
        self<span class="token punctuation">.</span>n_results <span class="token operator">=</span> n_results
    <span class="token keyword">def</span> <span class="token function">chat</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> user_query<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
        <span class="token comment"># 1. 检索</span>
        search_results <span class="token operator">=</span> self<span class="token punctuation">.</span>vector_db<span class="token punctuation">.</span>search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_results<span class="token punctuation">)</span>

        <span class="token comment"># 2. 构建 Prompt</span>
        prompt <span class="token operator">=</span> build_prompt<span class="token punctuation">(</span>
            prompt_template<span class="token punctuation">,</span> context<span class="token operator">=</span>search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> query<span class="token operator">=</span>user_query<span class="token punctuation">)</span>
            
        <span class="token comment"># 3. 调用 LLM</span>
        response <span class="token operator">=</span> self<span class="token punctuation">.</span>llm_api<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>
        <span class="token keyword">return</span> response<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>创建一个RAG机器人对象</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建一个RAG机器人</span>
bot <span class="token operator">=</span> RAG_Bot<span class="token punctuation">(</span>
    vector_db<span class="token punctuation">,</span>
    llm_api<span class="token operator">=</span>get_completion
<span class="token punctuation">)</span>

user_query <span class="token operator">=</span> <span class="token string">"llama 2有多少参数?"</span>

response <span class="token operator">=</span> bot<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>user_query<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里输出内容如下：</p>
<pre class="line-numbers language-none"><code class="language-none">Llama 2有7B、13B和70B参数的变体。<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h2 id="3-5-OpenAI-新发布的两个Embedding模型"><a href="#3-5-OpenAI-新发布的两个Embedding模型" class="headerlink" title="3.5 OpenAI 新发布的两个Embedding模型"></a>3.5 OpenAI 新发布的两个Embedding模型</h2><p>2024 年 1 月 25 日，OpenAI 新发布了两个 Embedding 模型</p>
<ul>
<li>text-embedding-3-large</li>
<li>text-embedding-3-small</li>
</ul>
<p>其最大特点是，支持自定义的缩短向量维度，从而在几乎不影响最终效果的情况下降低向量检索与相似度计算的复杂度。</p>
<p>通俗的说：<strong>越大越准、越小越快。</strong> 官方公布的评测结果:</p>
<p><img src="https://pic1.imgdb.cn/item/681b6c4e58cb8da5c8e3d9e8.png" alt="官方测评结果"></p>
<p>注：<a target="_blank" rel="noopener" href="https://huggingface.co/blog/mteb">MTEB</a> 是一个大规模多任务的 Embedding 模型公开评测集</p>
<div class="alert alert-info">
<b>RAG系统基本需要用到 两个模型<br>
embedded模型：采用open ai 的线上模型，向量模型的精确度直接影响query 相似度检索的文档召回率<br>
文本生成模型（对话模型）：采用本地私有化部署模型
</b>
</div>

<p>测试 <code>text-embedding-3-large</code> Embedding模型效果</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> <span class="token string">"text-embedding-3-large"</span>
dimensions <span class="token operator">=</span> <span class="token number">128</span>

<span class="token comment"># query = "国际争端"</span>

<span class="token comment"># 且能支持跨语言</span>
query <span class="token operator">=</span> <span class="token string">"global conflicts"</span>

documents <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"联合国就苏丹达尔富尔地区大规模暴力事件发出警告"</span><span class="token punctuation">,</span>
    <span class="token string">"土耳其、芬兰、瑞典与北约代表将继续就瑞典“入约”问题进行谈判"</span><span class="token punctuation">,</span>
    <span class="token string">"日本岐阜市陆上自卫队射击场内发生枪击事件 3人受伤"</span><span class="token punctuation">,</span>
    <span class="token string">"国家游泳中心（水立方）：恢复游泳、嬉水乐园等水上项目运营"</span><span class="token punctuation">,</span>
    <span class="token string">"我国首次在空间站开展舱外辐射生物学暴露实验"</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

query_vec <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span><span class="token punctuation">[</span>query<span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> dimensions<span class="token operator">=</span>dimensions<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

doc_vecs <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>documents<span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> dimensions<span class="token operator">=</span>dimensions<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"向量维度: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>query_vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与Documents的余弦距离:"</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> vec <span class="token keyword">in</span> doc_vecs<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>cos_sim<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> vec<span class="token punctuation">)</span><span class="token punctuation">)</span>
   
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Query与Documents的欧氏距离:"</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> vec <span class="token keyword">in</span> doc_vecs<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>l2<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出内容如下：</p>
<pre class="line-numbers language-none"><code class="language-none">向量维度: 128

Query与Documents的余弦距离:
0.33418796172379334
0.35462977252280126
0.31364599128817017
0.22422448391215455
0.12849126788491727

Query与Documents的欧氏距离:
1.1539601565325632
1.1361075718324967
1.1716262617987068
1.2456127243145834
1.320233859479998<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<div class="alert alert-info">
<b>扩展阅读：这种可变长度的 Embedding 技术背后的原理叫做 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2205.13147">Matryoshka Representation Learning</a> </b>
</div>

<h2 id="四、-实战-RAG-系统的进阶知识"><a href="#四、-实战-RAG-系统的进阶知识" class="headerlink" title="四、 实战 RAG 系统的进阶知识"></a>四、 实战 RAG 系统的进阶知识</h2><h3 id="4-1-文本分割的粒度"><a href="#4-1-文本分割的粒度" class="headerlink" title="4.1 文本分割的粒度"></a>4.1 文本分割的粒度</h3><p><strong>缺陷</strong></p>
<ol>
<li>粒度太大可能导致检索不精准，粒度太小可能导致信息不全面</li>
<li>问题的答案可能跨越两个片段</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建一个向量数据库对象</span>
vector_db <span class="token operator">=</span> MyVectorDBConnector<span class="token punctuation">(</span><span class="token string">"demo_text_split"</span><span class="token punctuation">,</span> get_embeddings<span class="token punctuation">)</span>

<span class="token comment"># 向向量数据库中添加文档</span>
vector_db<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>paragraphs<span class="token punctuation">)</span>

<span class="token comment"># 创建一个RAG机器人</span>
bot <span class="token operator">=</span> RAG_Bot<span class="token punctuation">(</span>
    vector_db<span class="token punctuation">,</span>
    llm_api<span class="token operator">=</span>get_completion
<span class="token punctuation">)</span>

<span class="token comment"># user_query = "llama 2有商用许可协议吗?"</span>
user_query<span class="token operator">=</span><span class="token string">"llama 2 chat有多少参数?"</span>
search_results <span class="token operator">=</span> vector_db<span class="token punctuation">.</span>search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> doc <span class="token keyword">in</span> search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>doc<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>

response <span class="token operator">=</span> bot<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>user_query<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"====回复===="</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"=============================="</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
<span class="token keyword">for</span> p <span class="token keyword">in</span> paragraphs<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"=========="</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>p<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出内容如下：</p>
<pre class="line-numbers language-none"><code class="language-none">In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models. They also appear to be on par with some of the closed-source models, at least on the human evaluations we performed (see Figures 1 and 3). We have taken measures to increase the safety of these models, using safety-speciﬁc data annotation and tuning, as well as conducting red-teaming and employing iterative evaluations. Additionally, this paper contributes a thorough description of our ﬁne-tuning methodology and approach to improving LLM safety. We hope that this openness will enable the community to reproduce ﬁne-tuned LLMs and continue to improve the safety of those models, paving the way for more responsible development of LLMs. We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge.

 2. Llama 2-Chat, a ﬁne-tuned version of Llama 2 that is optimized for dialogue use cases. We release

====回复====
Llama 2-Chat的参数规模可以达到70B。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>改进</strong>: 按一定粒度，部分重叠式的切割文本，使上下文更完整</p>
<p>安装<code>nltk</code>包</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> nltk<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>重新按照一定条件来切割文档</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>tokenize <span class="token keyword">import</span> sent_tokenize
<span class="token keyword">import</span> json

<span class="token comment"># chunk_size 一般根据文档内容或大小来设置</span>
<span class="token comment"># overlap_size 一般设置 chunk_size 大小的10%-20%之间</span>
<span class="token keyword">def</span> <span class="token function">split_text</span><span class="token punctuation">(</span>paragraphs<span class="token punctuation">,</span> chunk_size<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> overlap_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''按指定 chunk_size 和 overlap_size 交叠割文本'''</span>
    
    sentences <span class="token operator">=</span> <span class="token punctuation">[</span>s<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> paragraphs <span class="token keyword">for</span> s <span class="token keyword">in</span> sent_tokenize<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token comment"># sentences = [s.strip() for p in paragraphs for s in sent_tokenize(p, language='chinese')]</span>
    chunks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    i <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">while</span> i <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span><span class="token punctuation">:</span>
        chunk <span class="token operator">=</span> sentences<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        overlap <span class="token operator">=</span> <span class="token string">''</span>
        prev_len <span class="token operator">=</span> <span class="token number">0</span>
        prev <span class="token operator">=</span> i <span class="token operator">-</span> <span class="token number">1</span>

        <span class="token comment"># 向前计算重叠部分</span>
        <span class="token keyword">while</span> prev <span class="token operator">&gt;=</span> <span class="token number">0</span> <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">[</span>prev<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token builtin">len</span><span class="token punctuation">(</span>overlap<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> overlap_size<span class="token punctuation">:</span>
            overlap <span class="token operator">=</span> sentences<span class="token punctuation">[</span>prev<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">' '</span> <span class="token operator">+</span> overlap
            prev <span class="token operator">-=</span> <span class="token number">1</span>
        chunk <span class="token operator">=</span> overlap<span class="token operator">+</span>chunk
        <span class="token builtin">next</span> <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span>
        <span class="token comment"># 向后计算当前chunk</span>
        <span class="token keyword">while</span> <span class="token builtin">next</span> <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token builtin">len</span><span class="token punctuation">(</span>sentences<span class="token punctuation">[</span><span class="token builtin">next</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token builtin">len</span><span class="token punctuation">(</span>chunk<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> chunk_size<span class="token punctuation">:</span>
            chunk <span class="token operator">=</span> chunk <span class="token operator">+</span> <span class="token string">' '</span> <span class="token operator">+</span> sentences<span class="token punctuation">[</span><span class="token builtin">next</span><span class="token punctuation">]</span>
            <span class="token builtin">next</span> <span class="token operator">+=</span> <span class="token number">1</span>
        chunks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>chunk<span class="token punctuation">)</span>
        i <span class="token operator">=</span> <span class="token builtin">next</span>

    <span class="token keyword">return</span> chunks

chunks <span class="token operator">=</span> split_text<span class="token punctuation">(</span>paragraphs<span class="token punctuation">,</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<div class="alert alert-info">
此处 sent_tokenize 为针对英文的实现，针对中文的实现请参考 chinese_utils.py
</div>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建一个向量数据库对象</span>
vector_db <span class="token operator">=</span> MyVectorDBConnector<span class="token punctuation">(</span><span class="token string">"demo_text_split"</span><span class="token punctuation">,</span> get_embeddings<span class="token punctuation">)</span>

<span class="token comment"># 向向量数据库中添加文档</span>
vector_db<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>chunks<span class="token punctuation">)</span>

<span class="token comment"># 创建一个RAG机器人</span>
bot <span class="token operator">=</span> RAG_Bot<span class="token punctuation">(</span>
     vector_db<span class="token punctuation">,</span>
     llm_api<span class="token operator">=</span>get_completion
<span class="token punctuation">)</span>

<span class="token comment"># user_query = "llama 2有商用许可协议吗"</span>
user_query<span class="token operator">=</span><span class="token string">"llama 2 chat有多少参数"</span>

search_results <span class="token operator">=</span> vector_db<span class="token punctuation">.</span>search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> doc <span class="token keyword">in</span> search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>doc<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>

response <span class="token operator">=</span> bot<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>user_query<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"====回复===="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>结果输出如下：</p>
<pre class="line-numbers language-none"><code class="language-none">2. Llama 2-Chat, a ﬁne-tuned version of Llama 2 that is optimized for dialogue use cases. We release variants of this model with 7B, 13B, and 70B parameters as well. We believe that the open release of LLMs, when done safely, will be a net beneﬁt to society.

In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models.

====回复====
Llama 2-Chat 具有 7B、13B 和 70B 三种不同的参数规模。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>文本切割</p>
<ul>
<li>chunksize 和 overlap 来重叠切割<br>&nbsp; &nbsp; - \n \n\n 基于某些规则来切分的</li>
<li>对于复杂的文本的切分<br>&nbsp; &nbsp; - NSP任务来进行微调训练（拿自己的业务数据来喂投）<br>&nbsp; &nbsp; &nbsp; &nbsp; - A和B两个句子（段落）是否有关系<br>&nbsp; &nbsp; &nbsp; &nbsp; 若有关系则进行合并</li>
</ul>
<h3 id="4-2-检索后排序"><a href="#4-2-检索后排序" class="headerlink" title="4.2 检索后排序"></a>4.2 检索后排序</h3><p>问题：有时，最合适的答案不一定排在检索的最前面，例如：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">user_query <span class="token operator">=</span> <span class="token string">"how safe is llama 2"</span>
search_results <span class="token operator">=</span> vector_db<span class="token punctuation">.</span>search<span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> doc <span class="token keyword">in</span> search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>doc<span class="token operator">+</span><span class="token string">"\n"</span><span class="token punctuation">)</span>

response <span class="token operator">=</span> bot<span class="token punctuation">.</span>chat<span class="token punctuation">(</span>user_query<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"====回复===="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>结果输出如下：</p>
<pre class="line-numbers language-none"><code class="language-none">We believe that the open release of LLMs, when done safely, will be a net beneﬁt to society. Like all LLMs, Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021; Solaiman et al., 2023).

We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. Figure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed source models.

In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models.

Additionally, these safety evaluations are performed using content standards that are likely to be biased towards the Llama 2-Chat models. We are releasing the following models to the general public for research and commercial use‡: 1.

We provide a responsible use guide¶ and code examples‖ to facilitate the safe deployment of Llama 2 and Llama 2-Chat. More details of our responsible release strategy can be found in Section 5.3.

====回复====
我无法回答您的问题。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>方案</strong>:</p>
<ol>
<li>检索时通过招回一部分文本</li>
<li>通过一个排序模型对 query 和 document 重新打分排序</li>
</ol>
<p><img src="https://pic1.imgdb.cn/item/681b6be158cb8da5c8e3d9ae.png" alt="检索召回"></p>
<div class="alert alert-danger">
以下代码运行前我们要确保能访问 Hugging Face！
</div>
安装`sentence_transformers`库
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> sentence_transformers<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sentence_transformers <span class="token keyword">import</span> CrossEncoder

<span class="token comment"># 访问调用Hugging Face模型</span>
model <span class="token operator">=</span> CrossEncoder<span class="token punctuation">(</span><span class="token string">'cross-encoder/ms-marco-MiniLM-L-6-v2'</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">)</span> <span class="token comment"># 英文，模型较小</span>
<span class="token comment"># model = CrossEncoder('BAAI/bge-reranker-large', max_length=512) # 多语言，国产，模型较大</span>


user_query <span class="token operator">=</span> <span class="token string">"how safe is llama 2"</span>
<span class="token comment"># user_query = "llama 2安全性如何"</span>

scores <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span>user_query<span class="token punctuation">,</span> doc<span class="token punctuation">)</span> <span class="token keyword">for</span> doc <span class="token keyword">in</span> search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 按得分排序</span>
sorted_list <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>scores<span class="token punctuation">,</span> search_results<span class="token punctuation">[</span><span class="token string">'documents'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> score<span class="token punctuation">,</span> doc <span class="token keyword">in</span> sorted_list<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>score<span class="token punctuation">}</span></span><span class="token string">\t</span><span class="token interpolation"><span class="token punctuation">{</span>doc<span class="token punctuation">}</span></span><span class="token string">\n"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>输出结果如下，可以看到下面内容是按得分然后重新排序得到的：</p>
<pre class="line-numbers language-none"><code class="language-none">6.613734722137451	We believe that the open release of LLMs, when done safely, will be a net beneﬁt to society. Like all LLMs, Llama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021; Solaiman et al., 2023).

5.310717582702637	In this work, we develop and release Llama 2, a family of pretrained and ﬁne-tuned LLMs, Llama 2 and Llama 2-Chat, at scales up to 70B parameters. On the series of helpfulness and safety benchmarks we tested, Llama 2-Chat models generally perform better than existing open-source models.

4.709955215454102	We provide a responsible use guide¶ and code examples‖ to facilitate the safe deployment of Llama 2 and Llama 2-Chat. More details of our responsible release strategy can be found in Section 5.3.

4.5439653396606445	We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. Figure 3: Safety human evaluation results for Llama 2-Chat compared to other open-source and closed source models.

4.0338897705078125	Additionally, these safety evaluations are performed using content standards that are likely to be biased towards the Llama 2-Chat models. We are releasing the following models to the general public for research and commercial use‡: 1.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<div class="alert alert-danger">
！所以切割也比较重要，这里我因为前面新切割方法报错所以没有使用新的切割后的文本，这里输出的答案有些是不同的
</div>

<h4 id="一些-Rerank-的-API-服务"><a href="#一些-Rerank-的-API-服务" class="headerlink" title="一些 Rerank 的 API 服务"></a>一些 Rerank 的 API 服务</h4><ul>
<li><a target="_blank" rel="noopener" href="https://cohere.com/rerank">Cohere Rerank</a>：支持多语言</li>
<li><a target="_blank" rel="noopener" href="https://jina.ai/reranker/">Jina Rerank</a>：目前只支持英文</li>
</ul>
<h3 id="4-3-混合检索（Hybrid-Search）"><a href="#4-3-混合检索（Hybrid-Search）" class="headerlink" title="4.3 混合检索（Hybrid Search）"></a><strong>4.3 混合检索（Hybrid Search）</strong></h3><p>在<strong>实际生产</strong>中，传统的关键字检索（稀疏表示）与向量检索（稠密表示）各有优劣。</p>
<p>举个具体例子，比如文档中包含很长的专有名词，关键字检索往往更精准而向量检索容易引入概念混淆。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 背景说明：在医学中“小细胞肺癌”和“非小细胞肺癌”是两种不同的癌症</span>
query <span class="token operator">=</span> <span class="token string">"非小细胞肺癌的患者"</span>

documents <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"玛丽患有肺癌，癌细胞已转移"</span><span class="token punctuation">,</span>
    <span class="token string">"刘某肺癌I期"</span><span class="token punctuation">,</span>
    <span class="token string">"张某经诊断为非小细胞肺癌III期"</span><span class="token punctuation">,</span>
    <span class="token string">"小细胞肺癌是肺癌的一种"</span>
<span class="token punctuation">]</span>

query_vec <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span><span class="token punctuation">[</span>query<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
doc_vecs <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Cosine distance:"</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> vec <span class="token keyword">in</span> doc_vecs<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>cos_sim<span class="token punctuation">(</span>query_vec<span class="token punctuation">,</span> vec<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出的结果如下：</p>
<pre class="line-numbers language-none"><code class="language-none">Cosine distance:
0.8912871311166322
0.8896135883660553
0.9039894669142209
0.9131454293290566<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>所以，有时候我们需要结合不同的检索算法，来达到比单一检索算法更优的效果。这就是<strong>混合检索</strong>。<br>混合检索的核心是，综合文档 $d$ 在不同检索算法下的排序名次（rank），为其生成最终排序。<br>一个最常用的算法叫 <strong>Reciprocal Rank Fusion（RRF）</strong><br>$rrf(d)=\sum_{a\in A}\frac{1}{k+rank_a(d)}$<br>其中 $A$ 表示所有使用的检索算法的集合，$rank_a(d)$ 表示使用算法 $a$ 检索时，文档 $d$ 的排序，$k$ 是个常数。<br>很多向量数据库都支持混合检索，比如 <a target="_blank" rel="noopener" href="https://weaviate.io/blog/hybrid-search-explained">Weaviate</a>、<a target="_blank" rel="noopener" href="https://www.pinecone.io/learn/hybrid-search-intro/">Pinecone</a> 等。也可以根据上述原理自己实现。</p>
<h4 id="4-3-1-手写个简单的例子"><a href="#4-3-1-手写个简单的例子" class="headerlink" title="4.3.1 手写个简单的例子"></a>4.3.1 手写个简单的例子</h4><div class="alert alert-danger">
注意：需要安装好 Elastic Search Server，并启动！
</div>

<p>1.基于关键字检索的排序</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> elasticsearch7<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> time

<span class="token keyword">class</span> <span class="token class-name">MyEsConnector</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> es_client<span class="token punctuation">,</span> index_name<span class="token punctuation">,</span> keyword_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>es_client <span class="token operator">=</span> es_client
        self<span class="token punctuation">.</span>index_name <span class="token operator">=</span> index_name
        self<span class="token punctuation">.</span>keyword_fn <span class="token operator">=</span> keyword_fn

    <span class="token keyword">def</span> <span class="token function">add_documents</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> documents<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''文档灌库'''</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>es_client<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>index<span class="token operator">=</span>self<span class="token punctuation">.</span>index_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>es_client<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>delete<span class="token punctuation">(</span>index<span class="token operator">=</span>self<span class="token punctuation">.</span>index_name<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>es_client<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>create<span class="token punctuation">(</span>index<span class="token operator">=</span>self<span class="token punctuation">.</span>index_name<span class="token punctuation">)</span>
        actions <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token punctuation">{</span>
                <span class="token string">"_index"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>index_name<span class="token punctuation">,</span>
                <span class="token string">"_source"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                    <span class="token string">"keywords"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>keyword_fn<span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token string">"text"</span><span class="token punctuation">:</span> doc<span class="token punctuation">,</span>
                    <span class="token string">"id"</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f"doc_</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">"</span></span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">}</span>
            <span class="token keyword">for</span> i<span class="token punctuation">,</span> doc <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span>
        <span class="token punctuation">]</span>
        helpers<span class="token punctuation">.</span>bulk<span class="token punctuation">(</span>self<span class="token punctuation">.</span>es_client<span class="token punctuation">,</span> actions<span class="token punctuation">)</span>
        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query_string<span class="token punctuation">,</span> top_n<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''检索'''</span>
        search_query <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">"match"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                <span class="token string">"keywords"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>keyword_fn<span class="token punctuation">(</span>query_string<span class="token punctuation">)</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
        res <span class="token operator">=</span> self<span class="token punctuation">.</span>es_client<span class="token punctuation">.</span>search<span class="token punctuation">(</span>
            index<span class="token operator">=</span>self<span class="token punctuation">.</span>index_name<span class="token punctuation">,</span> query<span class="token operator">=</span>search_query<span class="token punctuation">,</span> size<span class="token operator">=</span>top_n<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">{</span>
            hit<span class="token punctuation">[</span><span class="token string">"_source"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                <span class="token string">"text"</span><span class="token punctuation">:</span> hit<span class="token punctuation">[</span><span class="token string">"_source"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token string">"rank"</span><span class="token punctuation">:</span> i<span class="token punctuation">,</span>
            <span class="token punctuation">}</span>
            <span class="token keyword">for</span> i<span class="token punctuation">,</span> hit <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>res<span class="token punctuation">[</span><span class="token string">"hits"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"hits"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> chinese_utils <span class="token keyword">import</span> to_keywords  <span class="token comment"># 使用中文的关键字提取函数</span>

<span class="token comment"># 引入配置文件</span>
ELASTICSEARCH_BASE_URL <span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ELASTICSEARCH_BASE_URL'</span><span class="token punctuation">)</span>
ELASTICSEARCH_PASSWORD <span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ELASTICSEARCH_PASSWORD'</span><span class="token punctuation">)</span>
ELASTICSEARCH_NAME<span class="token operator">=</span> os<span class="token punctuation">.</span>getenv<span class="token punctuation">(</span><span class="token string">'ELASTICSEARCH_NAME'</span><span class="token punctuation">)</span>

es <span class="token operator">=</span> Elasticsearch<span class="token punctuation">(</span>
    hosts<span class="token operator">=</span><span class="token punctuation">[</span>ELASTICSEARCH_BASE_URL<span class="token punctuation">]</span><span class="token punctuation">,</span>
    http_auth<span class="token operator">=</span><span class="token punctuation">(</span>ELASTICSEARCH_NAME<span class="token punctuation">,</span> ELASTICSEARCH_PASSWORD<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 用户名，密码</span>
<span class="token punctuation">)</span>

<span class="token comment"># 创建 ES 连接器</span>
es_connector <span class="token operator">=</span> MyEsConnector<span class="token punctuation">(</span>es<span class="token punctuation">,</span> <span class="token string">"demo_es_rrf"</span><span class="token punctuation">,</span> to_keywords<span class="token punctuation">)</span>

<span class="token comment"># 文档灌库</span>
es_connector<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>

<span class="token comment"># 关键字检索</span>
keyword_search_results <span class="token operator">=</span> es_connector<span class="token punctuation">.</span>search<span class="token punctuation">(</span>query<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>keyword_search_results<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>2.基于向量检索的排序</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 创建向量数据库连接器</span>
vecdb_connector <span class="token operator">=</span> MyVectorDBConnector<span class="token punctuation">(</span><span class="token string">"demo_vec_rrf"</span><span class="token punctuation">,</span> get_embeddings<span class="token punctuation">)</span>

<span class="token comment"># 文档灌库</span>
vecdb_connector<span class="token punctuation">.</span>add_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>

<span class="token comment"># 向量检索</span>
vector_search_results <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">"doc_"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>documents<span class="token punctuation">.</span>index<span class="token punctuation">(</span>doc<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
        <span class="token string">"text"</span><span class="token punctuation">:</span> doc<span class="token punctuation">,</span>
        <span class="token string">"rank"</span><span class="token punctuation">:</span> i
    <span class="token punctuation">}</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> doc <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>
        vecdb_connector<span class="token punctuation">.</span>search<span class="token punctuation">(</span>query<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"documents"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token punctuation">)</span>
<span class="token punctuation">}</span>  <span class="token comment"># 把结果转成跟上面关键字检索结果一样的格式</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>vector_search_results<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>3.基于 RRF 的融合排序</p>
<p>参考资料：<a target="_blank" rel="noopener" href="https://learn.microsoft.com/zh-cn/azure/search/hybrid-search-ranking">https://learn.microsoft.com/zh-cn/azure/search/hybrid-search-ranking</a></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> json

<span class="token keyword">def</span> <span class="token function">rrf</span><span class="token punctuation">(</span>ranks<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    ret <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
    <span class="token comment"># 遍历每次的排序结果</span>
    <span class="token keyword">for</span> rank <span class="token keyword">in</span> ranks<span class="token punctuation">:</span>
        <span class="token comment"># 遍历排序中每个元素</span>
        <span class="token keyword">for</span> <span class="token builtin">id</span><span class="token punctuation">,</span> val <span class="token keyword">in</span> rank<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">id</span> <span class="token keyword">not</span> <span class="token keyword">in</span> ret<span class="token punctuation">:</span>
                ret<span class="token punctuation">[</span><span class="token builtin">id</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"score"</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token punctuation">:</span> val<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
            <span class="token comment"># 计算 RRF 得分</span>
            ret<span class="token punctuation">[</span><span class="token builtin">id</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"score"</span><span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1.0</span><span class="token operator">/</span><span class="token punctuation">(</span>k<span class="token operator">+</span>val<span class="token punctuation">[</span><span class="token string">"rank"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 按 RRF 得分排序，并返回</span>
    <span class="token keyword">return</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>ret<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> item<span class="token punctuation">:</span> item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"score"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 融合两次检索的排序结果</span>
reranked <span class="token operator">=</span> rrf<span class="token punctuation">(</span><span class="token punctuation">[</span>keyword_search_results<span class="token punctuation">,</span> vector_search_results<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>reranked<span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="五、PDF文档中的表格怎样处理"><a href="#五、PDF文档中的表格怎样处理" class="headerlink" title="五、PDF文档中的表格怎样处理"></a>五、PDF文档中的表格怎样处理</h2><p><img src="https://pic1.imgdb.cn/item/681b6be158cb8da5c8e3d9af.png" alt="PDF中表格处理"></p>
<h3 id="5-1-将每页-PDF-转成图片"><a href="#5-1-将每页-PDF-转成图片" class="headerlink" title="5.1 将每页 PDF 转成图片"></a><strong>5.1 将每页 PDF 转成图片</strong></h3><p>安装 <code>PyMuPDF</code> 和 <code>matplotlib</code> 库</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> PyMuPDF
pip <span class="token function">install</span> matplotlib<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> fitz
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image

<span class="token keyword">def</span> <span class="token function">pdf2images</span><span class="token punctuation">(</span>pdf_file<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''将 PDF 每页转成一个 PNG 图像'''</span>

    <span class="token comment"># 保存路径为原 PDF 文件名（不含扩展名）</span>
    output_directory_path<span class="token punctuation">,</span> _ <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>splitext<span class="token punctuation">(</span>pdf_file<span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>output_directory_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>output_directory_path<span class="token punctuation">)</span>
    <span class="token comment"># 加载 PDF 文件</span>
    pdf_document <span class="token operator">=</span> fitz<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>pdf_file<span class="token punctuation">)</span>
    <span class="token comment"># 每页转一张图</span>
    <span class="token keyword">for</span> page_number <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>pdf_document<span class="token punctuation">.</span>page_count<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 取一页</span>
        page <span class="token operator">=</span> pdf_document<span class="token punctuation">[</span>page_number<span class="token punctuation">]</span>
        <span class="token comment"># 转图像</span>
        pix <span class="token operator">=</span> page<span class="token punctuation">.</span>get_pixmap<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 从位图创建 PNG 对象</span>
        image <span class="token operator">=</span> Image<span class="token punctuation">.</span>frombytes<span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>pix<span class="token punctuation">.</span>width<span class="token punctuation">,</span> pix<span class="token punctuation">.</span>height<span class="token punctuation">]</span><span class="token punctuation">,</span> pix<span class="token punctuation">.</span>samples<span class="token punctuation">)</span>
        <span class="token comment"># 保存 PNG 文件</span>
        image<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"./</span><span class="token interpolation"><span class="token punctuation">{</span>output_directory_path<span class="token punctuation">}</span></span><span class="token string">/page_</span><span class="token interpolation"><span class="token punctuation">{</span>page_number <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">.png"</span></span><span class="token punctuation">)</span>
    <span class="token comment"># 关闭 PDF 文件</span>
    pdf_document<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> os
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">def</span> <span class="token function">show_images</span><span class="token punctuation">(</span>dir_path<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">'''显示目录下的 PNG 图像'''</span>
    <span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>dir_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">file</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'.png'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 打开图像</span>
            img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dir_path<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment"># 显示图像</span>
            plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
            plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>  <span class="token comment"># 不显示坐标轴</span>
            plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python">pdf2images<span class="token punctuation">(</span><span class="token string">"llama2_page8.pdf"</span><span class="token punctuation">)</span>
show_images<span class="token punctuation">(</span><span class="token string">"llama2_page8"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>结果输出如下：</p>
<p><img src="https://pic1.imgdb.cn/item/681bf96d58cb8da5c8e3e89a.png" alt="PDF表格转图片"></p>
<h3 id="5-2-识别文档（图片）中的表格"><a href="#5-2-识别文档（图片）中的表格" class="headerlink" title="5.2 识别文档（图片）中的表格"></a><strong>5.2 识别文档（图片）中的表格</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MaxResize</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''缩放图像'''</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> max_size<span class="token operator">=</span><span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>max_size <span class="token operator">=</span> max_size

    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image<span class="token punctuation">)</span><span class="token punctuation">:</span>
        width<span class="token punctuation">,</span> height <span class="token operator">=</span> image<span class="token punctuation">.</span>size
        current_max_size <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>width<span class="token punctuation">,</span> height<span class="token punctuation">)</span>
        scale <span class="token operator">=</span> self<span class="token punctuation">.</span>max_size <span class="token operator">/</span> current_max_size
        resized_image <span class="token operator">=</span> image<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>
            <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">round</span><span class="token punctuation">(</span>scale <span class="token operator">*</span> width<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">round</span><span class="token punctuation">(</span>scale <span class="token operator">*</span> height<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

        <span class="token keyword">return</span> resized_image<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>安装三个环境包：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> torchvision
pip <span class="token function">install</span> transformers
pip <span class="token function">install</span> timm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms

<span class="token comment"># 图像预处理</span>
detection_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        MaxResize<span class="token punctuation">(</span><span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token comment"># 将原始的PILImage格式的数据格式化为可被pytorch快速处理的张量类型</span>
        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForObjectDetection

<span class="token comment"># 加载 TableTransformer 模型</span>
model <span class="token operator">=</span> AutoModelForObjectDetection<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    <span class="token string">"microsoft/table-transformer-detection"</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>识别后的坐标换算和后处理</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 识别后的坐标换算与后处理</span>
<span class="token keyword">def</span> <span class="token function">box_cxcywh_to_xyxy</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''坐标转换'''</span>
    x_c<span class="token punctuation">,</span> y_c<span class="token punctuation">,</span> w<span class="token punctuation">,</span> h <span class="token operator">=</span> x<span class="token punctuation">.</span>unbind<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    b <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>x_c <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>y_c <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> h<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_c <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> w<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>y_c <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> h<span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>b<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">rescale_bboxes</span><span class="token punctuation">(</span>out_bbox<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''区域缩放'''</span>
    width<span class="token punctuation">,</span> height <span class="token operator">=</span> size
    boxes <span class="token operator">=</span> box_cxcywh_to_xyxy<span class="token punctuation">(</span>out_bbox<span class="token punctuation">)</span>
    boxes <span class="token operator">=</span> boxes <span class="token operator">*</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>width<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> height<span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> boxes

<span class="token keyword">def</span> <span class="token function">outputs_to_objects</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> img_size<span class="token punctuation">,</span> id2label<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''从模型输出中取定位框坐标'''</span>
    m <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    pred_labels <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>indices<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    pred_scores <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>m<span class="token punctuation">.</span>values<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    pred_bboxes <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token string">"pred_boxes"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    pred_bboxes <span class="token operator">=</span> <span class="token punctuation">[</span>
        elem<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> elem <span class="token keyword">in</span> rescale_bboxes<span class="token punctuation">(</span>pred_bboxes<span class="token punctuation">,</span> img_size<span class="token punctuation">)</span>
    <span class="token punctuation">]</span>

    objects <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> label<span class="token punctuation">,</span> score<span class="token punctuation">,</span> bbox <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>pred_labels<span class="token punctuation">,</span> pred_scores<span class="token punctuation">,</span> pred_bboxes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        class_label <span class="token operator">=</span> id2label<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> class_label <span class="token operator">==</span> <span class="token string">"no object"</span><span class="token punctuation">:</span>
            objects<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                <span class="token punctuation">{</span>
                    <span class="token string">"label"</span><span class="token punctuation">:</span> class_label<span class="token punctuation">,</span>
                    <span class="token string">"score"</span><span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">(</span>score<span class="token punctuation">)</span><span class="token punctuation">,</span>
                    <span class="token string">"bbox"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">(</span>elem<span class="token punctuation">)</span> <span class="token keyword">for</span> elem <span class="token keyword">in</span> bbox<span class="token punctuation">]</span><span class="token punctuation">,</span>
                <span class="token punctuation">}</span>
            <span class="token punctuation">)</span>
    <span class="token keyword">return</span> objects<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>识别表格，并将表格部分单独存为图像文件</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch

<span class="token comment"># 识别表格，并将表格部分单独存为图像文件</span>

<span class="token keyword">def</span> <span class="token function">detect_and_crop_save_table</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 加载图像（PDF页）    </span>
    image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>
    filename<span class="token punctuation">,</span> _ <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>splitext<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>basename<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 输出路径</span>
    cropped_table_directory <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"table_images"</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>cropped_table_directory<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>cropped_table_directory<span class="token punctuation">)</span>
    <span class="token comment"># 预处理</span>
    pixel_values <span class="token operator">=</span> detection_transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment"># 识别表格</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span>pixel_values<span class="token punctuation">)</span>

    <span class="token comment"># 后处理，得到表格子区域</span>
    id2label <span class="token operator">=</span> model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>id2label
    id2label<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>config<span class="token punctuation">.</span>id2label<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"no object"</span>
    detected_tables <span class="token operator">=</span> outputs_to_objects<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> image<span class="token punctuation">.</span>size<span class="token punctuation">,</span> id2label<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"number of tables detected </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>detected_tables<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> idx <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>detected_tables<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将识别从的表格区域单独存为图像</span>
        cropped_table <span class="token operator">=</span> image<span class="token punctuation">.</span>crop<span class="token punctuation">(</span>detected_tables<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"bbox"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        cropped_table<span class="token punctuation">.</span>save<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>cropped_table_directory<span class="token punctuation">,</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>filename<span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>idx<span class="token punctuation">}</span></span><span class="token string">.png"</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>最后结果输出如下：<br><img src="https://pic1.imgdb.cn/item/681bfaca58cb8da5c8e3e8a9.png" alt="表格转图片"></p>
<p><img src="https://pic1.imgdb.cn/item/681bfaca58cb8da5c8e3e8a8.png" alt="表格转图片"></p>
<h3 id="5-3-基于-GPT-4-Vision-API-做表格回答"><a href="#5-3-基于-GPT-4-Vision-API-做表格回答" class="headerlink" title="5.3 基于 GPT-4 Vision API 做表格回答"></a><strong>5.3 基于 GPT-4 Vision API 做表格回答</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> base64
<span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI

client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">encode_image</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> <span class="token string">"rb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> image_file<span class="token punctuation">:</span>
    <span class="token keyword">return</span> base64<span class="token punctuation">.</span>b64encode<span class="token punctuation">(</span>image_file<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">image_qa</span><span class="token punctuation">(</span>query<span class="token punctuation">,</span> image_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    base64_image <span class="token operator">=</span> encode_image<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span>
    response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
        model<span class="token operator">=</span><span class="token string">"gpt-4o"</span><span class="token punctuation">,</span>
        temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
        seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">,</span>
        messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{</span>
            <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span>
              <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
                  <span class="token punctuation">{</span><span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"text"</span><span class="token punctuation">,</span> <span class="token string">"text"</span><span class="token punctuation">:</span> query<span class="token punctuation">}</span><span class="token punctuation">,</span>
                  <span class="token punctuation">{</span>
                      <span class="token string">"type"</span><span class="token punctuation">:</span> <span class="token string">"image_url"</span><span class="token punctuation">,</span>
                      <span class="token string">"image_url"</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>
                          <span class="token string">"url"</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f"data:image/jpeg;base64,</span><span class="token interpolation"><span class="token punctuation">{</span>base64_image<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">,</span>
                      <span class="token punctuation">}</span><span class="token punctuation">,</span>
                  <span class="token punctuation">}</span><span class="token punctuation">,</span>
              <span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">return</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content


response <span class="token operator">=</span> image_qa<span class="token punctuation">(</span><span class="token string">"哪个模型在AGI Eval数据集上表现最好。得分多少"</span><span class="token punctuation">,</span><span class="token string">"llama2_page8/table_images/page_1_0.png"</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>结果输出如下：</p>
<pre class="line-numbers language-none"><code class="language-none">在AGI Eval数据集上表现最好的模型是 **Llama 2 70B**，得分为 **54.2**。<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>可以看到，大模型的回答就是根据我们上面的图片内容回答的。</p>
<h3 id="5-4-用GPT-4-Vision-生成表格-图片-描述-并向量化用于检索"><a href="#5-4-用GPT-4-Vision-生成表格-图片-描述-并向量化用于检索" class="headerlink" title="5.4 用GPT-4 Vision 生成表格(图片)描述,并向量化用于检索"></a><strong>5.4 用GPT-4 Vision 生成表格(图片)描述,并向量化用于检索</strong></h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> chromadb
<span class="token keyword">from</span> chromadb<span class="token punctuation">.</span>config <span class="token keyword">import</span> Settings

<span class="token keyword">class</span> <span class="token class-name">NewVectorDBConnector</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> collection_name<span class="token punctuation">,</span> embedding_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
        chroma_client <span class="token operator">=</span> chromadb<span class="token punctuation">.</span>Client<span class="token punctuation">(</span>Settings<span class="token punctuation">(</span>allow_reset<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 为了演示，实际不需要每次 reset()</span>
        chroma_client<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 创建一个 collection</span>
        self<span class="token punctuation">.</span>collection <span class="token operator">=</span> chroma_client<span class="token punctuation">.</span>get_or_create_collection<span class="token punctuation">(</span>
            name<span class="token operator">=</span>collection_name<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>embedding_fn <span class="token operator">=</span> embedding_fn

    <span class="token keyword">def</span> <span class="token function">add_documents</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> documents<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''向 collection 中添加文档与向量'''</span>
        self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>add<span class="token punctuation">(</span>
            embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding_fn<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 每个文档的向量</span>
            documents<span class="token operator">=</span>documents<span class="token punctuation">,</span>  <span class="token comment"># 文档的原文</span>
            ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"id</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">"</span></span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># 每个文档的 id</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">add_images</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> image_paths<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''向 collection 中添加图像'''</span>
        documents <span class="token operator">=</span> <span class="token punctuation">[</span>
            image_qa<span class="token punctuation">(</span><span class="token string">"请简要描述图片中的信息"</span><span class="token punctuation">,</span>image<span class="token punctuation">)</span>
            <span class="token keyword">for</span> image <span class="token keyword">in</span> image_paths
        <span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>add<span class="token punctuation">(</span>
            embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding_fn<span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 每个文档的向量</span>
            documents<span class="token operator">=</span>documents<span class="token punctuation">,</span>  <span class="token comment"># 文档的原文</span>
            ids<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"id</span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">"</span></span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>documents<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 每个文档的 id</span>
            metadatas<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"image"</span><span class="token punctuation">:</span> image<span class="token punctuation">}</span> <span class="token keyword">for</span> image <span class="token keyword">in</span> image_paths<span class="token punctuation">]</span> <span class="token comment"># 用 metadata 标记源图像路径</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> query<span class="token punctuation">,</span> top_n<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''检索向量数据库'''</span>
        results <span class="token operator">=</span> self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>query<span class="token punctuation">(</span>
            query_embeddings<span class="token operator">=</span>self<span class="token punctuation">.</span>embedding_fn<span class="token punctuation">(</span><span class="token punctuation">[</span>query<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            n_results<span class="token operator">=</span>top_n
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> results

images <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
dir_path <span class="token operator">=</span> <span class="token string">"llama2_page8/table_images"</span>
<span class="token keyword">for</span> <span class="token builtin">file</span> <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>dir_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> <span class="token builtin">file</span><span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'.png'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 打开图像</span>
        images<span class="token punctuation">.</span>append<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>dir_path<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

new_db_connector <span class="token operator">=</span> NewVectorDBConnector<span class="token punctuation">(</span><span class="token string">"table_demo"</span><span class="token punctuation">,</span>get_embeddings<span class="token punctuation">)</span>
new_db_connector<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span>images<span class="token punctuation">)</span>

query  <span class="token operator">=</span> <span class="token string">"哪个模型在AGI Eval数据集上表现最差。得分多少"</span>

results <span class="token operator">=</span> new_db_connector<span class="token punctuation">.</span>search<span class="token punctuation">(</span>query<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
metadata <span class="token operator">=</span> results<span class="token punctuation">[</span><span class="token string">"metadatas"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"====检索结果===="</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metadata<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"====回复===="</span><span class="token punctuation">)</span>
response <span class="token operator">=</span> image_qa<span class="token punctuation">(</span>query<span class="token punctuation">,</span>metadata<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"image"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>输出结果如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">==</span><span class="token operator">==</span>检索结果<span class="token operator">==</span><span class="token operator">==</span>
<span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'image'</span><span class="token punctuation">:</span> <span class="token string">'llama2_page8/table_images\\page_1_0.png'</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
<span class="token operator">==</span><span class="token operator">==</span>回复<span class="token operator">==</span><span class="token operator">==</span>
在AGI Eval数据集上表现最差的模型是Falcon 7B，得分为<span class="token number">21.2</span>。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="一些面向-RAG-的文档解析辅助工具"><a href="#一些面向-RAG-的文档解析辅助工具" class="headerlink" title="一些面向 RAG 的文档解析辅助工具"></a>一些面向 RAG 的文档解析辅助工具</h3><ul>
<li><a target="_blank" rel="noopener" href="https://pymupdf.readthedocs.io/en/latest/">PyMuPDF</a>: PDF 文件处理基础库，带有基于规则的表格与图像抽取（不准）</li>
<li><a target="_blank" rel="noopener" href="https://github.com/infiniflow/ragflow">RAGFlow</a>: 一款基于深度文档理解构建的开源 RAG 引擎，支持多种文档格式（火爆）（重要）</li>
<li><a target="_blank" rel="noopener" href="https://unstructured.io/">Unstructured.io</a>: 一个开源+SaaS形式的文档解析库，支持多种文档格式</li>
<li><a target="_blank" rel="noopener" href="https://docs.llamaindex.ai/en/stable/llama_cloud/llama_parse/">LlamaParse</a>：付费 API 服务，由 LlamaIndex 官方提供，解析不保证100%准确，实测偶有文字丢失或错位发生</li>
<li><a target="_blank" rel="noopener" href="https://mathpix.com/">Mathpix</a>：付费 API 服务，效果较好，可解析段落结构、表格、公式等，贵！</li>
</ul>
<p>在工程上，PDF 解析本身是个复杂且琐碎的工作。以上工具都不完美，建议在自己实际场景测试后选择使用。</p>
<h2 id="六、说说-GraphRAG"><a href="#六、说说-GraphRAG" class="headerlink" title="六、说说 GraphRAG"></a>六、说说 GraphRAG</h2><p><img src="https://pic1.imgdb.cn/item/681b6c4e58cb8da5c8e3d9ea.png" alt="GraphRAG"></p>
<ol>
<li><strong>什么是 GraphRAG</strong>：核心思想是将知识预先处理成知识图谱</li>
<li><strong>优点</strong>：适合复杂问题，尤其是以查询为中心的总结，例如：“XXX团队去年有哪些贡献”</li>
<li><strong>缺点</strong>：知识图谱的构建、清洗、维护更新等都有可观的成本</li>
<li><strong>建议</strong>：<br>&nbsp; &nbsp;- GraphRAG 不是万能良药<br>&nbsp; &nbsp;- 领会其核心思想<br>&nbsp; &nbsp;- 遇到传统 RAG 无论如何优化都不好解决的问题时，酌情使用</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><h3 id="RAG-的流程"><a href="#RAG-的流程" class="headerlink" title="RAG 的流程"></a>RAG 的流程</h3><ul>
<li>离线步骤：</li>
</ul>
<ol>
<li>文档加载</li>
<li>文档切分</li>
<li>向量化</li>
<li>灌入向量数据库</li>
</ol>
<ul>
<li>在线步骤</li>
</ul>
<ol>
<li>获取用户问题</li>
<li>用户问题向量化</li>
<li>检索向量数据库</li>
<li>将检索结果和用户问题填入 Prompt 模板</li>
<li>用最终获得的 Prompt 调用 LLM</li>
<li>用 LLM 生成回复</li>
</ol>
<h3 id="如果使用了开源-RAG，但是不好用怎么办？"><a href="#如果使用了开源-RAG，但是不好用怎么办？" class="headerlink" title="如果使用了开源 RAG，但是不好用怎么办？"></a>如果使用了开源 RAG，但是不好用怎么办？</h3><ol>
<li>检查预处理效果：文档加载是否正确，切割的是否合理</li>
<li>测试检验效果：问题检索回来的文本片段是否包含答案</li>
<li>测试大模型能力：给定问题和包含答案文本片段的前提下，大模型能不能正确回答问题</li>
</ol>
<h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="一、在测试Embeddings模型时报错"><a href="#一、在测试Embeddings模型时报错" class="headerlink" title="一、在测试Embeddings模型时报错"></a>一、在测试Embeddings模型时报错</h3><h4 id="报错代码："><a href="#报错代码：" class="headerlink" title="报错代码："></a>报错代码：</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">test_query <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"测试文本"</span><span class="token punctuation">]</span>
vec <span class="token operator">=</span> get_embeddings<span class="token punctuation">(</span>test_query<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Total dimension: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>vec<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"First 10 elements: </span><span class="token interpolation"><span class="token punctuation">{</span>vec<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token format-spec">10]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="报错内容："><a href="#报错内容：" class="headerlink" title="报错内容："></a>报错内容：</h4><pre class="line-numbers language-none"><code class="language-none">---------------------------------------------------------------------------
BadRequestError &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Traceback (most recent call last)
Cell In[11], line 2
&nbsp; &nbsp; &nbsp; 1 test_query = ["测试文本"]
----&gt; 2 vec = get_embeddings(test_query)[0]
&nbsp; &nbsp; &nbsp; 3 print(f"Total dimension: {len(vec)}")
&nbsp; &nbsp; &nbsp; 4 print(f"First 10 elements: {vec[:10]}")
Cell In[10], line 9, in get_embeddings(texts, model, dimensions)
&nbsp; &nbsp; &nbsp; 6 &nbsp; &nbsp; data = client.embeddings.create(
&nbsp; &nbsp; &nbsp; 7 &nbsp; &nbsp; &nbsp; &nbsp; input=texts, model=model, dimensions=dimensions).data
&nbsp; &nbsp; &nbsp; 8 else:
----&gt; 9 &nbsp; &nbsp; data = client.embeddings.create(input=texts, model=model).data
&nbsp; &nbsp; &nbsp;10 return [x.embedding for x in data]
File d:\Soft\Dev_Soft\anaconda3\envs\rag-learn\lib\site-packages\openai\resources\embeddings.py:128, in Embeddings.create(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)
&nbsp; &nbsp; 122 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; embedding.embedding = np.frombuffer( &nbsp;# type: ignore[no-untyped-call]
&nbsp; &nbsp; 123 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; base64.b64decode(data), dtype="float32"
&nbsp; &nbsp; 124 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ).tolist()
&nbsp; &nbsp; 126 &nbsp; &nbsp; return obj
--&gt; 128 return self._post(
&nbsp; &nbsp; 129 &nbsp; &nbsp; "/embeddings",
&nbsp; &nbsp; 130 &nbsp; &nbsp; body=maybe_transform(params, embedding_create_params.EmbeddingCreateParams),
&nbsp; &nbsp; 131 &nbsp; &nbsp; options=make_request_options(
&nbsp; &nbsp; 132 &nbsp; &nbsp; &nbsp; &nbsp; extra_headers=extra_headers,
&nbsp; &nbsp; 133 &nbsp; &nbsp; &nbsp; &nbsp; extra_query=extra_query,
&nbsp; &nbsp; 134 &nbsp; &nbsp; &nbsp; &nbsp; extra_body=extra_body,
&nbsp; &nbsp; 135 &nbsp; &nbsp; &nbsp; &nbsp; timeout=timeout,
&nbsp; &nbsp; 136 &nbsp; &nbsp; &nbsp; &nbsp; post_parser=parser,
&nbsp; &nbsp; 137 &nbsp; &nbsp; ),
&nbsp; &nbsp; 138 &nbsp; &nbsp; cast_to=CreateEmbeddingResponse,
&nbsp; &nbsp; 139 )
File d:\Soft\Dev_Soft\anaconda3\envs\rag-learn\lib\site-packages\openai\_base_client.py:1242, in SyncAPIClient.post(self, path, cast_to, body, options, files, stream, stream_cls)
&nbsp; &nbsp;1228 def post(
&nbsp; &nbsp;1229 &nbsp; &nbsp; self,
&nbsp; &nbsp;1230 &nbsp; &nbsp; path: str,
&nbsp; &nbsp;(...)
&nbsp; &nbsp;1237 &nbsp; &nbsp; stream_cls: type[_StreamT] | None = None,
&nbsp; &nbsp;1238 ) -&gt; ResponseT | _StreamT:
&nbsp; &nbsp;1239 &nbsp; &nbsp; opts = FinalRequestOptions.construct(
&nbsp; &nbsp;1240 &nbsp; &nbsp; &nbsp; &nbsp; method="post", url=path, json_data=body, files=to_httpx_files(files), **options
&nbsp; &nbsp;1241 &nbsp; &nbsp; )
-&gt; 1242 &nbsp; &nbsp; return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
File d:\Soft\Dev_Soft\anaconda3\envs\rag-learn\lib\site-packages\openai\_base_client.py:919, in SyncAPIClient.request(self, cast_to, options, remaining_retries, stream, stream_cls)
&nbsp; &nbsp; 916 else:
&nbsp; &nbsp; 917 &nbsp; &nbsp; retries_taken = 0
--&gt; 919 return self._request(
&nbsp; &nbsp; 920 &nbsp; &nbsp; cast_to=cast_to,
&nbsp; &nbsp; 921 &nbsp; &nbsp; options=options,
&nbsp; &nbsp; 922 &nbsp; &nbsp; stream=stream,
&nbsp; &nbsp; 923 &nbsp; &nbsp; stream_cls=stream_cls,
&nbsp; &nbsp; 924 &nbsp; &nbsp; retries_taken=retries_taken,
&nbsp; &nbsp; 925 )
File d:\Soft\Dev_Soft\anaconda3\envs\rag-learn\lib\site-packages\openai\_base_client.py:1023, in SyncAPIClient._request(self, cast_to, options, retries_taken, stream, stream_cls)
&nbsp; &nbsp;1020 &nbsp; &nbsp; &nbsp; &nbsp; err.response.read()
&nbsp; &nbsp;1022 &nbsp; &nbsp; log.debug("Re-raising status error")
-&gt; 1023 &nbsp; &nbsp; raise self._make_status_error_from_response(err.response) from None
&nbsp; &nbsp;1025 return self._process_response(
&nbsp; &nbsp;1026 &nbsp; &nbsp; cast_to=cast_to,
&nbsp; &nbsp;1027 &nbsp; &nbsp; options=options,
&nbsp; &nbsp;(...)
&nbsp; &nbsp;1031 &nbsp; &nbsp; retries_taken=retries_taken,
&nbsp; &nbsp;1032 )
BadRequestError: Error code: 400 - {'error': {'message': 'Unknown model: text-embedding-ada-002 (request id: 2025050722295246817707943411229) (request id: 2025050722295245370563533xRaOCs)', 'type': '', 'param': '', 'code': 'unknown_model'}}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="错误记录："><a href="#错误记录：" class="headerlink" title="错误记录："></a>错误记录：</h4><p>这里频繁报错的原因是使用dotenv和.env文件调用api不成功而导致的错误，后续在申请调用OpenAI API的程序处，通过在client.OpenAI()函数里面直接调用填写api key和请求地址解决了这个问题。至于为什么会导致这个错误目前还不清楚，等后续在研究看看。</p>
<p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a target="_blank" rel="noopener" href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">墨宇Logic</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://ismoyuai.github.io/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-rag-embedding-vector-zhi-shi-dian-xue-xi/">https://ismoyuai.github.io/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-rag-embedding-vector-zhi-shi-dian-xue-xi/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">墨宇Logic</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Markdown/">
                                    <span class="chip bg-color">Markdown</span>
                                </a>
                            
                                <a href="/tags/RAG/">
                                    <span class="chip bg-color">RAG</span>
                                </a>
                            
                                <a href="/tags/Embeddings/">
                                    <span class="chip bg-color">Embeddings</span>
                                </a>
                            
                                <a href="/tags/OpenAI/">
                                    <span class="chip bg-color">OpenAI</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-xue-xi-langchain-da-mo-xing-feng-zhuang-gong-ju-kuang-jia/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/6.png" class="responsive-img" alt="【AI大模型应用学习笔记】学习LangChain大模型能力封装工具框架">
                        
                        <span class="card-title">【AI大模型应用学习笔记】学习LangChain大模型能力封装工具框架</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            学习目标：1. 如何使用 LangChain：一套在大模型能力上封装的工具框架2. 如何用几行代码实现一个复杂的 AI 应用3. 面向大模型的流程开发的过程抽象
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-17
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/" class="post-category">
                                    AI大模型应用开发
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                    <a href="/tags/RAG/">
                        <span class="chip bg-color">RAG</span>
                    </a>
                    
                    <a href="/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                    <a href="/tags/AI/">
                        <span class="chip bg-color">AI</span>
                    </a>
                    
                    <a href="/tags/Embeddings/">
                        <span class="chip bg-color">Embeddings</span>
                    </a>
                    
                    <a href="/tags/LangChain/">
                        <span class="chip bg-color">LangChain</span>
                    </a>
                    
                    <a href="/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/hexo-github-netlify-clouldflare-da-jian-ge-ren-bo-ke/">
                    <div class="card-image">
                        
                        <img src="/medias/featureimages/6.png" class="responsive-img" alt="hexo+github+Netlify+ClouldFlare搭建个人博客">
                        
                        <span class="card-title">hexo+github+Netlify+ClouldFlare搭建个人博客</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            这个教程使用的个人博客框架是hexo，博客文件拖管于github，博客网站用netlify生成，国内访问采用Cloudflare进行CDN加速。
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-11
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%95%99%E7%A8%8B/" class="post-category">
                                    博客搭建教程
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Markdown/">
                        <span class="chip bg-color">Markdown</span>
                    </a>
                    
                    <a href="/tags/css/">
                        <span class="chip bg-color">css</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE' || selection.getRangeAt(0).commonAncestorContainer.nodeName === 'CODE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 墨宇Logic<br />'
            + '文章作者: 墨宇Logic<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">墨宇Logic</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
                <span id="translate">|&nbsp;繁/简：</span><a id="translateLink" href="javascript:translatePage();">繁</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">49.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2025";
                        var startMonth = "4";
                        var startDate = "10";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/isMoyuAI" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:loushuaicn@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2542345108" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2542345108" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>









    <a href="https://space.bilibili.com/347413381" class="tooltipped" target="_blank" data-tooltip="关注我的bilbil" data-position="top" data-delay="50">
        <i class="fa-brands fa-bilibili"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
        <script type="text/javascript" src="/js/tw_cn.js"></script>
        <script type="text/javascript">
          var defaultEncoding = 2; //网站编写字体是否繁体，1-繁体，2-简体
          var translateDelay = 0; //延迟时间,若不在前, 要设定延迟翻译时间, 如100表示100ms,默认为0
          var cookieDomain = "https://ismoyuai.github.io"; //Cookie地址, 一定要设定, 通常为你的网址
          var msgToTraditionalChinese = "繁"; //此处可以更改为你想要显示的文字
          var msgToSimplifiedChinese = "简"; //同上，但两处均不建议更改
          var translateButtonId = "translateLink"; //默认互换id
          translateInitilization();
        </script>
    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
