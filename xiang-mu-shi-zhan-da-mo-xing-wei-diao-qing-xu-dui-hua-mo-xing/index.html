<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="【项目实战】大模型微调-情绪对话模型, AI,Python,C,C++,Linux">
    <meta name="description" content="实战微调一个情绪对话模型项目，包含数据收集处理、模型选型、模型训练评估、以及模型部署全流程">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>【项目实战】大模型微调-情绪对话模型 | 墨宇Logic</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    
    <style>
        body{
            background-image: url(https://pic1.imgdb.cn/item/680901b758cb8da5c8c6b23f.webp);
            background-repeat:no-repeat;
            background-size: 100% 100%;
            background-attachment:fixed;
        }
    </style>



    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


 
    <style type="text/css" lang="css">
    #loading-container{
        position: fixed;
        top: 0;
        left: 0;
        min-height: 100vh;
        width: 100vw;
        z-index: 9999;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        background: #FFF;
        text-align: center;
        /* loader页面消失采用渐隐的方式*/
        -webkit-transition: opacity 1s ease;
        -moz-transition: opacity 1s ease;
        -o-transition: opacity 1s ease;
        transition: opacity 1s ease;
    }
    .loading-image{
        width: 120px;
        height: 50px;
        transform: translate(-50%);
    }

    .loading-image div:nth-child(2) {
        -webkit-animation: pacman-balls 1s linear 0s infinite;
        animation: pacman-balls 1s linear 0s infinite
    }

    .loading-image div:nth-child(3) {
        -webkit-animation: pacman-balls 1s linear .33s infinite;
        animation: pacman-balls 1s linear .33s infinite
    }

    .loading-image div:nth-child(4) {
        -webkit-animation: pacman-balls 1s linear .66s infinite;
        animation: pacman-balls 1s linear .66s infinite
    }

    .loading-image div:nth-child(5) {
        -webkit-animation: pacman-balls 1s linear .99s infinite;
        animation: pacman-balls 1s linear .99s infinite
    }

   .loading-image div:first-of-type {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_up .5s 0s infinite;
        animation: rotate_pacman_half_up .5s 0s infinite;
    }
    .loading-image div:nth-child(2) {
        width: 0;
        height: 0;
        border: 25px solid #49b1f5;
        border-right-color: transparent;
        border-radius: 25px;
        -webkit-animation: rotate_pacman_half_down .5s 0s infinite;
        animation: rotate_pacman_half_down .5s 0s infinite;
        margin-top: -50px;
    }
    @-webkit-keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @keyframes rotate_pacman_half_up {0% {transform: rotate(270deg)}50% {transform: rotate(1turn)}to {transform: rotate(270deg)}}

    @-webkit-keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @keyframes rotate_pacman_half_down {0% {transform: rotate(90deg)}50% {transform: rotate(0deg)}to {transform: rotate(90deg)}}

    @-webkit-keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}

    @keyframes pacman-balls {75% {opacity: .7}to {transform: translate(-100px, -6.25px)}}


    .loading-image div:nth-child(3),
    .loading-image div:nth-child(4),
    .loading-image div:nth-child(5),
    .loading-image div:nth-child(6){
        background-color: #49b1f5;
        width: 15px;
        height: 15px;
        border-radius: 100%;
        margin: 2px;
        width: 10px;
        height: 10px;
        position: absolute;
        transform: translateY(-6.25px);
        top: 25px;
        left: 100px;
    }
    .loading-text{
        margin-bottom: 20vh;
        text-align: center;
        color: #2c3e50;
        font-size: 2rem;
        box-sizing: border-box;
        padding: 0 10px;
        text-shadow: 0 2px 10px rgba(0,0,0,0.2);
    }
    @media only screen and (max-width: 500px) {
         .loading-text{
            font-size: 1.5rem;
         }
    }
    .fadeout {
        opacity: 0;
        filter: alpha(opacity=0);
    }
    /* logo出现动画 */
    @-webkit-keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}100%{opacity:1;-webkit-transform:none;transform:none}}
    @keyframes fadeInDown{0%{opacity:0;-webkit-transform:translate3d(0,-100%,0);}}
 </style>
 <script>
(function () {
    const loaded = function(){
       setTimeout(function(){
            const loader = document.getElementById("loading-container");
            loader.className="fadeout" ;//使用渐隐的方法淡出loading page
            // document.getElementById("body-wrap").style.display="flex";
            setTimeout(function(){
                loader.style.display="none";
            },2500); 
        },1000);//强制显示loading page 1s  
    };
    loaded();
})()
</script>
 
<body>
    
        <div id="loading-container">
             <p class="loading-text">嘘~  正在从服务器偷取页面 . . . </p> 
             <div class="loading-image">
                 <div></div>
                 <div></div>
                 <div></div>
                 <div></div> 
                 <div></div>
             </div>
        </div>
    

    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">墨宇Logic</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">墨宇Logic</div>
        <div class="logo-desc">
            
            这里是墨宇的个人博客
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/ismoyuai" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/ismoyuai" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/0.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">【项目实战】大模型微调-情绪对话模型</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/Markdown/">
                                <span class="chip bg-color">Markdown</span>
                            </a>
                        
                            <a href="/tags/Python/">
                                <span class="chip bg-color">Python</span>
                            </a>
                        
                            <a href="/tags/Linux/">
                                <span class="chip bg-color">Linux</span>
                            </a>
                        
                            <a href="/tags/LLaMA-Factory/">
                                <span class="chip bg-color">LLaMA-Factory</span>
                            </a>
                        
                            <a href="/tags/Embeddings/">
                                <span class="chip bg-color">Embeddings</span>
                            </a>
                        
                            <a href="/tags/LLM/">
                                <span class="chip bg-color">LLM</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/" class="post-category">
                                AI大模型开发项目实战
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-05-07
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-05-10
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    12.2k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    57 分
                </div>
                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h2 id="一、项目介绍"><a href="#一、项目介绍" class="headerlink" title="一、项目介绍"></a>一、<strong>项目介绍</strong></h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a><strong>背景</strong></h3><p>在看抖音时经常刷到一个小智聊天机器人，发现它在回答时具有非常强烈和个性化的情绪表达，使用就准备以此为目标，自己尝试做一个这样的情绪对话大模型。<br>加上在人工智能技术快速发展的今天，对话系统已广泛应用于客服、心理辅导、社交娱乐等领域。例如，在心理咨询场景中，模型需识别用户的焦虑或抑郁情绪并给出共情回应；在电商客服中，需对用户的不满情绪进行安抚。<br>因此，<strong>构建具备情绪感知能力的对话模型</strong>也是一个非常有价值的事情。</p>
<h3 id="项目目标"><a href="#项目目标" class="headerlink" title="项目目标"></a><strong>项目目标</strong></h3><p>本项目旨在通过实战微调一个<strong>情绪对话模型</strong>，覆盖数据收集、模型训练、评估优化到部署的全流程，重点解决以下问题：</p>
<ul>
<li><p>如何从多来源数据中构建高质量的情绪对话数据集？</p>
</li>
<li><p>如何选择合适的预训练模型并针对性优化其情感生成能力？</p>
</li>
<li><p>如何平衡生成内容的流畅性与情绪准确性？</p>
</li>
<li><p>如何将模型高效部署到实际应用场景？</p>
</li>
</ul>
<h2 id="二、数据收集与处理"><a href="#二、数据收集与处理" class="headerlink" title="二、数据收集与处理"></a><strong>二、数据收集与处理</strong></h2><h3 id="2-1-数据来源"><a href="#2-1-数据来源" class="headerlink" title="2.1 数据来源"></a>2.1 <strong>数据来源</strong></h3><p>本次项目数据来源主要有两点：</p>
<ol>
<li>人工制定</li>
<li>基于现有开源数据，让AI实现情绪数据集制作。</li>
</ol>
<blockquote>
<p>注意：如果让AI来帮助处理数据，尽可能选择效果较好的API接口，不要使用本地的大模型来处理。</p>
</blockquote>
<h3 id="2-2-数据标注工具与方法"><a href="#2-2-数据标注工具与方法" class="headerlink" title="2.2 数据标注工具与方法"></a>2.2 <strong>数据标注工具与方法</strong></h3><p>本项目数据主要是根据公开数据集然后使用Python代码+AI大模型来进行生成，没有用到其他标注工具和方法。</p>
<h3 id="2-3-数据清洗与预处理"><a href="#2-3-数据清洗与预处理" class="headerlink" title="2.3 数据清洗与预处理"></a>2.3 <strong>数据清洗与预处理</strong></h3><p>通过Python代码指定数据生成模板，然后基于收集的问题来让AI进行自动生成，并设置规则，让AI生成符合我们需求的高质量的数据。</p>
<p>数据清洗和预处理流程如下：</p>
<ul>
<li><p>设置数据风格模板（主要修正消息格式）</p>
<ul>
<li>让AI大模型按照我们想要的数据模板进行生成</li>
</ul>
</li>
<li><p>生成函数（主要修正消息的结构）</p>
<ul>
<li>调用大模型API来准备生成数据并返回</li>
</ul>
</li>
<li><p>设置数据质量过滤规则（添加空值检查）</p>
<ul>
<li>规则1：回复长度检查</li>
<li>规则2：风格关键词检查</li>
<li>规则3：语义相似度检查</li>
</ul>
</li>
<li><p>执行生成（添加容错）</p>
</li>
</ul>
<h3 id="2-4-数据划分"><a href="#2-4-数据划分" class="headerlink" title="2.4 数据划分"></a>2.4 <strong>数据划分</strong></h3><p>训练集、验证集、测试集划分</p>
<h2 id="三、数据收集与处理（实现篇）"><a href="#三、数据收集与处理（实现篇）" class="headerlink" title="三、数据收集与处理（实现篇）"></a><strong>三、数据收集与处理（实现篇）</strong></h2><h3 id="3-1-数据收集整理"><a href="#3-1-数据收集整理" class="headerlink" title="3.1 数据收集整理"></a><strong>3.1 数据收集整理</strong></h3><p>使用的是公开的<a target="_blank" rel="noopener" href="https://github.com/thu-coai/CDial-GPT">CDial-GPT</a>数据集<br>还有魔塔社区的 <a target="_blank" rel="noopener" href="https://www.modelscope.cn/datasets/OmniData/LCCC">LCCC</a> 数据集</p>
<p>数据集下载后，在里面挑选 1000~3000 条数据即可</p>
<h3 id="3-2-配置文件创建"><a href="#3-2-配置文件创建" class="headerlink" title="3.2 配置文件创建"></a>3.2 配置文件创建</h3><p>主要用来存放我们的 API 密匙、模型本地路径等敏感配置以及风格模板配置</p>
<p>打开 Pycharm 新建一个<code>emotion_dialogue_tuner</code>项目，在项目下新建 <code>config</code> 目录，然后新建<code>config/settings.yaml</code>和<code>config/style_config.json</code>文件，分别用来存放<strong>API密钥等敏感配置</strong>和<strong>风格模板配置</strong></p>
<p><code>settings.yaml</code>文件内容如下：</p>
<pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">API</span><span class="token punctuation">:</span>
  <span class="token key atrule">ZHIPU_API_KEY</span><span class="token punctuation">:</span> <span class="token string">"your_api_key_here"</span>  <span class="token comment"># 敏感信息隔离</span>
  <span class="token key atrule">MODEL_NAME</span><span class="token punctuation">:</span> <span class="token string">"glm-3-turbo"</span>

<span class="token key atrule">PATHS</span><span class="token punctuation">:</span>
  <span class="token key atrule">EMBEDDING_MODEL</span><span class="token punctuation">:</span> <span class="token string">"embedding_model/thomas/text2vec-base-chinese"</span>  <span class="token comment"># 你本地embedding模型路径</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<p>我embedding模型选择的是thomas/text2vec-base-chinese，可以在魔塔社区下载</p>
</blockquote>
<p><code>style_config.json</code>文件内容如下：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>  
    <span class="token property">"温柔"</span><span class="token operator">:</span><span class="token punctuation">{</span>  
        <span class="token property">"system_prompt"</span><span class="token operator">:</span><span class="token string">"你是一个温柔体贴的聊天助手，说话时总是充满关怀，使用以下特征：\n1. 包含'呢、呀、啦'等语气词\n2. 使用🌸💖😊等温暖表情\n3. 主动询问用户感受"</span><span class="token punctuation">,</span>  
        <span class="token property">"examples"</span><span class="token operator">:</span> <span class="token punctuation">[</span>  
            <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"今天好累啊"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  
            <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"辛苦啦~ 要给自己泡杯热茶放松一下吗？🌸"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  
            <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"考试没考好..."</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  
            <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"没关系的呀~ 下次一定会更好！需要我陪你聊聊吗？😊"</span><span class="token punctuation">}</span>  
        <span class="token punctuation">]</span><span class="token punctuation">,</span>     <span class="token property">"temperature"</span><span class="token operator">:</span> <span class="token number">0.3</span>  
    <span class="token punctuation">}</span><span class="token punctuation">,</span>  
    <span class="token property">"毒舌"</span><span class="token operator">:</span><span class="token punctuation">{</span>  
        <span class="token property">"system_prompt"</span><span class="token operator">:</span><span class="token string">"你是一个喜欢用犀利吐槽表达关心的朋友，需满足：\n1. 使用网络流行语（如'栓Q''退退退'）\n2. 包含夸张比喻（'你这速度堪比树懒'）\n3. 结尾隐藏关心"</span><span class="token punctuation">,</span>  
        <span class="token property">"examples"</span><span class="token operator">:</span> <span class="token punctuation">[</span>  
            <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"又胖了5斤！"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  
            <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"好家伙！你这是要把体重秤压成分子料理？🏋️"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  
            <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"游戏又输了"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  
            <span class="token punctuation">{</span><span class="token property">"role"</span><span class="token operator">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token property">"content"</span><span class="token operator">:</span> <span class="token string">"菜就多练练！需要给你推荐《从零开始的电竞之路》吗？🎮"</span><span class="token punctuation">}</span>  
        <span class="token punctuation">]</span><span class="token punctuation">,</span>     <span class="token property">"temperature"</span><span class="token operator">:</span> <span class="token number">0.7</span>  
    <span class="token punctuation">}</span>  
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>我这里风格类型主要配置了两种：温柔和毒舌两种相反风格，然后为它们设置了相应的系统提示词和示例，让大模型明确自己的角色以及学习我们需要的数据模板类型，以供后续生成。</p>
<h3 id="3-3-配置文件加载模块"><a href="#3-3-配置文件加载模块" class="headerlink" title="3.3 配置文件加载模块"></a>3.3 配置文件加载模块</h3><p>新建<code>emotion_dialogue_tuner/src/utils/config_loader.py</code>文件</p>
<p>这个文件主要负责统一管理API密钥、模型路径等敏感信息和风格配置</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># config_loader.py  </span>
<span class="token triple-quoted-string string">"""配置文件加载模块，负责统一管理API密钥、模型路径等敏感信息和风格配置"""</span>  
  
<span class="token keyword">import</span> yaml  
<span class="token keyword">import</span> json  
<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path  
  
  
<span class="token keyword">class</span> <span class="token class-name">ConfigLoader</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""配置加载器，封装配置文件的读取操作"""</span>  
  
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""初始化时自动定位项目根目录"""</span>  
        self<span class="token punctuation">.</span>root_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">.</span>resolve<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent  <span class="token comment"># 根据实际层级调整  </span>
  
    <span class="token keyword">def</span> <span class="token function">load_settings</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""加载YAML格式的全局设置  
        Returns:            dict: 包含API密钥、模型路径等配置的字典  
        """</span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_path <span class="token operator">/</span> <span class="token string">"config/settings.yaml"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>  
            <span class="token keyword">return</span> yaml<span class="token punctuation">.</span>safe_load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>  
  
    <span class="token keyword">def</span> <span class="token function">load_style_config</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""加载JSON格式的风格配置  
        Returns:            dict: 包含不同对话风格的模板配置  
        """</span>        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_path <span class="token operator">/</span> <span class="token string">"config/style_config.json"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>  
            <span class="token keyword">return</span> json<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-4-数据生成核心模块"><a href="#3-4-数据生成核心模块" class="headerlink" title="3.4 数据生成核心模块"></a>3.4 数据生成核心模块</h3><p>新建<code>emotion_dialogue_tuner/src/data_generator.py</code>文件</p>
<p>这个文件主要负责调用API生成指定风格的对话数据</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># data_generator.py  </span>
<span class="token triple-quoted-string string">"""数据生成核心模块，负责调用API生成指定风格的对话数据"""</span>  
  
<span class="token keyword">from</span> zhipuai <span class="token keyword">import</span> ZhipuAI  
<span class="token keyword">import</span> random  
<span class="token keyword">import</span> time  
  
<span class="token keyword">class</span> <span class="token class-name">StyleDataGenerator</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""对话数据生成器，根据配置生成特定风格的对话数据"""</span>  
  
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> api_key<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> style_config<span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""  
        Args:            api_key (str): 智普API访问密钥  
            style_config (dict): 风格配置字典  
        """</span>        self<span class="token punctuation">.</span>client <span class="token operator">=</span> ZhipuAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span>api_key<span class="token punctuation">)</span>  
        self<span class="token punctuation">.</span>style_config <span class="token operator">=</span> style_config  
  
    <span class="token keyword">def</span> <span class="token function">_build_messages</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style_name<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""构建符合API要求的消息格式  
        Args:            style_name (str): 目标风格名称（如'温柔'）  
        Returns:            list: 包含系统提示和示例对话的消息列表  
        """</span>        config <span class="token operator">=</span> self<span class="token punctuation">.</span>style_config<span class="token punctuation">[</span>style_name<span class="token punctuation">]</span>  
        <span class="token keyword">return</span> <span class="token punctuation">[</span>  
            <span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> config<span class="token punctuation">[</span><span class="token string">"system_prompt"</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">,</span>  
            <span class="token operator">*</span>config<span class="token punctuation">[</span><span class="token string">"examples"</span><span class="token punctuation">]</span>  <span class="token comment"># 展开示例对话  </span>
        <span class="token punctuation">]</span>  
  
    <span class="token keyword">def</span> <span class="token function">generate_style_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style_name<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> num_samples<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">list</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""生成指定风格的对话数据  
        Args:            style_name (str): 目标风格名称  
            num_samples (int): 需要生成的样本数量  
        Returns:            list: 生成的对话数据列表，每个元素包含用户输入、助手回复和风格标签  
        """</span>        data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  
        messages <span class="token operator">=</span> self<span class="token punctuation">.</span>_build_messages<span class="token punctuation">(</span>style_name<span class="token punctuation">)</span>  
  
        <span class="token comment"># 从本地文件加载用户输入  </span>
        user_inputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"data/cleaned_output.txt"</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>  <span class="token comment"># 修改为清理后的文件路径  </span>
            <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">:</span>  
                <span class="token comment"># 直接读取每行内容并去除换行符  </span>
                cleaned_line <span class="token operator">=</span> line<span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>  <span class="token comment"># 或使用 line.strip()                if cleaned_line:  # 空行过滤（冗余保护）  </span>
                    user_inputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cleaned_line<span class="token punctuation">)</span>  
  
        <span class="token comment"># 添加空值检查  </span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> user_inputs<span class="token punctuation">:</span>  
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"文件内容为空或未成功加载数据，请检查："</span>  
                             <span class="token string">"1. 文件路径是否正确 2. 文件是否包含有效内容"</span><span class="token punctuation">)</span>  
  
        <span class="token comment"># 初始化顺序索引  </span>
        current_index <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 添加索引计数器  </span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_samples<span class="token punctuation">)</span><span class="token punctuation">:</span>  
            <span class="token keyword">try</span><span class="token punctuation">:</span>  
  
                <span class="token comment"># 按顺序选择用户输入（修改核心部分）  </span>
                user_msg <span class="token operator">=</span> user_inputs<span class="token punctuation">[</span>current_index<span class="token punctuation">]</span>  
                current_index <span class="token operator">=</span> <span class="token punctuation">(</span>current_index <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token builtin">len</span><span class="token punctuation">(</span>user_inputs<span class="token punctuation">)</span>  <span class="token comment"># 循环计数  </span>
  
                <span class="token comment"># 添加当前用户消息  </span>
                current_messages <span class="token operator">=</span> messages <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> user_msg<span class="token punctuation">}</span><span class="token punctuation">]</span>  
  
                <span class="token comment"># 调用大模型API生成回复  </span>
                response <span class="token operator">=</span> self<span class="token punctuation">.</span>client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>  
                    model<span class="token operator">=</span><span class="token string">"glm-3-turbo"</span><span class="token punctuation">,</span>  
                    messages<span class="token operator">=</span>current_messages<span class="token punctuation">,</span>  
                    temperature<span class="token operator">=</span>self<span class="token punctuation">.</span>style_config<span class="token punctuation">[</span>style_name<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"temperature"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  
                    max_tokens<span class="token operator">=</span><span class="token number">100</span>  
                <span class="token punctuation">)</span>  
                reply <span class="token operator">=</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content  
  
                <span class="token comment"># 保存通过质量检查的数据  </span>
                <span class="token keyword">if</span> self<span class="token punctuation">.</span>_validate_reply<span class="token punctuation">(</span>style_name<span class="token punctuation">,</span> user_msg<span class="token punctuation">,</span> reply<span class="token punctuation">)</span><span class="token punctuation">:</span>  
                    data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span>  
                        <span class="token string">"user"</span><span class="token punctuation">:</span> user_msg<span class="token punctuation">,</span>  
                        <span class="token string">"assistant"</span><span class="token punctuation">:</span> reply<span class="token punctuation">,</span>  
                        <span class="token string">"style"</span><span class="token punctuation">:</span> style_name  
                    <span class="token punctuation">}</span><span class="token punctuation">)</span>  
  
                time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1.5</span><span class="token punctuation">)</span>  <span class="token comment"># API调用频率限制保护  </span>
  
            <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>  
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"生成失败: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>  
  
        <span class="token keyword">return</span> data  
  
    <span class="token keyword">def</span> <span class="token function">_validate_reply</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> user_msg<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> reply<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""内部方法：验证回复质量（实际实现应调用Validator类）"""</span>  
        <span class="token comment"># 简化的验证逻辑，实际应使用独立的Validator类  </span>
        <span class="token keyword">return</span> <span class="token builtin">bool</span><span class="token punctuation">(</span>reply<span class="token punctuation">)</span>  <span class="token comment"># 示例代码</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-5-生成数据质量验证模块"><a href="#3-5-生成数据质量验证模块" class="headerlink" title="3.5 生成数据质量验证模块"></a>3.5 生成数据质量验证模块</h3><p>新建<code>emotion_dialogue_tuner/src/utils/validator.py</code>文件</p>
<p>这个文件主要负责回复质量验证，确保生成数据符合质量标准</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># validator.py  </span>
<span class="token triple-quoted-string string">"""回复质量验证模块，确保生成数据符合质量标准"""</span>  
  
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np  
<span class="token keyword">from</span> sentence_transformers <span class="token keyword">import</span> SentenceTransformer  
  
  
<span class="token keyword">class</span> <span class="token class-name">ReplyValidator</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""回复验证器，执行多维度质量检查"""</span>  
  
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_path<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""  
        Args:            model_path (str): 本地嵌入模型文件路径  
        """</span>        self<span class="token punctuation">.</span>style_model <span class="token operator">=</span> SentenceTransformer<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>  
  
    <span class="token keyword">def</span> <span class="token function">validate</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> user_msg<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> reply<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> ref_text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""执行完整的质量验证流程  
        Args:            style (str): 目标风格名称  
            user_msg (str): 用户输入文本  
            reply (str): 待验证的回复文本  
            ref_text (str): 参考文本（用于相似度计算）  
        Returns:            bool: 是否通过所有验证规则  
        """</span>        <span class="token comment"># 基础格式检查  </span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>_basic_checks<span class="token punctuation">(</span>reply<span class="token punctuation">)</span><span class="token punctuation">:</span>  
            <span class="token keyword">return</span> <span class="token boolean">False</span>  
  
        <span class="token comment"># 风格关键词匹配检查  </span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>_style_keyword_check<span class="token punctuation">(</span>style<span class="token punctuation">,</span> reply<span class="token punctuation">)</span><span class="token punctuation">:</span>  
            <span class="token keyword">return</span> <span class="token boolean">False</span>  
  
        <span class="token comment"># 语义相似度验证  </span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_semantic_similarity_check<span class="token punctuation">(</span>ref_text<span class="token punctuation">,</span> reply<span class="token punctuation">)</span>  
  
    <span class="token keyword">def</span> <span class="token function">_basic_checks</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> reply<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""执行基础格式检查  
        1. 非空检查  
        2. 长度限制检查  
        """</span>        <span class="token keyword">return</span> <span class="token builtin">bool</span><span class="token punctuation">(</span>reply<span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token punctuation">(</span><span class="token number">5</span> <span class="token operator">&lt;=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>reply<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> <span class="token number">150</span><span class="token punctuation">)</span>  
  
    <span class="token keyword">def</span> <span class="token function">_style_keyword_check</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> style<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> reply<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""检查是否包含风格特征关键词"""</span>  
        keyword_map <span class="token operator">=</span> <span class="token punctuation">{</span>  
            <span class="token string">"温柔"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"呢"</span><span class="token punctuation">,</span> <span class="token string">"呀"</span><span class="token punctuation">,</span> <span class="token string">"😊"</span><span class="token punctuation">,</span> <span class="token string">"🌸"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  
            <span class="token string">"毒舌"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"好家伙"</span><span class="token punctuation">,</span> <span class="token string">"栓Q"</span><span class="token punctuation">,</span> <span class="token string">"!"</span><span class="token punctuation">,</span> <span class="token string">"🏋️"</span><span class="token punctuation">]</span>  
        <span class="token punctuation">}</span>        <span class="token keyword">return</span> <span class="token builtin">any</span><span class="token punctuation">(</span>kw <span class="token keyword">in</span> reply <span class="token keyword">for</span> kw <span class="token keyword">in</span> keyword_map<span class="token punctuation">.</span>get<span class="token punctuation">(</span>style<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
  
    <span class="token keyword">def</span> <span class="token function">_semantic_similarity_check</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ref_text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> reply<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>  
        <span class="token triple-quoted-string string">"""计算与参考文本的语义相似度  
        使用余弦相似度判断，阈值设为0.65  
        """</span>        ref_vec <span class="token operator">=</span> self<span class="token punctuation">.</span>style_model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>ref_text<span class="token punctuation">)</span>  
        reply_vec <span class="token operator">=</span> self<span class="token punctuation">.</span>style_model<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>reply<span class="token punctuation">)</span>  
        similarity <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>ref_vec<span class="token punctuation">,</span> reply_vec<span class="token punctuation">)</span>  
        <span class="token keyword">return</span> similarity <span class="token operator">&gt;</span> <span class="token number">0.65</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-6-主函数-main-py-实现"><a href="#3-6-主函数-main-py-实现" class="headerlink" title="3.6 主函数 main.py 实现"></a>3.6 主函数 main.py 实现</h3><p>新建<code>emotion_dialogue_tuner/main.py</code> 文件</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># main.py  </span>
<span class="token triple-quoted-string string">"""主执行入口，协调各模块完成数据生成任务"""</span>  
  
<span class="token keyword">from</span> src<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>config_loader <span class="token keyword">import</span> ConfigLoader  
<span class="token keyword">from</span> src<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>validator <span class="token keyword">import</span> ReplyValidator  
<span class="token keyword">from</span> src<span class="token punctuation">.</span>data_generator <span class="token keyword">import</span> StyleDataGenerator  
<span class="token keyword">import</span> json  
<span class="token keyword">import</span> os  
  
  
<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token comment"># 初始化配置加载器  </span>
    config_loader <span class="token operator">=</span> ConfigLoader<span class="token punctuation">(</span><span class="token punctuation">)</span>  
  
    <span class="token comment"># 加载配置信息  </span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>  
        settings <span class="token operator">=</span> config_loader<span class="token punctuation">.</span>load_settings<span class="token punctuation">(</span><span class="token punctuation">)</span>  
        style_config <span class="token operator">=</span> config_loader<span class="token punctuation">.</span>load_style_config<span class="token punctuation">(</span><span class="token punctuation">)</span>  
    <span class="token keyword">except</span> FileNotFoundError <span class="token keyword">as</span> e<span class="token punctuation">:</span>  
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"配置文件缺失：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>  
        <span class="token keyword">return</span>  
  
    <span class="token comment"># 初始化核心组件  </span>
    generator <span class="token operator">=</span> StyleDataGenerator<span class="token punctuation">(</span>  
        api_key<span class="token operator">=</span>settings<span class="token punctuation">[</span><span class="token string">"API"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"ZHIPU_API_KEY"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  
        style_config<span class="token operator">=</span>style_config  
    <span class="token punctuation">)</span>  
    validator <span class="token operator">=</span> ReplyValidator<span class="token punctuation">(</span>  
        model_path<span class="token operator">=</span>settings<span class="token punctuation">[</span><span class="token string">"PATHS"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"EMBEDDING_MODEL"</span><span class="token punctuation">]</span>  
    <span class="token punctuation">)</span>  
    <span class="token comment"># 执行数据生成流程  </span>
    all_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  
    <span class="token keyword">try</span><span class="token punctuation">:</span>  
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正在生成温柔风格数据..."</span><span class="token punctuation">)</span>  
        gentle_data <span class="token operator">=</span> generator<span class="token punctuation">.</span>generate_style_data<span class="token punctuation">(</span><span class="token string">"温柔"</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>  
        all_data<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>gentle_data<span class="token punctuation">)</span>  
  
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"正在生成毒舌风格数据..."</span><span class="token punctuation">)</span>  
        sarcastic_data <span class="token operator">=</span> generator<span class="token punctuation">.</span>generate_style_data<span class="token punctuation">(</span><span class="token string">"毒舌"</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>  
        all_data<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>sarcastic_data<span class="token punctuation">)</span>  
  
    <span class="token keyword">except</span> KeyboardInterrupt<span class="token punctuation">:</span>  
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n用户中断操作，正在保存已生成数据..."</span><span class="token punctuation">)</span>  
    <span class="token keyword">finally</span><span class="token punctuation">:</span>  
        <span class="token comment"># 确保输出目录存在  </span>
        output_dir <span class="token operator">=</span> <span class="token string">"outputs"</span>  
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>output_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  
  
        <span class="token comment"># 持久化保存数据  </span>
        output_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>output_dir<span class="token punctuation">,</span> <span class="token string">"style_chat_data.json"</span><span class="token punctuation">)</span>  
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>output_path<span class="token punctuation">,</span> <span class="token string">"w"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>  
            json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>all_data<span class="token punctuation">,</span> f<span class="token punctuation">,</span> ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>  
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"数据保存完成，有效样本数：</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>all_data<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>  
  
  
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>  
    main<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>



<h2 id="四、模型选型与设计"><a href="#四、模型选型与设计" class="headerlink" title="四、模型选型与设计"></a><strong>四、模型选型与设计</strong></h2><p>1.模型选型<br>根据当前的任务特点，选择合适的评测数据以及预选的候选模型</p>
<p>一般来讲，做什么样的任务就选什么样的模型，我们要做的是一个情感对话模型，所以我们在选择模型时应选择对中文文本理解能力较强的模型。</p>
<p>2.模型的大小选择</p>
<ul>
<li>服务器配置</li>
<li>任务复杂度</li>
</ul>
<p>可以根据任务选择对应的评测数据，对期望模型客观评测</p>
<p>当前任务为日常聊天对话模型，主要要求模型的中文理解能力，所以我们这里可以用 CLUE（中文理解）数据进行评测：</p>
<p>我们需要准备 opencompass 环境，参考[[【AI大模型应用学习笔记】OpenCompass模型评估框架的使用教程]]</p>
<p>进入OpenCompass根目录下，执行命令</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">#输出数据集清单</span>
python tools/list_configs.py clue<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>执行后输出结果如下：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">+-----------------------------+------------------------------------------------------------------------------+
| Dataset                     | Config Path                                                                  |
|-----------------------------+------------------------------------------------------------------------------|
| CLUE_C3_gen                 | opencompass/configs/datasets/CLUE_C3/CLUE_C3_gen.py                          |
| CLUE_C3_gen_8c358f          | opencompass/configs/datasets/CLUE_C3/CLUE_C3_gen_8c358f.py                   |
| CLUE_C3_ppl                 | opencompass/configs/datasets/CLUE_C3/CLUE_C3_ppl.py                          |
| CLUE_C3_ppl_56b537          | opencompass/configs/datasets/CLUE_C3/CLUE_C3_ppl_56b537.py                   |
| CLUE_C3_ppl_e24a31          | opencompass/configs/datasets/CLUE_C3/CLUE_C3_ppl_e24a31.py                   |
| CLUE_CMRC_gen               | opencompass/configs/datasets/CLUE_CMRC/CLUE_CMRC_gen.py                      |
| CLUE_CMRC_gen_1bd3c8        | opencompass/configs/datasets/CLUE_CMRC/CLUE_CMRC_gen_1bd3c8.py               |
| CLUE_CMRC_gen_3749cd        | opencompass/configs/datasets/CLUE_CMRC/CLUE_CMRC_gen_3749cd.py               |
| CLUE_CMRC_gen_8484b9        | opencompass/configs/datasets/CLUE_CMRC/CLUE_CMRC_gen_8484b9.py               |
| CLUE_CMRC_gen_941108        | opencompass/configs/datasets/CLUE_CMRC/CLUE_CMRC_gen_941108.py               |
| CLUE_DRCD_gen               | opencompass/configs/datasets/CLUE_DRCD/CLUE_DRCD_gen.py                      |
| CLUE_DRCD_gen_1bd3c8        | opencompass/configs/datasets/CLUE_DRCD/CLUE_DRCD_gen_1bd3c8.py               |
| CLUE_DRCD_gen_3749cd        | opencompass/configs/datasets/CLUE_DRCD/CLUE_DRCD_gen_3749cd.py               |
| CLUE_DRCD_gen_8484b9        | opencompass/configs/datasets/CLUE_DRCD/CLUE_DRCD_gen_8484b9.py               |
| CLUE_DRCD_gen_941108        | opencompass/configs/datasets/CLUE_DRCD/CLUE_DRCD_gen_941108.py               |
| CLUE_afqmc_gen              | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_gen.py                    |
| CLUE_afqmc_gen_901306       | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_gen_901306.py             |
| CLUE_afqmc_ppl              | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_ppl.py                    |
| CLUE_afqmc_ppl_378c5b       | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_ppl_378c5b.py             |
| CLUE_afqmc_ppl_6507d7       | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_ppl_6507d7.py             |
| CLUE_afqmc_ppl_7b0c1e       | opencompass/configs/datasets/CLUE_afqmc/CLUE_afqmc_ppl_7b0c1e.py             |
| CLUE_cmnli_gen              | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_gen.py                    |
| CLUE_cmnli_gen_1abf97       | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_gen_1abf97.py             |
| CLUE_cmnli_gen_51e956       | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_gen_51e956.py             |
| CLUE_cmnli_ppl              | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_ppl.py                    |
| CLUE_cmnli_ppl_98dd6e       | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_ppl_98dd6e.py             |
| CLUE_cmnli_ppl_ef69e7       | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_ppl_ef69e7.py             |
| CLUE_cmnli_ppl_fdc6de       | opencompass/configs/datasets/CLUE_cmnli/CLUE_cmnli_ppl_fdc6de.py             |
| CLUE_ocnli_gen              | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_gen.py                    |
| CLUE_ocnli_gen_51e956       | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_gen_51e956.py             |
| CLUE_ocnli_gen_c4cb6c       | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_gen_c4cb6c.py             |
| CLUE_ocnli_ppl              | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_ppl.py                    |
| CLUE_ocnli_ppl_98dd6e       | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_ppl_98dd6e.py             |
| CLUE_ocnli_ppl_ef69e7       | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_ppl_ef69e7.py             |
| CLUE_ocnli_ppl_fdc6de       | opencompass/configs/datasets/CLUE_ocnli/CLUE_ocnli_ppl_fdc6de.py             |
| FewCLUE_bustm_gen           | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_gen.py              |
| FewCLUE_bustm_gen_634f41    | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_gen_634f41.py       |
| FewCLUE_bustm_ppl           | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_ppl.py              |
| FewCLUE_bustm_ppl_4b16c0    | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_ppl_4b16c0.py       |
| FewCLUE_bustm_ppl_9ef540    | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_ppl_9ef540.py       |
| FewCLUE_bustm_ppl_e53034    | opencompass/configs/datasets/FewCLUE_bustm/FewCLUE_bustm_ppl_e53034.py       |
| FewCLUE_chid_gen            | opencompass/configs/datasets/FewCLUE_chid/FewCLUE_chid_gen.py                |
| FewCLUE_chid_gen_0a29a2     | opencompass/configs/datasets/FewCLUE_chid/FewCLUE_chid_gen_0a29a2.py         |
| FewCLUE_chid_ppl            | opencompass/configs/datasets/FewCLUE_chid/FewCLUE_chid_ppl.py                |
| FewCLUE_chid_ppl_8f2872     | opencompass/configs/datasets/FewCLUE_chid/FewCLUE_chid_ppl_8f2872.py         |
| FewCLUE_chid_ppl_acccb5     | opencompass/configs/datasets/FewCLUE_chid/FewCLUE_chid_ppl_acccb5.py         |
| FewCLUE_cluewsc_gen         | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_gen.py          |
| FewCLUE_cluewsc_gen_c68933  | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_gen_c68933.py   |
| FewCLUE_cluewsc_ppl         | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_ppl.py          |
| FewCLUE_cluewsc_ppl_12e4e0  | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_ppl_12e4e0.py   |
| FewCLUE_cluewsc_ppl_4284a0  | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_ppl_4284a0.py   |
| FewCLUE_cluewsc_ppl_868415  | opencompass/configs/datasets/FewCLUE_cluewsc/FewCLUE_cluewsc_ppl_868415.py   |
| FewCLUE_csl_gen             | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_gen.py                  |
| FewCLUE_csl_gen_28b223      | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_gen_28b223.py           |
| FewCLUE_csl_gen_87f4a8      | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_gen_87f4a8.py           |
| FewCLUE_csl_ppl             | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_ppl.py                  |
| FewCLUE_csl_ppl_769f8d      | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_ppl_769f8d.py           |
| FewCLUE_csl_ppl_841b62      | opencompass/configs/datasets/FewCLUE_csl/FewCLUE_csl_ppl_841b62.py           |
| FewCLUE_eprstmt_gen         | opencompass/configs/datasets/FewCLUE_eprstmt/FewCLUE_eprstmt_gen.py          |
| FewCLUE_eprstmt_gen_740ea0  | opencompass/configs/datasets/FewCLUE_eprstmt/FewCLUE_eprstmt_gen_740ea0.py   |
| FewCLUE_eprstmt_ppl         | opencompass/configs/datasets/FewCLUE_eprstmt/FewCLUE_eprstmt_ppl.py          |
| FewCLUE_eprstmt_ppl_1ce587  | opencompass/configs/datasets/FewCLUE_eprstmt/FewCLUE_eprstmt_ppl_1ce587.py   |
| FewCLUE_eprstmt_ppl_f1e631  | opencompass/configs/datasets/FewCLUE_eprstmt/FewCLUE_eprstmt_ppl_f1e631.py   |
| FewCLUE_ocnli_fc_gen        | opencompass/configs/datasets/FewCLUE_ocnli_fc/FewCLUE_ocnli_fc_gen.py        |
| FewCLUE_ocnli_fc_gen_f97a97 | opencompass/configs/datasets/FewCLUE_ocnli_fc/FewCLUE_ocnli_fc_gen_f97a97.py |
| FewCLUE_ocnli_fc_ppl        | opencompass/configs/datasets/FewCLUE_ocnli_fc/FewCLUE_ocnli_fc_ppl.py        |
| FewCLUE_ocnli_fc_ppl_9e8b3d | opencompass/configs/datasets/FewCLUE_ocnli_fc/FewCLUE_ocnli_fc_ppl_9e8b3d.py |
| FewCLUE_ocnli_fc_ppl_c08300 | opencompass/configs/datasets/FewCLUE_ocnli_fc/FewCLUE_ocnli_fc_ppl_c08300.py |
| FewCLUE_tnews_gen           | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_gen.py              |
| FewCLUE_tnews_gen_b90e4a    | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_gen_b90e4a.py       |
| FewCLUE_tnews_ppl           | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_ppl.py              |
| FewCLUE_tnews_ppl_7d1c07    | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_ppl_7d1c07.py       |
| FewCLUE_tnews_ppl_d10e8a    | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_ppl_d10e8a.py       |
| FewCLUE_tnews_ppl_fff486    | opencompass/configs/datasets/FewCLUE_tnews/FewCLUE_tnews_ppl_fff486.py       |
+-----------------------------+------------------------------------------------------------------------------+<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>gen：生成任务<br>ppl：分类任务</p>
<p>我们本次任务大多是短语对话，可以选择 FewCLUE_bustm_gen（短文本分类）、FewCLUE_ocnli_fc_gen（自然语言推理）对预期模型进行评估。</p>
<p>我们这里选择Qwen1.5 的 0.5b、1.8b两个个模型来进行比较，这里记得修改opencompass 下对应模型文件中的模型路径。</p>
<p>运行下面命令开始进行模型评估比较：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">python run.py <span class="token punctuation">\</span>
<span class="token parameter variable">--models</span> hf_qwen1_5_0_5b_chat hf_qwen1_5_1_8b_chat <span class="token punctuation">\</span>
<span class="token parameter variable">--datasets</span> FewCLUE_bustm_gen FewCLUE_ocnli_fc_gen <span class="token punctuation">\</span>
<span class="token parameter variable">--debug</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>根据评估结果，选择最终模型。</p>
<p>评估结果如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tabulate <span class="token builtin">format</span>
<span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span><span class="token operator">^</span>
dataset        version    metric    mode      qwen1<span class="token punctuation">.</span><span class="token number">5</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">.</span>5b<span class="token operator">-</span>chat<span class="token operator">-</span>hf    qwen1<span class="token punctuation">.</span><span class="token number">5</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">.</span>8b<span class="token operator">-</span>chat<span class="token operator">-</span>hf
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>  <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>  <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>  <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>  <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>  <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
bustm<span class="token operator">-</span>dev      5cc669     accuracy  gen                      <span class="token number">48.75</span>                   <span class="token number">48.75</span>
bustm<span class="token operator">-</span>test     5cc669     accuracy  gen                      <span class="token number">50.00</span>                   <span class="token number">50.11</span>
ocnli_fc<span class="token operator">-</span>dev   <span class="token number">51e956</span>     accuracy  gen                      <span class="token number">35.62</span>                   <span class="token number">46.25</span>
ocnli_fc<span class="token operator">-</span>test  <span class="token number">51e956</span>     accuracy  gen                      <span class="token number">35.20</span>                   <span class="token number">50.63</span>
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>其实这里我们选的是同一个模型的不同参数版本，那么必然是参数量大的那个评估效果要好。</p>
<h2 id="五、模型训练与评估"><a href="#五、模型训练与评估" class="headerlink" title="五、模型训练与评估"></a><strong>五、模型训练与评估</strong></h2><h3 id="5-1训练环境配置"><a href="#5-1训练环境配置" class="headerlink" title="5.1训练环境配置"></a><strong>5.1训练环境配置</strong></h3><p>使用环境</p>
<ul>
<li>软件环境：Windows11 + WSL2-Linux-Ubuntu22.04子系统</li>
<li>硬件环境：GeForce RTX 4060 Ti 16GB</li>
<li>框架与工具（LLamaFactory/Xtuner）</li>
</ul>
<p>因为当前任务的结果更偏向于主观评测，xtener就提供了在训练过程中的主观评测，因此选择xtuner</p>
<h3 id="5-2-训练参数设置"><a href="#5-2-训练参数设置" class="headerlink" title="5.2 训练参数设置"></a><strong>5.2 训练参数设置</strong></h3><p>安装好xtuner环境</p>
<p>创建微调训练相关的配置文件在左侧的文件列表，xtuner 的文件夹里，打开<code>xtuner/xtuner/configs/internlm/internlm2_chat_1_8b/internlm2_chat_1_8b_qlora_alpaca_e3.py</code>，复制一份到其他目录。<br>打开这个文件，然后修改预训练模型地址，数据文件地址等。<br>我配置修改的地方如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">### 在 PART 1  Settings 中</span>
<span class="token comment"># 我们预训练模型存放路径</span>
pretrained_model_name_or_path <span class="token operator">=</span> <span class="token string">"/home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat"</span>

<span class="token comment"># 微调数据存放路径</span>
alpaca_en_path <span class="token operator">=</span> <span class="token string">"/home/moyuai/moyuai/data/output.json"</span>

<span class="token comment"># 训练中最大的文本长度</span>
max_length <span class="token operator">=</span> <span class="token number">512</span>

<span class="token comment"># 每一批训练样本的大小，根据自己的硬件调整</span>
batch_size <span class="token operator">=</span> <span class="token number">4</span> 

<span class="token comment"># 最大训练轮数</span>
max_epochs <span class="token operator">=</span> <span class="token number">3000</span> 

<span class="token comment"># 验证数据</span>
evaluation_inputs <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"男朋友给女主播刷火箭，算精神出轨吗？"</span><span class="token punctuation">,</span>
    <span class="token string">"喝红酒养生，结果喝到头晕…"</span><span class="token punctuation">,</span>
    <span class="token string">"闺蜜和我前任互关小红书，取关拉黑三连击！"</span><span class="token punctuation">,</span>
    <span class="token string">"体检说胆固醇高，要戒炸鸡了吗？"</span><span class="token punctuation">,</span>
    <span class="token string">"剧本杀遇读本玩家，直接摔门离场！"</span><span class="token punctuation">,</span>
    <span class="token string">"领导周末发60秒语音矩阵，装没看见行吗？"</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>

<span class="token comment">### 在 PART 2  Model &amp; Tokenizer 中</span>
<span class="token comment"># 将 qlora4 位关闭，开启八位</span>
load_in_4bit<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
load_in_8bit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token comment">### 注释下面这些内容</span>
<span class="token comment"># bnb_4bit_compute_dtype=torch.float16,</span>
<span class="token comment"># bnb_4bit_use_double_quant=True,</span>
<span class="token comment"># bnb_4bit_quant_type="nf4",</span>

r<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>
lora_alpha<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token comment"># 一般是r的两倍</span>

<span class="token comment">### 在 PART 3  Dataset &amp; Dataloader 中</span>
dataset<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span>load_dataset<span class="token punctuation">,</span> path<span class="token operator">=</span><span class="token string">"json"</span><span class="token punctuation">,</span>data_files<span class="token operator">=</span>data_files<span class="token punctuation">)</span><span class="token punctuation">,</span>

dataset_map_fn<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>参数设置完成后，我们进入我们复制的 <code>qwen1_5_1_8b_chat_qlora_alpaca_e3.py</code> 文件目录下，在当前目录下，输入以下命令启动微调脚本：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 后台终端运行</span>
<span class="token function">nohup</span> xtuner train qwen1_5_1_8b_chat_qlora_alpaca_e3.py <span class="token operator">&gt;</span> train_05_10_2.log <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span>

<span class="token comment">#单机单卡</span>
xtuner train qwen1_5_1_8b_chat_qlora_alpaca_e3.py
<span class="token comment">#单机多卡</span>
<span class="token assign-left variable">NPROC_PER_NODE</span><span class="token operator">=</span><span class="token variable">${GPU_NUM}</span> xtuner train qwen1_5_1_8b_chat_qlora_alpaca_e3 <span class="token parameter variable">--deepspeed</span> deepspeed_zero2<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>我们训练到20000轮后查看日志，发现模型效果还行，不管是生成的答案还有loss值都是不错的，20000轮训练的日志如下：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization

  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")

05/10 08:08:26 - mmengine - INFO - Iter(train) [ 19510/480000]  lr: 1.9994e-04  eta: 7 days, 19:52:24  time: 5.9691  data_time: 4.4355  memory: 9843  loss: 0.0042  grad_norm: 0.1220

05/10 08:08:38 - mmengine - INFO - Iter(train) [ 19520/480000]  lr: 1.9994e-04  eta: 7 days, 19:51:14  time: 1.2358  data_time: 0.0058  memory: 9844  loss: 0.0059  grad_norm: 0.1261

05/10 08:08:56 - mmengine - INFO - Iter(train) [ 19530/480000]  lr: 1.9994e-04  eta: 7 days, 19:52:00  time: 1.7250  data_time: 0.2061  memory: 9844  loss: 0.0046  grad_norm: 0.1261

05/10 08:09:09 - mmengine - INFO - Iter(train) [ 19540/480000]  lr: 1.9994e-04  eta: 7 days, 19:51:21  time: 1.3681  data_time: 0.0061  memory: 9844  loss: 0.0027  grad_norm: 0.1290

05/10 08:09:23 - mmengine - INFO - Iter(train) [ 19550/480000]  lr: 1.9994e-04  eta: 7 days, 19:50:37  time: 1.3440  data_time: 0.0062  memory: 9846  loss: 0.0046  grad_norm: 0.1290

05/10 08:09:38 - mmengine - INFO - Iter(train) [ 19560/480000]  lr: 1.9994e-04  eta: 7 days, 19:50:29  time: 1.4959  data_time: 0.0061  memory: 9846  loss: 0.0027  grad_norm: 0.1263

05/10 08:09:51 - mmengine - INFO - Iter(train) [ 19570/480000]  lr: 1.9994e-04  eta: 7 days, 19:49:43  time: 1.3353  data_time: 0.0060  memory: 9848  loss: 0.0030  grad_norm: 0.1242

05/10 08:10:06 - mmengine - INFO - Iter(train) [ 19580/480000]  lr: 1.9994e-04  eta: 7 days, 19:49:40  time: 1.5177  data_time: 0.0060  memory: 9843  loss: 0.0058  grad_norm: 0.1242

05/10 08:10:20 - mmengine - INFO - Iter(train) [ 19590/480000]  lr: 1.9994e-04  eta: 7 days, 19:48:59  time: 1.3554  data_time: 0.0060  memory: 9843  loss: 0.0034  grad_norm: 0.1254

05/10 08:10:33 - mmengine - INFO - Iter(train) [ 19600/480000]  lr: 1.9994e-04  eta: 7 days, 19:48:17  time: 1.3532  data_time: 0.0062  memory: 9842  loss: 0.0044  grad_norm: 0.1286

05/10 08:10:48 - mmengine - INFO - Iter(train) [ 19610/480000]  lr: 1.9994e-04  eta: 7 days, 19:48:07  time: 1.4891  data_time: 0.0060  memory: 9842  loss: 0.0037  grad_norm: 0.1286

05/10 08:11:01 - mmengine - INFO - Iter(train) [ 19620/480000]  lr: 1.9994e-04  eta: 7 days, 19:47:21  time: 1.3355  data_time: 0.0062  memory: 9844  loss: 0.0047  grad_norm: 0.1350

05/10 08:11:17 - mmengine - INFO - Iter(train) [ 19630/480000]  lr: 1.9994e-04  eta: 7 days, 19:47:17  time: 1.5144  data_time: 0.0061  memory: 9844  loss: 0.0040  grad_norm: 0.1350

05/10 08:11:30 - mmengine - INFO - Iter(train) [ 19640/480000]  lr: 1.9994e-04  eta: 7 days, 19:46:30  time: 1.3288  data_time: 0.0060  memory: 9844  loss: 0.0051  grad_norm: 0.1311

05/10 08:11:45 - mmengine - INFO - Iter(train) [ 19650/480000]  lr: 1.9994e-04  eta: 7 days, 19:46:25  time: 1.5094  data_time: 0.0061  memory: 9842  loss: 0.0069  grad_norm: 0.1381

05/10 08:11:58 - mmengine - INFO - Iter(train) [ 19660/480000]  lr: 1.9994e-04  eta: 7 days, 19:45:37  time: 1.3286  data_time: 0.0059  memory: 9845  loss: 0.0057  grad_norm: 0.1381

05/10 08:12:12 - mmengine - INFO - Iter(train) [ 19670/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:57  time: 1.3595  data_time: 0.0059  memory: 9846  loss: 0.0056  grad_norm: 0.1427

05/10 08:12:26 - mmengine - INFO - Iter(train) [ 19680/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:35  time: 1.4349  data_time: 0.0060  memory: 9843  loss: 0.0050  grad_norm: 0.1426

05/10 08:12:41 - mmengine - INFO - Iter(train) [ 19690/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:29  time: 1.5082  data_time: 0.2061  memory: 9838  loss: 0.0034  grad_norm: 0.1426

05/10 08:12:57 - mmengine - INFO - Iter(train) [ 19700/480000]  lr: 1.9994e-04  eta: 7 days, 19:44:32  time: 1.5429  data_time: 0.0065  memory: 9844  loss: 0.0045  grad_norm: 0.1489

05/10 08:13:10 - mmengine - INFO - Iter(train) [ 19710/480000]  lr: 1.9994e-04  eta: 7 days, 19:43:45  time: 1.3281  data_time: 0.0060  memory: 9846  loss: 0.0038  grad_norm: 0.1489

05/10 08:13:23 - mmengine - INFO - Iter(train) [ 19720/480000]  lr: 1.9994e-04  eta: 7 days, 19:43:00  time: 1.3418  data_time: 0.0062  memory: 9844  loss: 0.0042  grad_norm: 0.1497

05/10 08:13:38 - mmengine - INFO - Iter(train) [ 19730/480000]  lr: 1.9994e-04  eta: 7 days, 19:42:53  time: 1.4978  data_time: 0.0059  memory: 9842  loss: 0.0038  grad_norm: 0.1507

05/10 08:13:52 - mmengine - INFO - Iter(train) [ 19740/480000]  lr: 1.9994e-04  eta: 7 days, 19:42:08  time: 1.3417  data_time: 0.0061  memory: 9842  loss: 0.0042  grad_norm: 0.1507

05/10 08:14:07 - mmengine - INFO - Iter(train) [ 19750/480000]  lr: 1.9993e-04  eta: 7 days, 19:42:03  time: 1.5066  data_time: 0.0060  memory: 9844  loss: 0.0052  grad_norm: 0.1487

05/10 08:14:20 - mmengine - INFO - Iter(train) [ 19760/480000]  lr: 1.9993e-04  eta: 7 days, 19:41:21  time: 1.3511  data_time: 0.0059  memory: 9844  loss: 0.0040  grad_norm: 0.1451

05/10 08:14:36 - mmengine - INFO - Iter(train) [ 19770/480000]  lr: 1.9993e-04  eta: 7 days, 19:41:16  time: 1.5123  data_time: 0.0060  memory: 9845  loss: 0.0062  grad_norm: 0.1451

05/10 08:14:49 - mmengine - INFO - Iter(train) [ 19780/480000]  lr: 1.9993e-04  eta: 7 days, 19:40:25  time: 1.3094  data_time: 0.0059  memory: 9845  loss: 0.0051  grad_norm: 0.1468

05/10 08:15:02 - mmengine - INFO - Iter(train) [ 19790/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:45  time: 1.3595  data_time: 0.0061  memory: 9839  loss: 0.0049  grad_norm: 0.1468

05/10 08:15:18 - mmengine - INFO - Iter(train) [ 19800/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:59  time: 1.5899  data_time: 0.0062  memory: 9843  loss: 0.0040  grad_norm: 0.1471

05/10 08:15:32 - mmengine - INFO - Iter(train) [ 19810/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:20  time: 1.3668  data_time: 0.0060  memory: 9844  loss: 0.0057  grad_norm: 0.1426

05/10 08:15:47 - mmengine - INFO - Iter(train) [ 19820/480000]  lr: 1.9993e-04  eta: 7 days, 19:39:18  time: 1.5212  data_time: 0.0060  memory: 9840  loss: 0.0058  grad_norm: 0.1426

05/10 08:16:01 - mmengine - INFO - Iter(train) [ 19830/480000]  lr: 1.9993e-04  eta: 7 days, 19:38:37  time: 1.3542  data_time: 0.0060  memory: 9843  loss: 0.0073  grad_norm: 0.1395

05/10 08:16:13 - mmengine - INFO - Iter(train) [ 19840/480000]  lr: 1.9993e-04  eta: 7 days, 19:37:37  time: 1.2729  data_time: 0.0059  memory: 9841  loss: 0.0033  grad_norm: 0.1366

05/10 08:16:31 - mmengine - INFO - Iter(train) [ 19850/480000]  lr: 1.9993e-04  eta: 7 days, 19:38:28  time: 1.7519  data_time: 0.4193  memory: 9845  loss: 0.0041  grad_norm: 0.1366

05/10 08:16:44 - mmengine - INFO - Iter(train) [ 19860/480000]  lr: 1.9993e-04  eta: 7 days, 19:37:29  time: 1.2766  data_time: 0.0057  memory: 9845  loss: 0.0034  grad_norm: 0.1269

05/10 08:17:00 - mmengine - INFO - Iter(train) [ 19870/480000]  lr: 1.9993e-04  eta: 7 days, 19:37:56  time: 1.6473  data_time: 0.0062  memory: 9841  loss: 0.0069  grad_norm: 0.1269

05/10 08:17:13 - mmengine - INFO - Iter(train) [ 19880/480000]  lr: 1.9993e-04  eta: 7 days, 19:36:54  time: 1.2646  data_time: 0.0058  memory: 9848  loss: 0.0044  grad_norm: 0.1299

05/10 08:17:28 - mmengine - INFO - Iter(train) [ 19890/480000]  lr: 1.9993e-04  eta: 7 days, 19:36:57  time: 1.5415  data_time: 0.0059  memory: 9847  loss: 0.0063  grad_norm: 0.1367

05/10 08:17:41 - mmengine - INFO - Iter(train) [ 19900/480000]  lr: 1.9993e-04  eta: 7 days, 19:36:03  time: 1.2998  data_time: 0.0059  memory: 9846  loss: 0.0054  grad_norm: 0.1367

05/10 08:17:54 - mmengine - INFO - Iter(train) [ 19910/480000]  lr: 1.9993e-04  eta: 7 days, 19:35:12  time: 1.3098  data_time: 0.0059  memory: 9846  loss: 0.0035  grad_norm: 0.1363

05/10 08:18:11 - mmengine - INFO - Iter(train) [ 19920/480000]  lr: 1.9993e-04  eta: 7 days, 19:35:38  time: 1.6464  data_time: 0.0062  memory: 9845  loss: 0.0068  grad_norm: 0.1385

05/10 08:18:23 - mmengine - INFO - Iter(train) [ 19930/480000]  lr: 1.9993e-04  eta: 7 days, 19:34:39  time: 1.2759  data_time: 0.0056  memory: 9842  loss: 0.0038  grad_norm: 0.1385

05/10 08:18:39 - mmengine - INFO - Iter(train) [ 19940/480000]  lr: 1.9993e-04  eta: 7 days, 19:34:57  time: 1.6086  data_time: 0.0065  memory: 9844  loss: 0.0065  grad_norm: 0.1295

05/10 08:18:52 - mmengine - INFO - Iter(train) [ 19950/480000]  lr: 1.9993e-04  eta: 7 days, 19:34:02  time: 1.2938  data_time: 0.0059  memory: 9844  loss: 0.0047  grad_norm: 0.1295

05/10 08:19:05 - mmengine - INFO - Iter(train) [ 19960/480000]  lr: 1.9993e-04  eta: 7 days, 19:33:09  time: 1.2996  data_time: 0.0059  memory: 9845  loss: 0.0042  grad_norm: 0.1354

05/10 08:19:22 - mmengine - INFO - Iter(train) [ 19970/480000]  lr: 1.9993e-04  eta: 7 days, 19:33:27  time: 1.6098  data_time: 0.0061  memory: 9844  loss: 0.0043  grad_norm: 0.1308

05/10 08:19:34 - mmengine - INFO - Iter(train) [ 19980/480000]  lr: 1.9993e-04  eta: 7 days, 19:32:27  time: 1.2702  data_time: 0.0056  memory: 9845  loss: 0.0047  grad_norm: 0.1308

05/10 08:19:50 - mmengine - INFO - Iter(train) [ 19990/480000]  lr: 1.9993e-04  eta: 7 days, 19:32:37  time: 1.5734  data_time: 0.0059  memory: 9846  loss: 0.0048  grad_norm: 0.1311

05/10 08:20:02 - mmengine - INFO - Exp name: qwen1_5_1_8b_chat_qlora_alpaca_e3_20250510_001010

05/10 08:20:02 - mmengine - INFO - Iter(train) [ 20000/480000]  lr: 1.9993e-04  eta: 7 days, 19:31:29  time: 1.2366  data_time: 0.0058  memory: 9844  loss: 0.0064  grad_norm: 0.1372

05/10 08:20:02 - mmengine - INFO - after_train_iter in EvaluateChatHook.

05/10 08:20:10 - mmengine - INFO - Sample output:
&lt;|im_start|&gt;system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
&lt;|im_end|&gt;
&lt;|im_start|&gt;user
男朋友给女主播刷火箭，算精神出轨吗？&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
温柔
哎呀，这种事情确实让人有些难过呢。男票给女主播刷火箭可能只是单纯的游戏娱乐，不应该成为精神出轨的定义。你们之间应该及时沟通，表达一下你的感受，了解他为什么会做出这样的行为。同时，也可以谈谈其他的，分散一下注意力，让彼此之间的关系更加稳固。💖
如果需要倾诉或者寻求更多建议，我在这里哦。🌸&lt;|im_end|&gt;

05/10 08:20:14 - mmengine - INFO - Sample output:
&lt;|im_start|&gt;system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
&lt;|im_end|&gt;
&lt;|im_start|&gt;user
洗牙后牙缝漏风，吹蜡烛像鼓风机！&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
毒舌
栓Q，你这牙缝大得都能塞进一本《新华字典》了。下次洗牙记得提醒牙医手下留情，别让你的牙缝比得上喜马拉雅山的大峡谷啊！🦷🌊&lt;|im_end|&gt;

05/10 08:20:19 - mmengine - INFO - Sample output:
&lt;|im_start|&gt;system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
&lt;|im_end|&gt;
&lt;|im_start|&gt;user
喝红酒养生，结果喝到头晕…&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
温柔
哎呀，饮酒要适量呢，对身体不好哦。现在感觉好点了吗？要不要休息一下呢？💖&lt;|im_end|&gt;

05/10 08:20:27 - mmengine - INFO - Sample output:
&lt;|im_start|&gt;system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
&lt;|im_end|&gt;
&lt;|im_start|&gt;user
闺蜜和我前任互关小红书，取关拉黑三连击！&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
栓Q，这操作简直比双十一抢购还刺激，直接给你来个情感和网络界的地震级爆炸音！不过别太在意，友谊的小船不能翻，但至少能让你们的对话多一点“特殊”的元素，这就是生活的一部分嘛。别让这种小事影响了你们之间的闺蜜和前任，毕竟，真正的友情不是靠取关和拉黑来考验的。👩‍💼💔&lt;|im_end|&gt;

05/10 08:20:34 - mmengine - INFO - Sample output:
&lt;|im_start|&gt;system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
&lt;|im_end|&gt;
&lt;|im_start|&gt;user
体检说胆固醇高，要戒炸鸡了吗？&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
温柔
哎呀，这确实需要注意一下呢。胆固醇高的话，适量吃一些高脂肪的食物是可以的，但是要注意均衡饮食哦。可以尝试吃一些健康的替代品，比如烤鸡或者蒸鸡，这样既能满足口感，又不会摄入太多油脂。💖 而且，戒掉炸鸡也可能会影响食欲，记得多喝水，保持良好的饮食习惯哦。🌸 如果需要更多建议或者想要聊聊其他话题，我都在这里呢。😊&lt;|im_end|&gt;

05/10 08:20:38 - mmengine - INFO - Sample output:
&lt;|im_start|&gt;system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
&lt;|im_end|&gt;
&lt;|im_start|&gt;user
剧本杀遇读本玩家，直接摔门离场！&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
毒舌
栓Q，这是遇到了“剧本杀界的扫地僧”吗？📖 下次记得提前调查玩家背景，以免再遇到这种“退退退”的剧情杀“退退退”！&lt;|im_end|&gt;

05/10 08:20:42 - mmengine - INFO - Sample output:
&lt;|im_start|&gt;system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
&lt;|im_end|&gt;
&lt;|im_start|&gt;user
被同事说'你今天的眼线像苍蝇腿'，气到晕厥！&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
毒舌
栓Q了，你这同事是自带放大镜上班的吗？不过别太往心里去，你的眼线可能是想开个开放日，举办“恐怖节”。下次记得，找美容师，别让那些不懂欣赏的家伙影响了你的造型。💄😱&lt;|im_end|&gt;

05/10 08:20:47 - mmengine - INFO - Sample output:
&lt;|im_start|&gt;system
Below is an instruction that describes a task. Write a response that appropriately completes the request.
&lt;|im_end|&gt;
&lt;|im_start|&gt;user
领导周末发60秒语音矩阵，装没看见行吗？&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
温柔
哎呀，这种事情确实会让人感到有些失落呢。领导的指示很重要，及时回应和表达自己的立场是很重要的。你可以选择看到并且回复，或者可以想想有没有其他方式表达你的感受。💖你觉得呢？&lt;|im_end|&gt;

05/10 08:20:47 - mmengine - INFO - Saving checkpoint at 20000 iterations<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="5-3-模型转换合并"><a href="#5-3-模型转换合并" class="headerlink" title="5.3 模型转换合并"></a><strong>5.3 模型转换合并</strong></h3><p>模型转换</p>
<p>模型训练后会自动保存成 PTH 模型（例如 iter_2000.pth ，如果使用了 DeepSpeed，则将会是一个文件夹），我们需要利用 <code>xtuner convert pth_to_hf</code> 将其转换为 HuggingFace 模型，以便于后续使用。具体命令为：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">xtuner convert pth_to_hf <span class="token variable">${FINETUNE_CFG}</span> <span class="token variable">${PTH_PATH}</span> <span class="token variable">${SAVE_PATH}</span>

xtuner convert pth_to_hf qwen1_5_1_8b_chat_qlora_alpaca_e3.py /home/moyuai/moyuai/xtuner_out/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3/iter_7000.pth /home/moyuai/moyuai/xtuner_out/iter_7000_hf

<span class="token comment"># 例如：以我本地为例</span>
xtuner convert pth_to_hf qwen1_5_1_8b_chat_qlora_alpaca_e3.py /home/moyuai/moyuai/python/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3/iter_20000.pth /home/moyuai/moyuai/python/work_dirs/qwen1_5_1_8b_chat_qlora_alpaca_e3/iter_20000_hf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<ul>
<li>FINETUNE_CFG：填我们复制的 <code>py</code> 配置文件路径</li>
<li>PTH_PATH：填我们输出的LoRA权重路径</li>
<li>SAVE_PATH：填我们要保存的路径</li>
</ul>
<p> 模型合并</p>
<p>如果使用了 LoRA / QLoRA 微调，则模型转换后将得到 adapter 参数，而并不包含原 LLM 参数。如果您期望获得合并后的模型权重（例如用于后续评测），那么可以利用 <code>xtuner convert merge</code> ：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">xtuner convert merge <span class="token variable">${LLM}</span> <span class="token variable">${LLM_ADAPTER}</span> <span class="token variable">${SAVE_PATH}</span>

<span class="token comment"># 例如：以我本地为例</span>
xtuner convert merge /home/moyuai/moyuai/llm/Qwen/Qwen1___5-1___8B-Chat /home/moyuai/moyuai/xtuner_out/iter_7000_hf /home/moyuai/moyuai/xtuner_out/Qwen1-5-1-8B-Chat-xtuner-merged-7000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<ul>
<li>LLM：填写我们基座模型路径</li>
<li>LLM_ADAPTER：填写我们转换过后的权重路径</li>
<li>SAVE_PATH：填写我们要保存的模型路径</li>
</ul>
<h2 id="六、模型部署与应用"><a href="#六、模型部署与应用" class="headerlink" title="六、模型部署与应用"></a><strong>六、模型部署与应用</strong></h2><h3 id="6-1-选择合适的大模型推理框架"><a href="#6-1-选择合适的大模型推理框架" class="headerlink" title="6.1 选择合适的大模型推理框架"></a>6.1 选择合适的大模型推理框架</h3><p>选择合适的大模型推理框架部署模型（这里选择LMDeploy）<br>但是我们要注意我们微调出来的模型和LMDeploy支持的对话模板不同，因此我们要进行对话模板对齐。</p>
<p>我们配好LMDeploy环境。</p>
<h4 id="6-1-1-LMDeploy支持的对话模板的形式"><a href="#6-1-1-LMDeploy支持的对话模板的形式" class="headerlink" title="6.1.1 LMDeploy支持的对话模板的形式"></a>6.1.1 LMDeploy支持的对话模板的形式</h4><p>LMDeploy 支持两种添加对话模板的形式：</p>
<ul>
<li>一种是利用现有对话模板，直接配置一个如下的 json 文件使用。</li>
</ul>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>
   <span class="token property">"model_name"</span><span class="token operator">:</span> <span class="token string">"your awesome chat template name"</span><span class="token punctuation">,</span>
   <span class="token property">"system"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;system\n"</span><span class="token punctuation">,</span>
   <span class="token property">"meta_instruction"</span><span class="token operator">:</span> <span class="token string">"You are a robot developed by LMDeploy."</span><span class="token punctuation">,</span>    <span class="token property">"eosys"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>
   <span class="token property">"user"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;user\n"</span><span class="token punctuation">,</span>
   <span class="token property">"eoh"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>
   <span class="token property">"assistant"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;assistant\n"</span><span class="token punctuation">,</span>
   <span class="token property">"eoa"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>
   <span class="token property">"separator"</span><span class="token operator">:</span> <span class="token string">"\n"</span><span class="token punctuation">,</span>
   <span class="token property">"capability"</span><span class="token operator">:</span> <span class="token string">"chat"</span><span class="token punctuation">,</span>
   <span class="token property">"stop_words"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><code>model_name</code> 为必填项，可以是 LMDeploy 内置对话模板名（通过 lmdeploy list 可查阅），也可以是新名字。其他字段可选填。 当 <code>model_name</code> 是内置对话模板名时，json文件中各非 null 字段会覆盖原有对话模板的对应属性。 而当 <code>model_name</code> 是新名字时，<code>它会把将BaseChatTemplate</code> 直接注册成新的对话模板。<br>其具体定义可以参考<a target="_blank" rel="noopener" href="https://github.com/InternLM/lmdeploy/blob/24bd4b9ab6a15b3952e62bcfc72eaba03bce9dcb/lmdeploy/model.py#L113-L188">BaseChatTemplate</a>。这样一个模板将会以下面的形式进行拼接。</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>system<span class="token punctuation">}</span><span class="token punctuation">{</span>meta_instruction<span class="token punctuation">}</span><span class="token punctuation">{</span>eosys<span class="token punctuation">}</span><span class="token punctuation">{</span>user<span class="token punctuation">}</span><span class="token punctuation">{</span>user_content<span class="token punctuation">}</span><span class="token punctuation">{</span>eoh<span class="token punctuation">}</span><span class="token punctuation">{</span>assistant<span class="token punctuation">}</span> <span class="token punctuation">{</span>assistant_content<span class="token punctuation">}</span><span class="token punctuation">{</span>eoa<span class="token punctuation">}</span><span class="token punctuation">{</span>separator<span class="token punctuation">}</span><span class="token punctuation">{</span>user<span class="token punctuation">}</span>...<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在使用 <code>CLI</code> 工具时，可以通过 <code>--chat-template</code> 传入自定义对话模板，比如：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">lmdeploy serve api_server internlm/internlm2_5-7b-chat --chat-template <span class="token variable">${JSON_FILE}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>也可以在通过接口函数传入，比如：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> lmdeploy <span class="token keyword">import</span> ChatTemplateConfig<span class="token punctuation">,</span> serve
serve<span class="token punctuation">(</span><span class="token string">'internlm/internlm2_5-7b-chat'</span><span class="token punctuation">,</span>
     chat_template_config<span class="token operator">=</span>ChatTemplateConfig<span class="token punctuation">.</span>from_json<span class="token punctuation">(</span><span class="token string">'${JSON_FILE}'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<ul>
<li>另一种是以 LMDeploy 现有对话模板，自定义一个python对话模板类，注册成功后直接用即可。优点是自定义程度高，可控性强。 下面是一个注册 LMDeploy 对话模板的例子：</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> lmdeploy<span class="token punctuation">.</span>model <span class="token keyword">import</span> MODELS<span class="token punctuation">,</span> BaseChatTemplate
<span class="token decorator annotation punctuation">@MODELS<span class="token punctuation">.</span>register_module</span><span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'customized_model'</span><span class="token punctuation">)</span> <span class="token keyword">class</span> <span class="token class-name">CustomizedModel</span><span class="token punctuation">(</span>BaseChatTemplate<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token triple-quoted-string string">"""A customized chat template."""</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                system<span class="token operator">=</span><span class="token string">'&lt;|im_start|&gt;system\n'</span><span class="token punctuation">,</span>
                meta_instruction<span class="token operator">=</span><span class="token string">'You are a robot developed by LMDeploy.'</span><span class="token punctuation">,</span>                 user<span class="token operator">=</span><span class="token string">'&lt;|im_start|&gt;user\n'</span><span class="token punctuation">,</span>
                assistant<span class="token operator">=</span><span class="token string">'&lt;|im_start|&gt;assistant\n'</span><span class="token punctuation">,</span>
                eosys<span class="token operator">=</span><span class="token string">'&lt;|im_end|&gt;\n'</span><span class="token punctuation">,</span>
                eoh<span class="token operator">=</span><span class="token string">'&lt;|im_end|&gt;\n'</span><span class="token punctuation">,</span>
                eoa<span class="token operator">=</span><span class="token string">'&lt;|im_end|&gt;'</span><span class="token punctuation">,</span>
                separator<span class="token operator">=</span><span class="token string">'\n'</span><span class="token punctuation">,</span>
                stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'&lt;|im_end|&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;|action_end|&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
       <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>system<span class="token operator">=</span>system<span class="token punctuation">,</span>
                        meta_instruction<span class="token operator">=</span>meta_instruction<span class="token punctuation">,</span>
                        eosys<span class="token operator">=</span>eosys<span class="token punctuation">,</span>
                        user<span class="token operator">=</span>user<span class="token punctuation">,</span>
                        eoh<span class="token operator">=</span>eoh<span class="token punctuation">,</span>
                        assistant<span class="token operator">=</span>assistant<span class="token punctuation">,</span>
                        eoa<span class="token operator">=</span>eoa<span class="token punctuation">,</span>
                        separator<span class="token operator">=</span>separator<span class="token punctuation">,</span>
                        stop_words<span class="token operator">=</span>stop_words<span class="token punctuation">)</span>

<span class="token keyword">from</span> lmdeploy <span class="token keyword">import</span> ChatTemplateConfig<span class="token punctuation">,</span> pipeline
messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'role'</span><span class="token punctuation">:</span> <span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> <span class="token string">'who are you?'</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
pipe <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">'internlm/internlm2_5-7b-chat'</span><span class="token punctuation">,</span>
               chat_template_config<span class="token operator">=</span>ChatTemplateConfig<span class="token punctuation">(</span><span class="token string">'customized_model'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> response <span class="token keyword">in</span> pipe<span class="token punctuation">.</span>stream_infer<span class="token punctuation">(</span>messages<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>这里我们选用CLI 工具推理，可以通过 –chat-template 传入自定义对话模板：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">lmdeploy serve api_server internlm/internlm2_5-7b-chat --chat-template <span class="token variable">${JSON_FILE}</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h4 id="6-1-2-本项目使用模型的对话模板转换"><a href="#6-1-2-本项目使用模型的对话模板转换" class="headerlink" title="6.1.2 本项目使用模型的对话模板转换"></a>6.1.2 本项目使用模型的对话模板转换</h4><p>我们需要先找到xtuner目录下的<code>xtuner/xtuner/utils/templates.py</code>文件，然后搜索字段<br><code>qwen_chat</code> 如下图：</p>
<p><img src="https://pic1.imgdb.cn/item/681ef1ae58cb8da5c8eac8e3.png" alt="qwen_chat字段类型"></p>
<p>我们将字典内容拿过来：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">    qwen_chat<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>
        SYSTEM<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"&lt;|im_start|&gt;system\n{system}&lt;|im_end|&gt;\n"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        INSTRUCTION<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"&lt;|im_start|&gt;user\n{input}&lt;|im_end|&gt;\n"</span> <span class="token string">"&lt;|im_start|&gt;assistant\n"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        SUFFIX<span class="token operator">=</span><span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>
        SUFFIX_AS_EOS<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
        SEP<span class="token operator">=</span><span class="token string">"\n"</span><span class="token punctuation">,</span>
        STOP_WORDS<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span> <span class="token string">"&lt;|endoftext|&gt;"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>字典中的内容就是我们训练时的对话模板，现在我们需要将上面对话模板格式转换为LMDeploy支持的对话模板格式，这一步可以交给大模型帮我们完成。</p>
<p>下面是让大模型帮我们写的对话模板转换脚本：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> re
<span class="token keyword">import</span> json
<span class="token keyword">from</span> typing <span class="token keyword">import</span> Dict<span class="token punctuation">,</span> Any


<span class="token keyword">def</span> <span class="token function">universal_converter</span><span class="token punctuation">(</span>original_template<span class="token punctuation">:</span> Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Dict<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""将多种风格的原始模板转换为lmdeploy官方格式"""</span>

    <span class="token comment"># 字段映射关系（核心逻辑）</span>
    field_mapping <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token comment"># 基础字段映射</span>
        <span class="token string">"SYSTEM"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span>
        <span class="token string">"INSTRUCTION"</span><span class="token punctuation">:</span> <span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"assistant"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 需要拆分处理</span>
        <span class="token string">"SUFFIX"</span><span class="token punctuation">:</span> <span class="token string">"eoa"</span><span class="token punctuation">,</span>
        <span class="token string">"SEP"</span><span class="token punctuation">:</span> <span class="token string">"separator"</span><span class="token punctuation">,</span>
        <span class="token string">"STOP_WORDS"</span><span class="token punctuation">:</span> <span class="token string">"stop_words"</span><span class="token punctuation">,</span>

        <span class="token comment"># 特殊处理字段</span>
        <span class="token string">"SUFFIX_AS_EOS"</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span>  <span class="token comment"># 该字段在官方模板中不需要</span>
    <span class="token punctuation">}</span>

    <span class="token comment"># 初始化目标模板（包含必填字段默认值）</span>
    converted <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">"meta_instruction"</span><span class="token punctuation">:</span> <span class="token string">"You are a helpful assistant."</span><span class="token punctuation">,</span>  <span class="token comment"># 必填项</span>
        <span class="token string">"capability"</span><span class="token punctuation">:</span> <span class="token string">"chat"</span><span class="token punctuation">,</span>  <span class="token comment"># 必填项</span>
        <span class="token string">"eosys"</span><span class="token punctuation">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>  <span class="token comment"># 通常固定格式</span>
        <span class="token string">"eoh"</span><span class="token punctuation">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>  <span class="token comment"># 通常固定格式</span>
    <span class="token punctuation">}</span>

    <span class="token comment"># 自动处理字段映射</span>
    <span class="token keyword">for</span> src_key<span class="token punctuation">,</span> dest_key <span class="token keyword">in</span> field_mapping<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> src_key <span class="token keyword">in</span> original_template<span class="token punctuation">:</span>
            value <span class="token operator">=</span> original_template<span class="token punctuation">[</span>src_key<span class="token punctuation">]</span>

            <span class="token comment"># 处理需要拆分的字段（如INSTRUCTION）</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dest_key<span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span> <span class="token keyword">and</span> src_key <span class="token operator">==</span> <span class="token string">"INSTRUCTION"</span><span class="token punctuation">:</span>
                <span class="token comment"># 使用正则拆分user和assistant部分</span>
                parts <span class="token operator">=</span> re<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">r'(&lt;\|im_start\|&gt;assistant\n?)'</span><span class="token punctuation">,</span> value<span class="token punctuation">)</span>
                converted<span class="token punctuation">[</span><span class="token string">"user"</span><span class="token punctuation">]</span> <span class="token operator">=</span> parts<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parts<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">:</span>
                    converted<span class="token punctuation">[</span><span class="token string">"assistant"</span><span class="token punctuation">]</span> <span class="token operator">=</span> parts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> parts<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>parts<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">2</span> <span class="token keyword">else</span> parts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

            <span class="token comment"># 处理直接映射字段</span>
            <span class="token keyword">elif</span> dest_key <span class="token keyword">and</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>dest_key<span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                converted<span class="token punctuation">[</span>dest_key<span class="token punctuation">]</span> <span class="token operator">=</span> value

    <span class="token comment"># 特殊处理system字段的占位符</span>
    <span class="token keyword">if</span> <span class="token string">"system"</span> <span class="token keyword">in</span> converted<span class="token punctuation">:</span>
        converted<span class="token punctuation">[</span><span class="token string">"system"</span><span class="token punctuation">]</span> <span class="token operator">=</span> converted<span class="token punctuation">[</span><span class="token string">"system"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"{system}"</span><span class="token punctuation">,</span> <span class="token string">"{{ system }}"</span><span class="token punctuation">)</span>

    <span class="token comment"># 处理用户输入占位符</span>
    <span class="token keyword">if</span> <span class="token string">"user"</span> <span class="token keyword">in</span> converted<span class="token punctuation">:</span>
        converted<span class="token punctuation">[</span><span class="token string">"user"</span><span class="token punctuation">]</span> <span class="token operator">=</span> converted<span class="token punctuation">[</span><span class="token string">"user"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">"{input}"</span><span class="token punctuation">,</span> <span class="token string">"{{ input }}"</span><span class="token punctuation">)</span>

    <span class="token comment"># 自动处理停止词（兼容列表和字符串）</span>
    <span class="token keyword">if</span> <span class="token string">"stop_words"</span> <span class="token keyword">in</span> converted <span class="token keyword">and</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>converted<span class="token punctuation">[</span><span class="token string">"stop_words"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        converted<span class="token punctuation">[</span><span class="token string">"stop_words"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>converted<span class="token punctuation">[</span><span class="token string">"stop_words"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

    <span class="token comment"># 保留原始模板中的额外字段（带警告）</span>
    <span class="token keyword">for</span> key <span class="token keyword">in</span> original_template<span class="token punctuation">:</span>
        <span class="token keyword">if</span> key <span class="token keyword">not</span> <span class="token keyword">in</span> field_mapping<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Warning: 发现未映射字段 [</span><span class="token interpolation"><span class="token punctuation">{</span>key<span class="token punctuation">}</span></span><span class="token string">]，已保留原样"</span></span><span class="token punctuation">)</span>
            converted<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> original_template<span class="token punctuation">[</span>key<span class="token punctuation">]</span>

    <span class="token keyword">return</span> converted


<span class="token comment"># 示例用法</span>
original_qwen_chat <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>
SYSTEM<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"&lt;|im_start|&gt;system\n{system}&lt;|im_end|&gt;\n"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  
INSTRUCTION<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">"&lt;|im_start|&gt;user\n{input}&lt;|im_end|&gt;\n"</span> <span class="token string">"&lt;|im_start|&gt;assistant\n"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
SUFFIX<span class="token operator">=</span><span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>  
SUFFIX_AS_EOS<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  
SEP<span class="token operator">=</span><span class="token string">"\n"</span><span class="token punctuation">,</span>  
STOP_WORDS<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span> <span class="token string">"&lt;|endoftext|&gt;"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token comment"># 执行转换</span>
converted_template <span class="token operator">=</span> universal_converter<span class="token punctuation">(</span>original_qwen_chat<span class="token punctuation">)</span>

<span class="token comment"># 生成JSON文件</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'chat_template.json'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>converted_template<span class="token punctuation">,</span> f<span class="token punctuation">,</span>
              indent<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>
              ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
              separators<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">': '</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>运行代码后生成的内容：</p>
<pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>
  <span class="token property">"meta_instruction"</span><span class="token operator">:</span> <span class="token string">"You are a helpful assistant."</span><span class="token punctuation">,</span>
  <span class="token property">"capability"</span><span class="token operator">:</span> <span class="token string">"chat"</span><span class="token punctuation">,</span>
  <span class="token property">"eosys"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>
  <span class="token property">"eoh"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>
  <span class="token property">"system"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;system\n{{ system }}&lt;|im_end|&gt;\n"</span><span class="token punctuation">,</span>
  <span class="token property">"user"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;user\n{{ input }}&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>
  <span class="token property">"assistant"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_start|&gt;assistant\n"</span><span class="token punctuation">,</span>
  <span class="token property">"eoa"</span><span class="token operator">:</span> <span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>
  <span class="token property">"separator"</span><span class="token operator">:</span> <span class="token string">"\n"</span><span class="token punctuation">,</span>
  <span class="token property">"stop_words"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token string">"&lt;|im_end|&gt;"</span><span class="token punctuation">,</span>
    <span class="token string">"&lt;|endoftext|&gt;"</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>进入LMDeploy环境，执行命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">lmdeploy serve api_server internlm/internlm2_5-7b-chat --chat-template <span class="token variable">${JSON_FILE}</span>

<span class="token comment"># 我本地命令</span>
lmdeploy serve api_server /home/moyuai/moyuai/xtuner_out/Qwen1-5-1-8B-Chat-xtuner-merged-7000 --chat-template /home/moyuai/moyuai/xtuner_out/chat_template.json
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>执行命令后如果出现以下内容，那么可以判断我们的自定义对话模板基本没有问题：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token punctuation">[</span>WARNING<span class="token punctuation">]</span> gemm_config.in is not found<span class="token punctuation">;</span> using default GEMM algo             
HINT:    Please <span class="token function">open</span> http://0.0.0.0:23333 <span class="token keyword">in</span> a browser <span class="token keyword">for</span> detailed api usage<span class="token operator">!</span><span class="token operator">!</span><span class="token operator">!</span>
HINT:    Please <span class="token function">open</span> http://0.0.0.0:23333 <span class="token keyword">in</span> a browser <span class="token keyword">for</span> detailed api usage<span class="token operator">!</span><span class="token operator">!</span><span class="token operator">!</span>
HINT:    Please <span class="token function">open</span> http://0.0.0.0:23333 <span class="token keyword">in</span> a browser <span class="token keyword">for</span> detailed api usage<span class="token operator">!</span><span class="token operator">!</span><span class="token operator">!</span>
INFO:     Started server process <span class="token punctuation">[</span><span class="token number">239994</span><span class="token punctuation">]</span>
INFO:     Waiting <span class="token keyword">for</span> application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:23333 <span class="token punctuation">(</span>Press CTRL+C to quit<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>在使用一个简单的openai对话模板调用一下我们的服务进行进一步测试，代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#多轮对话</span>
<span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI

<span class="token comment">#定义多轮对话方法</span>
<span class="token keyword">def</span> <span class="token function">run_chat_session</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#初始化客户端</span>
    client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>base_url<span class="token operator">=</span><span class="token string">"http://localhost:23333/v1/"</span><span class="token punctuation">,</span>api_key<span class="token operator">=</span><span class="token string">"ismoyuai"</span><span class="token punctuation">)</span>
    <span class="token comment">#初始化对话历史</span>
    chat_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token comment">#启动对话循环</span>
    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
        <span class="token comment">#获取用户输入</span>
        user_input <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"用户："</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> user_input<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"exit"</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"退出对话。"</span><span class="token punctuation">)</span>
            <span class="token keyword">break</span>
        <span class="token comment">#更新对话历史(添加用户输入)</span>
        chat_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span><span class="token string">"user"</span><span class="token punctuation">,</span><span class="token string">"content"</span><span class="token punctuation">:</span>user_input<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token comment">#调用模型回答</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            chat_complition <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
                messages<span class="token operator">=</span>chat_history<span class="token punctuation">,</span>
                model<span class="token operator">=</span><span class="token string">"/home/moyuai/moyuai/xtuner_out/Qwen1-5-1-8B-Chat-xtuner-merged-10000"</span>
                <span class="token punctuation">)</span>
            <span class="token comment">#获取最新回答</span>
            model_response <span class="token operator">=</span> chat_complition<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"AI:"</span><span class="token punctuation">,</span>model_response<span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
            <span class="token comment">#更新对话历史（添加AI模型的回复）</span>
            chat_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span><span class="token string">"assistant"</span><span class="token punctuation">,</span><span class="token string">"content"</span><span class="token punctuation">:</span>model_response<span class="token punctuation">.</span>message<span class="token punctuation">.</span>content<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"发生错误："</span><span class="token punctuation">,</span>e<span class="token punctuation">)</span>
            <span class="token keyword">break</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    run_chat_session<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>运行后我们输入问题，出现报错，后续发现是自定义对话模板有问题，因为我们不加载对话模板则，能够正常进行对话。</p>
<h3 id="6-2-模型测试评估"><a href="#6-2-模型测试评估" class="headerlink" title="6.2 模型测试评估"></a>6.2 模型测试评估</h3><p>下面我们不用自定义对话模板来进行模型效果测试，这里我们用一个叫<code>streamlit</code>的大模型前端框架来测试我们的模型效果。<br>安装<code>streamlit</code>包</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> streamlit<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>简单编写一个<code>streamlit</code>前端页面，新建一个<code>chat_app.py</code>文件，文件代码如下：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> streamlit <span class="token keyword">as</span> st
<span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI

<span class="token comment"># 初始化客户端</span>
client <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>base_url<span class="token operator">=</span><span class="token string">"http://localhost:23333/v1/"</span><span class="token punctuation">,</span> api_key<span class="token operator">=</span><span class="token string">"ismoyuai"</span><span class="token punctuation">)</span>

<span class="token comment"># 设置页面标题</span>
st<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"moyuai-Chat"</span><span class="token punctuation">)</span>
st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span><span class="token string">"## 这是一个基于Qwen-1.5-1.8B的情感聊天机器人"</span><span class="token punctuation">)</span>

<span class="token comment"># 初始化session状态（仅用于显示历史）</span>
<span class="token keyword">if</span> <span class="token string">"messages"</span> <span class="token keyword">not</span> <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">:</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment"># 显示历史消息</span>
<span class="token keyword">for</span> message <span class="token keyword">in</span> st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>messages<span class="token punctuation">:</span>
    <span class="token keyword">with</span> st<span class="token punctuation">.</span>chat_message<span class="token punctuation">(</span>message<span class="token punctuation">[</span><span class="token string">"role"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span>message<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 获取用户输入</span>
<span class="token keyword">if</span> prompt <span class="token operator">:=</span> st<span class="token punctuation">.</span>chat_input<span class="token punctuation">(</span><span class="token string">"请输入您的问题，或输入exit退出"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 处理退出命令</span>
    <span class="token keyword">if</span> prompt<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"exit"</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"退出对话。"</span><span class="token punctuation">)</span>
        st<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 添加用户消息到显示历史</span>
    st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> st<span class="token punctuation">.</span>chat_message<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span>

    <span class="token keyword">try</span><span class="token punctuation">:</span>
        <span class="token comment"># 发起API请求（每次只发送当前消息）</span>
        response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
            messages<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 每次只发送当前问题</span>
            model<span class="token operator">=</span><span class="token string">"/home/moyuai/moyuai/xtuner_out/Qwen1-5-1-8B-Chat-xtuner-merged-10000"</span>
        <span class="token punctuation">)</span>

        <span class="token comment"># 获取模型回复</span>
        model_response <span class="token operator">=</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content
        <span class="token comment"># 添加AI回复到显示历史</span>
        st<span class="token punctuation">.</span>session_state<span class="token punctuation">.</span>messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> model_response<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> st<span class="token punctuation">.</span>chat_message<span class="token punctuation">(</span><span class="token string">"assistant"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            st<span class="token punctuation">.</span>markdown<span class="token punctuation">(</span>model_response<span class="token punctuation">)</span>

    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>

        st<span class="token punctuation">.</span>error<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"发生错误：</span><span class="token interpolation"><span class="token punctuation">{</span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>启动<code>streamlit</code>前端服务，服务启动前一定要保证我们的LMDeploy服务是启动的：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">streamlit run chat_app.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>启动后界面如下：</p>
<p><img src="https://pic1.imgdb.cn/item/681f102258cb8da5c8eaec00.png" alt="streamlit前端页面"></p>
<p>我们进行问题测试：<br><img src="https://pic1.imgdb.cn/item/681f102258cb8da5c8eaebfd.png" alt="模型测试主观效果"></p>
<p>可以看到，我们模型训练生成的回答是按照我们的风格来的，说明模型训练有效果，但是我用同一个问题问了好几次，模型给我们的回答都是一样的，这说明模型训练的过拟合了，泛用性很差，这次训练也是以失败告结的，其实我在看训练日志时，发现到后面模型的loss值非常低，差不多后面一直在<code>0.0044</code>，这个loss值算比较低的了，就是快要过拟合的状态了；而在训练到差不多10000批次左右，模型就已经差不多是拟合状态了，但是由于我是在晚上挂机进行训练的，而在当初设置xtenur训练参数时，只选择保存最后两个训练权重，导致前面训练的权重不存在；所以只能后续在重新训练，在来看一下模型训练效果。</p>
<h3 id="6-3-模型测试评估-重新训练版"><a href="#6-3-模型测试评估-重新训练版" class="headerlink" title="6.3 模型测试评估(重新训练版)"></a>6.3 模型测试评估(重新训练版)</h3><p>重新训练后，在训练到6000<del>7000轮左右时，这时训练的loss值控制在了0.04</del>0.03左右，可以说是比较不错，所以就没有继续训练，这时我们将模型转换合并后，重新部署，下面就是重新测试对话效果的图片，看的出来模型这次对同一个问题没有出现完全一样的回答了，这次训练算是比较成功的了。</p>
<p><img src="https://pic1.imgdb.cn/item/681f3bf758cb8da5c8eb6cc9.png" alt="模型重新测试评估效果"></p>
<h2 id="七、总结"><a href="#七、总结" class="headerlink" title="七、总结"></a><strong>七、总结</strong></h2><p>1.项目成果总结<br>    本次项目总体来讲是成功的了，虽然还有不少地方可以完善，但也算是第一次完整的从0-1完成关于大模型微调项目的整个流程，这才是最重要的，特别是在做项目的过程中遇到的问题和解决问题的过程是最宝贵的经验。</p>
<p>2.挑战与解决方案回顾<br>    本次项目完成后在回顾，重要的点在于前期的数据收集部分，一份好的质量高的数据集是非常重要的，我在收集数据方面也是花了一些心思，这样在后续的数据生成过程中才能有一个好的前提。<br>    项目过程中遇到的问题其实其他的都还好，主要花时间多一点的地方就是在于一些框架的环境配置方面，需要特别注意一些依赖包的版本，不太适合太新的版本。<br>    还有一个就是最后模型部署方面，在自定义对话模板这里遇到的问题一直没有解决，虽然最后达到的效果是好的，后续<br>3. 未来方向（语言播放，集成开发板）<br>	这个项目本来就是根据抖音最近比较火的小智机器人想做的，后续可能就是在对话大模型结合语音方面已经部署到 开发板上面来进行研究，这也算是我可能可以做到的，因为自己大学专业学的就是单片机嵌入式开发等等，有软硬结合的底子在，我个人也是比较有需求的。</p>
<h2 id="八、附录与参考资料"><a href="#八、附录与参考资料" class="headerlink" title="八、附录与参考资料"></a><strong>八、附录与参考资料</strong></h2><p>1.代码仓库与工具链</p>
<ul>
<li>项目GitHub仓库：</li>
<li>智谱清言API：<a target="_blank" rel="noopener" href="https://www.bigmodel.cn/console/overview">https://www.bigmodel.cn/console/overview</a></li>
<li>XTuner 中文文档：<a target="_blank" rel="noopener" href="https://xtuner.readthedocs.io/zh-cn/latest/index.html">https://xtuner.readthedocs.io/zh-cn/latest/index.html</a></li>
<li>OpenCompass 中文教程：<a target="_blank" rel="noopener" href="https://doc.opencompass.org.cn/zh_CN/">https://doc.opencompass.org.cn/zh_CN/</a></li>
<li>LMDeploy 中文教程：<a target="_blank" rel="noopener" href="https://lmdeploy.readthedocs.io/zh-cn/latest/index.html">https://lmdeploy.readthedocs.io/zh-cn/latest/index.html</a></li>
</ul>
<p>2.数据集链接</p>
<ul>
<li>CDial-GPT：<a target="_blank" rel="noopener" href="https://github.com/corpus-dataset/CDial-GPT">https://github.com/corpus-dataset/CDial-GPT</a></li>
</ul>
<h2 id="九、问题记录"><a href="#九、问题记录" class="headerlink" title="九、问题记录"></a><strong>九、问题记录</strong></h2><h3 id="1-报settings-yaml配置文件找不到"><a href="#1-报settings-yaml配置文件找不到" class="headerlink" title="1.报settings.yaml配置文件找不到"></a>1.报settings.yaml配置文件找不到</h3><p>报错信息：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">配置文件缺失：[Errno 2] No such file or directory: 'E:\\xuexiziliao\\AiProject\\emotion_dialogue_tuner\\src\\config\\settings.yaml'<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>解决方法：<br>是因为在<code>config_loader.py</code>文件中,路径层级少配置一层</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 修改前</span>
self<span class="token punctuation">.</span>root_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">.</span>resolve<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent

<span class="token comment"># 修改后</span>
self<span class="token punctuation">.</span>root_path <span class="token operator">=</span> Path<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token punctuation">.</span>resolve<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent<span class="token punctuation">.</span>parent  <span class="token comment"># 根据实际层级调整</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-文件编码格式加载不正确"><a href="#2-文件编码格式加载不正确" class="headerlink" title="2.文件编码格式加载不正确"></a>2.文件编码格式加载不正确</h3><p>报错信息：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">UnicodeDecodeError: 'gbk' codec can't decode byte 0xa6 in position 94: illegal multibyte sequence<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>解决方法：<br>报错原因是因为在<code>config_loader.py</code>文件中的<code>load_settings</code>方法没有指定<code>yaml</code>文件的打开格式。在修改所有文件读取操作，添加<code>encoding='utf-8'</code>参数即可：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 修改前代码</span>
<span class="token keyword">def</span> <span class="token function">load_settings</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""加载YAML格式的全局设置  
    Returns:        dict: 包含API密钥、模型路径等配置的字典  
    """</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_path <span class="token operator">/</span> <span class="token string">"config/settings.yaml"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>  
        <span class="token keyword">return</span> yaml<span class="token punctuation">.</span>safe_load<span class="token punctuation">(</span>f<span class="token punctuation">)</span>

<span class="token comment"># 修改后代码</span>
<span class="token keyword">def</span> <span class="token function">load_settings</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">dict</span><span class="token punctuation">:</span>  
    <span class="token triple-quoted-string string">"""加载YAML格式的全局设置  
    Returns:        dict: 包含API密钥、模型路径等配置的字典  
    """</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_path <span class="token operator">/</span> <span class="token string">"config/settings.yaml"</span><span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>  
        <span class="token keyword">return</span> yaml<span class="token punctuation">.</span>safe_load<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-生成的数据有些是完全一样的"><a href="#3-生成的数据有些是完全一样的" class="headerlink" title="3.生成的数据有些是完全一样的"></a>3.生成的数据有些是完全一样的</h3><p>查看生成数据时，发现有些数据是完全一样的，出现了重复，这就导致了数据质量不高。</p>
<p>解决方法：可以自己测试调整判断阈值，或者重新添加新的规则来判断去重。</p>
<h3 id="4-使用Xtuner进行模型qlora模型微调的时候，报错-No-module-named-‘triton-ops’"><a href="#4-使用Xtuner进行模型qlora模型微调的时候，报错-No-module-named-‘triton-ops’" class="headerlink" title="4.使用Xtuner进行模型qlora模型微调的时候，报错 No module named ‘triton.ops’"></a>4.使用Xtuner进行模型qlora模型微调的时候，报错 No module named ‘triton.ops’</h3><p>执行命令：</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">xtuner train qwen1_5_1_8b_chat_qlora_alpaca_e3.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>问题记录：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/moyuai/moyuai/xtuner/xtuner/tools/train.py", line 392, in &lt;module&gt;
    main()
  File "/home/moyuai/moyuai/xtuner/xtuner/tools/train.py", line 381, in main
    runner = Runner.from_cfg(cfg)
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/runner/runner.py", line 462, in from_cfg
    runner = cls(
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/runner/runner.py", line 429, in __init__
    self.model = self.build_model(model)
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/runner/runner.py", line 836, in build_model
    model = MODELS.build(model)
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/registry/registry.py", line 570, in build
    return self.build_func(cfg, *args, **kwargs, registry=self)
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 234, in build_model_from_cfg
    return build_from_cfg(cfg, registry, default_args)
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 123, in build_from_cfg
    obj = obj_cls(**args)  # type: ignore
  File "/home/moyuai/moyuai/xtuner/xtuner/model/sft.py", line 97, in __init__
    self.llm = self.build_llm_from_cfg(
  File "/home/moyuai/moyuai/xtuner/xtuner/model/sft.py", line 143, in build_llm_from_cfg
    llm = self._build_from_cfg_or_module(llm)
  File "/home/moyuai/moyuai/xtuner/xtuner/model/sft.py", line 296, in _build_from_cfg_or_module
    return BUILDER.build(cfg_or_mod)
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/registry/registry.py", line 570, in build
    return self.build_func(cfg, *args, **kwargs, registry=self)
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 123, in build_from_cfg
    obj = obj_cls(**args)  # type: ignore
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3620, in from_pretrained
    hf_quantizer.validate_environment(
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/transformers/quantizers/quantizer_bnb_8bit.py", line 77, in validate_environment
    from ..integrations import validate_bnb_backend_availability
  File "&lt;frozen importlib._bootstrap&gt;", line 1075, in _handle_fromlist
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1805, in __getattr__
    module = self._get_module(self._class_to_module[name])
  File "/home/moyuai/anaconda3/envs/xtuner_env/lib/python3.10/site-packages/transformers/utils/import_utils.py", line 1819, in _get_module
    raise RuntimeError(
RuntimeError: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):
No module named 'triton.ops'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>问题分析：<br>这是在尝试使用&nbsp;<strong>BitsAndBytes（8-bit 量化）</strong>&nbsp;加载模型时发生的，我们查看一下&nbsp;<code>bitsandbytes</code>&nbsp;库是否正确安装。</p>
<p>可能是版本不对，试着重装一下后还是报错，最后查找资料发现是torch2.6以上版本和bitstandbytes版本的冲突问题。</p>
<p>安装<strong>低版本</strong>的<code>pytorch==2.5.1</code> 和<code>torchvision==0.20.1</code> ，我们进入xtuner目录 下的这个 <code>xtuner/requirements/runtime.txt</code>文件里面修改一下torch版本</p>
<p><img src="https://pic1.imgdb.cn/item/681e229258cb8da5c8e9fe1e.png" alt="修改环境"></p>
<p>修改过后还是有问题，这次报错信息如下：</p>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">Traceback (most recent call last): File "/home/moyuai/anaconda3/envs/xtuner-env/bin/xtuner", line 33, in &lt;module&gt; sys.exit(load_entry_point('xtuner', 'console_scripts', 'xtuner')()) File "/home/moyuai/anaconda3/envs/xtuner-env/bin/xtuner", line 25, in importlib_load_entry_point return next(matches).load() File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/importlib/metadata/__init__.py", line 171, in load module = import_module(match.group('module')) File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/importlib/__init__.py", line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File "&lt;frozen importlib._bootstrap&gt;", line 1050, in _gcd_import File "&lt;frozen importlib._bootstrap&gt;", line 1027, in _find_and_load File "&lt;frozen importlib._bootstrap&gt;", line 1006, in _find_and_load_unlocked File "&lt;frozen importlib._bootstrap&gt;", line 688, in _load_unlocked File "&lt;frozen importlib._bootstrap_external&gt;", line 883, in exec_module File "&lt;frozen importlib._bootstrap&gt;", line 241, in _call_with_frames_removed File "/home/moyuai/moyuai/xtuner/xtuner/__init__.py", line 4, in &lt;module&gt; from mmengine.utils import digit_version File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/__init__.py", line 6, in &lt;module&gt; from .registry import * File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/__init__.py", line 2, in &lt;module&gt; from .build_functions import (build_from_cfg, build_model_from_cfg, File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/mmengine/registry/build_functions.py", line 6, in &lt;module&gt; import torch File "/home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/__init__.py", line 367, in &lt;module&gt; from torch._C import * # noqa: F403 ImportError: /home/moyuai/anaconda3/envs/xtuner-env/lib/python3.10/site-packages/torch/lib/../../nvidia/cusparse/lib/libcusparse.so.12: undefined symbol: __nvJitLinkComplete_12_4, version libnvJitLink.so.12<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>推测还是因为<code>torch</code>版本和<code>CUDA</code>版本导致的，这次重新将<code>torch</code>版本和<code>CUDA</code>版本进行修改，进行如下操作</p>
<h4 id="1-完全卸载当前PyTorch和CUDA工具链"><a href="#1-完全卸载当前PyTorch和CUDA工具链" class="headerlink" title="(1)完全卸载当前PyTorch和CUDA工具链"></a><strong>(1)完全卸载当前PyTorch和CUDA工具链</strong></h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment"># 删除conda环境（确保已退出环境）</span>
conda deactivate
conda remove <span class="token parameter variable">-n</span> xtuner-env <span class="token parameter variable">--all</span> <span class="token parameter variable">-y</span>

<span class="token comment"># 清除残留的CUDA软链接</span>
<span class="token function">sudo</span> <span class="token function">rm</span> <span class="token parameter variable">-f</span> /usr/local/cuda<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="2-安装匹配的CUDA-12-1工具包"><a href="#2-安装匹配的CUDA-12-1工具包" class="headerlink" title="(2)安装匹配的CUDA 12.1工具包"></a><strong>(2)安装匹配的CUDA 12.1工具包</strong></h4><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token comment">### **安装匹配的CUDA 12.1工具包**</span>
<span class="token comment"># 从NVIDIA官网下载CUDA 12.1.1</span>
<span class="token function">wget</span> https://developer.download.nvidia.com/compute/cuda/12.1.1/local_installers/cuda_12.1.1_530.30.02_linux.run
<span class="token function">sudo</span> <span class="token function">sh</span> cuda_12.1.1_530.30.02_linux.run <span class="token parameter variable">--override</span>

<span class="token comment"># 配置环境变量</span>
<span class="token builtin class-name">echo</span> <span class="token string">'export PATH=/usr/local/cuda-12.1/bin:$PATH'</span> <span class="token operator">&gt;&gt;</span> ~/.bashrc
<span class="token builtin class-name">echo</span> <span class="token string">'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH'</span> <span class="token operator">&gt;&gt;</span> ~/.bashrc
<span class="token builtin class-name">source</span> ~/.bashrc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="3-创建全新的虚拟环境并安装PyTorch-2-2-0"><a href="#3-创建全新的虚拟环境并安装PyTorch-2-2-0" class="headerlink" title="(3)创建全新的虚拟环境并安装PyTorch 2.2.0"></a>(3)创建全新的虚拟环境并安装PyTorch 2.2.0</h4><p>这里我们记得到xtuner目录下的 <code>xtuner/requirements/runtime.txt</code>文件里面重新修改一下torch版本，版本和下面要安装的命令里面的版本保持一致。<code>PyTorch 2.2.0 + CUDA 12.1</code></p>
<p><img src="https://pic1.imgdb.cn/item/681e9b6158cb8da5c8ea15aa.png" alt="重新指定torch版本"></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">conda create <span class="token parameter variable">-n</span> xtuner-env <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.10</span> <span class="token parameter variable">-y</span>
conda activate xtuner-env

<span class="token comment"># 安装PyTorch 2.2.0 + CUDA 12.1</span>
pip <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">2.2</span>.0+cu121 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.17</span>.0+cu121 --extra-index-url https://download.pytorch.org/whl/cu121

<span class="token comment"># 重新安装xtuner所需依赖</span>
<span class="token builtin class-name">cd</span> xtuner
pip <span class="token function">install</span> <span class="token parameter variable">-e</span> <span class="token string">'.[all]'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>最后重新运行训练命令，能够正常进行训练</p>
<h3 id="5-发生错误：-‘NoneType’-object-is-not-subscriptable"><a href="#5-发生错误：-‘NoneType’-object-is-not-subscriptable" class="headerlink" title="5. 发生错误： ‘NoneType’ object is not subscriptable"></a>5. 发生错误： ‘NoneType’ object is not subscriptable</h3><p>这个问题是在LMDeploy导入自定义对话模板时启动openai对话服务后，进行对话时出现的错误。<br>后面不进行自定义对话模板导入而是直接用LMDeploy启动我们训练的模型后可以正常回答，推测应该是自定义对话模板有问题</p>
<p><strong>更多实用文章和AI大模型应用开发文章欢迎到我个人博客来观看：</strong><a target="_blank" rel="noopener" href="https://blog.csdn.net/etrospect/article/details/blog.ismoyu.cn">墨宇Logic</a></p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">墨宇Logic</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://ismoyuai.github.io/xiang-mu-shi-zhan-da-mo-xing-wei-diao-qing-xu-dui-hua-mo-xing/">https://ismoyuai.github.io/xiang-mu-shi-zhan-da-mo-xing-wei-diao-qing-xu-dui-hua-mo-xing/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">墨宇Logic</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/Markdown/">
                                    <span class="chip bg-color">Markdown</span>
                                </a>
                            
                                <a href="/tags/Python/">
                                    <span class="chip bg-color">Python</span>
                                </a>
                            
                                <a href="/tags/Linux/">
                                    <span class="chip bg-color">Linux</span>
                                </a>
                            
                                <a href="/tags/LLaMA-Factory/">
                                    <span class="chip bg-color">LLaMA-Factory</span>
                                </a>
                            
                                <a href="/tags/Embeddings/">
                                    <span class="chip bg-color">Embeddings</span>
                                </a>
                            
                                <a href="/tags/LLM/">
                                    <span class="chip bg-color">LLM</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-windows11-xi-tong-ben-di-bu-shu-dify-bing-gou-jian-rag-xi-tong-fang-an/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/18.jpg" class="responsive-img" alt="【AI大模型应用学习笔记】Windows11系统本地部署Dify并构建RAG系统方案">
                        
                        <span class="card-title">【AI大模型应用学习笔记】Windows11系统本地部署Dify并构建RAG系统方案</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            在Windows环境下进行本地部署Dify方案，包括Desktop环境安装，以及一键部署Dify，然后用Dify构建RAG系统的案例
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-05-12
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/" class="post-category">
                                    AI大模型应用开发
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                    <a href="/tags/RAG/">
                        <span class="chip bg-color">RAG</span>
                    </a>
                    
                    <a href="/tags/Dify/">
                        <span class="chip bg-color">Dify</span>
                    </a>
                    
                    <a href="/tags/Agent/">
                        <span class="chip bg-color">Agent</span>
                    </a>
                    
                    <a href="/tags/AI/">
                        <span class="chip bg-color">AI</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/ai-da-mo-xing-ying-yong-xue-xi-bi-ji-ji-yu-llamaindex-shi-xian-rag/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/7.png" class="responsive-img" alt="【AI大模型应用学习笔记】基于LlamaIndex实现RAG">
                        
                        <span class="card-title">【AI大模型应用学习笔记】基于LlamaIndex实现RAG</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            介绍LlamaIndex核心组件，以及使用LlamaIndex简单实现RAG系统
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-05-02
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/AI%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/" class="post-category">
                                    AI大模型应用开发
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Python/">
                        <span class="chip bg-color">Python</span>
                    </a>
                    
                    <a href="/tags/vllm/">
                        <span class="chip bg-color">vllm</span>
                    </a>
                    
                    <a href="/tags/RAG/">
                        <span class="chip bg-color">RAG</span>
                    </a>
                    
                    <a href="/tags/LlamaIndex/">
                        <span class="chip bg-color">LlamaIndex</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE' || selection.getRangeAt(0).commonAncestorContainer.nodeName === 'CODE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: 墨宇Logic<br />'
            + '文章作者: 墨宇Logic<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    

    <div class="container row center-align"
         style="margin-bottom: 15px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">墨宇Logic</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
                <span id="translate">|&nbsp;繁/简：</span><a id="translateLink" href="javascript:translatePage();">繁</a>
            
            <br>
            
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                        class="white-color">49.5k</span>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2025";
                        var startMonth = "4";
                        var startDate = "10";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'zh-CN';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/isMoyuAI" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:loushuaicn@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2542345108" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2542345108" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>









    <a href="https://space.bilibili.com/347413381" class="tooltipped" target="_blank" data-tooltip="关注我的bilbil" data-position="top" data-delay="50">
        <i class="fa-brands fa-bilibili"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
        <script type="text/javascript" src="/js/tw_cn.js"></script>
        <script type="text/javascript">
          var defaultEncoding = 2; //网站编写字体是否繁体，1-繁体，2-简体
          var translateDelay = 0; //延迟时间,若不在前, 要设定延迟翻译时间, 如100表示100ms,默认为0
          var cookieDomain = "https://ismoyuai.github.io"; //Cookie地址, 一定要设定, 通常为你的网址
          var msgToTraditionalChinese = "繁"; //此处可以更改为你想要显示的文字
          var msgToSimplifiedChinese = "简"; //同上，但两处均不建议更改
          var translateButtonId = "translateLink"; //默认互换id
          translateInitilization();
        </script>
    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
